Deblobbed ctx_progs, ctxprogs and ctxvals.  The latter might very well
be just data, but since we're deblobbing other stuff that renders the
rest unusable, why take risks?

diff --git a/drivers/gpu/drm/Kconfig b/drivers/gpu/drm/Kconfig
index a74980b..36582ff 100644
--- a/drivers/gpu/drm/Kconfig
+++ b/drivers/gpu/drm/Kconfig
@@ -133,3 +133,18 @@ config DRM_SAVAGE
 	help
 	  Choose this option if you have a Savage3D/4/SuperSavage/Pro/Twister
 	  chipset. If M is selected the module will be called savage.
+
+config DRM_NOUVEAU
+	tristate "Nouveau (nVidia) cards"
+	depends on DRM
+	help
+	  Choose this option for open-source nVidia support.
+
+config DRM_NOUVEAU_KMS
+	bool "Enable modesetting on nouveau by default"
+	depends on DRM_NOUVEAU
+	help
+	Choose this option if you want kernel modesetting enabled by default,
+	and you have a new enough userspace to support this. Running old
+	userspaces with this enabled will cause pain.
+
diff --git a/drivers/gpu/drm/Makefile b/drivers/gpu/drm/Makefile
index d6788df..97aa0c8 100644
--- a/drivers/gpu/drm/Makefile
+++ b/drivers/gpu/drm/Makefile
@@ -27,4 +27,5 @@ obj-$(CONFIG_DRM_I915)  += i915/
 obj-$(CONFIG_DRM_SIS)   += sis/
 obj-$(CONFIG_DRM_SAVAGE)+= savage/
 obj-$(CONFIG_DRM_VIA)	+=via/
+obj-$(CONFIG_DRM_NOUVEAU) +=nouveau/
 
diff --git a/drivers/gpu/drm/drm_bufs.c b/drivers/gpu/drm/drm_bufs.c
index 4d2161f..ac503e2 100644
--- a/drivers/gpu/drm/drm_bufs.c
+++ b/drivers/gpu/drm/drm_bufs.c
@@ -51,38 +51,24 @@ resource_size_t drm_get_resource_len(struct drm_device *dev, unsigned int resour
 
 EXPORT_SYMBOL(drm_get_resource_len);
 
-static struct drm_map_list *drm_find_matching_map(struct drm_device *dev,
-						  struct drm_local_map *map)
+struct drm_map_list *drm_find_matching_map(struct drm_device *dev,
+					   struct drm_local_map *map)
 {
 	struct drm_map_list *entry;
 	list_for_each_entry(entry, &dev->maplist, head) {
-		/*
-		 * Because the kernel-userspace ABI is fixed at a 32-bit offset
-		 * while PCI resources may live above that, we ignore the map
-		 * offset for maps of type _DRM_FRAMEBUFFER or _DRM_REGISTERS.
-		 * It is assumed that each driver will have only one resource of
-		 * each type.
-		 */
 		if (!entry->map ||
 		    map->type != entry->map->type ||
 		    entry->master != dev->primary->master)
 			continue;
-		switch (map->type) {
-		case _DRM_SHM:
-			if (map->flags != _DRM_CONTAINS_LOCK)
-				break;
-		case _DRM_REGISTERS:
-		case _DRM_FRAME_BUFFER:
-			return entry;
-		default: /* Make gcc happy */
-			;
-		}
-		if (entry->map->offset == map->offset)
+
+		if (entry->map->offset == map->offset ||
+		    (map->type == _DRM_SHM && map->flags & _DRM_CONTAINS_LOCK))
 			return entry;
 	}
 
 	return NULL;
 }
+EXPORT_SYMBOL(drm_find_matching_map);
 
 static int drm_map_handle(struct drm_device *dev, struct drm_hash_item *hash,
 			  unsigned long user_token, int hashed_handle, int shm)
@@ -349,7 +335,7 @@ static int drm_addmap_core(struct drm_device * dev, resource_size_t offset,
 	/* We do it here so that dev->struct_mutex protects the increment */
 	user_token = (map->type == _DRM_SHM) ? (unsigned long)map->handle :
 		map->offset;
-	ret = drm_map_handle(dev, &list->hash, user_token, 0,
+	ret = drm_map_handle(dev, &list->hash, user_token, 1,
 			     (map->type == _DRM_SHM));
 	if (ret) {
 		if (map->type == _DRM_REGISTERS)
diff --git a/drivers/gpu/drm/drm_fence.c b/drivers/gpu/drm/drm_fence.c
index f1c386c..fd62fd9 100644
--- a/drivers/gpu/drm/drm_fence.c
+++ b/drivers/gpu/drm/drm_fence.c
@@ -369,7 +369,7 @@ int drm_fence_object_wait(struct drm_fence_object *fence,
 	struct drm_fence_manager *fm = &dev->fm;
 	struct drm_fence_class_manager *fc = &fm->fence_class[fence->fence_class];
 	int ret = 0;
-	unsigned long _end = 3 * DRM_HZ;
+	unsigned long _end = jiffies + 3 * DRM_HZ;
 
 	if (mask & ~fence->type) {
 		DRM_ERROR("Wait trying to extend fence type"
diff --git a/drivers/gpu/drm/drm_gem.c b/drivers/gpu/drm/drm_gem.c
index 4984aa8..dee9b40 100644
--- a/drivers/gpu/drm/drm_gem.c
+++ b/drivers/gpu/drm/drm_gem.c
@@ -280,48 +280,58 @@ drm_gem_close_ioctl(struct drm_device *dev, void *data,
  * is freed, the name goes away.
  */
 int
-drm_gem_flink_ioctl(struct drm_device *dev, void *data,
-		    struct drm_file *file_priv)
+drm_gem_object_name(struct drm_device *dev, struct drm_gem_object *obj,
+		    uint64_t *name)
 {
-	struct drm_gem_flink *args = data;
-	struct drm_gem_object *obj;
 	int ret;
 
-	if (!(dev->driver->driver_features & DRIVER_GEM))
-		return -ENODEV;
-
-	obj = drm_gem_object_lookup(dev, file_priv, args->handle);
-	if (obj == NULL)
-		return -EBADF;
-
 again:
-	if (idr_pre_get(&dev->object_name_idr, GFP_KERNEL) == 0) {
-		ret = -ENOMEM;
-		goto err;
-	}
+	if (idr_pre_get(&dev->object_name_idr, GFP_KERNEL) == 0)
+		return -ENOMEM;
 
 	spin_lock(&dev->object_name_lock);
 	if (!obj->name) {
 		ret = idr_get_new_above(&dev->object_name_idr, obj, 1,
 					&obj->name);
-		args->name = (uint64_t) obj->name;
+		*name = (uint64_t) obj->name;
 		spin_unlock(&dev->object_name_lock);
 
 		if (ret == -EAGAIN)
 			goto again;
 
 		if (ret != 0)
-			goto err;
+			return ret;
 
 		/* Allocate a reference for the name table.  */
 		drm_gem_object_reference(obj);
 	} else {
-		args->name = (uint64_t) obj->name;
+		*name = (uint64_t) obj->name;
 		spin_unlock(&dev->object_name_lock);
-		ret = 0;
 	}
 
-err:
+	return 0;
+}
+EXPORT_SYMBOL(drm_gem_object_name);
+
+int
+drm_gem_flink_ioctl(struct drm_device *dev, void *data,
+		    struct drm_file *file_priv)
+{
+	struct drm_gem_flink *args = data;
+	struct drm_gem_object *obj;
+	uint64_t name;
+	int ret;
+
+	if (!(dev->driver->driver_features & DRIVER_GEM))
+		return -ENODEV;
+
+	obj = drm_gem_object_lookup(dev, file_priv, args->handle);
+	if (obj == NULL)
+		return -EBADF;
+
+	ret = drm_gem_object_name(dev, obj, &name);
+	args->name = name;
+
 	mutex_lock(&dev->struct_mutex);
 	drm_gem_object_unreference(obj);
 	mutex_unlock(&dev->struct_mutex);
diff --git a/drivers/gpu/drm/nouveau/Makefile b/drivers/gpu/drm/nouveau/Makefile
new file mode 100644
index 0000000..06483d0
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/Makefile
@@ -0,0 +1,24 @@
+#
+# Makefile for the drm device driver.  This driver provides support for the
+# Direct Rendering Infrastructure (DRI) in XFree86 4.1.0 and higher.
+
+ccflags-y := -Iinclude/drm
+nouveau-y := nouveau_drv.o nouveau_state.o nouveau_fifo.o nouveau_mem.o \
+             nouveau_object.o nouveau_irq.o nouveau_notifier.o \
+             nouveau_swmthd.o nouveau_sgdma.o nouveau_dma.o \
+             nouveau_bo.o nouveau_fence.o nouveau_gem.o \
+             nouveau_hw.o nouveau_calc.o nouveau_bios.o nouveau_i2c.o \
+	     nouveau_display.o nouveau_fbcon.o nouveau_backlight.o \
+             nv04_timer.o \
+             nv04_mc.o nv40_mc.o nv50_mc.o \
+             nv04_fb.o nv10_fb.o nv40_fb.o \
+             nv04_fifo.o nv10_fifo.o nv40_fifo.o nv50_fifo.o \
+             nv04_graph.o nv10_graph.o nv20_graph.o \
+             nv40_graph.o nv50_graph.o \
+             nv04_instmem.o nv50_instmem.o \
+             nv50_crtc.o nv50_dac.o nv50_sor.o nv50_connector.o \
+             nv50_cursor.o nv50_display.o nv50_fbcon.o
+
+nouveau-$(CONFIG_COMPAT) += nouveau_ioc32.o
+
+obj-$(CONFIG_DRM_NOUVEAU)+= nouveau.o
diff --git a/drivers/gpu/drm/nouveau/nouveau_backlight.c b/drivers/gpu/drm/nouveau/nouveau_backlight.c
new file mode 100644
index 0000000..e3d354f
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_backlight.c
@@ -0,0 +1,152 @@
+/*
+ * Copyright (C) 2009 Red Hat <mjg@redhat.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/*
+ * Authors:
+ *  Matthew Garrett <mjg@redhat.com>
+ *
+ * Register locations derived from NVClock by Roderick Colenbrander
+ */
+
+#include <linux/backlight.h>
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+#include "nouveau_reg.h"
+
+static int nv40_get_intensity(struct backlight_device *bd)
+{
+	struct drm_device *dev = bl_get_data(bd);
+	int val = (nv_rd32(NV40_PMC_BACKLIGHT) & NV40_PMC_BACKLIGHT_MASK) >> 16;
+
+	return val;
+}
+
+static int nv40_set_intensity(struct backlight_device *bd)
+{
+	struct drm_device *dev = bl_get_data(bd);
+	int val = bd->props.brightness;
+	int reg = nv_rd32(NV40_PMC_BACKLIGHT);
+
+	nv_wr32(NV40_PMC_BACKLIGHT,
+		 (val << 16) | (reg & ~NV40_PMC_BACKLIGHT_MASK));
+
+	return 0;
+}
+
+static struct backlight_ops nv40_bl_ops = {
+	.options = BL_CORE_SUSPENDRESUME,
+	.get_brightness = nv40_get_intensity,
+	.update_status = nv40_set_intensity,
+};
+
+static int nv50_get_intensity(struct backlight_device *bd)
+{
+	struct drm_device *dev = bl_get_data(bd);
+
+	return nv_rd32(NV50_PDISPLAY_BACKLIGHT);
+}
+
+static int nv50_set_intensity(struct backlight_device *bd)
+{
+	struct drm_device *dev = bl_get_data(bd);
+	int val = bd->props.brightness;
+
+	nv_wr32(NV50_PDISPLAY_BACKLIGHT, val | NV50_PDISPLAY_BACKLIGHT_ENABLE);
+
+	return 0;
+}
+
+static struct backlight_ops nv50_bl_ops = {
+	.options = BL_CORE_SUSPENDRESUME,
+	.get_brightness = nv50_get_intensity,
+	.update_status = nv50_set_intensity,
+};
+
+static int nouveau_nv40_backlight_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct backlight_device *bd;
+	
+	if (!(nv_rd32(NV40_PMC_BACKLIGHT) & NV40_PMC_BACKLIGHT_MASK))
+		return 0;
+
+	bd = backlight_device_register("nv_backlight", &dev->pdev->dev, dev,
+				       &nv40_bl_ops);
+	if (IS_ERR(bd))
+		return PTR_ERR(bd);
+
+	dev_priv->backlight = bd;
+	bd->props.max_brightness = 31;
+	bd->props.brightness = nv40_get_intensity(bd);
+	backlight_update_status(bd);
+
+	return 0;
+}
+
+static int nouveau_nv50_backlight_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct backlight_device *bd;
+
+	if (!nv_rd32(NV50_PDISPLAY_BACKLIGHT))
+		return 0;
+
+	bd = backlight_device_register("nv_backlight", &dev->pdev->dev, dev,
+				       &nv50_bl_ops);
+	if (IS_ERR(bd))
+		return PTR_ERR(bd);
+
+	dev_priv->backlight = bd;
+	bd->props.max_brightness = 1025;
+	bd->props.brightness = nv50_get_intensity(bd);
+	backlight_update_status(bd);
+	return 0;
+}
+
+int nouveau_backlight_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	switch (dev_priv->card_type) {
+	case NV_40:
+	case NV_44:
+		return nouveau_nv40_backlight_init(dev);
+		break;
+	case NV_50:
+		return nouveau_nv50_backlight_init(dev);
+		break;
+	}
+	return 0;
+}
+
+void nouveau_backlight_exit(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->backlight)
+		backlight_device_unregister(dev_priv->backlight);
+}	
diff --git a/drivers/gpu/drm/nouveau/nouveau_bios.c b/drivers/gpu/drm/nouveau/nouveau_bios.c
new file mode 100644
index 0000000..b90beab
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_bios.c
@@ -0,0 +1,4828 @@
+/*
+ * Copyright 2005-2006 Erik Waling
+ * Copyright 2006 Stephane Marchesin
+ * Copyright 2007-2009 Stuart Bennett
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF
+ * OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_hw.h"
+
+/* these defines are made up */
+#define NV_CIO_CRE_44_HEADA 0x0
+#define NV_CIO_CRE_44_HEADB 0x3
+#define FEATURE_MOBILE 0x10	/* also FEATURE_QUADRO for BMP */
+#define LEGACY_I2C_CRT 0x80
+#define LEGACY_I2C_PANEL 0x81
+
+#define EDID1_LEN 128
+
+#define BIOSLOG(sip, fmt, arg...) NV_DEBUG(sip, fmt, ##arg)
+#define LOG_OLD_VALUE(x) //x
+
+#define BIOS_USLEEP(n) msleep((n)/1000)
+
+#define ROM16(x) le16_to_cpu(*(uint16_t *)&(x))
+#define ROM32(x) le32_to_cpu(*(uint32_t *)&(x))
+
+static int crtchead = 0;
+
+/* this will need remembering across a suspend */
+static uint32_t saved_nv_pfb_cfg0;
+
+typedef struct {
+	bool execute;
+	bool repeat;
+} init_exec_t;
+
+static bool nv_cksum(const uint8_t *data, unsigned int length)
+{
+	/* there's a few checksums in the BIOS, so here's a generic checking function */
+	int i;
+	uint8_t sum = 0;
+
+	for (i = 0; i < length; i++)
+		sum += data[i];
+
+	if (sum)
+		return true;
+
+	return false;
+}
+
+static int
+score_vbios(struct drm_device *dev, const uint8_t *data, const bool writeable)
+{
+	if (!(data[0] == 0x55 && data[1] == 0xAA)) {
+		NV_TRACEWARN(dev, "... BIOS signature not found\n");
+		return 0;
+	}
+
+	if (nv_cksum(data, data[2] * 512)) {
+		NV_TRACEWARN(dev, "... BIOS checksum invalid\n");
+		/* if a ro image is somewhat bad, it's probably all rubbish */
+		return writeable ? 2 : 1;
+	} else
+		NV_TRACE(dev, "... appears to be valid\n");
+
+	return 3;
+}
+
+static void load_vbios_prom(struct drm_device *dev, uint8_t *data)
+{
+	uint32_t pci_nv_20, save_pci_nv_20;
+	int pcir_ptr;
+	int i;
+
+	if (nv_arch(dev) >= NV_50)
+		pci_nv_20 = 0x88050;
+	else
+		pci_nv_20 = NV_PBUS_PCI_NV_20;
+
+	/* enable ROM access */
+	save_pci_nv_20 = nvReadMC(dev, pci_nv_20);
+	nvWriteMC(dev, pci_nv_20,
+		  save_pci_nv_20 & ~NV_PBUS_PCI_NV_20_ROM_SHADOW_ENABLED);
+
+	/* bail if no rom signature */
+	if (nv_rd08(NV_PROM_OFFSET) != 0x55 ||
+	    nv_rd08(NV_PROM_OFFSET + 1) != 0xaa)
+		goto out;
+
+	/* additional check (see note below) - read PCI record header */
+	pcir_ptr = nv_rd08(NV_PROM_OFFSET + 0x18) |
+		   nv_rd08(NV_PROM_OFFSET + 0x19) << 8;
+	if (nv_rd08(NV_PROM_OFFSET + pcir_ptr) != 'P' ||
+	    nv_rd08(NV_PROM_OFFSET + pcir_ptr + 1) != 'C' ||
+	    nv_rd08(NV_PROM_OFFSET + pcir_ptr + 2) != 'I' ||
+	    nv_rd08(NV_PROM_OFFSET + pcir_ptr + 3) != 'R')
+		goto out;
+
+	/* on some 6600GT/6800LE prom reads are messed up.  nvclock alleges a
+	 * a good read may be obtained by waiting or re-reading (cargocult: 5x)
+	 * each byte.  we'll hope pramin has something usable instead
+	 */
+	for (i = 0; i < NV_PROM_SIZE; i++)
+		data[i] = nv_rd08(NV_PROM_OFFSET + i);
+
+out:
+	/* disable ROM access */
+	nvWriteMC(dev, pci_nv_20,
+		  save_pci_nv_20 | NV_PBUS_PCI_NV_20_ROM_SHADOW_ENABLED);
+}
+
+static void load_vbios_pramin(struct drm_device *dev, uint8_t *data)
+{
+	uint32_t old_bar0_pramin = 0;
+	int i;
+
+	if (nv_arch(dev) >= NV_50) {
+		uint32_t vbios_vram = (nv_rd32(0x619f04) & ~0xff) << 8;
+
+		if (!vbios_vram)
+			vbios_vram = (nv_rd32(0x1700) << 16) + 0xf0000;
+
+		old_bar0_pramin = nv_rd32(0x1700);
+		nv_wr32(0x1700, vbios_vram >> 16);
+	}
+
+	/* bail if no rom signature */
+	if (nv_rd08(NV_PRAMIN_OFFSET) != 0x55 ||
+	    nv_rd08(NV_PRAMIN_OFFSET + 1) != 0xaa)
+		goto out;
+
+	for (i = 0; i < NV_PROM_SIZE; i++)
+		data[i] = nv_rd08(NV_PRAMIN_OFFSET + i);
+
+out:
+	if (nv_arch(dev) >= NV_50)
+		nv_wr32(0x1700, old_bar0_pramin);
+}
+
+static void load_vbios_pci(struct drm_device *dev, uint8_t *data)
+{
+	void __iomem *rom = NULL;
+	size_t rom_len;
+	int ret;
+
+	ret = pci_enable_rom(dev->pdev);
+	if (ret)
+		return;
+
+	rom = pci_map_rom(dev->pdev, &rom_len);
+	if (!rom)
+		goto out;
+	memcpy(data, rom, rom_len);
+	pci_unmap_rom(dev->pdev, rom);
+
+out:
+	pci_disable_rom(dev->pdev);
+}
+
+struct methods {
+	const char desc[8];
+	void (*loadbios)(struct drm_device *, uint8_t *);
+	const bool rw;
+	int score;
+};
+
+static struct methods nv04_methods[] = {
+	{ "PROM", load_vbios_prom, false },
+	{ "PRAMIN", load_vbios_pramin, true },
+	{ "PCI ROM", load_vbios_pci, true },
+	{ }
+};
+
+static struct methods nv50_methods[] = {
+	{ "PRAMIN", load_vbios_pramin, true },
+	{ "PROM", load_vbios_prom, false },
+	{ "PCI ROM", load_vbios_pci, true },
+	{ }
+};
+
+static bool NVShadowVBIOS(struct drm_device *dev, uint8_t *data)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct methods *methods, *method;
+	int testscore = 3;
+
+	if (dev_priv->card_type < NV_50)
+		methods = nv04_methods;
+	else
+		methods = nv50_methods;
+
+	method = methods;
+	while (method->loadbios) {
+		NV_TRACE(dev, "Attempting to load BIOS image from %s\n",
+			 method->desc);
+		data[0] = data[1] = 0;	/* avoid reuse of previous image */
+		method->loadbios(dev, data);
+		method->score = score_vbios(dev, data, method->rw);
+		if (method->score == testscore)
+			return true;
+		method++;
+	}
+
+	while (--testscore > 0) {
+		method = methods;
+		while (method->loadbios) {
+			if (method->score == testscore) {
+				NV_TRACE(dev, "Using BIOS image from %s\n",
+					 method->desc);
+				method->loadbios(dev, data);
+				return true;
+			}
+			method++;
+		}
+	}
+
+	NV_ERROR(dev, "No valid BIOS image found\n");
+	return false;
+}
+
+typedef struct {
+	char* name;
+	uint8_t id;
+	int length;
+	int length_offset;
+	int length_multiplier;
+	bool (*handler)(struct drm_device *dev, struct nvbios *, uint16_t, init_exec_t *);
+} init_tbl_entry_t;
+
+typedef struct {
+	uint8_t id[2];
+	uint16_t length;
+	uint16_t offset;
+} bit_entry_t;
+
+static int parse_init_table(struct drm_device *dev, struct nvbios *bios, unsigned int offset, init_exec_t *iexec);
+
+#define MACRO_INDEX_SIZE	2
+#define MACRO_SIZE		8
+#define CONDITION_SIZE		12
+#define IO_FLAG_CONDITION_SIZE	9
+#define IO_CONDITION_SIZE	5
+#define MEM_INIT_SIZE		66
+
+static void still_alive(void)
+{
+//	sync();
+//	BIOS_USLEEP(2000);
+}
+
+static uint32_t
+munge_reg(struct drm_device *dev, uint32_t reg)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (nv_arch(dev) < NV_50)
+		return reg;
+
+	if (reg & 0x40000000)
+		reg += dev_priv->VBIOS.display.head * 0x800;
+
+	reg &= ~(0x40000000);
+	return reg;
+}
+
+static int valid_reg(struct drm_device *dev, uint32_t reg)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* C51 has misaligned regs on purpose. Marvellous */
+	if (reg & 0x2 || (reg & 0x1 && dev_priv->VBIOS.pub.chip_version != 0x51)) {
+		NV_ERROR(dev, "========== misaligned reg 0x%08X ==========\n",
+			 reg);
+		return 0;
+	}
+	/* warn on C51 regs that haven't been verified accessible in mmiotracing */
+	if (reg & 0x1 && dev_priv->VBIOS.pub.chip_version == 0x51 &&
+	    reg != 0x130d && reg != 0x1311 && reg != 0x60081d)
+		NV_WARN(dev, "=== C51 misaligned reg 0x%08X not verified ===\n",
+			reg);
+
+	#define WITHIN(x,y,z) ((x>=y)&&(x<=y+z))
+	if (WITHIN(reg,NV_PMC_OFFSET,NV_PMC_SIZE))
+		return 1;
+	if (WITHIN(reg,NV_PBUS_OFFSET,NV_PBUS_SIZE))
+		return 1;
+	if (WITHIN(reg,NV_PFIFO_OFFSET,NV_PFIFO_SIZE))
+		return 1;
+	/* maybe a little large, but it will do for the moment. */
+	if (nv_arch(dev) >= NV_50 && WITHIN(reg, 0x1000, 0xEFFF))
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version >= 0x30 && WITHIN(reg,0x4000,0x600))
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version >= 0x40 && WITHIN(reg,0xc000,0x48))
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version >= 0x17 && reg == 0x0000d204)
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version >= 0x40) {
+		if (reg == 0x00011014 || reg == 0x00020328)
+			return 1;
+		if (WITHIN(reg,0x88000,NV_PBUS_SIZE)) /* new PBUS */
+			return 1;
+	}
+	if (nv_arch(dev) >= NV_50) {
+		/* No clue what they do, but because they are outside normal
+		 * ranges we'd better list them seperately. */
+		if (reg == 0x00020018 || reg == 0x0002004C ||
+		    reg == 0x00020060 || reg == 0x00021218 ||
+		    reg == 0x0002130C || reg == 0x00089008 ||
+		    reg == 0x00089028)
+			return 1;
+	}
+	if (WITHIN(reg,NV_PFB_OFFSET,NV_PFB_SIZE))
+		return 1;
+	if (WITHIN(reg,NV_PEXTDEV_OFFSET,NV_PEXTDEV_SIZE))
+		return 1;
+	if (WITHIN(reg,NV_PCRTC0_OFFSET,NV_PCRTC0_SIZE * 2))
+		return 1;
+	if (nv_arch(dev) >= NV_50 &&
+	    WITHIN(reg, NV50_DISPLAY_OFFSET, NV50_DISPLAY_SIZE))
+		return 1;
+	if (WITHIN(reg,NV_PRAMDAC0_OFFSET,NV_PRAMDAC0_SIZE * 2))
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version >= 0x17 && reg == 0x0070fff0)
+		return 1;
+	if (dev_priv->VBIOS.pub.chip_version == 0x51 && WITHIN(reg,NV_PRAMIN_OFFSET,NV_PRAMIN_SIZE))
+		return 1;
+	#undef WITHIN
+
+	NV_ERROR(dev, "========== unknown reg 0x%08X ==========\n", reg);
+
+	return 0;
+}
+
+static bool valid_idx_port(struct drm_device *dev, uint16_t port)
+{
+	/* if adding more ports here, the read/write functions below will need
+	 * updating so that the correct mmio range (PRMCIO, PRMDIO, PRMVIO) is
+	 * used for the port in question
+	 */
+	if (port == NV_CIO_CRX__COLOR)
+		return true;
+	if (port == NV_VIO_SRX)
+		return true;
+
+	NV_ERROR(dev, "========== unknown indexed io port 0x%04X ==========\n",
+		 port);
+
+	return false;
+}
+
+static bool valid_port(struct drm_device *dev, uint16_t port)
+{
+	/* if adding more ports here, the read/write functions below will need
+	 * updating so that the correct mmio range (PRMCIO, PRMDIO, PRMVIO) is
+	 * used for the port in question
+	 */
+	if (port == NV_VIO_VSE2)
+		return true;
+
+	NV_ERROR(dev, "========== unknown io port 0x%04X ==========\n", port);
+
+	return false;
+}
+
+static uint32_t bios_rd32(struct drm_device *dev, uint32_t reg)
+{
+	uint32_t data;
+
+	reg = munge_reg(dev, reg);
+	if (!valid_reg(dev, reg))
+		return 0;
+
+	/* C51 sometimes uses regs with bit0 set in the address. For these
+	 * cases there should exist a translation in a BIOS table to an IO
+	 * port address which the BIOS uses for accessing the reg
+	 *
+	 * These only seem to appear for the power control regs to a flat panel,
+	 * and the GPIO regs at 0x60081*.  In C51 mmio traces the normal regs
+	 * for 0x1308 and 0x1310 are used - hence the mask below.  An S3
+	 * suspend-resume mmio trace from a C51 will be required to see if this
+	 * is true for the power microcode in 0x14.., or whether the direct IO
+	 * port access method is needed
+	 */
+	if (reg & 0x1)
+		reg &= ~0x1;
+
+	data = nv_rd32(reg);
+
+	BIOSLOG(dev, "	Read:  Reg: 0x%08X, Data: 0x%08X\n", reg, data);
+
+	return data;
+}
+
+static void bios_wr32(struct drm_device *dev, uint32_t reg, uint32_t data)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	reg = munge_reg(dev, reg);
+	if (!valid_reg(dev, reg))
+		return;
+
+	/* see note in bios_rd32 */
+	if (reg & 0x1)
+		reg &= 0xfffffffe;
+
+	LOG_OLD_VALUE(bios_rd32(dev, reg));
+	BIOSLOG(dev, "	Write: Reg: 0x%08X, Data: 0x%08X\n", reg, data);
+
+	if (dev_priv->VBIOS.execute) {
+		still_alive();
+		nv_wr32(reg, data);
+	}
+}
+
+static uint8_t bios_idxprt_rd(struct drm_device *dev, uint16_t port, uint8_t index)
+{
+	uint8_t data;
+
+	if (!valid_idx_port(dev, port))
+		return 0;
+
+	if (port == NV_VIO_SRX)
+		data = NVReadVgaSeq(dev, crtchead, index);
+	else	/* assume NV_CIO_CRX__COLOR */
+		data = NVReadVgaCrtc(dev, crtchead, index);
+
+	BIOSLOG(dev, "	Indexed IO read:  Port: 0x%04X, Index: 0x%02X, Head: 0x%02X, Data: 0x%02X\n",
+		port, index, crtchead, data);
+
+	return data;
+}
+
+static void bios_idxprt_wr(struct drm_device *dev, uint16_t port, uint8_t index, uint8_t data)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (!valid_idx_port(dev, port))
+		return;
+
+	/* The current head is maintained in a file scope variable crtchead.
+	 * We trap changes to CR44 and update the head variable and hence the
+	 * register set written.
+	 * As CR44 only exists on CRTC0, we update crtchead to head0 in advance
+	 * of the write, and to head1 after the write
+	 */
+	if (port == NV_CIO_CRX__COLOR && index == NV_CIO_CRE_44 && data != NV_CIO_CRE_44_HEADB)
+		crtchead = 0;
+
+	LOG_OLD_VALUE(bios_idxprt_rd(dev, port, index));
+	BIOSLOG(dev, "	Indexed IO write: Port: 0x%04X, Index: 0x%02X, Head: 0x%02X, Data: 0x%02X\n",
+		port, index, crtchead, data);
+
+	if (dev_priv->VBIOS.execute) {
+		still_alive();
+		if (port == NV_VIO_SRX)
+			NVWriteVgaSeq(dev, crtchead, index, data);
+		else	/* assume NV_CIO_CRX__COLOR */
+			NVWriteVgaCrtc(dev, crtchead, index, data);
+	}
+
+	if (port == NV_CIO_CRX__COLOR && index == NV_CIO_CRE_44 && data == NV_CIO_CRE_44_HEADB)
+		crtchead = 1;
+}
+
+static uint8_t bios_port_rd(struct drm_device *dev, uint16_t port)
+{
+	uint8_t data;
+
+	if (!valid_port(dev, port))
+		return 0;
+
+	data = NVReadPRMVIO(dev, crtchead, NV_PRMVIO0_OFFSET + port);
+
+	BIOSLOG(dev, "	IO read:  Port: 0x%04X, Head: 0x%02X, Data: 0x%02X\n",
+		port, crtchead, data);
+
+	return data;
+}
+
+static void bios_port_wr(struct drm_device *dev, uint16_t port, uint8_t data)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (!valid_port(dev, port))
+		return;
+
+	LOG_OLD_VALUE(bios_port_rd(dev, port));
+	BIOSLOG(dev, "	IO write: Port: 0x%04X, Head: 0x%02X, Data: 0x%02X\n",
+		port, crtchead, data);
+
+	if (dev_priv->VBIOS.execute) {
+		still_alive();
+		NVWritePRMVIO(dev, crtchead, NV_PRMVIO0_OFFSET + port, data);
+	}
+}
+
+static bool io_flag_condition_met(struct drm_device *dev, struct nvbios *bios, uint16_t offset, uint8_t cond)
+{
+	/* The IO flag condition entry has 2 bytes for the CRTC port; 1 byte
+	 * for the CRTC index; 1 byte for the mask to apply to the value
+	 * retrieved from the CRTC; 1 byte for the shift right to apply to the
+	 * masked CRTC value; 2 bytes for the offset to the flag array, to
+	 * which the shifted value is added; 1 byte for the mask applied to the
+	 * value read from the flag array; and 1 byte for the value to compare
+	 * against the masked byte from the flag table.
+	 */
+
+	uint16_t condptr = bios->io_flag_condition_tbl_ptr + cond * IO_FLAG_CONDITION_SIZE;
+	uint16_t crtcport = ROM16(bios->data[condptr]);
+	uint8_t crtcindex = bios->data[condptr + 2];
+	uint8_t mask = bios->data[condptr + 3];
+	uint8_t shift = bios->data[condptr + 4];
+	uint16_t flagarray = ROM16(bios->data[condptr + 5]);
+	uint8_t flagarraymask = bios->data[condptr + 7];
+	uint8_t cmpval = bios->data[condptr + 8];
+	uint8_t data;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X, Shift: 0x%02X, FlagArray: 0x%04X, FAMask: 0x%02X, Cmpval: 0x%02X\n",
+		offset, crtcport, crtcindex, mask, shift, flagarray, flagarraymask, cmpval);
+
+	data = bios_idxprt_rd(dev, crtcport, crtcindex);
+
+	data = bios->data[flagarray + ((data & mask) >> shift)];
+	data &= flagarraymask;
+
+	BIOSLOG(dev, "0x%04X: Checking if 0x%02X equals 0x%02X\n", offset, data, cmpval);
+
+	return (data == cmpval);
+}
+
+static bool bios_condition_met(struct drm_device *dev, struct nvbios *bios, uint16_t offset, uint8_t cond)
+{
+	/* The condition table entry has 4 bytes for the address of the
+	 * register to check, 4 bytes for a mask to apply to the register and
+	 * 4 for a test comparison value
+	 */
+
+	uint16_t condptr = bios->condition_tbl_ptr + cond * CONDITION_SIZE;
+	uint32_t reg = ROM32(bios->data[condptr]);
+	uint32_t mask = ROM32(bios->data[condptr + 4]);
+	uint32_t cmpval = ROM32(bios->data[condptr + 8]);
+	uint32_t data;
+
+	BIOSLOG(dev, "0x%04X: Cond: 0x%02X, Reg: 0x%08X, Mask: 0x%08X\n",
+		offset, cond, reg, mask);
+
+	data = bios_rd32(dev, reg) & mask;
+
+	BIOSLOG(dev, "0x%04X: Checking if 0x%08X equals 0x%08X\n",
+		offset, data, cmpval);
+
+	return (data == cmpval);
+}
+
+static bool io_condition_met(struct drm_device *dev, struct nvbios *bios, uint16_t offset, uint8_t cond)
+{
+	/* The IO condition entry has 2 bytes for the IO port address; 1 byte
+	 * for the index to write to io_port; 1 byte for the mask to apply to
+	 * the byte read from io_port+1; and 1 byte for the value to compare
+	 * against the masked byte.
+	 */
+
+	uint16_t condptr = bios->io_condition_tbl_ptr + cond * IO_CONDITION_SIZE;
+	uint16_t io_port = ROM16(bios->data[condptr]);
+	uint8_t port_index = bios->data[condptr + 2];
+	uint8_t mask = bios->data[condptr + 3];
+	uint8_t cmpval = bios->data[condptr + 4];
+
+	uint8_t data = bios_idxprt_rd(dev, io_port, port_index) & mask;
+
+	BIOSLOG(dev, "0x%04X: Checking if 0x%02X equals 0x%02X\n",
+		offset, data, cmpval);
+
+	return (data == cmpval);
+}
+
+static int setPLL(struct drm_device *dev, struct nvbios *bios, uint32_t reg, uint32_t clk)
+{
+	/* clk in kHz */
+	struct pll_lims pll_lim;
+	int ret;
+	struct nouveau_pll_vals pllvals;
+
+	/* high regs (such as in the mac g5 table) are not -= 4 */
+	if ((ret = get_pll_limits(dev, reg > 0x405c ? reg : reg - 4, &pll_lim)))
+		return ret;
+
+	if (!(clk = nouveau_calc_pll_mnp(dev, &pll_lim, clk, &pllvals)))
+		return -ERANGE;
+
+	if (bios->execute) {
+		still_alive();
+		nouveau_hw_setpll(dev, reg, &pllvals);
+	}
+
+	return 0;
+}
+
+static int dcb_entry_idx_from_crtchead(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* for the results of this function to be correct, CR44 must have been
+	 * set (using bios_idxprt_wr to set crtchead), CR58 set for CR57 = 0,
+	 * and the DCB table parsed, before the script calling the function is
+	 * run.  run_digital_op_script is example of how to do such setup
+	 */
+
+	uint8_t dcb_entry = NVReadVgaCrtc5758(dev, crtchead, 0);
+
+	if (dcb_entry > dev_priv->VBIOS.bdcb.dcb.entries) {
+		NV_ERROR(dev, "CR58 doesn't have a valid DCB entry currently "
+				"(%02X)\n", dcb_entry);
+		dcb_entry = 0x7f;	/* unused / invalid marker */
+	}
+
+	return dcb_entry;
+}
+
+static int init_dcb_i2c_entry(struct drm_device *dev, struct nvbios *bios, int index);
+
+static int
+create_i2c_device(struct drm_device *dev, struct nvbios *bios, int i2c_index,
+		  struct nouveau_i2c_chan **chan)
+{
+	struct bios_parsed_dcb *bdcb = &bios->bdcb;
+	int ret;
+
+	if (i2c_index == 0xff) {
+		/* note: dcb_entry_idx_from_crtchead needs pre-script set-up */
+		int idx = dcb_entry_idx_from_crtchead(dev), shift = 0;
+		int default_indices = bdcb->i2c_default_indices;
+
+		if (idx != 0x7f && bdcb->dcb.entry[idx].i2c_upper_default)
+			shift = 4;
+
+		i2c_index = (default_indices >> shift) & 0xf;
+	}
+	if (i2c_index == 0x80)	/* g80+ */
+		i2c_index = bdcb->i2c_default_indices & 0xf;
+
+	if ((ret = init_dcb_i2c_entry(dev, bios, i2c_index)))
+		return ret;
+
+	*chan = bdcb->dcb.i2c[i2c_index].chan;
+	return 0;
+}
+
+static uint32_t get_tmds_index_reg(struct drm_device *dev, uint8_t mlv)
+{
+	/* For mlv < 0x80, it is an index into a table of TMDS base addresses
+	 * For mlv == 0x80 use the "or" value of the dcb_entry indexed by CR58 for CR57 = 0
+	 * to index a table of offsets to the basic 0x6808b0 address
+	 * For mlv == 0x81 use the "or" value of the dcb_entry indexed by CR58 for CR57 = 0
+	 * to index a table of offsets to the basic 0x6808b0 address, and then flip the offset by 8
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	const int pramdac_offset[13] = {0, 0, 0x8, 0, 0x2000, 0, 0, 0, 0x2008, 0, 0, 0, 0x2000};
+	const uint32_t pramdac_table[4] = {0x6808b0, 0x6808b8, 0x6828b0, 0x6828b8};
+
+	if (mlv >= 0x80) {
+		int dcb_entry, dacoffset;
+
+		/* note: dcb_entry_idx_from_crtchead needs pre-script set-up */
+		if ((dcb_entry = dcb_entry_idx_from_crtchead(dev)) == 0x7f)
+			return 0;
+		dacoffset = pramdac_offset[dev_priv->VBIOS.bdcb.dcb.entry[dcb_entry].or];
+		if (mlv == 0x81)
+			dacoffset ^= 8;
+		return (0x6808b0 + dacoffset);
+	} else {
+		if (mlv > (sizeof(pramdac_table) / sizeof(uint32_t))) {
+			NV_ERROR(dev, "Magic Lookup Value too big (%02X)\n", mlv);
+			return 0;
+		}
+		return pramdac_table[mlv];
+	}
+}
+
+static bool init_io_restrict_prog(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO_RESTRICT_PROG   opcode: 0x32 ('2')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): CRTC index
+	 * offset + 4  (8  bit): mask
+	 * offset + 5  (8  bit): shift
+	 * offset + 6  (8  bit): count
+	 * offset + 7  (32 bit): register
+	 * offset + 11 (32 bit): configuration 1
+	 * ...
+	 *
+	 * Starting at offset + 11 there are "count" 32 bit values.
+	 * To find out which value to use read index "CRTC index" on "CRTC port",
+	 * AND this value with "mask" and then bit shift right "shift" bits.
+	 * Read the appropriate value using this index and write to "register"
+	 */
+
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t crtcindex = bios->data[offset + 3];
+	uint8_t mask = bios->data[offset + 4];
+	uint8_t shift = bios->data[offset + 5];
+	uint8_t count = bios->data[offset + 6];
+	uint32_t reg = ROM32(bios->data[offset + 7]);
+	uint8_t config;
+	uint32_t configval;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X, Shift: 0x%02X, Count: 0x%02X, Reg: 0x%08X\n",
+		offset, crtcport, crtcindex, mask, shift, count, reg);
+
+	config = (bios_idxprt_rd(dev, crtcport, crtcindex) & mask) >> shift;
+	if (config > count) {
+		NV_ERROR(dev,
+			 "0x%04X: Config 0x%02X exceeds maximal bound 0x%02X\n",
+			 offset, config, count);
+		return false;
+	}
+
+	configval = ROM32(bios->data[offset + 11 + config * 4]);
+
+	BIOSLOG(dev, "0x%04X: Writing config %02X\n", offset, config);
+
+	bios_wr32(dev, reg, configval);
+
+	return true;
+}
+
+static bool init_repeat(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_REPEAT   opcode: 0x33 ('3')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): count
+	 *
+	 * Execute script following this opcode up to INIT_REPEAT_END
+	 * "count" times
+	 */
+
+	uint8_t count = bios->data[offset + 1];
+	uint8_t i;
+
+	/* no iexec->execute check by design */
+
+	BIOSLOG(dev, "0x%04X: Repeating following segment %d times\n", offset, count);
+
+	iexec->repeat = true;
+
+	/* count - 1, as the script block will execute once when we leave this
+	 * opcode -- this is compatible with bios behaviour as:
+	 * a) the block is always executed at least once, even if count == 0
+	 * b) the bios interpreter skips to the op following INIT_END_REPEAT,
+	 * while we don't
+	 */
+	for (i = 0; i < count - 1; i++)
+		parse_init_table(dev, bios, offset + 2, iexec);
+
+	iexec->repeat = false;
+
+	return true;
+}
+
+static bool init_io_restrict_pll(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO_RESTRICT_PLL   opcode: 0x34 ('4')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): CRTC index
+	 * offset + 4  (8  bit): mask
+	 * offset + 5  (8  bit): shift
+	 * offset + 6  (8  bit): IO flag condition index
+	 * offset + 7  (8  bit): count
+	 * offset + 8  (32 bit): register
+	 * offset + 12 (16 bit): frequency 1
+	 * ...
+	 *
+	 * Starting at offset + 12 there are "count" 16 bit frequencies (10kHz).
+	 * Set PLL register "register" to coefficients for frequency n,
+	 * selected by reading index "CRTC index" of "CRTC port" ANDed with
+	 * "mask" and shifted right by "shift". If "IO flag condition index" > 0,
+	 * and condition met, double frequency before setting it.
+	 */
+
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t crtcindex = bios->data[offset + 3];
+	uint8_t mask = bios->data[offset + 4];
+	uint8_t shift = bios->data[offset + 5];
+	int8_t io_flag_condition_idx = bios->data[offset + 6];
+	uint8_t count = bios->data[offset + 7];
+	uint32_t reg = ROM32(bios->data[offset + 8]);
+	uint8_t config;
+	uint16_t freq;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X, Shift: 0x%02X, IO Flag Condition: 0x%02X, Count: 0x%02X, Reg: 0x%08X\n",
+		offset, crtcport, crtcindex, mask, shift, io_flag_condition_idx, count, reg);
+
+	config = (bios_idxprt_rd(dev, crtcport, crtcindex) & mask) >> shift;
+	if (config > count) {
+		NV_ERROR(dev,
+			 "0x%04X: Config 0x%02X exceeds maximal bound 0x%02X\n",
+			 offset, config, count);
+		return false;
+	}
+
+	freq = ROM16(bios->data[offset + 12 + config * 2]);
+
+	if (io_flag_condition_idx > 0) {
+		if (io_flag_condition_met(dev, bios, offset, io_flag_condition_idx)) {
+			BIOSLOG(dev, "0x%04X: Condition fulfilled -- frequency doubled\n", offset);
+			freq *= 2;
+		} else
+			BIOSLOG(dev, "0x%04X: Condition not fulfilled -- frequency unchanged\n", offset);
+	}
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, Config: 0x%02X, Freq: %d0kHz\n",
+		offset, reg, config, freq);
+
+	setPLL(dev, bios, reg, freq * 10);
+
+	return true;
+}
+
+static bool init_end_repeat(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_END_REPEAT   opcode: 0x36 ('6')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * Marks the end of the block for INIT_REPEAT to repeat
+	 */
+
+	/* no iexec->execute check by design */
+
+	/* iexec->repeat flag necessary to go past INIT_END_REPEAT opcode when
+	 * we're not in repeat mode
+	 */
+	if (iexec->repeat)
+		return false;
+
+	return true;
+}
+
+static bool init_copy(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_COPY   opcode: 0x37 ('7')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (8  bit): shift
+	 * offset + 6  (8  bit): srcmask
+	 * offset + 7  (16 bit): CRTC port
+	 * offset + 9  (8 bit): CRTC index
+	 * offset + 10  (8 bit): mask
+	 *
+	 * Read index "CRTC index" on "CRTC port", AND with "mask", OR with
+	 * (REGVAL("register") >> "shift" & "srcmask") and write-back to CRTC port
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint8_t shift = bios->data[offset + 5];
+	uint8_t srcmask = bios->data[offset + 6];
+	uint16_t crtcport = ROM16(bios->data[offset + 7]);
+	uint8_t crtcindex = bios->data[offset + 9];
+	uint8_t mask = bios->data[offset + 10];
+	uint32_t data;
+	uint8_t crtcdata;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, Shift: 0x%02X, SrcMask: 0x%02X, Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X\n",
+		offset, reg, shift, srcmask, crtcport, crtcindex, mask);
+
+	data = bios_rd32(dev, reg);
+
+	if (shift < 0x80)
+		data >>= shift;
+	else
+		data <<= (0x100 - shift);
+
+	data &= srcmask;
+
+	crtcdata = (bios_idxprt_rd(dev, crtcport, crtcindex) & mask) | (uint8_t)data;
+	bios_idxprt_wr(dev, crtcport, crtcindex, crtcdata);
+
+	return true;
+}
+
+static bool init_not(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_NOT   opcode: 0x38 ('8')
+	 *
+	 * offset      (8  bit): opcode
+	 *
+	 * Invert the current execute / no-execute condition (i.e. "else")
+	 */
+	if (iexec->execute)
+		BIOSLOG(dev, "0x%04X: ------ Skipping following commands  ------\n", offset);
+	else
+		BIOSLOG(dev, "0x%04X: ------ Executing following commands ------\n", offset);
+
+	iexec->execute = !iexec->execute;
+	return true;
+}
+
+static bool init_io_flag_condition(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO_FLAG_CONDITION   opcode: 0x39 ('9')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): condition number
+	 *
+	 * Check condition "condition number" in the IO flag condition table.
+	 * If condition not met skip subsequent opcodes until condition is
+	 * inverted (INIT_NOT), or we hit INIT_RESUME
+	 */
+
+	uint8_t cond = bios->data[offset + 1];
+
+	if (!iexec->execute)
+		return true;
+
+	if (io_flag_condition_met(dev, bios, offset, cond))
+		BIOSLOG(dev, "0x%04X: Condition fulfilled -- continuing to execute\n", offset);
+	else {
+		BIOSLOG(dev, "0x%04X: Condition not fulfilled -- skipping following commands\n", offset);
+		iexec->execute = false;
+	}
+
+	return true;
+}
+
+static bool init_idx_addr_latched(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_INDEX_ADDRESS_LATCHED   opcode: 0x49 ('I')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): control register
+	 * offset + 5  (32 bit): data register
+	 * offset + 9  (32 bit): mask
+	 * offset + 13 (32 bit): data
+	 * offset + 17 (8  bit): count
+	 * offset + 18 (8  bit): address 1
+	 * offset + 19 (8  bit): data 1
+	 * ...
+	 *
+	 * For each of "count" address and data pairs, write "data n" to "data register",
+	 * read the current value of "control register", and write it back once ANDed
+	 * with "mask", ORed with "data", and ORed with "address n"
+	 */
+
+	uint32_t controlreg = ROM32(bios->data[offset + 1]);
+	uint32_t datareg = ROM32(bios->data[offset + 5]);
+	uint32_t mask = ROM32(bios->data[offset + 9]);
+	uint32_t data = ROM32(bios->data[offset + 13]);
+	uint8_t count = bios->data[offset + 17];
+	uint32_t value;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: ControlReg: 0x%08X, DataReg: 0x%08X, Mask: 0x%08X, Data: 0x%08X, Count: 0x%02X\n",
+		offset, controlreg, datareg, mask, data, count);
+
+	for (i = 0; i < count; i++) {
+		uint8_t instaddress = bios->data[offset + 18 + i * 2];
+		uint8_t instdata = bios->data[offset + 19 + i * 2];
+
+		BIOSLOG(dev, "0x%04X: Address: 0x%02X, Data: 0x%02X\n", offset, instaddress, instdata);
+
+		bios_wr32(dev, datareg, instdata);
+		value = (bios_rd32(dev, controlreg) & mask) | data | instaddress;
+		bios_wr32(dev, controlreg, value);
+	}
+
+	return true;
+}
+
+static bool init_io_restrict_pll2(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO_RESTRICT_PLL2   opcode: 0x4A ('J')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): CRTC index
+	 * offset + 4  (8  bit): mask
+	 * offset + 5  (8  bit): shift
+	 * offset + 6  (8  bit): count
+	 * offset + 7  (32 bit): register
+	 * offset + 11 (32 bit): frequency 1
+	 * ...
+	 *
+	 * Starting at offset + 11 there are "count" 32 bit frequencies (kHz).
+	 * Set PLL register "register" to coefficients for frequency n,
+	 * selected by reading index "CRTC index" of "CRTC port" ANDed with
+	 * "mask" and shifted right by "shift".
+	 */
+
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t crtcindex = bios->data[offset + 3];
+	uint8_t mask = bios->data[offset + 4];
+	uint8_t shift = bios->data[offset + 5];
+	uint8_t count = bios->data[offset + 6];
+	uint32_t reg = ROM32(bios->data[offset + 7]);
+	uint8_t config;
+	uint32_t freq;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X, Shift: 0x%02X, Count: 0x%02X, Reg: 0x%08X\n",
+		offset, crtcport, crtcindex, mask, shift, count, reg);
+
+	if (!reg)
+		return true;
+
+	config = (bios_idxprt_rd(dev, crtcport, crtcindex) & mask) >> shift;
+	if (config > count) {
+		NV_ERROR(dev,
+			 "0x%04X: Config 0x%02X exceeds maximal bound 0x%02X\n",
+			 offset, config, count);
+		return false;
+	}
+
+	freq = ROM32(bios->data[offset + 11 + config * 4]);
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, Config: 0x%02X, Freq: %dkHz\n",
+		offset, reg, config, freq);
+
+	setPLL(dev, bios, reg, freq);
+
+	return true;
+}
+
+static bool init_pll2(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_PLL2   opcode: 0x4B ('K')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (32 bit): freq
+	 *
+	 * Set PLL register "register" to coefficients for frequency "freq"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint32_t freq = ROM32(bios->data[offset + 5]);
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%04X, Freq: %dkHz\n",
+		offset, reg, freq);
+
+	setPLL(dev, bios, reg, freq);
+
+	return true;
+}
+
+static bool init_i2c_byte(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_I2C_BYTE   opcode: 0x4C ('L')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): DCB I2C table entry index
+	 * offset + 2  (8 bit): I2C slave address
+	 * offset + 3  (8 bit): count
+	 * offset + 4  (8 bit): I2C register 1
+	 * offset + 5  (8 bit): mask 1
+	 * offset + 6  (8 bit): data 1
+	 * ...
+	 *
+	 * For each of "count" registers given by "I2C register n" on the device
+	 * addressed by "I2C slave address" on the I2C bus given by
+	 * "DCB I2C table entry index", read the register, AND the result with
+	 * "mask n" and OR it with "data n" before writing it back to the device
+	 */
+
+	uint8_t i2c_index = bios->data[offset + 1];
+	uint8_t i2c_address = bios->data[offset + 2];
+	uint8_t count = bios->data[offset + 3];
+	struct nouveau_i2c_chan *chan;
+	struct i2c_msg msg;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: DCBI2CIndex: 0x%02X, I2CAddress: 0x%02X, Count: 0x%02X\n",
+		offset, i2c_index, i2c_address, count);
+
+	if (create_i2c_device(dev, bios, i2c_index, &chan))
+		return false;
+
+	for (i = 0; i < count; i++) {
+		uint8_t i2c_reg = bios->data[offset + 4 + i * 3];
+		uint8_t mask = bios->data[offset + 5 + i * 3];
+		uint8_t data = bios->data[offset + 6 + i * 3];
+		uint8_t value;
+
+		msg.addr = i2c_address;
+		msg.flags = I2C_M_RD;
+		msg.len = 1;
+		msg.buf = &value;
+		if (i2c_transfer(&chan->adapter, &msg, 1) != 1)
+			return false;
+
+		BIOSLOG(dev, "0x%04X: I2CReg: 0x%02X, Value: 0x%02X, Mask: 0x%02X, Data: 0x%02X\n",
+			offset, i2c_reg, value, mask, data);
+
+		value = (value & mask) | data;
+
+		if (bios->execute) {
+			msg.addr = i2c_address;
+			msg.flags = 0;
+			msg.len = 1;
+			msg.buf = &value;
+			if (i2c_transfer(&chan->adapter, &msg, 1) != 1)
+				return false;
+		}
+	}
+
+	return true;
+}
+
+static bool init_zm_i2c_byte(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_I2C_BYTE   opcode: 0x4D ('M')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): DCB I2C table entry index
+	 * offset + 2  (8 bit): I2C slave address
+	 * offset + 3  (8 bit): count
+	 * offset + 4  (8 bit): I2C register 1
+	 * offset + 5  (8 bit): data 1
+	 * ...
+	 *
+	 * For each of "count" registers given by "I2C register n" on the device
+	 * addressed by "I2C slave address" on the I2C bus given by
+	 * "DCB I2C table entry index", set the register to "data n"
+	 */
+
+	uint8_t i2c_index = bios->data[offset + 1];
+	uint8_t i2c_address = bios->data[offset + 2];
+	uint8_t count = bios->data[offset + 3];
+	struct nouveau_i2c_chan *chan;
+	struct i2c_msg msg;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: DCBI2CIndex: 0x%02X, I2CAddress: 0x%02X, Count: 0x%02X\n",
+		offset, i2c_index, i2c_address, count);
+
+	if (create_i2c_device(dev, bios, i2c_index, &chan))
+		return false;
+
+	for (i = 0; i < count; i++) {
+		uint8_t i2c_reg = bios->data[offset + 4 + i * 2];
+		uint8_t data = bios->data[offset + 5 + i * 2];
+
+		BIOSLOG(dev, "0x%04X: I2CReg: 0x%02X, Data: 0x%02X\n",
+			offset, i2c_reg, data);
+
+		if (bios->execute) {
+			msg.addr = i2c_address;
+			msg.flags = 0;
+			msg.len = 1;
+			msg.buf = &data;
+			if (i2c_transfer(&chan->adapter, &msg, 1) != 1)
+				return false;
+		}
+	}
+
+	return true;
+}
+
+static bool init_zm_i2c(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_I2C   opcode: 0x4E ('N')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): DCB I2C table entry index
+	 * offset + 2  (8 bit): I2C slave address
+	 * offset + 3  (8 bit): count
+	 * offset + 4  (8 bit): data 1
+	 * ...
+	 *
+	 * Send "count" bytes ("data n") to the device addressed by "I2C slave
+	 * address" on the I2C bus given by "DCB I2C table entry index"
+	 */
+
+	uint8_t i2c_index = bios->data[offset + 1];
+	uint8_t i2c_address = bios->data[offset + 2];
+	uint8_t count = bios->data[offset + 3];
+	struct nouveau_i2c_chan *chan;
+	struct i2c_msg msg;
+	uint8_t data[256];
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: DCBI2CIndex: 0x%02X, I2CAddress: 0x%02X, Count: 0x%02X\n",
+		offset, i2c_index, i2c_address, count);
+
+	if (create_i2c_device(dev, bios, i2c_index, &chan))
+		return false;
+
+	for (i = 0; i < count; i++) {
+		data[i] = bios->data[offset + 4 + i];
+
+		BIOSLOG(dev, "0x%04X: Data: 0x%02X\n", offset, data[i]);
+	}
+
+	if (bios->execute) {
+		msg.addr = i2c_address;
+		msg.flags = 0;
+		msg.len = count;
+		msg.buf = data;
+		if (i2c_transfer(&chan->adapter, &msg, 1) != 1)
+			return false;
+	}
+
+	return true;
+}
+
+static bool init_tmds(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_TMDS   opcode: 0x4F ('O')	(non-canon name)
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): magic lookup value
+	 * offset + 2  (8 bit): TMDS address
+	 * offset + 3  (8 bit): mask
+	 * offset + 4  (8 bit): data
+	 *
+	 * Read the data reg for TMDS address "TMDS address", AND it with mask
+	 * and OR it with data, then write it back
+	 * "magic lookup value" determines which TMDS base address register is used --
+	 * see get_tmds_index_reg()
+	 */
+
+	uint8_t mlv = bios->data[offset + 1];
+	uint32_t tmdsaddr = bios->data[offset + 2];
+	uint8_t mask = bios->data[offset + 3];
+	uint8_t data = bios->data[offset + 4];
+	uint32_t reg, value;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: MagicLookupValue: 0x%02X, TMDSAddr: 0x%02X, Mask: 0x%02X, Data: 0x%02X\n",
+		offset, mlv, tmdsaddr, mask, data);
+
+	if (!(reg = get_tmds_index_reg(dev, mlv)))
+		return false;
+
+	bios_wr32(dev, reg, tmdsaddr | NV_PRAMDAC_FP_TMDS_CONTROL_WRITE_DISABLE);
+	value = (bios_rd32(dev, reg + 4) & mask) | data;
+	bios_wr32(dev, reg + 4, value);
+	bios_wr32(dev, reg, tmdsaddr);
+
+	return true;
+}
+
+static bool init_zm_tmds_group(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_TMDS_GROUP   opcode: 0x50 ('P')	(non-canon name)
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): magic lookup value
+	 * offset + 2  (8 bit): count
+	 * offset + 3  (8 bit): addr 1
+	 * offset + 4  (8 bit): data 1
+	 * ...
+	 *
+	 * For each of "count" TMDS address and data pairs write "data n" to "addr n"
+	 * "magic lookup value" determines which TMDS base address register is used --
+	 * see get_tmds_index_reg()
+	 */
+
+	uint8_t mlv = bios->data[offset + 1];
+	uint8_t count = bios->data[offset + 2];
+	uint32_t reg;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: MagicLookupValue: 0x%02X, Count: 0x%02X\n",
+		offset, mlv, count);
+
+	if (!(reg = get_tmds_index_reg(dev, mlv)))
+		return false;
+
+	for (i = 0; i < count; i++) {
+		uint8_t tmdsaddr = bios->data[offset + 3 + i * 2];
+		uint8_t tmdsdata = bios->data[offset + 4 + i * 2];
+
+		bios_wr32(dev, reg + 4, tmdsdata);
+		bios_wr32(dev, reg, tmdsaddr);
+	}
+
+	return true;
+}
+
+static bool init_cr_idx_adr_latch(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CR_INDEX_ADDRESS_LATCHED   opcode: 0x51 ('Q')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): CRTC index1
+	 * offset + 2  (8 bit): CRTC index2
+	 * offset + 3  (8 bit): baseaddr
+	 * offset + 4  (8 bit): count
+	 * offset + 5  (8 bit): data 1
+	 * ...
+	 *
+	 * For each of "count" address and data pairs, write "baseaddr + n" to
+	 * "CRTC index1" and "data n" to "CRTC index2"
+	 * Once complete, restore initial value read from "CRTC index1"
+	 */
+	uint8_t crtcindex1 = bios->data[offset + 1];
+	uint8_t crtcindex2 = bios->data[offset + 2];
+	uint8_t baseaddr = bios->data[offset + 3];
+	uint8_t count = bios->data[offset + 4];
+	uint8_t oldaddr, data;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Index1: 0x%02X, Index2: 0x%02X, BaseAddr: 0x%02X, Count: 0x%02X\n",
+		offset, crtcindex1, crtcindex2, baseaddr, count);
+
+	oldaddr = bios_idxprt_rd(dev, NV_CIO_CRX__COLOR, crtcindex1);
+
+	for (i = 0; i < count; i++) {
+		bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, crtcindex1, baseaddr + i);
+
+		data = bios->data[offset + 5 + i];
+		bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, crtcindex2, data);
+	}
+
+	bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, crtcindex1, oldaddr);
+
+	return true;
+}
+
+static bool init_cr(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CR   opcode: 0x52 ('R')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (8  bit): CRTC index
+	 * offset + 2  (8  bit): mask
+	 * offset + 3  (8  bit): data
+	 *
+	 * Assign the value of at "CRTC index" ANDed with mask and ORed with data
+	 * back to "CRTC index"
+	 */
+
+	uint8_t crtcindex = bios->data[offset + 1];
+	uint8_t mask = bios->data[offset + 2];
+	uint8_t data = bios->data[offset + 3];
+	uint8_t value;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Index: 0x%02X, Mask: 0x%02X, Data: 0x%02X\n",
+		offset, crtcindex, mask, data);
+
+	value = (bios_idxprt_rd(dev, NV_CIO_CRX__COLOR, crtcindex) & mask) | data;
+	bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, crtcindex, value);
+
+	return true;
+}
+
+static bool init_zm_cr(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_CR   opcode: 0x53 ('S')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): CRTC index
+	 * offset + 2  (8 bit): value
+	 *
+	 * Assign "value" to CRTC register with index "CRTC index".
+	 */
+
+	uint8_t crtcindex = ROM32(bios->data[offset + 1]);
+	uint8_t data = bios->data[offset + 2];
+
+	if (!iexec->execute)
+		return true;
+
+	bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, crtcindex, data);
+
+	return true;
+}
+
+static bool init_zm_cr_group(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_CR_GROUP   opcode: 0x54 ('T')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): count
+	 * offset + 2  (8 bit): CRTC index 1
+	 * offset + 3  (8 bit): value 1
+	 * ...
+	 *
+	 * For "count", assign "value n" to CRTC register with index "CRTC index n".
+	 */
+    
+	uint8_t count = bios->data[offset + 1];
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	for (i = 0; i < count; i++)
+		init_zm_cr(dev, bios, offset + 2 + 2 * i - 1, iexec);
+
+	return true;
+}
+
+static bool init_condition_time(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CONDITION_TIME   opcode: 0x56 ('V')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): condition number
+	 * offset + 2  (8 bit): retries / 50
+	 *
+	 * Check condition "condition number" in the condition table.
+	 * Bios code then sleeps for 2ms if the condition is not met, and
+	 * repeats up to "retries" times, but on one C51 this has proved
+	 * insufficient.  In mmiotraces the driver sleeps for 20ms, so we do
+	 * this, and bail after "retries" times, or 2s, whichever is less.
+	 * If still not met after retries, clear execution flag for this table.
+	 */
+
+	uint8_t cond = bios->data[offset + 1];
+	uint16_t retries = bios->data[offset + 2] * 50;
+
+	if (!iexec->execute)
+		return true;
+
+	if (retries > 100)
+		retries = 100;
+
+	BIOSLOG(dev, "0x%04X: Condition: 0x%02X, Retries: 0x%02X\n", offset, cond, retries);
+
+	for (; retries > 0; retries--)
+		if (bios_condition_met(dev, bios, offset, cond)) {
+			BIOSLOG(dev, "0x%04X: Condition met, continuing\n", offset);
+			break;
+		} else {
+			BIOSLOG(dev, "0x%04X: Condition not met, sleeping for 20ms\n", offset);
+			BIOS_USLEEP(20000);
+		}
+
+	if (!bios_condition_met(dev, bios, offset, cond)) {
+		NV_WARN(dev, "0x%04X: Condition still not met after %dms, "
+			       "skiping following opcodes\n", offset, 20 * retries);
+		iexec->execute = false;
+	}
+
+	return true;
+}
+
+static bool init_zm_reg_sequence(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_REG_SEQUENCE   opcode: 0x58 ('X')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): base register
+	 * offset + 5  (8  bit): count
+	 * offset + 6  (32 bit): value 1
+	 * ...
+	 *
+	 * Starting at offset + 6 there are "count" 32 bit values.
+	 * For "count" iterations set "base register" + 4 * current_iteration
+	 * to "value current_iteration"
+	 */
+
+	uint32_t basereg = ROM32(bios->data[offset + 1]);
+	uint32_t count = bios->data[offset + 5];
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: BaseReg: 0x%08X, Count: 0x%02X\n", offset, basereg, count);
+
+	for (i = 0; i < count; i++) {
+		uint32_t reg = basereg + i * 4;
+		uint32_t data = ROM32(bios->data[offset + 6 + i * 4]);
+
+		bios_wr32(dev, reg, data);
+	}
+
+	return true;
+}
+
+static bool init_sub_direct(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_SUB_DIRECT   opcode: 0x5B ('[')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): subroutine offset (in bios)
+	 *
+	 * Calls a subroutine that will execute commands until INIT_DONE
+	 * is found. 
+	 */
+
+	uint16_t sub_offset = ROM16(bios->data[offset + 1]);
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Executing subroutine at 0x%04X\n", offset, sub_offset);
+
+	parse_init_table(dev, bios, sub_offset, iexec);
+
+	BIOSLOG(dev, "0x%04X: End of 0x%04X subroutine\n", offset, sub_offset);
+
+	return true;
+}
+
+static bool init_copy_nv_reg(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_COPY_NV_REG   opcode: 0x5F ('_')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): src reg
+	 * offset + 5  (8  bit): shift
+	 * offset + 6  (32 bit): src mask
+	 * offset + 10 (32 bit): xor
+	 * offset + 14 (32 bit): dst reg
+	 * offset + 18 (32 bit): dst mask
+	 *
+	 * Shift REGVAL("src reg") right by (signed) "shift", AND result with
+	 * "src mask", then XOR with "xor". Write this OR'd with
+	 * (REGVAL("dst reg") AND'd with "dst mask") to "dst reg"
+	 */
+
+	uint32_t srcreg = *((uint32_t *)(&bios->data[offset + 1]));
+	uint8_t shift = bios->data[offset + 5];
+	uint32_t srcmask = *((uint32_t *)(&bios->data[offset + 6]));
+	uint32_t xor = *((uint32_t *)(&bios->data[offset + 10]));
+	uint32_t dstreg = *((uint32_t *)(&bios->data[offset + 14]));
+	uint32_t dstmask = *((uint32_t *)(&bios->data[offset + 18]));
+	uint32_t srcvalue, dstvalue;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: SrcReg: 0x%08X, Shift: 0x%02X, SrcMask: 0x%08X, Xor: 0x%08X, DstReg: 0x%08X, DstMask: 0x%08X\n",
+		offset, srcreg, shift, srcmask, xor, dstreg, dstmask);
+
+	srcvalue = bios_rd32(dev, srcreg);
+
+	if (shift < 0x80)
+		srcvalue >>= shift;
+	else
+		srcvalue <<= (0x100 - shift);
+
+	srcvalue = (srcvalue & srcmask) ^ xor;
+
+	dstvalue = bios_rd32(dev, dstreg) & dstmask;
+
+	bios_wr32(dev, dstreg, dstvalue | srcvalue);
+
+	return true;
+}
+
+static bool init_zm_index_io(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_INDEX_IO   opcode: 0x62 ('b')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): CRTC index
+	 * offset + 4  (8  bit): data
+	 *
+	 * Write "data" to index "CRTC index" of "CRTC port"
+	 */
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t crtcindex = bios->data[offset + 3];
+	uint8_t data = bios->data[offset + 4];
+
+	if (!iexec->execute)
+		return true;
+
+	bios_idxprt_wr(dev, crtcport, crtcindex, data);
+
+	return true;
+}
+
+static bool init_compute_mem(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_COMPUTE_MEM   opcode: 0x63 ('c')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * This opcode is meant to set NV_PFB_CFG0 (0x100200) appropriately so
+	 * that the hardware can correctly calculate how much VRAM it has
+	 * (and subsequently report that value in NV_PFB_CSTATUS (0x10020C))
+	 *
+	 * The implementation of this opcode in general consists of two parts:
+	 * 1) determination of the memory bus width
+	 * 2) determination of how many of the card's RAM pads have ICs attached
+	 *
+	 * 1) is done by a cunning combination of writes to offsets 0x1c and
+	 * 0x3c in the framebuffer, and seeing whether the written values are
+	 * read back correctly. This then affects bits 4-7 of NV_PFB_CFG0
+	 *
+	 * 2) is done by a cunning combination of writes to an offset slightly
+	 * less than the maximum memory reported by NV_PFB_CSTATUS, then seeing
+	 * if the test pattern can be read back. This then affects bits 12-15 of
+	 * NV_PFB_CFG0
+	 *
+	 * In this context a "cunning combination" may include multiple reads
+	 * and writes to varying locations, often alternating the test pattern
+	 * and 0, doubtless to make sure buffers are filled, residual charges
+	 * on tracks are removed etc.
+	 *
+	 * Unfortunately, the "cunning combination"s mentioned above, and the
+	 * changes to the bits in NV_PFB_CFG0 differ with nearly every bios
+	 * trace I have.
+	 *
+	 * Therefore, we cheat and assume the value of NV_PFB_CFG0 with which
+	 * we started was correct, and use that instead
+	 */
+
+	/* no iexec->execute check by design */
+
+	/* on every card I've seen, this step gets done for us earlier in the init scripts
+	uint8_t crdata = bios_idxprt_rd(dev, NV_VIO_SRX, 0x01);
+	bios_idxprt_wr(dev, NV_VIO_SRX, 0x01, crdata | 0x20);
+	*/
+
+	/* this also has probably been done in the scripts, but an mmio trace of
+	 * s3 resume shows nvidia doing it anyway (unlike the NV_VIO_SRX write)
+	 */
+	bios_wr32(dev, NV_PFB_REFCTRL, NV_PFB_REFCTRL_VALID_1);
+
+	/* write back the saved configuration value */
+	bios_wr32(dev, NV_PFB_CFG0, saved_nv_pfb_cfg0);
+
+	return true;
+}
+
+static bool init_reset(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_RESET   opcode: 0x65 ('e')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (32 bit): value1
+	 * offset + 9  (32 bit): value2
+	 *
+	 * Assign "value1" to "register", then assign "value2" to "register"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint32_t value1 = ROM32(bios->data[offset + 5]);
+	uint32_t value2 = ROM32(bios->data[offset + 9]);
+	uint32_t pci_nv_19, pci_nv_20;
+
+	/* no iexec->execute check by design */
+
+	pci_nv_19 = bios_rd32(dev, NV_PBUS_PCI_NV_19);
+	bios_wr32(dev, NV_PBUS_PCI_NV_19, 0);
+	bios_wr32(dev, reg, value1);
+
+	BIOS_USLEEP(10);
+
+	bios_wr32(dev, reg, value2);
+	bios_wr32(dev, NV_PBUS_PCI_NV_19, pci_nv_19);
+
+	pci_nv_20 = bios_rd32(dev, NV_PBUS_PCI_NV_20);
+	pci_nv_20 &= ~NV_PBUS_PCI_NV_20_ROM_SHADOW_ENABLED;	/* 0xfffffffe */
+	bios_wr32(dev, NV_PBUS_PCI_NV_20, pci_nv_20);
+
+	return true;
+}
+
+static bool init_configure_mem(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CONFIGURE_MEM   opcode: 0x66 ('f')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * Equivalent to INIT_DONE on bios version 3 or greater.
+	 * For early bios versions, sets up the memory registers, using values
+	 * taken from the memory init table
+	 */
+
+	/* no iexec->execute check by design */
+
+	uint16_t meminitoffs = bios->legacy.mem_init_tbl_ptr + MEM_INIT_SIZE * (bios_idxprt_rd(dev, NV_CIO_CRX__COLOR, NV_CIO_CRE_SCRATCH4__INDEX) >> 4);
+	uint16_t seqtbloffs = bios->legacy.sdr_seq_tbl_ptr, meminitdata = meminitoffs + 6;
+	uint32_t reg, data;
+
+	if (bios->major_version > 2)
+		return false;
+
+	bios_idxprt_wr(dev, NV_VIO_SRX, NV_VIO_SR_CLOCK_INDEX,
+		       bios_idxprt_rd(dev, NV_VIO_SRX, NV_VIO_SR_CLOCK_INDEX) | 0x20);
+
+	if (bios->data[meminitoffs] & 1)
+		seqtbloffs = bios->legacy.ddr_seq_tbl_ptr;
+
+	for (reg = ROM32(bios->data[seqtbloffs]);
+	     reg != 0xffffffff;
+	     reg = ROM32(bios->data[seqtbloffs += 4])) {
+
+		switch (reg) {
+		case NV_PFB_PRE:
+			data = NV_PFB_PRE_CMD_PRECHARGE;
+			break;
+		case NV_PFB_PAD:
+			data = NV_PFB_PAD_CKE_NORMAL;
+			break;
+		case NV_PFB_REF:
+			data = NV_PFB_REF_CMD_REFRESH;
+			break;
+		default:
+			data = ROM32(bios->data[meminitdata]);
+			meminitdata += 4;
+			if (data == 0xffffffff)
+				continue;
+		}
+
+		bios_wr32(dev, reg, data);
+	}
+
+	return true;
+}
+
+static bool init_configure_clk(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CONFIGURE_CLK   opcode: 0x67 ('g')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * Equivalent to INIT_DONE on bios version 3 or greater.
+	 * For early bios versions, sets up the NVClk and MClk PLLs, using
+	 * values taken from the memory init table
+	 */
+
+	/* no iexec->execute check by design */
+
+	uint16_t meminitoffs = bios->legacy.mem_init_tbl_ptr + MEM_INIT_SIZE * (bios_idxprt_rd(dev, NV_CIO_CRX__COLOR, NV_CIO_CRE_SCRATCH4__INDEX) >> 4);
+	int clock;
+
+	if (bios->major_version > 2)
+		return false;
+
+	clock = ROM16(bios->data[meminitoffs + 4]) * 10;
+	setPLL(dev, bios, NV_PRAMDAC_NVPLL_COEFF, clock);
+
+	clock = ROM16(bios->data[meminitoffs + 2]) * 10;
+	if (bios->data[meminitoffs] & 1) /* DDR */
+		clock *= 2;
+	setPLL(dev, bios, NV_PRAMDAC_MPLL_COEFF, clock);
+
+	return true;
+}
+
+static bool init_configure_preinit(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CONFIGURE_PREINIT   opcode: 0x68 ('h')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * Equivalent to INIT_DONE on bios version 3 or greater.
+	 * For early bios versions, does early init, loading ram and crystal
+	 * configuration from straps into CR3C
+	 */
+
+	/* no iexec->execute check by design */
+
+	uint32_t straps = bios_rd32(dev, NV_PEXTDEV_BOOT_0);
+	uint8_t cr3c = ((straps << 2) & 0xf0) | (straps & (1 << 6));
+
+	if (bios->major_version > 2)
+		return false;
+
+	bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, NV_CIO_CRE_SCRATCH4__INDEX, cr3c);
+
+	return true;
+}
+
+static bool init_io(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO   opcode: 0x69 ('i')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): mask
+	 * offset + 4  (8  bit): data
+	 *
+	 * Assign ((IOVAL("crtc port") & "mask") | "data") to "crtc port"
+	 */
+
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t mask = bios->data[offset + 3];
+	uint8_t data = bios->data[offset + 4];
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Mask: 0x%02X, Data: 0x%02X\n",
+		offset, crtcport, mask, data);
+
+	bios_port_wr(dev, crtcport, (bios_port_rd(dev, crtcport) & mask) | data);
+
+	return true;
+}
+
+static bool init_sub(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_SUB   opcode: 0x6B ('k')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): script number
+	 *
+	 * Execute script number "script number", as a subroutine
+	 */
+
+	uint8_t sub = bios->data[offset + 1];
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Calling script %d\n", offset, sub);
+
+	parse_init_table(dev, bios,
+			 ROM16(bios->data[bios->init_script_tbls_ptr + sub * 2]),
+			 iexec);
+
+	BIOSLOG(dev, "0x%04X: End of script %d\n", offset, sub);
+
+	return true;
+}
+
+static bool init_ram_condition(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_RAM_CONDITION   opcode: 0x6D ('m')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): mask
+	 * offset + 2  (8 bit): cmpval
+	 *
+	 * Test if (NV_PFB_BOOT_0 & "mask") equals "cmpval".
+	 * If condition not met skip subsequent opcodes until condition is
+	 * inverted (INIT_NOT), or we hit INIT_RESUME
+	 */
+
+	uint8_t mask = bios->data[offset + 1];
+	uint8_t cmpval = bios->data[offset + 2];
+	uint8_t data;
+
+	if (!iexec->execute)
+		return true;
+
+	data = bios_rd32(dev, NV_PFB_BOOT_0) & mask;
+
+	BIOSLOG(dev, "0x%04X: Checking if 0x%08X equals 0x%08X\n", offset, data, cmpval);
+
+	if (data == cmpval)
+		BIOSLOG(dev, "0x%04X: Condition fulfilled -- continuing to execute\n", offset);
+	else {
+		BIOSLOG(dev, "0x%04X: Condition not fulfilled -- skipping following commands\n", offset);
+		iexec->execute = false;
+	}
+
+	return true;
+}
+
+static bool init_nv_reg(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_NV_REG   opcode: 0x6E ('n')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (32 bit): mask
+	 * offset + 9  (32 bit): data
+	 *
+	 * Assign ((REGVAL("register") & "mask") | "data") to "register"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint32_t mask = ROM32(bios->data[offset + 5]);
+	uint32_t data = ROM32(bios->data[offset + 9]);
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, Mask: 0x%08X, Data: 0x%08X\n", offset, reg, mask, data);
+
+	bios_wr32(dev, reg, (bios_rd32(dev, reg) & mask) | data);
+
+	return true;
+}
+
+static bool init_macro(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_MACRO   opcode: 0x6F ('o')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): macro number
+	 *
+	 * Look up macro index "macro number" in the macro index table.
+	 * The macro index table entry has 1 byte for the index in the macro table,
+	 * and 1 byte for the number of times to repeat the macro.
+	 * The macro table entry has 4 bytes for the register address and
+	 * 4 bytes for the value to write to that register
+	 */
+
+	uint8_t macro_index_tbl_idx = bios->data[offset + 1];
+	uint16_t tmp = bios->macro_index_tbl_ptr + (macro_index_tbl_idx * MACRO_INDEX_SIZE);
+	uint8_t macro_tbl_idx = bios->data[tmp];
+	uint8_t count = bios->data[tmp + 1];
+	uint32_t reg, data;
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Macro: 0x%02X, MacroTableIndex: 0x%02X, Count: 0x%02X\n",
+		offset, macro_index_tbl_idx, macro_tbl_idx, count);
+
+	for (i = 0; i < count; i++) {
+		uint16_t macroentryptr = bios->macro_tbl_ptr + (macro_tbl_idx + i) * MACRO_SIZE;
+
+		reg = ROM32(bios->data[macroentryptr]);
+		data = ROM32(bios->data[macroentryptr + 4]);
+
+		bios_wr32(dev, reg, data);
+	}
+
+	return true;
+}
+
+static bool init_done(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_DONE   opcode: 0x71 ('q')
+	 *
+	 * offset      (8  bit): opcode
+	 *
+	 * End the current script
+	 */
+
+	/* mild retval abuse to stop parsing this table */
+	return false;
+}
+
+static bool init_resume(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_RESUME   opcode: 0x72 ('r')
+	 *
+	 * offset      (8  bit): opcode
+	 *
+	 * End the current execute / no-execute condition
+	 */
+
+	if (iexec->execute)
+		return true;
+
+	iexec->execute = true;
+	BIOSLOG(dev, "0x%04X: ---- Executing following commands ----\n", offset);
+
+	return true;
+}
+
+static bool init_time(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_TIME   opcode: 0x74 ('t')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): time
+	 *
+	 * Sleep for "time" microseconds.
+	 */
+
+	uint16_t time = ROM16(bios->data[offset + 1]);
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Sleeping for 0x%04X microseconds\n", offset, time);
+
+	BIOS_USLEEP(time);
+
+	return true;
+}
+
+static bool init_condition(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_CONDITION   opcode: 0x75 ('u')
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): condition number
+	 *
+	 * Check condition "condition number" in the condition table.
+	 * If condition not met skip subsequent opcodes until condition is
+	 * inverted (INIT_NOT), or we hit INIT_RESUME
+	 */
+
+	uint8_t cond = bios->data[offset + 1];
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Condition: 0x%02X\n", offset, cond);
+
+	if (bios_condition_met(dev, bios, offset, cond))
+		BIOSLOG(dev, "0x%04X: Condition fulfilled -- continuing to execute\n", offset);
+	else {
+		BIOSLOG(dev, "0x%04X: Condition not fulfilled -- skipping following commands\n", offset);
+		iexec->execute = false;
+	}
+
+	return true;
+}
+
+static bool init_io_condition(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_IO_CONDITION  opcode: 0x76
+	 *
+	 * offset      (8 bit): opcode
+	 * offset + 1  (8 bit): condition number
+	 *
+	 * Check condition "condition number" in the io condition table.
+	 * If condition not met skip subsequent opcodes until condition is
+	 * inverted (INIT_NOT), or we hit INIT_RESUME
+	 */
+
+	uint8_t cond = bios->data[offset + 1];
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: IO condition: 0x%02X\n", offset, cond);
+
+	if (io_condition_met(dev, bios, offset, cond))
+		BIOSLOG(dev, "0x%04X: Condition fulfilled -- continuing to execute\n", offset);
+	else {
+		BIOSLOG(dev, "0x%04X: Condition not fulfilled -- skipping following commands\n", offset);
+		iexec->execute = false;
+	}
+
+	return true;
+}
+
+static bool init_index_io(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_INDEX_IO   opcode: 0x78 ('x')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (16 bit): CRTC port
+	 * offset + 3  (8  bit): CRTC index
+	 * offset + 4  (8  bit): mask
+	 * offset + 5  (8  bit): data
+	 *
+	 * Read value at index "CRTC index" on "CRTC port", AND with "mask", OR with "data", write-back
+	 */
+
+	uint16_t crtcport = ROM16(bios->data[offset + 1]);
+	uint8_t crtcindex = bios->data[offset + 3];
+	uint8_t mask = bios->data[offset + 4];
+	uint8_t data = bios->data[offset + 5];
+	uint8_t value;
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Port: 0x%04X, Index: 0x%02X, Mask: 0x%02X, Data: 0x%02X\n",
+		offset, crtcport, crtcindex, mask, data);
+
+	value = (bios_idxprt_rd(dev, crtcport, crtcindex) & mask) | data;
+	bios_idxprt_wr(dev, crtcport, crtcindex, value);
+
+	return true;
+}
+
+static bool init_pll(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_PLL   opcode: 0x79 ('y')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (16 bit): freq
+	 *
+	 * Set PLL register "register" to coefficients for frequency (10kHz) "freq"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint16_t freq = ROM16(bios->data[offset + 5]);
+
+	if (!iexec->execute)
+		return true;
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, Freq: %d0kHz\n", offset, reg, freq);
+
+	setPLL(dev, bios, reg, freq * 10);
+
+	return true;
+}
+
+static bool init_zm_reg(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_REG   opcode: 0x7A ('z')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): register
+	 * offset + 5  (32 bit): value
+	 *
+	 * Assign "value" to "register"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint32_t value = ROM32(bios->data[offset + 5]);
+
+	if (!iexec->execute)
+		return true;
+
+	bios_wr32(dev, reg, value);
+
+	return true;
+}
+
+static bool init_8e(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_8E   opcode: 0x8E ('')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * The purpose of this opcode is unclear (being for nv50 cards), and
+	 * the literal functionality can be seen in the code below.
+	 *
+	 * A brief synopsis is that for each entry in a table pointed to by the
+	 * DCB table header, depending on the settings of various bits, various
+	 * other bits in registers 0xe100, 0xe104, and 0xe108, are set or
+	 * cleared.
+	 */
+
+	uint8_t headerlen = bios->data[bios->bdcb.init8e_table_ptr + 1];
+	uint8_t entries = bios->data[bios->bdcb.init8e_table_ptr + 2];
+	uint8_t recordlen = bios->data[bios->bdcb.init8e_table_ptr + 3];
+	int i;
+
+	if (bios->bdcb.version != 0x40) {
+		NV_ERROR(dev, "DCB table not version 4.0\n");
+		return false;
+	}
+	if (!bios->bdcb.init8e_table_ptr) {
+		NV_WARN(dev, "Invalid pointer to INIT_8E table\n");
+		return false;
+	}
+
+	for (i = 0; i < entries; i++) {
+		uint32_t entry = ROM32(bios->data[bios->bdcb.init8e_table_ptr + headerlen + recordlen * i]);
+		int shift = (entry & 0x1f) * 4;
+		uint32_t mask;
+		uint32_t reg = 0xe104;
+		uint32_t data;
+
+		if ((entry & 0xff00) == 0xff00)
+			continue;
+
+		if (shift >= 32) {
+			reg += 4;
+			shift -= 32;
+		}
+		shift %= 32;
+
+		mask = ~(3 << shift);
+		if (entry & (1 << 24))
+			data = (entry >> 21);
+		else
+			data = (entry >> 19);
+		data = ((data & 3) ^ 2) << shift;
+
+		BIOSLOG(dev, "0x%04X: Entry: 0x%08X, Reg: 0x%08X, Shift: 0x%02X, Mask: 0x%08X, Data: 0x%08X\n",
+			offset, entry, reg, shift, mask, data);
+
+		bios_wr32(dev, reg, (bios_rd32(dev, reg) & mask) | data);
+
+		reg = 0xe100;
+		shift = entry & 0x1f;
+
+		mask = ~(1 << 16 | 1);
+		mask = mask << shift | mask >> (32 - shift);
+		data = 0;
+		if ((entry & (3 << 25)) == (1 << 25))
+			data |= 1;
+		if ((entry & (3 << 25)) == (2 << 25))
+			data |= 0x10000;
+		data <<= shift;
+
+		BIOSLOG(dev, "0x%04X: Entry: 0x%08X, Reg: 0x%08X, Shift: 0x%02X, Mask: 0x%08X, Data: 0x%08X\n",
+			offset, entry, reg, shift, mask, data);
+
+		bios_wr32(dev, reg, (bios_rd32(dev, reg) & mask) | data);
+	}
+
+	return true;
+}
+
+/* hack to avoid moving the itbl_entry array before this function */
+int init_ram_restrict_zm_reg_group_blocklen = 0;
+
+static bool init_ram_restrict_zm_reg_group(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_RAM_RESTRICT_ZM_REG_GROUP   opcode: 0x8F ('')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): reg
+	 * offset + 5  (8  bit): regincrement
+	 * offset + 6  (8  bit): count
+	 * offset + 7  (32 bit): value 1,1
+	 * ...
+	 *
+	 * Use the RAMCFG strap of PEXTDEV_BOOT as an index into the table at
+	 * ram_restrict_table_ptr. The value read from here is 'n', and
+	 * "value 1,n" gets written to "reg". This repeats "count" times and on
+	 * each iteration 'm', "reg" increases by "regincrement" and
+	 * "value m,n" is used. The extent of n is limited by a number read
+	 * from the 'M' BIT table, herein called "blocklen"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint8_t regincrement = bios->data[offset + 5];
+	uint8_t count = bios->data[offset + 6];
+	uint32_t strap_ramcfg, data;
+	uint16_t blocklen;
+	uint8_t index;
+	int i;
+
+	/* previously set by 'M' BIT table */
+	blocklen = init_ram_restrict_zm_reg_group_blocklen;
+
+	if (!iexec->execute)
+		return true;
+
+	if (!blocklen) {
+		NV_ERROR(dev, "0x%04X: Zero block length - has the M table "
+				"been parsed?\n", offset);
+		return false;
+	}
+
+	strap_ramcfg = (bios_rd32(dev, NV_PEXTDEV_BOOT_0) >> 2) & 0xf;
+	index = bios->data[bios->ram_restrict_tbl_ptr + strap_ramcfg];
+
+	BIOSLOG(dev, "0x%04X: Reg: 0x%08X, RegIncrement: 0x%02X, Count: 0x%02X, StrapRamCfg: 0x%02X, Index: 0x%02X\n",
+		offset, reg, regincrement, count, strap_ramcfg, index);
+
+	for (i = 0; i < count; i++) {
+		data = ROM32(bios->data[offset + 7 + index * 4 + blocklen * i]);
+
+		bios_wr32(dev, reg, data);
+
+		reg += regincrement;
+	}
+
+	return true;
+}
+
+static bool init_copy_zm_reg(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_COPY_ZM_REG   opcode: 0x90 ('')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): src reg
+	 * offset + 5  (32 bit): dst reg
+	 *
+	 * Put contents of "src reg" into "dst reg"
+	 */
+
+	uint32_t srcreg = ROM32(bios->data[offset + 1]);
+	uint32_t dstreg = ROM32(bios->data[offset + 5]);
+
+	if (!iexec->execute)
+		return true;
+
+	bios_wr32(dev, dstreg, bios_rd32(dev, srcreg));
+
+	return true;
+}
+
+static bool init_zm_reg_group_addr_latched(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_ZM_REG_GROUP_ADDRESS_LATCHED   opcode: 0x91 ('')
+	 *
+	 * offset      (8  bit): opcode
+	 * offset + 1  (32 bit): dst reg
+	 * offset + 5  (8  bit): count
+	 * offset + 6  (32 bit): data 1
+	 * ...
+	 *
+	 * For each of "count" values write "data n" to "dst reg"
+	 */
+
+	uint32_t reg = ROM32(bios->data[offset + 1]);
+	uint8_t count = bios->data[offset + 5];
+	int i;
+
+	if (!iexec->execute)
+		return true;
+
+	for (i = 0; i < count; i++) {
+		uint32_t data = ROM32(bios->data[offset + 6 + 4 * i]);
+		bios_wr32(dev, reg, data);
+	}
+
+	return true;
+}
+
+static bool init_reserved(struct drm_device *dev, struct nvbios *bios, uint16_t offset, init_exec_t *iexec)
+{
+	/* INIT_RESERVED   opcode: 0x92 ('')
+	 *
+	 * offset      (8 bit): opcode
+	 *
+	 * Seemingly does nothing
+	 */
+
+	return true;
+}
+
+static init_tbl_entry_t itbl_entry[] = {
+	/* command name                       , id  , length  , offset  , mult    , command handler                 */
+	/* INIT_PROG (0x31, 15, 10, 4) removed due to no example of use */
+	{ "INIT_IO_RESTRICT_PROG"             , 0x32, 11      , 6       , 4       , init_io_restrict_prog           },
+	{ "INIT_REPEAT"                       , 0x33, 2       , 0       , 0       , init_repeat                     },
+	{ "INIT_IO_RESTRICT_PLL"              , 0x34, 12      , 7       , 2       , init_io_restrict_pll            },
+	{ "INIT_END_REPEAT"                   , 0x36, 1       , 0       , 0       , init_end_repeat                 },
+	{ "INIT_COPY"                         , 0x37, 11      , 0       , 0       , init_copy                       },
+	{ "INIT_NOT"                          , 0x38, 1       , 0       , 0       , init_not                        },
+	{ "INIT_IO_FLAG_CONDITION"            , 0x39, 2       , 0       , 0       , init_io_flag_condition          },
+	{ "INIT_INDEX_ADDRESS_LATCHED"        , 0x49, 18      , 17      , 2       , init_idx_addr_latched           },
+	{ "INIT_IO_RESTRICT_PLL2"             , 0x4A, 11      , 6       , 4       , init_io_restrict_pll2           },
+	{ "INIT_PLL2"                         , 0x4B, 9       , 0       , 0       , init_pll2                       },
+	{ "INIT_I2C_BYTE"                     , 0x4C, 4       , 3       , 3       , init_i2c_byte                   },
+	{ "INIT_ZM_I2C_BYTE"                  , 0x4D, 4       , 3       , 2       , init_zm_i2c_byte                },
+	{ "INIT_ZM_I2C"                       , 0x4E, 4       , 3       , 1       , init_zm_i2c                     },
+	{ "INIT_TMDS"                         , 0x4F, 5       , 0       , 0       , init_tmds                       },
+	{ "INIT_ZM_TMDS_GROUP"                , 0x50, 3       , 2       , 2       , init_zm_tmds_group              },
+	{ "INIT_CR_INDEX_ADDRESS_LATCHED"     , 0x51, 5       , 4       , 1       , init_cr_idx_adr_latch           },
+	{ "INIT_CR"                           , 0x52, 4       , 0       , 0       , init_cr                         },
+	{ "INIT_ZM_CR"                        , 0x53, 3       , 0       , 0       , init_zm_cr                      },
+	{ "INIT_ZM_CR_GROUP"                  , 0x54, 2       , 1       , 2       , init_zm_cr_group                },
+	{ "INIT_CONDITION_TIME"               , 0x56, 3       , 0       , 0       , init_condition_time             },
+	{ "INIT_ZM_REG_SEQUENCE"              , 0x58, 6       , 5       , 4       , init_zm_reg_sequence            },
+	/* INIT_INDIRECT_REG (0x5A, 7, 0, 0) removed due to no example of use */
+	{ "INIT_SUB_DIRECT"                   , 0x5B, 3       , 0       , 0       , init_sub_direct                 },
+	{ "INIT_COPY_NV_REG"                  , 0x5F, 22      , 0       , 0       , init_copy_nv_reg                },
+	{ "INIT_ZM_INDEX_IO"                  , 0x62, 5       , 0       , 0       , init_zm_index_io                },
+	{ "INIT_COMPUTE_MEM"                  , 0x63, 1       , 0       , 0       , init_compute_mem                },
+	{ "INIT_RESET"                        , 0x65, 13      , 0       , 0       , init_reset                      },
+	{ "INIT_CONFIGURE_MEM"                , 0x66, 1       , 0       , 0       , init_configure_mem              },
+	{ "INIT_CONFIGURE_CLK"                , 0x67, 1       , 0       , 0       , init_configure_clk              },
+	{ "INIT_CONFIGURE_PREINIT"            , 0x68, 1       , 0       , 0       , init_configure_preinit          },
+	{ "INIT_IO"                           , 0x69, 5       , 0       , 0       , init_io                         },
+	{ "INIT_SUB"                          , 0x6B, 2       , 0       , 0       , init_sub                        },
+	{ "INIT_RAM_CONDITION"                , 0x6D, 3       , 0       , 0       , init_ram_condition              },
+	{ "INIT_NV_REG"                       , 0x6E, 13      , 0       , 0       , init_nv_reg                     },
+	{ "INIT_MACRO"                        , 0x6F, 2       , 0       , 0       , init_macro                      },
+	{ "INIT_DONE"                         , 0x71, 1       , 0       , 0       , init_done                       },
+	{ "INIT_RESUME"                       , 0x72, 1       , 0       , 0       , init_resume                     },
+	/* INIT_RAM_CONDITION2 (0x73, 9, 0, 0) removed due to no example of use */
+	{ "INIT_TIME"                         , 0x74, 3       , 0       , 0       , init_time                       },
+	{ "INIT_CONDITION"                    , 0x75, 2       , 0       , 0       , init_condition                  },
+	{ "INIT_IO_CONDITION"                 , 0x76, 2       , 0       , 0       , init_io_condition               },
+	{ "INIT_INDEX_IO"                     , 0x78, 6       , 0       , 0       , init_index_io                   },
+	{ "INIT_PLL"                          , 0x79, 7       , 0       , 0       , init_pll                        },
+	{ "INIT_ZM_REG"                       , 0x7A, 9       , 0       , 0       , init_zm_reg                     },
+	{ "INIT_8E"                           , 0x8E, 1       , 0       , 0       , init_8e                         },
+	/* INIT_RAM_RESTRICT_ZM_REG_GROUP's mult is loaded by M table in BIT */
+	{ "INIT_RAM_RESTRICT_ZM_REG_GROUP"    , 0x8F, 7       , 6       , 0       , init_ram_restrict_zm_reg_group  },
+	{ "INIT_COPY_ZM_REG"                  , 0x90, 9       , 0       , 0       , init_copy_zm_reg                },
+	{ "INIT_ZM_REG_GROUP_ADDRESS_LATCHED" , 0x91, 6       , 5       , 4       , init_zm_reg_group_addr_latched  },
+	{ "INIT_RESERVED"                     , 0x92, 1       , 0       , 0       , init_reserved                   },
+	{ 0                                   , 0   , 0       , 0       , 0       , 0                               }
+};
+
+static unsigned int get_init_table_entry_length(struct nvbios *bios, unsigned int offset, int i)
+{
+	/* Calculates the length of a given init table entry. */
+	return itbl_entry[i].length + bios->data[offset + itbl_entry[i].length_offset]*itbl_entry[i].length_multiplier;
+}
+
+#define MAX_TABLE_OPS 1000
+
+static int parse_init_table(struct drm_device *dev, struct nvbios *bios, unsigned int offset, init_exec_t *iexec)
+{
+	/* Parses all commands in an init table.
+	 *
+	 * We start out executing all commands found in the init table. Some
+	 * opcodes may change the status of iexec->execute to SKIP, which will
+	 * cause the following opcodes to perform no operation until the value
+	 * is changed back to EXECUTE.
+	 */
+
+	int count = 0, i;
+	uint8_t id;
+
+	/* Loop until INIT_DONE causes us to break out of the loop
+	 * (or until offset > bios length just in case... )
+	 * (and no more than MAX_TABLE_OPS iterations, just in case... ) */
+	while ((offset < bios->length) && (count++ < MAX_TABLE_OPS)) {
+		id = bios->data[offset];
+
+		/* Find matching id in itbl_entry */
+		for (i = 0; itbl_entry[i].name && (itbl_entry[i].id != id); i++)
+			;
+
+		if (itbl_entry[i].name) {
+			BIOSLOG(dev, "0x%04X: [ (0x%02X) - %s ]\n",
+				offset, itbl_entry[i].id, itbl_entry[i].name);
+
+			/* execute eventual command handler */
+			if (itbl_entry[i].handler)
+				if (!(*itbl_entry[i].handler)(dev, bios, offset, iexec))
+					break;
+		} else {
+			NV_ERROR(dev, "0x%04X: Init table command not found: "
+					"0x%02X\n", offset, id);
+			return -ENOENT;
+		}
+
+		/* Add the offset of the current command including all data
+		 * of that command. The offset will then be pointing on the
+		 * next op code.
+		 */
+		offset += get_init_table_entry_length(bios, offset, i);
+	}
+
+	if (offset >= bios->length)
+		NV_WARN(dev,
+			"Offset 0x%04X greater than known bios image length.  "
+			"Corrupt image?\n", offset);
+	if (count >= MAX_TABLE_OPS)
+		NV_WARN(dev, "More than %d opcodes to a table is unlikely, "
+			       "is the bios image corrupt?\n", MAX_TABLE_OPS);
+
+	return 0;
+}
+
+static void parse_init_tables(struct drm_device *dev, struct nvbios *bios)
+{
+	/* Loops and calls parse_init_table() for each present table. */
+
+	int i = 0;
+	uint16_t table;
+	init_exec_t iexec = {true, false};
+
+	if (bios->old_style_init) {
+		if (bios->init_script_tbls_ptr)
+			parse_init_table(dev, bios, bios->init_script_tbls_ptr, &iexec);
+		if (bios->extra_init_script_tbl_ptr)
+			parse_init_table(dev, bios, bios->extra_init_script_tbl_ptr, &iexec);
+
+		return;
+	}
+
+	while ((table = ROM16(bios->data[bios->init_script_tbls_ptr + i]))) {
+		NV_INFO(dev, "Parsing VBIOS init table %d at offset 0x%04X\n",
+			i / 2, table);
+		BIOSLOG(dev, "0x%04X: ------ Executing following commands ------\n", table);
+
+		parse_init_table(dev, bios, table, &iexec);
+		i += 2;
+	}
+}
+
+static void link_head_and_output(struct drm_device *dev, struct dcb_entry *dcbent, int head, bool dl)
+{
+	/* The BIOS scripts don't do this for us, sadly
+	 * Luckily we do know the values ;-)
+	 *
+	 * head < 0 indicates we wish to force a setting with the overrideval
+	 * (for VT restore etc.)
+	 */
+
+	int ramdac = (dcbent->or & OUTPUT_C) >> 2;
+	uint8_t tmds04 = 0x80;
+
+	if (head != ramdac)
+		tmds04 = 0x88;
+
+	if (dcbent->type == OUTPUT_LVDS)
+		tmds04 |= 0x01;
+
+	nv_write_tmds(dev, dcbent->or, 0, 0x04, tmds04);
+
+	if (dl)	/* dual link */
+		nv_write_tmds(dev, dcbent->or, 1, 0x04, tmds04 ^ 0x08);
+}
+
+static uint16_t clkcmptable(struct nvbios *bios, uint16_t clktable, int pxclk)
+{
+	int compare_record_len, i = 0;
+	uint16_t compareclk, scriptptr = 0;
+
+	if (bios->major_version < 5) /* pre BIT */
+		compare_record_len = 3;
+	else
+		compare_record_len = 4;
+
+	do {
+		compareclk = ROM16(bios->data[clktable + compare_record_len * i]);
+		if (pxclk >= compareclk * 10) {
+			if (bios->major_version < 5) {
+				uint8_t tmdssub = bios->data[clktable + 2 + compare_record_len * i];
+				scriptptr = ROM16(bios->data[bios->init_script_tbls_ptr + tmdssub * 2]);
+			} else
+				scriptptr = ROM16(bios->data[clktable + 2 + compare_record_len * i]);
+			break;
+		}
+		i++;
+	} while (compareclk);
+
+	return scriptptr;
+}
+
+static void run_digital_op_script(struct drm_device *dev, uint16_t scriptptr, struct dcb_entry *dcbent, int head, bool dl)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	init_exec_t iexec = {true, false};
+
+	NV_TRACE(dev, "0x%04X: Parsing digital output script table\n",
+		 scriptptr);
+	bios_idxprt_wr(dev, NV_CIO_CRX__COLOR, NV_CIO_CRE_44,
+		       head ? NV_CIO_CRE_44_HEADB : NV_CIO_CRE_44_HEADA);
+	/* note: if dcb entries have been merged, index may be misleading */
+	NVWriteVgaCrtc5758(dev, head, 0, dcbent->index);
+	parse_init_table(dev, bios, scriptptr, &iexec);
+
+	link_head_and_output(dev, dcbent, head, dl);
+}
+
+static int call_lvds_manufacturer_script(struct drm_device *dev, struct dcb_entry *dcbent, int head, enum LVDS_script script)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	uint8_t sub = bios->data[bios->fp.xlated_entry + script] + (bios->fp.link_c_increment && dcbent->or & OUTPUT_C ? 1 : 0);
+	uint16_t scriptofs = ROM16(bios->data[bios->init_script_tbls_ptr + sub * 2]);
+
+	if (!bios->fp.xlated_entry || !sub || !scriptofs)
+		return -EINVAL;
+
+	run_digital_op_script(dev, scriptofs, dcbent, head, bios->fp.dual_link);
+
+	if (script == LVDS_PANEL_OFF)
+		/* off-on delay in ms */
+		BIOS_USLEEP(ROM16(bios->data[bios->fp.xlated_entry + 7]));
+#ifdef __powerpc__
+	/* Powerbook specific quirks */
+	if (script == LVDS_RESET && ((dev->pci_device & 0xffff) == 0x0179 || (dev->pci_device & 0xffff) == 0x0329))
+		nv_write_tmds(dev, dcbent->or, 0, 0x02, 0x72);
+	if ((dev->pci_device & 0xffff) == 0x0179 || (dev->pci_device & 0xffff) == 0x0189 || (dev->pci_device & 0xffff) == 0x0329) {
+		if (script == LVDS_PANEL_ON) {
+			bios_wr32(dev, NV_PBUS_DEBUG_DUALHEAD_CTL, bios_rd32(dev, NV_PBUS_DEBUG_DUALHEAD_CTL) | (1 << 31));
+			bios_wr32(dev, NV_PCRTC_GPIO_EXT, bios_rd32(dev, NV_PCRTC_GPIO_EXT) | 1);
+		}
+		if (script == LVDS_PANEL_OFF) {
+			bios_wr32(dev, NV_PBUS_DEBUG_DUALHEAD_CTL, bios_rd32(dev, NV_PBUS_DEBUG_DUALHEAD_CTL) & ~(1 << 31));
+			bios_wr32(dev, NV_PCRTC_GPIO_EXT, bios_rd32(dev, NV_PCRTC_GPIO_EXT) & ~3);
+		}
+	}
+#endif
+
+	return 0;
+}
+
+static int run_lvds_table(struct drm_device *dev, struct dcb_entry *dcbent, int head, enum LVDS_script script, int pxclk)
+{
+	/* The BIT LVDS table's header has the information to setup the
+	 * necessary registers. Following the standard 4 byte header are:
+	 * A bitmask byte and a dual-link transition pxclk value for use in
+	 * selecting the init script when not using straps; 4 script pointers
+	 * for panel power, selected by output and on/off; and 8 table pointers
+	 * for panel init, the needed one determined by output, and bits in the
+	 * conf byte. These tables are similar to the TMDS tables, consisting
+	 * of a list of pxclks and script pointers.
+	 */
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	unsigned int outputset = (dcbent->or == 4) ? 1 : 0;
+	uint16_t scriptptr = 0, clktable;
+	uint8_t clktableptr = 0;
+
+	/* for now we assume version 3.0 table - g80 support will need some changes */
+
+	switch (script) {
+	case LVDS_INIT:
+		return -ENOSYS;
+	case LVDS_BACKLIGHT_ON:
+	case LVDS_PANEL_ON:
+		scriptptr = ROM16(bios->data[bios->fp.lvdsmanufacturerpointer + 7 + outputset * 2]);
+		break;
+	case LVDS_BACKLIGHT_OFF:
+	case LVDS_PANEL_OFF:
+		scriptptr = ROM16(bios->data[bios->fp.lvdsmanufacturerpointer + 11 + outputset * 2]);
+		break;
+	case LVDS_RESET:
+		if (dcbent->lvdsconf.use_straps_for_mode) {
+			if (bios->fp.dual_link)
+				clktableptr += 2;
+			if (bios->fp.BITbit1)
+				clktableptr++;
+		} else {
+			/* using EDID */
+			uint8_t fallback = bios->data[bios->fp.lvdsmanufacturerpointer + 4];
+			int fallbackcmpval = (dcbent->or == 4) ? 4 : 1;
+
+			if (bios->fp.dual_link) {
+				clktableptr += 2;
+				fallbackcmpval *= 2;
+			}
+			if (fallbackcmpval & fallback)
+				clktableptr++;
+		}
+
+		/* adding outputset * 8 may not be correct */
+		clktable = ROM16(bios->data[bios->fp.lvdsmanufacturerpointer + 15 + clktableptr * 2 + outputset * 8]);
+		if (!clktable) {
+			NV_ERROR(dev, "Pixel clock comparison table not found\n");
+			return -ENOENT;
+		}
+		scriptptr = clkcmptable(bios, clktable, pxclk);
+	}
+
+	if (!scriptptr) {
+		NV_ERROR(dev, "LVDS output init script not found\n");
+		return -ENOENT;
+	}
+	run_digital_op_script(dev, scriptptr, dcbent, head, bios->fp.dual_link);
+
+	return 0;
+}
+
+int call_lvds_script(struct drm_device *dev, struct dcb_entry *dcbent, int head, enum LVDS_script script, int pxclk)
+{
+	/* LVDS operations are multiplexed in an effort to present a single API
+	 * which works with two vastly differing underlying structures.
+	 * This acts as the demux
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	uint8_t lvds_ver = bios->data[bios->fp.lvdsmanufacturerpointer];
+	uint32_t sel_clk_binding, sel_clk;
+	int ret;
+
+	if (bios->fp.last_script_invoc == (script << 1 | head) || !lvds_ver ||
+	    (lvds_ver >= 0x30 && script == LVDS_INIT))
+		return 0;
+
+	if (!bios->fp.lvds_init_run) {
+		bios->fp.lvds_init_run = true;
+		call_lvds_script(dev, dcbent, head, LVDS_INIT, pxclk);
+	}
+
+	if (script == LVDS_PANEL_ON && bios->fp.reset_after_pclk_change)
+		call_lvds_script(dev, dcbent, head, LVDS_RESET, pxclk);
+	if (script == LVDS_RESET && bios->fp.power_off_for_reset)
+		call_lvds_script(dev, dcbent, head, LVDS_PANEL_OFF, pxclk);
+
+	NV_TRACE(dev, "Calling LVDS script %d:\n", script);
+
+	/* don't let script change pll->head binding */
+	sel_clk_binding = bios_rd32(dev, NV_PRAMDAC_SEL_CLK) & 0x50000;
+
+	if (lvds_ver < 0x30)
+		ret = call_lvds_manufacturer_script(dev, dcbent, head, script);
+	else
+		ret = run_lvds_table(dev, dcbent, head, script, pxclk);
+
+	bios->fp.last_script_invoc = (script << 1 | head);
+
+	sel_clk = NVReadRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK) & ~0x50000;
+	NVWriteRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK, sel_clk | sel_clk_binding);
+	/* some scripts set a value in NV_PBUS_POWERCTRL_2 and break video overlay */
+	nvWriteMC(dev, NV_PBUS_POWERCTRL_2, 0);
+
+	return ret;
+}
+
+struct lvdstableheader {
+	uint8_t lvds_ver, headerlen, recordlen;
+};
+
+static int parse_lvds_manufacturer_table_header(struct drm_device *dev, struct nvbios *bios, struct lvdstableheader *lth)
+{
+	/* BMP version (0xa) LVDS table has a simple header of version and
+	 * record length. The BIT LVDS table has the typical BIT table header:
+	 * version byte, header length byte, record length byte, and a byte for
+	 * the maximum number of records that can be held in the table */
+
+	uint8_t lvds_ver, headerlen, recordlen;
+
+	memset(lth, 0, sizeof(struct lvdstableheader));
+
+	if (bios->fp.lvdsmanufacturerpointer == 0x0) {
+		NV_ERROR(dev, "Pointer to LVDS manufacturer table invalid\n");
+		return -EINVAL;
+	}
+
+	lvds_ver = bios->data[bios->fp.lvdsmanufacturerpointer];
+
+	switch (lvds_ver) {
+	case 0x0a:	/* pre NV40 */
+		headerlen = 2;
+		recordlen = bios->data[bios->fp.lvdsmanufacturerpointer + 1];
+		break;
+	case 0x30:	/* NV4x */
+		headerlen = bios->data[bios->fp.lvdsmanufacturerpointer + 1];
+		if (headerlen < 0x1f) {
+			NV_ERROR(dev, "LVDS table header not understood\n");
+			return -EINVAL;
+		}
+		recordlen = bios->data[bios->fp.lvdsmanufacturerpointer + 2];
+		break;
+	case 0x40:	/* G80/G90 */
+		headerlen = bios->data[bios->fp.lvdsmanufacturerpointer + 1];
+		if (headerlen < 0x7) {
+			NV_ERROR(dev, "LVDS table header not understood\n");
+			return -EINVAL;
+		}
+		recordlen = bios->data[bios->fp.lvdsmanufacturerpointer + 2];
+		break;
+	default:
+		NV_ERROR(dev,
+			 "LVDS table revision %d.%d not currently supported\n",
+			 lvds_ver >> 4, lvds_ver & 0xf);
+		return -ENOSYS;
+	}
+
+	lth->lvds_ver = lvds_ver;
+	lth->headerlen = headerlen;
+	lth->recordlen = recordlen;
+
+	return 0;
+}
+
+static int get_fp_strap(struct drm_device *dev, struct nvbios *bios)
+{
+	/* the fp strap is normally dictated by the "User Strap" in
+	 * PEXTDEV_BOOT_0[20:16], but on BMP cards when bit 2 of the
+	 * Internal_Flags struct at 0x48 is set, the user strap gets overriden
+	 * by the PCI subsystem ID during POST, but not before the previous user
+	 * strap has been committed to CR58 for CR57=0xf on head A, which may be
+	 * read and used instead
+	 */
+
+	if (bios->major_version < 5 && bios->data[0x48] & 0x4)
+		return (NVReadVgaCrtc5758(dev, 0, 0xf) & 0xf);
+
+	if (nv_arch(dev) >= NV_50)
+		return ((bios_rd32(dev, NV_PEXTDEV_BOOT_0) >> 24) & 0xf);
+	else
+		return ((bios_rd32(dev, NV_PEXTDEV_BOOT_0) >> 16) & 0xf);
+}
+
+static int parse_fp_mode_table(struct drm_device *dev, struct nvbios *bios)
+{
+	uint8_t *fptable;
+	uint8_t fptable_ver, headerlen = 0, recordlen, fpentries = 0xf, fpindex;
+	int ret, ofs, fpstrapping;
+	struct lvdstableheader lth;
+
+	if (bios->fp.fptablepointer == 0x0) {
+		/* Apple cards don't have the fp table; the laptops use DDC */
+#ifndef __powerpc__
+		NV_ERROR(dev, "Pointer to flat panel table invalid\n");
+		if (bios->pub.chip_version != 0x67 && /* sigh, IGPs */
+		    bios->pub.chip_version != 0x73)
+			return -EINVAL;
+#endif
+		bios->pub.digital_min_front_porch = 0x4b;
+		return 0;
+	}
+
+	fptable = &bios->data[bios->fp.fptablepointer];
+	fptable_ver = fptable[0];
+
+	switch (fptable_ver) {
+	/* BMP version 0x5.0x11 BIOSen have version 1 like tables, but no version field,
+	 * and miss one of the spread spectrum/PWM bytes.
+	 * This could affect early GF2Go parts (not seen any appropriate ROMs though).
+	 * Here we assume that a version of 0x05 matches this case (combining with a
+	 * BMP version check would be better), as the common case for the panel type
+	 * field is 0x0005, and that is in fact what we are reading the first byte of. */
+	case 0x05:	/* some NV10, 11, 15, 16 */
+		recordlen = 42;
+		ofs = -1;
+		break;
+	case 0x10:	/* some NV15/16, and NV11+ */
+		recordlen = 44;
+		ofs = 0;
+		break;
+	case 0x20:	/* NV40+ */
+		headerlen = fptable[1];
+		recordlen = fptable[2];
+		fpentries = fptable[3];
+		/* fptable[4] is the minimum RAMDAC_FP_HCRTC->RAMDAC_FP_HSYNC_START gap */
+		bios->pub.digital_min_front_porch = fptable[4];
+		ofs = -7;
+		break;
+	default:
+		NV_ERROR(dev,
+			 "FP table revision %d.%d not currently supported\n",
+			 fptable_ver >> 4, fptable_ver & 0xf);
+		return -ENOSYS;
+	}
+
+	if (!bios->is_mobile) /* !mobile only needs digital_min_front_porch */
+		return 0;
+
+	if ((ret = parse_lvds_manufacturer_table_header(dev, bios, &lth)))
+		return ret;
+
+	if (lth.lvds_ver == 0x30 || lth.lvds_ver == 0x40) {
+		bios->fp.fpxlatetableptr = bios->fp.lvdsmanufacturerpointer + lth.headerlen + 1;
+		bios->fp.xlatwidth = lth.recordlen;
+	}
+	if (bios->fp.fpxlatetableptr == 0x0) {
+		NV_ERROR(dev, "Pointer to flat panel xlat table invalid\n");
+		return -EINVAL;
+	}
+
+	fpstrapping = get_fp_strap(dev, bios);
+
+	fpindex = bios->data[bios->fp.fpxlatetableptr + fpstrapping * bios->fp.xlatwidth];
+
+	if (fpindex > fpentries) {
+		NV_ERROR(dev, "Bad flat panel table index\n");
+		return -ENOENT;
+	}
+
+	/* nv4x cards need both a strap value and fpindex of 0xf to use DDC */
+	if (lth.lvds_ver > 0x10)
+		bios->pub.fp_no_ddc = fpstrapping != 0xf || fpindex != 0xf;
+
+	/* if either the strap or xlated fpindex value are 0xf there is no
+	 * panel using a strap-derived bios mode present.  this condition
+	 * includes, but is different from, the DDC panel indicator above
+	 */
+	if (fpstrapping == 0xf || fpindex == 0xf)
+		return 0;
+
+	bios->fp.mode_ptr = bios->fp.fptablepointer + headerlen +
+			    recordlen * fpindex + ofs;
+
+	NV_TRACE(dev, "BIOS FP mode: %dx%d (%dkHz pixel clock)\n",
+		 ROM16(bios->data[bios->fp.mode_ptr + 11]) + 1,
+		 ROM16(bios->data[bios->fp.mode_ptr + 25]) + 1,
+		 ROM16(bios->data[bios->fp.mode_ptr + 7]) * 10);
+
+	return 0;
+}
+
+bool nouveau_bios_fp_mode(struct drm_device *dev, struct drm_display_mode *mode)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	uint8_t *mode_entry = &bios->data[bios->fp.mode_ptr];
+
+	if (!mode)	/* just checking whether we can produce a mode */
+		return bios->fp.mode_ptr;
+
+	memset(mode, 0, sizeof(struct drm_display_mode));
+	/* for version 1.0 (version in byte 0):
+	 * bytes 1-2 are "panel type", including bits on whether Colour/mono,
+	 * single/dual link, and type (TFT etc.)
+	 * bytes 3-6 are bits per colour in RGBX */
+	mode->clock = ROM16(mode_entry[7]) * 10;
+	/* bytes 9-10 is HActive */
+	mode->hdisplay = ROM16(mode_entry[11]) + 1;
+	/* bytes 13-14 is HValid Start
+	 * bytes 15-16 is HValid End */
+	mode->hsync_start = ROM16(mode_entry[17]) + 1;
+	mode->hsync_end = ROM16(mode_entry[19]) + 1;
+	mode->htotal = ROM16(mode_entry[21]) + 1;
+	/* bytes 23-24, 27-30 similarly, but vertical */
+	mode->vdisplay = ROM16(mode_entry[25]) + 1;
+	mode->vsync_start = ROM16(mode_entry[31]) + 1;
+	mode->vsync_end = ROM16(mode_entry[33]) + 1;
+	mode->vtotal = ROM16(mode_entry[35]) + 1;
+	mode->flags |= (mode_entry[37] & 0x10) ?
+			DRM_MODE_FLAG_PHSYNC : DRM_MODE_FLAG_NHSYNC;
+	mode->flags |= (mode_entry[37] & 0x1) ?
+			DRM_MODE_FLAG_PVSYNC : DRM_MODE_FLAG_NVSYNC;
+	/* bytes 38-39 relate to spread spectrum settings
+	 * bytes 40-43 are something to do with PWM */
+
+	mode->status = MODE_OK;
+	mode->type = DRM_MODE_TYPE_DRIVER | DRM_MODE_TYPE_PREFERRED;
+	drm_mode_set_name(mode);
+	return bios->fp.mode_ptr;
+}
+
+int nouveau_bios_parse_lvds_table(struct drm_device *dev, int pxclk, bool *dl, bool *if_is_24bit)
+{
+	/* The LVDS table header is (mostly) described in
+	 * parse_lvds_manufacturer_table_header(): the BIT header additionally
+	 * contains the dual-link transition pxclk (in 10s kHz), at byte 5 - if
+	 * straps are not being used for the panel, this specifies the frequency
+	 * at which modes should be set up in the dual link style.
+	 *
+	 * Following the header, the BMP (ver 0xa) table has several records,
+	 * indexed by a seperate xlat table, indexed in turn by the fp strap in
+	 * EXTDEV_BOOT. Each record had a config byte, followed by 6 script
+	 * numbers for use by INIT_SUB which controlled panel init and power,
+	 * and finally a dword of ms to sleep between power off and on
+	 * operations.
+	 *
+	 * In the BIT versions, the table following the header serves as an
+	 * integrated config and xlat table: the records in the table are
+	 * indexed by the FP strap nibble in EXTDEV_BOOT, and each record has
+	 * two bytes - the first as a config byte, the second for indexing the
+	 * fp mode table pointed to by the BIT 'D' table
+	 *
+	 * DDC is not used until after card init, so selecting the correct table
+	 * entry and setting the dual link flag for EDID equipped panels,
+	 * requiring tests against the native-mode pixel clock, cannot be done
+	 * until later, when this function should be called with non-zero pxclk
+	 */
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	int fpstrapping = get_fp_strap(dev, bios), lvdsmanufacturerindex = 0;
+	struct lvdstableheader lth;
+	uint16_t lvdsofs;
+	int ret, chip_version = bios->pub.chip_version;
+
+	if ((ret = parse_lvds_manufacturer_table_header(dev, bios, &lth)))
+		return ret;
+
+	switch (lth.lvds_ver) {
+	case 0x0a:	/* pre NV40 */
+		lvdsmanufacturerindex = bios->data[bios->fp.fpxlatemanufacturertableptr + fpstrapping];
+
+		/* we're done if this isn't the EDID panel case */
+		if (!pxclk)
+			break;
+
+		if (chip_version < 0x25) {
+			/* nv17 behaviour */
+			/* it seems the old style lvds script pointer is reused
+			 * to select 18/24 bit colour depth for EDID panels */
+			lvdsmanufacturerindex = (bios->legacy.lvds_single_a_script_ptr & 1) ? 2 : 0;
+			if (pxclk >= bios->fp.duallink_transition_clk)
+				lvdsmanufacturerindex++;
+		} else if (chip_version < 0x30) {
+			/* nv28 behaviour (off-chip encoder) */
+			/* nv28 does a complex dance of first using byte 121 of
+			 * the EDID to choose the lvdsmanufacturerindex, then
+			 * later attempting to match the EDID manufacturer and
+			 * product IDs in a table (signature 'pidt' (panel id
+			 * table?)), setting an lvdsmanufacturerindex of 0 and
+			 * an fp strap of the match index (or 0xf if none)
+			 */
+			lvdsmanufacturerindex = 0;
+		} else {
+			/* nv31, nv34 behaviour */
+			lvdsmanufacturerindex = 0;
+			if (pxclk >= bios->fp.duallink_transition_clk)
+				lvdsmanufacturerindex = 2;
+			if (pxclk >= 140000)
+				lvdsmanufacturerindex = 3;
+		}
+
+		/* nvidia set the high nibble of (cr57=f, cr58) to
+		 * lvdsmanufacturerindex in this case; we don't */
+		break;
+	case 0x30:	/* NV4x */
+	case 0x40:	/* G80/G90 */
+		lvdsmanufacturerindex = fpstrapping;
+		break;
+	default:
+		NV_ERROR(dev, "LVDS table revision not currently supported\n");
+		return -ENOSYS;
+	}
+
+	lvdsofs = bios->fp.xlated_entry = bios->fp.lvdsmanufacturerpointer + lth.headerlen + lth.recordlen * lvdsmanufacturerindex;
+	switch (lth.lvds_ver) {
+	case 0x0a:
+		bios->fp.power_off_for_reset = bios->data[lvdsofs] & 1;
+		bios->fp.reset_after_pclk_change = bios->data[lvdsofs] & 2;
+		bios->fp.dual_link = bios->data[lvdsofs] & 4;
+		bios->fp.link_c_increment = bios->data[lvdsofs] & 8;
+		*if_is_24bit = bios->data[lvdsofs] & 16;
+		break;
+	case 0x30:
+		/* My money would be on there being a 24 bit interface bit in this table,
+		 * but I have no example of a laptop bios with a 24 bit panel to confirm that.
+		 * Hence we shout loudly if any bit other than bit 0 is set (I've not even
+		 * seen bit 1)
+		 */
+		if (bios->data[lvdsofs] > 1)
+			NV_ERROR(dev,
+				 "You have a very unusual laptop display; please report it\n");
+		/* no sign of the "power off for reset" or "reset for panel on" bits, but it's safer to assume we should */
+		bios->fp.power_off_for_reset = true;
+		bios->fp.reset_after_pclk_change = true;
+		/* it's ok lvdsofs is wrong for nv4x edid case; dual_link is
+		 * over-written, and BITbit1 isn't used */
+		bios->fp.dual_link = bios->data[lvdsofs] & 1;
+		bios->fp.BITbit1 = bios->data[lvdsofs] & 2;
+		bios->fp.duallink_transition_clk = ROM16(bios->data[bios->fp.lvdsmanufacturerpointer + 5]) * 10;
+#if 0	// currently unused
+		break;
+	case 0x40:
+		/* fairly sure, but not 100% */
+		bios->fp.dual_link = bios->data[lvdsofs] & 1;
+		bios->fp.duallink_transition_clk = ROM16(bios->data[bios->fp.lvdsmanufacturerpointer + 5]) * 10;
+		break;
+#endif
+	}
+
+	/* set dual_link flag for EDID case */
+	if (pxclk && (chip_version < 0x25 || chip_version > 0x28))
+		bios->fp.dual_link = (pxclk >= bios->fp.duallink_transition_clk);
+
+	*dl = bios->fp.dual_link;
+
+	return 0;
+}
+
+static int
+find_script_pointers(struct drm_device *dev, uint8_t *table, uint16_t *script0,
+		     uint16_t *script1, uint16_t headerlen, int pxclk,
+		     int cmpval)
+{
+	/* The output script tables describing a particular output type
+	 * look as follows:
+	 *
+	 * offset + 0   (32 bits): output this table matches (hash of DCB)
+	 * offset + 4   ( 8 bits): unknown
+	 * offset + 5   ( 8 bits): number of configurations
+	 * offset + 6   (16 bits): pointer to some script
+	 * offset + 8   (16 bits): pointer to some script
+	 *
+	 * headerlen == 10
+	 * offset + 10           : configuration 0
+	 *
+	 * headerlen == 12
+	 * offset + 10           : pointer to some script
+	 * offset + 12           : configuration 0
+	 *
+	 * Each config entry is as follows:
+	 *
+	 * offset + 0   (16 bits): unknown, assumed to be a match value
+	 * offset + 2   (16 bits): pointer to script table (clock set?)
+	 * offset + 4   (16 bits): pointer to script table (reset?)
+	 *
+	 * There doesn't appear to be a count value to say how many
+	 * entries exist in each script table, instead, a 0 value in
+	 * the first 16-bit word seems to indicate both the end of the
+	 * list and the default entry.  The second 16-bit word in the
+	 * script tables is a pointer to the script to execute.
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	int i;
+
+	*script0 = *script1 = 0;
+	for (i = 0; i < table[5]; i++) {
+		uint16_t offset;
+
+		if (ROM16(table[headerlen + i*6 + 0]) != cmpval)
+			continue;
+
+		offset = ROM16(table[headerlen + i*6 + 2]);
+		if (offset)
+			*script0 = clkcmptable(bios, offset, pxclk);
+
+		if (!*script0)
+			NV_WARN(dev, "script0 missing!\n");
+
+		offset = ROM16(table[headerlen + i*6 + 4]);
+		if (offset)
+			*script1 = clkcmptable(bios, offset, pxclk);
+
+		return 0;
+	}
+
+	NV_ERROR(dev, "couldn't find suitable output scripts\n");
+	return 1;
+}
+
+int
+nouveau_bios_run_display_table(struct drm_device *dev, struct dcb_entry *dcbent,
+			       int pxclk)
+{
+	/* The display script table is located by the BIT 'U' table.
+	 *
+	 * It contains an array of pointers to various tables describing
+	 * a particular output type.  The first 32-bits of the output
+	 * tables contains similar information to a DCB entry, and is
+	 * used to decide whether that particular table is suitable for
+	 * the output you want to access.
+	 *
+	 * The "record header length" field here seems to indicate the
+	 * offset of the first configuration entry in the output tables.
+	 * This is 10 on most cards I've seen, but 12 has been witnessed
+	 * on DP cards, and there's another script pointer within the
+	 * header.
+	 *
+	 * offset + 0   ( 8 bits): version
+	 * offset + 1   ( 8 bits): header length
+	 * offset + 2   ( 8 bits): record length
+	 * offset + 3   ( 8 bits): number of records
+	 * offset + 4   ( 8 bits): record header length
+	 * offset + 5   (16 bits): pointer to first output script table
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	init_exec_t iexec = {true, false};
+	struct nvbios *bios = &dev_priv->VBIOS;
+	uint8_t *table = &bios->data[bios->display.script_table_ptr];
+	uint8_t *entry, *otable = NULL;
+	uint16_t script0, script1;
+	int i;
+
+	if (!bios->display.script_table_ptr) {
+		NV_ERROR(dev, "No pointer to output script table\n");
+		return 1;
+	}
+
+	if (table[0] != 0x20) {
+		NV_ERROR(dev, "Output script table version 0x%02x unknown\n", table[0]);
+		return 1;
+	}
+
+	NV_DEBUG(dev, "Searching for output entry for %d %d %d\n",
+			dcbent->type, dcbent->location, dcbent->or);
+	entry = table + table[1];
+	for (i = 0; i < table[3]; i++, entry += table[2]) {
+		uint32_t match;
+
+		if (ROM16(entry[0]) == 0)
+			continue;
+		otable = &bios->data[ROM16(entry[0])];
+		match = ROM32(otable[0]);
+
+		NV_DEBUG(dev, " %d: 0x%08x\n", i, match);
+		if ((((match & 0x000f0000) >> 16)  & dcbent->or) &&
+		     ((match & 0x0000000f) >>  0) == dcbent->type &&
+		     ((match & 0x000000f0) >>  4) == dcbent->location)
+			break;
+	}
+
+	if (i == table[3]) {
+		NV_ERROR(dev, "Couldn't find matching output script table\n");
+		return 1;
+	}
+
+	if (find_script_pointers(dev, otable, &script0, &script1, table[4],
+				 pxclk, dcbent->type == OUTPUT_LVDS ?
+				 0x0100 : (pxclk > 165000 ? 0x0105 : 0x0001)))
+		return 1;
+	bios->display.head = ffs(dcbent->or) - 1;
+
+	if (script0) {
+		NV_TRACE(dev, "0x%04X: Parsing output Script0\n", script0);
+		parse_init_table(dev, bios, script0, &iexec);
+	} else {
+		NV_ERROR(dev, "clock script missing!\n");
+		return 1;
+	}
+
+	if (script1) {
+		NV_TRACE(dev, "0x%04X: Parsing output Script1\n", script1);
+		parse_init_table(dev, bios, script1, &iexec);
+	}
+
+	return 0;
+}
+
+
+int run_tmds_table(struct drm_device *dev, struct dcb_entry *dcbent, int head, int pxclk)
+{
+	/* the pxclk parameter is in kHz
+	 *
+	 * This runs the TMDS regs setting code found on BIT bios cards
+	 *
+	 * For ffs(or) == 1 use the first table, for ffs(or) == 2 and
+	 * ffs(or) == 3, use the second.
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	int cv = bios->pub.chip_version;
+	uint16_t clktable = 0, scriptptr;
+	uint32_t sel_clk_binding, sel_clk;
+
+	/* pre-nv17 off-chip tmds uses scripts, post nv17 doesn't */
+	if (cv >= 0x17 && cv != 0x1a && cv != 0x20 &&
+	    dcbent->location != DCB_LOC_ON_CHIP)
+		return 0;
+
+	switch (ffs(dcbent->or)) {
+	case 1:
+		clktable = bios->tmds.output0_script_ptr;
+		break;
+	case 2:
+	case 3:
+		clktable = bios->tmds.output1_script_ptr;
+		break;
+	}
+
+	if (!clktable) {
+		NV_ERROR(dev, "Pixel clock comparison table not found\n");
+		return -EINVAL;
+	}
+
+	scriptptr = clkcmptable(bios, clktable, pxclk);
+
+	if (!scriptptr) {
+		NV_ERROR(dev, "TMDS output init script not found\n");
+		return -ENOENT;
+	}
+
+	/* don't let script change pll->head binding */
+	sel_clk_binding = bios_rd32(dev, NV_PRAMDAC_SEL_CLK) & 0x50000;
+	run_digital_op_script(dev, scriptptr, dcbent, head, pxclk >= 165000);
+	sel_clk = NVReadRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK) & ~0x50000;
+	NVWriteRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK, sel_clk | sel_clk_binding);
+
+	return 0;
+}
+
+int get_pll_limits(struct drm_device *dev, uint32_t limit_match, struct pll_lims *pll_lim)
+{
+	/* PLL limits table
+	 *
+	 * Version 0x10: NV30, NV31
+	 * One byte header (version), one record of 24 bytes
+	 * Version 0x11: NV36 - Not implemented
+	 * Seems to have same record style as 0x10, but 3 records rather than 1
+	 * Version 0x20: Found on Geforce 6 cards
+	 * Trivial 4 byte BIT header. 31 (0x1f) byte record length
+	 * Version 0x21: Found on Geforce 7, 8 and some Geforce 6 cards
+	 * 5 byte header, fifth byte of unknown purpose. 35 (0x23) byte record
+	 * length in general, some (integrated) have an extra configuration byte
+	 * Version 0x30: Found on Geforce 8, separates the register mapping
+	 * from the limits tables.
+	 */
+
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	int cv = bios->pub.chip_version, pllindex = 0;
+	uint8_t pll_lim_ver = 0, headerlen = 0, recordlen = 0, entries = 0;
+	uint32_t crystal_strap_mask, crystal_straps;
+
+	if (!bios->pll_limit_tbl_ptr) {
+		if (cv == 0x30 || cv == 0x31 || cv == 0x35 || cv == 0x36 ||
+		    cv >= 0x40) {
+			NV_ERROR(dev, "Pointer to PLL limits table invalid\n");
+			return -EINVAL;
+		}
+	} else
+		pll_lim_ver = bios->data[bios->pll_limit_tbl_ptr];
+
+	crystal_strap_mask = 1 << 6;
+        /* open coded dev->twoHeads test */
+        if (cv > 0x10 && cv != 0x15 && cv != 0x1a && cv != 0x20)
+                crystal_strap_mask |= 1 << 22;
+	crystal_straps = nvReadEXTDEV(dev, NV_PEXTDEV_BOOT_0) & crystal_strap_mask;
+
+	switch (pll_lim_ver) {
+	/* we use version 0 to indicate a pre limit table bios (single stage pll)
+	 * and load the hard coded limits instead */
+	case 0:
+		break;
+	case 0x10:
+	case 0x11: /* strictly v0x11 has 3 entries, but the last two don't seem to get used */
+		headerlen = 1;
+		recordlen = 0x18;
+		entries = 1;
+		pllindex = 0;
+		break;
+	case 0x20:
+	case 0x21:
+	case 0x30:
+		headerlen = bios->data[bios->pll_limit_tbl_ptr + 1];
+		recordlen = bios->data[bios->pll_limit_tbl_ptr + 2];
+		entries = bios->data[bios->pll_limit_tbl_ptr + 3];
+		break;
+	default:
+		NV_ERROR(dev, "PLL limits table revision 0x%X not currently "
+				"supported\n", pll_lim_ver);
+		return -ENOSYS;
+	}
+
+	/* initialize all members to zero */
+	memset(pll_lim, 0, sizeof(struct pll_lims));
+
+	if (pll_lim_ver == 0x10 || pll_lim_ver == 0x11) {
+		uint8_t *pll_rec = &bios->data[bios->pll_limit_tbl_ptr + headerlen + recordlen * pllindex];
+
+		pll_lim->vco1.minfreq = ROM32(pll_rec[0]);
+		pll_lim->vco1.maxfreq = ROM32(pll_rec[4]);
+		pll_lim->vco2.minfreq = ROM32(pll_rec[8]);
+		pll_lim->vco2.maxfreq = ROM32(pll_rec[12]);
+		pll_lim->vco1.min_inputfreq = ROM32(pll_rec[16]);
+		pll_lim->vco2.min_inputfreq = ROM32(pll_rec[20]);
+		pll_lim->vco1.max_inputfreq = pll_lim->vco2.max_inputfreq = INT_MAX;
+
+		/* these values taken from nv30/31/36 */
+		pll_lim->vco1.min_n = 0x1;
+		if (cv == 0x36)
+			pll_lim->vco1.min_n = 0x5;
+		pll_lim->vco1.max_n = 0xff;
+		pll_lim->vco1.min_m = 0x1;
+		pll_lim->vco1.max_m = 0xd;
+		pll_lim->vco2.min_n = 0x4;
+		/* on nv30, 31, 36 (i.e. all cards with two stage PLLs with this
+		 * table version (apart from nv35)), N2 is compared to
+		 * maxN2 (0x46) and 10 * maxM2 (0x4), so set maxN2 to 0x28 and
+		 * save a comparison
+		 */
+		pll_lim->vco2.max_n = 0x28;
+		if (cv == 0x30 || cv == 0x35)
+		       /* only 5 bits available for N2 on nv30/35 */
+			pll_lim->vco2.max_n = 0x1f;
+		pll_lim->vco2.min_m = 0x1;
+		pll_lim->vco2.max_m = 0x4;
+		pll_lim->max_log2p = 0x7;
+		pll_lim->max_usable_log2p = 0x6;
+	} else if (pll_lim_ver == 0x20 || pll_lim_ver == 0x21) {
+		uint16_t plloffs = bios->pll_limit_tbl_ptr + headerlen;
+		uint32_t reg = 0; /* default match */
+		uint8_t *pll_rec;
+		int i;
+
+		/* first entry is default match, if nothing better. warn if reg field nonzero */
+		if (ROM32(bios->data[plloffs]))
+			NV_WARN(dev, "Default PLL limit entry has non-zero "
+				       "register field\n");
+
+		if (limit_match > MAX_PLL_TYPES)
+			/* we've been passed a reg as the match */
+			reg = limit_match;
+		else /* limit match is a pll type */
+			for (i = 1; i < entries && !reg; i++) {
+				uint32_t cmpreg = ROM32(bios->data[plloffs + recordlen * i]);
+
+				if (limit_match == NVPLL &&
+				    (cmpreg == NV_PRAMDAC_NVPLL_COEFF || cmpreg == 0x4000))
+					reg = cmpreg;
+				if (limit_match == MPLL &&
+				    (cmpreg == NV_PRAMDAC_MPLL_COEFF || cmpreg == 0x4020))
+					reg = cmpreg;
+				if (limit_match == VPLL1 &&
+				    (cmpreg == NV_PRAMDAC_VPLL_COEFF || cmpreg == 0x4010))
+					reg = cmpreg;
+				if (limit_match == VPLL2 &&
+				    (cmpreg == NV_RAMDAC_VPLL2 || cmpreg == 0x4018))
+					reg = cmpreg;
+			}
+
+		for (i = 1; i < entries; i++)
+			if (ROM32(bios->data[plloffs + recordlen * i]) == reg) {
+				pllindex = i;
+				break;
+			}
+
+		pll_rec = &bios->data[plloffs + recordlen * pllindex];
+
+		BIOSLOG(dev, "Loading PLL limits for reg 0x%08x\n", pllindex ? reg : 0);
+
+		/* frequencies are stored in tables in MHz, kHz are more useful, so we convert */
+
+		/* What output frequencies can each VCO generate? */
+		pll_lim->vco1.minfreq = ROM16(pll_rec[4]) * 1000;
+		pll_lim->vco1.maxfreq = ROM16(pll_rec[6]) * 1000;
+		pll_lim->vco2.minfreq = ROM16(pll_rec[8]) * 1000;
+		pll_lim->vco2.maxfreq = ROM16(pll_rec[10]) * 1000;
+
+		/* What input frequencies do they accept (past the m-divider)? */
+		pll_lim->vco1.min_inputfreq = ROM16(pll_rec[12]) * 1000;
+		pll_lim->vco2.min_inputfreq = ROM16(pll_rec[14]) * 1000;
+		pll_lim->vco1.max_inputfreq = ROM16(pll_rec[16]) * 1000;
+		pll_lim->vco2.max_inputfreq = ROM16(pll_rec[18]) * 1000;
+
+		/* What values are accepted as multiplier and divider? */
+		pll_lim->vco1.min_n = pll_rec[20];
+		pll_lim->vco1.max_n = pll_rec[21];
+		pll_lim->vco1.min_m = pll_rec[22];
+		pll_lim->vco1.max_m = pll_rec[23];
+		pll_lim->vco2.min_n = pll_rec[24];
+		pll_lim->vco2.max_n = pll_rec[25];
+		pll_lim->vco2.min_m = pll_rec[26];
+		pll_lim->vco2.max_m = pll_rec[27];
+
+		pll_lim->max_usable_log2p = pll_lim->max_log2p = pll_rec[29];
+		if (pll_lim->max_log2p > 0x7)
+			/* pll decoding in nv_hw.c assumes never > 7 */
+			NV_WARN(dev, "Max log2 P value greater than 7 (%d)\n",
+				pll_lim->max_log2p);
+		if (cv < 0x60)
+			pll_lim->max_usable_log2p = 0x6;
+		pll_lim->log2p_bias = pll_rec[30];
+
+		if (recordlen > 0x22)
+			pll_lim->refclk = ROM32(pll_rec[31]);
+
+		if (recordlen > 0x23 && pll_rec[35])
+			NV_WARN(dev, 
+				"Bits set in PLL configuration byte (%x)\n",
+				pll_rec[35]);
+
+		/* C51 special not seen elsewhere */
+		if (cv == 0x51 && !pll_lim->refclk) {
+			uint32_t sel_clk = bios_rd32(dev, NV_PRAMDAC_SEL_CLK);
+
+			if (((limit_match == NV_PRAMDAC_VPLL_COEFF || limit_match == VPLL1) && sel_clk & 0x20) ||
+			    ((limit_match == NV_RAMDAC_VPLL2 || limit_match == VPLL2) && sel_clk & 0x80)) {
+				if (bios_idxprt_rd(dev, NV_CIO_CRX__COLOR, NV_CIO_CRE_CHIP_ID_INDEX) < 0xa3)
+					pll_lim->refclk = 200000;
+				else
+					pll_lim->refclk = 25000;
+			}
+		}
+	} else if (pll_lim_ver) { /* ver 0x30 */
+		uint8_t *entry = &bios->data[bios->pll_limit_tbl_ptr + headerlen];
+		uint8_t *record = NULL;
+		int i;
+
+		BIOSLOG(dev, "Loading PLL limits for register 0x%08x\n",
+			limit_match);
+
+		for (i = 0; i < entries; i++, entry += recordlen) {
+			if (ROM32(entry[3]) == limit_match) {
+				record = &bios->data[ROM16(entry[1])];
+				break;
+			}
+		}
+
+		if (!record) {
+			NV_ERROR(dev, "Register 0x%08x not found in PLL "
+				 "limits table", limit_match);
+			return -ENOENT;
+		}
+
+		pll_lim->vco1.minfreq = ROM16(record[0]) * 1000;
+		pll_lim->vco1.maxfreq = ROM16(record[2]) * 1000;
+		pll_lim->vco2.minfreq = ROM16(record[4]) * 1000;
+		pll_lim->vco2.maxfreq = ROM16(record[6]) * 1000;
+		pll_lim->vco1.min_inputfreq = ROM16(record[8]) * 1000;
+		pll_lim->vco2.min_inputfreq = ROM16(record[10]) * 1000;
+		pll_lim->vco1.max_inputfreq = ROM16(record[12]) * 1000;
+		pll_lim->vco2.max_inputfreq = ROM16(record[14]) * 1000;
+		pll_lim->vco1.min_n = record[16];
+		pll_lim->vco1.max_n = record[17];
+		pll_lim->vco1.min_m = record[18];
+		pll_lim->vco1.max_m = record[19];
+		pll_lim->vco2.min_n = record[20];
+		pll_lim->vco2.max_n = record[21];
+		pll_lim->vco2.min_m = record[22];
+		pll_lim->vco2.max_m = record[23];
+		pll_lim->max_usable_log2p = pll_lim->max_log2p = record[25];
+		pll_lim->log2p_bias = record[27];
+		pll_lim->refclk = ROM32(record[28]);
+	}
+
+	/* By now any valid limit table ought to have set a max frequency for
+	 * vco1, so if it's zero it's either a pre limit table bios, or one
+	 * with an empty limit table (seen on nv18)
+	 */
+	if (!pll_lim->vco1.maxfreq) {
+		pll_lim->vco1.minfreq = bios->fminvco;
+		pll_lim->vco1.maxfreq = bios->fmaxvco;
+		pll_lim->vco1.min_inputfreq = 0;
+		pll_lim->vco1.max_inputfreq = INT_MAX;
+		pll_lim->vco1.min_n = 0x1;
+		pll_lim->vco1.max_n = 0xff;
+		pll_lim->vco1.min_m = 0x1;
+		if (crystal_straps == 0) {
+			/* nv05 does this, nv11 doesn't, nv10 unknown */
+			if (cv < 0x11)
+				pll_lim->vco1.min_m = 0x7;
+			pll_lim->vco1.max_m = 0xd;
+		} else {
+			if (cv < 0x11)
+				pll_lim->vco1.min_m = 0x8;
+			pll_lim->vco1.max_m = 0xe;
+		}
+		if (cv < 0x17 || cv == 0x1a || cv == 0x20)
+			pll_lim->max_log2p = 4;
+		else
+			pll_lim->max_log2p = 5;
+		pll_lim->max_usable_log2p = pll_lim->max_log2p;
+	}
+
+	if (!pll_lim->refclk)
+		switch (crystal_straps) {
+		case 0:
+			pll_lim->refclk = 13500;
+			break;
+		case (1 << 6):
+			pll_lim->refclk = 14318;
+			break;
+		case (1 << 22):
+			pll_lim->refclk = 27000;
+			break;
+		case (1 << 22 | 1 << 6):
+			pll_lim->refclk = 25000;
+			break;
+		}
+
+#if 0 /* for easy debugging */
+	ErrorF("pll.vco1.minfreq: %d\n", pll_lim->vco1.minfreq);
+	ErrorF("pll.vco1.maxfreq: %d\n", pll_lim->vco1.maxfreq);
+	ErrorF("pll.vco2.minfreq: %d\n", pll_lim->vco2.minfreq);
+	ErrorF("pll.vco2.maxfreq: %d\n", pll_lim->vco2.maxfreq);
+
+	ErrorF("pll.vco1.min_inputfreq: %d\n", pll_lim->vco1.min_inputfreq);
+	ErrorF("pll.vco1.max_inputfreq: %d\n", pll_lim->vco1.max_inputfreq);
+	ErrorF("pll.vco2.min_inputfreq: %d\n", pll_lim->vco2.min_inputfreq);
+	ErrorF("pll.vco2.max_inputfreq: %d\n", pll_lim->vco2.max_inputfreq);
+
+	ErrorF("pll.vco1.min_n: %d\n", pll_lim->vco1.min_n);
+	ErrorF("pll.vco1.max_n: %d\n", pll_lim->vco1.max_n);
+	ErrorF("pll.vco1.min_m: %d\n", pll_lim->vco1.min_m);
+	ErrorF("pll.vco1.max_m: %d\n", pll_lim->vco1.max_m);
+	ErrorF("pll.vco2.min_n: %d\n", pll_lim->vco2.min_n);
+	ErrorF("pll.vco2.max_n: %d\n", pll_lim->vco2.max_n);
+	ErrorF("pll.vco2.min_m: %d\n", pll_lim->vco2.min_m);
+	ErrorF("pll.vco2.max_m: %d\n", pll_lim->vco2.max_m);
+
+	ErrorF("pll.max_log2p: %d\n", pll_lim->max_log2p);
+	ErrorF("pll.log2p_bias: %d\n", pll_lim->log2p_bias);
+
+	ErrorF("pll.refclk: %d\n", pll_lim->refclk);
+#endif
+
+	return 0;
+}
+
+static void parse_bios_version(struct drm_device *dev, struct nvbios *bios, uint16_t offset)
+{
+	/* offset + 0  (8 bits): Micro version
+	 * offset + 1  (8 bits): Minor version
+	 * offset + 2  (8 bits): Chip version
+	 * offset + 3  (8 bits): Major version
+	 */
+
+	bios->major_version = bios->data[offset + 3];
+	bios->pub.chip_version = bios->data[offset + 2];
+	NV_TRACE(dev, "Bios version %02x.%02x.%02x.%02x\n",
+		 bios->data[offset + 3], bios->data[offset + 2],
+		 bios->data[offset + 1], bios->data[offset]);
+}
+
+static void parse_script_table_pointers(struct nvbios *bios, uint16_t offset)
+{
+	/* Parses the init table segment for pointers used in script execution.
+	 *
+	 * offset + 0  (16 bits): init script tables pointer
+	 * offset + 2  (16 bits): macro index table pointer
+	 * offset + 4  (16 bits): macro table pointer
+	 * offset + 6  (16 bits): condition table pointer
+	 * offset + 8  (16 bits): io condition table pointer
+	 * offset + 10 (16 bits): io flag condition table pointer
+	 * offset + 12 (16 bits): init function table pointer
+	 */
+
+	bios->init_script_tbls_ptr = ROM16(bios->data[offset]);
+	bios->macro_index_tbl_ptr = ROM16(bios->data[offset + 2]);
+	bios->macro_tbl_ptr = ROM16(bios->data[offset + 4]);
+	bios->condition_tbl_ptr = ROM16(bios->data[offset + 6]);
+	bios->io_condition_tbl_ptr = ROM16(bios->data[offset + 8]);
+	bios->io_flag_condition_tbl_ptr = ROM16(bios->data[offset + 10]);
+	bios->init_function_tbl_ptr = ROM16(bios->data[offset + 12]);
+}
+
+static int parse_bit_A_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* Parses the load detect values for g80 cards.
+	 *
+	 * offset + 0 (16 bits): loadval table pointer
+	 */
+
+	uint16_t load_table_ptr;
+	uint8_t version, headerlen, entrylen, num_entries;
+
+	if (bitentry->length != 3) {
+		NV_ERROR(dev, "Do not understand BIT A table\n");
+		return -EINVAL;
+	}
+
+	load_table_ptr = ROM16(bios->data[bitentry->offset]);
+
+	if (load_table_ptr == 0x0) {
+		NV_ERROR(dev, "Pointer to BIT loadval table invalid\n");
+		return -EINVAL;
+	}
+
+	version = bios->data[load_table_ptr];
+
+	if (version != 0x10) {
+		NV_ERROR(dev, "BIT loadval table version %d.%d not supported\n",
+			 version >> 4, version & 0xF);
+		return -ENOSYS;
+	}
+
+	headerlen = bios->data[load_table_ptr + 1];
+	entrylen = bios->data[load_table_ptr + 2];
+	num_entries = bios->data[load_table_ptr + 3];
+
+	if (headerlen != 4 || entrylen != 4 || num_entries != 2) {
+		NV_ERROR(dev, "Do not understand BIT loadval table\n");
+		return -EINVAL;
+	}
+
+	/* First entry is normal dac, 2nd tv-out perhaps? */
+	bios->pub.dactestval = ROM32(bios->data[load_table_ptr + headerlen]) & 0x3ff;
+
+	return 0;
+}
+
+static int parse_bit_C_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* offset + 8  (16 bits): PLL limits table pointer
+	 *
+	 * There's more in here, but that's unknown.
+	 */
+
+	if (bitentry->length < 10) {
+		NV_ERROR(dev, "Do not understand BIT C table\n");
+		return -EINVAL;
+	}
+
+	bios->pll_limit_tbl_ptr = ROM16(bios->data[bitentry->offset + 8]);
+
+	return 0;
+}
+
+static int parse_bit_display_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* Parses the flat panel table segment that the bit entry points to.
+	 * Starting at bitentry->offset:
+	 *
+	 * offset + 0  (16 bits): ??? table pointer - seems to have 18 byte records beginning with a freq
+	 * offset + 2  (16 bits): mode table pointer
+	 */
+
+	if (bitentry->length != 4) {
+		NV_ERROR(dev, "Do not understand BIT display table\n");
+		return -EINVAL;
+	}
+
+	bios->fp.fptablepointer = ROM16(bios->data[bitentry->offset + 2]);
+
+	return 0;
+}
+
+static int parse_bit_init_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* Parses the init table segment that the bit entry points to.
+	 * 
+	 * See parse_script_table_pointers for layout
+	 */
+
+	if (bitentry->length < 14) {
+		NV_ERROR(dev, "Do not understand init table\n");
+		return -EINVAL;
+	}
+
+	parse_script_table_pointers(bios, bitentry->offset);
+
+	return 0;
+}
+
+static int parse_bit_i_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* BIT 'i' (info?) table
+	 *
+	 * offset + 0  (32 bits): BIOS version dword (as in B table)
+	 * offset + 5  (8  bits): BIOS feature byte (same as for BMP?)
+	 * offset + 13 (16 bits): pointer to table containing DAC load detection comparison values
+	 *
+	 * There's other things in the table, purpose unknown
+	 */
+
+	uint16_t daccmpoffset;
+	uint8_t dacver, dacheaderlen;
+
+	if (bitentry->length < 6) {
+		NV_ERROR(dev, "BIT i table too short for needed information\n");
+		return -EINVAL;
+	}
+
+	parse_bios_version(dev, bios, bitentry->offset);
+
+	/* bit 4 seems to indicate a mobile bios (doesn't suffer from BMP's
+	 * Quadro identity crisis), other bits possibly as for BMP feature byte
+	 */
+	bios->feature_byte = bios->data[bitentry->offset + 5];
+	bios->is_mobile = bios->feature_byte & FEATURE_MOBILE;
+
+	if (bitentry->length < 15) {
+		NV_WARN(dev, "BIT i table not long enough for DAC load "
+			       "detection comparison table\n");
+		return -EINVAL;
+	}
+
+	daccmpoffset = ROM16(bios->data[bitentry->offset + 13]);
+
+	/* doesn't exist on g80 */
+	if (!daccmpoffset)
+		return 0;
+
+	/* The first value in the table, following the header, is the comparison value
+	 * Purpose of subsequent values unknown -- TV load detection?
+	 */
+
+	dacver = bios->data[daccmpoffset];
+	dacheaderlen = bios->data[daccmpoffset + 1];
+
+	if (dacver != 0x00 && dacver != 0x10) {
+		NV_WARN(dev, "DAC load detection comparison table version "
+			       "%d.%d not known\n", dacver >> 4, dacver & 0xf);
+		return -ENOSYS;
+	}
+
+	bios->pub.dactestval = ROM32(bios->data[daccmpoffset + dacheaderlen]);
+
+	return 0;
+}
+
+static int parse_bit_lvds_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* Parses the LVDS table segment that the bit entry points to.
+	 * Starting at bitentry->offset:
+	 *
+	 * offset + 0  (16 bits): LVDS strap xlate table pointer
+	 */
+
+	if (bitentry->length != 2) {
+		NV_ERROR(dev, "Do not understand BIT LVDS table\n");
+		return -EINVAL;
+	}
+
+	/* no idea if it's still called the LVDS manufacturer table, but the concept's close enough */
+	bios->fp.lvdsmanufacturerpointer = ROM16(bios->data[bitentry->offset]);
+
+	return 0;
+}
+
+static int parse_bit_M_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* offset + 2  (8  bits): number of options in an INIT_RAM_RESTRICT_ZM_REG_GROUP opcode option set
+	 * offset + 3  (16 bits): pointer to strap xlate table for RAM restrict option selection
+	 *
+	 * There's a bunch of bits in this table other than the RAM restrict
+	 * stuff that we don't use - their use currently unknown
+	 */
+
+	int i;
+
+	/* Older bios versions don't have a sufficiently long table for what we want */
+	if (bitentry->length < 0x5)
+		return 0;
+
+	/* set up multiplier for INIT_RAM_RESTRICT_ZM_REG_GROUP */
+	for (i = 0; itbl_entry[i].name && (itbl_entry[i].id != 0x8f); i++)
+		;
+	itbl_entry[i].length_multiplier = bios->data[bitentry->offset + 2] * 4;
+	init_ram_restrict_zm_reg_group_blocklen = itbl_entry[i].length_multiplier;
+
+	bios->ram_restrict_tbl_ptr = ROM16(bios->data[bitentry->offset + 3]);
+
+	return 0;
+}
+
+static int parse_bit_tmds_tbl_entry(struct drm_device *dev, struct nvbios *bios, bit_entry_t *bitentry)
+{
+	/* Parses the pointer to the TMDS table
+	 *
+	 * Starting at bitentry->offset:
+	 *
+	 * offset + 0  (16 bits): TMDS table pointer
+	 *
+	 * The TMDS table is typically found just before the DCB table, with a
+	 * characteristic signature of 0x11,0x13 (1.1 being version, 0x13 being
+	 * length?)
+	 *
+	 * At offset +7 is a pointer to a script, which I don't know how to run yet
+	 * At offset +9 is a pointer to another script, likewise
+	 * Offset +11 has a pointer to a table where the first word is a pxclk
+	 * frequency and the second word a pointer to a script, which should be
+	 * run if the comparison pxclk frequency is less than the pxclk desired.
+	 * This repeats for decreasing comparison frequencies
+	 * Offset +13 has a pointer to a similar table
+	 * The selection of table (and possibly +7/+9 script) is dictated by
+	 * "or" from the DCB.
+	 */
+
+	uint16_t tmdstableptr, script1, script2;
+
+	if (bitentry->length != 2) {
+		NV_ERROR(dev, "Do not understand BIT TMDS table\n");
+		return -EINVAL;
+	}
+
+	tmdstableptr = ROM16(bios->data[bitentry->offset]);
+
+	if (tmdstableptr == 0x0) {
+		NV_ERROR(dev, "Pointer to TMDS table invalid\n");
+		return -EINVAL;
+	}
+
+	/* nv50+ has v2.0, but we don't parse it atm */
+	if (bios->data[tmdstableptr] != 0x11) {
+		NV_WARN(dev,
+			"TMDS table revision %d.%d not currently supported\n",
+			bios->data[tmdstableptr] >> 4, bios->data[tmdstableptr] & 0xf);
+		return -ENOSYS;
+	}
+
+	/* These two scripts are odd: they don't seem to get run even when they are not stubbed */
+	script1 = ROM16(bios->data[tmdstableptr + 7]);
+	script2 = ROM16(bios->data[tmdstableptr + 9]);
+	if (bios->data[script1] != 'q' || bios->data[script2] != 'q')
+		NV_WARN(dev, "TMDS table script pointers not stubbed\n");
+
+	bios->tmds.output0_script_ptr = ROM16(bios->data[tmdstableptr + 11]);
+	bios->tmds.output1_script_ptr = ROM16(bios->data[tmdstableptr + 13]);
+
+	return 0;
+}
+
+static int
+parse_bit_U_tbl_entry(struct drm_device *dev, struct nvbios *bios,
+		      bit_entry_t *bitentry)
+{
+	/* Parses the pointer to the G80 output script tables
+	 *
+	 * Starting at bitentry->offset:
+	 *
+	 * offset + 0  (16 bits): output script table pointer
+	 */
+
+	uint16_t outputscripttableptr;
+
+	if (bitentry->length != 3) {
+		NV_ERROR(dev, "Do not understand BIT U table\n");
+		return -EINVAL;
+	}
+
+	outputscripttableptr = ROM16(bios->data[bitentry->offset]);
+	bios->display.script_table_ptr = outputscripttableptr;
+	return 0;
+}
+
+struct bit_table {
+	const char id;
+	int (* const parse_fn)(struct drm_device *, struct nvbios *, bit_entry_t *);
+};
+
+#define BIT_TABLE(id, funcid) ((struct bit_table){ id, parse_bit_##funcid##_tbl_entry })
+
+static int parse_bit_table(struct drm_device *dev, struct nvbios *bios, const uint16_t bitoffset, struct bit_table *table)
+{
+	uint8_t maxentries = bios->data[bitoffset + 4];
+	int i, offset;
+	bit_entry_t bitentry;
+
+	for (i = 0, offset = bitoffset + 6; i < maxentries; i++, offset += 6) {
+		bitentry.id[0] = bios->data[offset];
+
+		if (bitentry.id[0] != table->id)
+			continue;
+
+		bitentry.id[1] = bios->data[offset + 1];
+		bitentry.length = ROM16(bios->data[offset + 2]);
+		bitentry.offset = ROM16(bios->data[offset + 4]);
+
+		return table->parse_fn(dev, bios, &bitentry);
+	}
+
+	NV_ERROR(dev, "BIT table '%c' not found\n", table->id);
+
+	return -ENOSYS;
+}
+
+static int parse_bit_structure(struct drm_device *dev, struct nvbios *bios, const uint16_t bitoffset)
+{
+	int ret;
+
+	/* the only restriction on parsing order currently is having 'i' first
+	 * for use of bios->*_version or bios->feature_byte while parsing;
+	 * functions shouldn't be actually *doing* anything apart from pulling
+	 * data from the image into the bios struct, thus no interdependencies
+	 */
+	if ((ret = parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('i', i)))) /* info? */
+		return ret;
+	if (bios->major_version >= 0x60) /* g80+ */
+		parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('A', A));
+	if ((ret = parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('C', C))))
+		return ret;
+	parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('D', display));
+	if ((ret = parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('I', init))))
+		return ret;
+	parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('M', M)); /* memory? */
+	parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('L', lvds));
+	parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('T', tmds));
+	parse_bit_table(dev, bios, bitoffset, &BIT_TABLE('U', U));
+
+	return 0;
+}
+
+static int parse_bmp_structure(struct drm_device *dev, struct nvbios *bios, unsigned int offset)
+{
+	/* Parses the BMP structure for useful things, but does not act on them
+	 *
+	 * offset +   5: BMP major version
+	 * offset +   6: BMP minor version
+	 * offset +   9: BMP feature byte
+	 * offset +  10: BCD encoded BIOS version
+	 *
+	 * offset +  18: init script table pointer (for bios versions < 5.10h)
+	 * offset +  20: extra init script table pointer (for bios versions < 5.10h)
+	 *
+	 * offset +  24: memory init table pointer (used on early bios versions)
+	 * offset +  26: SDR memory sequencing setup data table
+	 * offset +  28: DDR memory sequencing setup data table
+	 *
+	 * offset +  54: index of I2C CRTC pair to use for CRT output
+	 * offset +  55: index of I2C CRTC pair to use for TV output
+	 * offset +  56: index of I2C CRTC pair to use for flat panel output
+	 * offset +  58: write CRTC index for I2C pair 0
+	 * offset +  59: read CRTC index for I2C pair 0
+	 * offset +  60: write CRTC index for I2C pair 1
+	 * offset +  61: read CRTC index for I2C pair 1
+	 *
+	 * offset +  67: maximum internal PLL frequency (single stage PLL)
+	 * offset +  71: minimum internal PLL frequency (single stage PLL)
+	 *
+	 * offset +  75: script table pointers, as described in parse_script_table_pointers
+	 *
+	 * offset +  89: TMDS single link output A table pointer
+	 * offset +  91: TMDS single link output B table pointer
+	 * offset +  95: LVDS single link output A table pointer
+	 * offset + 105: flat panel timings table pointer
+	 * offset + 107: flat panel strapping translation table pointer
+	 * offset + 117: LVDS manufacturer panel config table pointer
+	 * offset + 119: LVDS manufacturer strapping translation table pointer
+	 *
+	 * offset + 142: PLL limits table pointer
+	 *
+	 * offset + 156: minimum pixel clock for LVDS dual link
+	 */
+
+	uint8_t *bmp = &bios->data[offset], bmp_version_major, bmp_version_minor;
+	uint16_t bmplength;
+	uint16_t legacy_scripts_offset, legacy_i2c_offset;
+
+	/* load needed defaults in case we can't parse this info */
+	bios->bdcb.dcb.i2c[0].write = NV_CIO_CRE_DDC_WR__INDEX;
+	bios->bdcb.dcb.i2c[0].read = NV_CIO_CRE_DDC_STATUS__INDEX;
+	bios->bdcb.dcb.i2c[1].write = NV_CIO_CRE_DDC0_WR__INDEX;
+	bios->bdcb.dcb.i2c[1].read = NV_CIO_CRE_DDC0_STATUS__INDEX;
+	bios->pub.digital_min_front_porch = 0x4b;
+	bios->fmaxvco = 256000;
+	bios->fminvco = 128000;
+	bios->fp.duallink_transition_clk = 90000;
+
+	bmp_version_major = bmp[5];
+	bmp_version_minor = bmp[6];
+
+	NV_TRACE(dev, "BMP version %d.%d\n",
+		 bmp_version_major, bmp_version_minor);
+
+	/* Make sure that 0x36 is blank and can't be mistaken for a DCB pointer on early versions */
+	if (bmp_version_major < 5)
+		*(uint16_t *)&bios->data[0x36] = 0;
+
+	/* Seems that the minor version was 1 for all major versions prior to 5 */
+	/* Version 6 could theoretically exist, but I suspect BIT happened instead */
+	if ((bmp_version_major < 5 && bmp_version_minor != 1) || bmp_version_major > 5) {
+		NV_ERROR(dev, "You have an unsupported BMP version. "
+				"Please send in your bios\n");
+		return -ENOSYS;
+	}
+
+	if (bmp_version_major == 0) /* nothing that's currently useful in this version */
+		return 0;
+	else if (bmp_version_major == 1)
+		bmplength = 44; /* exact for 1.01 */
+	else if (bmp_version_major == 2)
+		bmplength = 48; /* exact for 2.01 */
+	else if (bmp_version_major == 3)
+		bmplength = 54; /* guessed - mem init tables added in this version */
+	else if (bmp_version_major == 4 || bmp_version_minor < 0x1) /* don't know if 5.0 exists... */
+		bmplength = 62; /* guessed - BMP I2C indices added in version 4*/
+	else if (bmp_version_minor < 0x6)
+		bmplength = 67; /* exact for 5.01 */
+	else if (bmp_version_minor < 0x10)
+		bmplength = 75; /* exact for 5.06 */
+	else if (bmp_version_minor == 0x10)
+		bmplength = 89; /* exact for 5.10h */
+	else if (bmp_version_minor < 0x14)
+		bmplength = 118; /* exact for 5.11h */
+	else if (bmp_version_minor < 0x24) /* not sure of version where pll limits came in;
+					    * certainly exist by 0x24 though */
+		/* length not exact: this is long enough to get lvds members */
+		bmplength = 123;
+	else if (bmp_version_minor < 0x27)
+		/* length not exact: this is long enough to get pll limit member */
+		bmplength = 144;
+	else
+		/* length not exact: this is long enough to get dual link transition clock */
+		bmplength = 158;
+
+	/* checksum */
+	if (nv_cksum(bmp, 8)) {
+		NV_ERROR(dev, "Bad BMP checksum\n");
+		return -EINVAL;
+	}
+
+	/* bit 4 seems to indicate either a mobile bios or a quadro card --
+	 * mobile behaviour consistent (nv11+), quadro only seen nv18gl-nv36gl
+	 * (not nv10gl), bit 5 that the flat panel tables are present, and
+	 * bit 6 a tv bios */
+	bios->feature_byte = bmp[9];
+
+	parse_bios_version(dev, bios, offset + 10);
+
+	if (bmp_version_major < 5 || bmp_version_minor < 0x10)
+		bios->old_style_init = true;
+	legacy_scripts_offset = 18;
+	if (bmp_version_major < 2)
+		legacy_scripts_offset -= 4;
+	bios->init_script_tbls_ptr = ROM16(bmp[legacy_scripts_offset]);
+	bios->extra_init_script_tbl_ptr = ROM16(bmp[legacy_scripts_offset + 2]);
+
+	if (bmp_version_major > 2) {	/* appears in BMP 3 */
+		bios->legacy.mem_init_tbl_ptr = ROM16(bmp[24]);
+		bios->legacy.sdr_seq_tbl_ptr = ROM16(bmp[26]);
+		bios->legacy.ddr_seq_tbl_ptr = ROM16(bmp[28]);
+	}
+
+	legacy_i2c_offset = 0x48;	/* BMP version 2 & 3 */
+	if (bmplength > 61)
+		legacy_i2c_offset = offset + 54;
+	bios->legacy.i2c_indices.crt = bios->data[legacy_i2c_offset];
+	bios->legacy.i2c_indices.tv = bios->data[legacy_i2c_offset + 1];
+	bios->legacy.i2c_indices.panel = bios->data[legacy_i2c_offset + 2];
+	bios->bdcb.dcb.i2c[0].write = bios->data[legacy_i2c_offset + 4];
+	bios->bdcb.dcb.i2c[0].read = bios->data[legacy_i2c_offset + 5];
+	bios->bdcb.dcb.i2c[1].write = bios->data[legacy_i2c_offset + 6];
+	bios->bdcb.dcb.i2c[1].read = bios->data[legacy_i2c_offset + 7];
+
+	if (bmplength > 74) {
+		bios->fmaxvco = ROM32(bmp[67]);
+		bios->fminvco = ROM32(bmp[71]);
+	}
+	if (bmplength > 88)
+		parse_script_table_pointers(bios, offset + 75);
+	if (bmplength > 94) {
+		bios->tmds.output0_script_ptr = ROM16(bmp[89]);
+		bios->tmds.output1_script_ptr = ROM16(bmp[91]);
+		/* never observed in use with lvds scripts, but is reused for
+		 * 18/24 bit panel interface default for EDID equipped panels
+		 * (if_is_24bit not set directly to avoid any oscillation) */
+		bios->legacy.lvds_single_a_script_ptr = ROM16(bmp[95]);
+	}
+	if (bmplength > 108) {
+		bios->fp.fptablepointer = ROM16(bmp[105]);
+		bios->fp.fpxlatetableptr = ROM16(bmp[107]);
+		bios->fp.xlatwidth = 1;
+	}
+	if (bmplength > 120) {
+		bios->fp.lvdsmanufacturerpointer = ROM16(bmp[117]);
+		bios->fp.fpxlatemanufacturertableptr = ROM16(bmp[119]);
+	}
+	if (bmplength > 143)
+		bios->pll_limit_tbl_ptr = ROM16(bmp[142]);
+
+	if (bmplength > 157)
+		bios->fp.duallink_transition_clk = ROM16(bmp[156]) * 10;
+
+	return 0;
+}
+
+static uint16_t findstr(uint8_t *data, int n, const uint8_t *str, int len)
+{
+	int i, j;
+
+	for (i = 0; i <= (n - len); i++) {
+		for (j = 0; j < len; j++)
+			if (data[i + j] != str[j])
+				break;
+		if (j == len)
+			return i;
+	}
+
+	return 0;
+}
+
+static int
+read_dcb_i2c_entry(struct drm_device *dev, int dcb_version, uint8_t *i2ctable, int index, struct dcb_i2c_entry *i2c)
+{
+	uint8_t dcb_i2c_ver = dcb_version, headerlen = 0, entry_len = 4;
+	int i2c_entries = DCB_MAX_NUM_I2C_ENTRIES;
+	int recordoffset = 0, rdofs = 1, wrofs = 0;
+	uint8_t port_type = 0;
+
+	if (!i2ctable)
+		return -EINVAL;
+
+	if (dcb_version >= 0x30) {
+		if (i2ctable[0] != dcb_version) /* necessary? */
+			NV_WARN(dev,
+				"DCB I2C table version mismatch (%02X vs %02X)\n",
+				i2ctable[0], dcb_version);
+		dcb_i2c_ver = i2ctable[0];
+		headerlen = i2ctable[1];
+		if (i2ctable[2] <= DCB_MAX_NUM_I2C_ENTRIES)
+			i2c_entries = i2ctable[2];
+		else
+			NV_WARN(dev,
+				"DCB I2C table has more entries than indexable "
+				"(%d entries, max index 15)\n", i2ctable[2]);
+		entry_len = i2ctable[3];
+		/* [4] is i2c_default_indices, read in parse_dcb_table() */
+	}
+	/* it's your own fault if you call this function on a DCB 1.1 BIOS --
+	 * the test below is for DCB 1.2
+	 */
+	if (dcb_version < 0x14) {
+		recordoffset = 2;
+		rdofs = 0;
+		wrofs = 1;
+	}
+
+	if (index == 0xf)
+		return 0;
+	if (index > i2c_entries) {
+		NV_ERROR(dev, "DCB I2C index too big (%d > %d)\n",
+			 index, i2ctable[2]);
+		return -ENOENT;
+	}
+	if (i2ctable[headerlen + entry_len * index + 3] == 0xff) {
+		NV_ERROR(dev, "DCB I2C entry invalid\n");
+		return -EINVAL;
+	}
+
+	if (dcb_i2c_ver >= 0x30) {
+		port_type = i2ctable[headerlen + recordoffset + 3 + entry_len * index];
+
+		/* fixup for chips using same address offset for read and write */
+		if (port_type == 4)	/* seen on C51 */
+			rdofs = wrofs = 1;
+		if (port_type == 5)	/* G80+ */
+			rdofs = wrofs = 0;
+	}
+	if (dcb_i2c_ver >= 0x40 && port_type != 5)
+		NV_WARN(dev, "DCB I2C table has port type %d\n", port_type);
+
+	i2c->port_type = port_type;
+	i2c->read = i2ctable[headerlen + recordoffset + rdofs + entry_len * index];
+	i2c->write = i2ctable[headerlen + recordoffset + wrofs + entry_len * index];
+
+	return 0;
+}
+
+static int
+init_dcb_i2c_entry(struct drm_device *dev, struct nvbios *bios, int index)
+{
+	struct dcb_i2c_entry *i2c = &bios->bdcb.dcb.i2c[index];
+	char adaptorname[11];
+	int ret;
+
+	if (i2c->chan)
+		return 0;
+
+	if (bios->bdcb.version < 0x15) {
+		NV_ERROR(dev, "DCB table not version 1.5 or greater\n");
+		return -ENOSYS;
+	}
+
+	if (!bios->bdcb.i2c_table) {
+		NV_ERROR(dev, "No parsed DCB I2C port table\n");
+		return -EINVAL;
+	}
+
+	ret = read_dcb_i2c_entry(dev, bios->bdcb.version, bios->bdcb.i2c_table,
+				 index, i2c);
+	if (ret)
+		return ret;
+
+	snprintf(adaptorname, 11, "DCB-I2C-%d", index);
+	ret = nouveau_i2c_new(dev, adaptorname, index, &i2c->chan);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static struct dcb_entry * new_dcb_entry(struct parsed_dcb *dcb)
+{
+	struct dcb_entry *entry = &dcb->entry[dcb->entries];
+
+	memset(entry, 0, sizeof (struct dcb_entry));
+	entry->index = dcb->entries++;
+
+	return entry;
+}
+
+static void fabricate_vga_output(struct parsed_dcb *dcb, int i2c, int heads)
+{
+	struct dcb_entry *entry = new_dcb_entry(dcb);
+
+	entry->type = 0;
+	entry->i2c_index = i2c;
+	entry->heads = heads;
+	entry->location = DCB_LOC_ON_CHIP;
+	/* "or" mostly unused in early gen crt modesetting, 0 is fine */
+}
+
+static void fabricate_dvi_i_output(struct parsed_dcb *dcb, bool twoHeads)
+{
+	struct dcb_entry *entry = new_dcb_entry(dcb);
+
+	entry->type = 2;
+	entry->i2c_index = LEGACY_I2C_PANEL;
+	entry->heads = twoHeads ? 3 : 1;
+	entry->location = !DCB_LOC_ON_CHIP;	/* ie OFF CHIP */
+	entry->or = 1;	/* naturally on head A; see setting of CRE_LCD__INDEX */
+	entry->duallink_possible = false; /* SiI164 and co. are single link */
+
+#if 0
+	/* for dvi-a either crtc probably works, but my card appears to only
+	 * support dvi-d.  "nvidia" still attempts to program it for dvi-a,
+	 * doing the full fp output setup (program 0x6808.. fp dimension regs,
+	 * setting 0x680848 to 0x10000111 to enable, maybe setting 0x680880);
+	 * the monitor picks up the mode res ok and lights up, but no pixel
+	 * data appears, so the board manufacturer probably connected up the
+	 * sync lines, but missed the video traces / components
+	 *
+	 * with this introduction, dvi-a left as an exercise for the reader.
+	 */
+	fabricate_vga_output(dcb, LEGACY_I2C_PANEL, entry->heads);
+#endif
+}
+
+static bool
+parse_dcb20_entry(struct drm_device *dev, struct bios_parsed_dcb *bdcb,
+		  uint32_t conn, uint32_t conf, struct dcb_entry *entry)
+{
+	entry->type = conn & 0xf;
+	entry->i2c_index = (conn >> 4) & 0xf;
+	entry->heads = (conn >> 8) & 0xf;
+	entry->bus = (conn >> 16) & 0xf;
+	entry->location = (conn >> 20) & 0x3;
+	entry->or = (conn >> 24) & 0xf;
+	/* Normal entries consist of a single bit, but dual link has the
+	 * next most significant bit set too
+	 */
+	entry->duallink_possible =
+			((1 << (ffs(entry->or) - 1)) * 3 == entry->or);
+
+	switch (entry->type) {
+	case OUTPUT_ANALOG:
+		/* although the rest of a CRT conf dword is usually
+		 * zeros, mac biosen have stuff there so we must mask
+		 */
+		entry->crtconf.maxfreq = (bdcb->version < 0x30) ?
+					 (conf & 0xffff) * 10 :
+					 (conf & 0xff) * 10000;
+		break;
+	case OUTPUT_LVDS:
+		{
+		uint32_t mask;
+		if (conf & 0x1)
+			entry->lvdsconf.use_straps_for_mode = true;
+		if (bdcb->version < 0x22) {
+			mask = ~0xd;
+			/* the laptop in bug 14567 lies and claims to not use
+			 * straps when it does, so assume all DCB 2.0 laptops
+			 * use straps, until a broken EDID using one is produced
+			 */
+			entry->lvdsconf.use_straps_for_mode = true;
+			/* both 0x4 and 0x8 show up in v2.0 tables; assume they
+			 * mean the same thing (probably wrong, but might work)
+			 */
+			if (conf & 0x4 || conf & 0x8)
+				entry->lvdsconf.use_power_scripts = true;
+		} else {
+			mask = ~0x5;
+			if (conf & 0x4)
+				entry->lvdsconf.use_power_scripts = true;
+		}
+		if (conf & mask) {
+			/* I'm bored of getting this reported; left as a reminder for someone to fix it */
+			if (bdcb->version >= 0x40) {
+				NV_WARN(dev, "G80+ LVDS not initialized by driver; ignoring conf bits\n");
+				break;
+			}
+			NV_ERROR(dev, "Unknown LVDS configuration bits, "
+					"please report\n");
+			/* cause output setting to fail, so message is seen */
+			bdcb->dcb.entries = 0;
+			return false;
+		}
+		break;
+		}
+	case 0xe:
+		/* weird g80 mobile type that "nv" treats as a terminator */
+		bdcb->dcb.entries--;
+		return false;
+	}
+	/* unsure what DCB version introduces this, 3.0? */
+	if (conf & 0x100000)
+		entry->i2c_upper_default = true;
+
+	return true;
+}
+
+static bool
+parse_dcb15_entry(struct drm_device *dev, struct parsed_dcb *dcb,
+		  uint32_t conn, uint32_t conf, struct dcb_entry *entry)
+{
+	if (conn != 0xf0003f00 && conn != 0xf2247f10 &&
+	    conn != 0xf2204001 && conn != 0xf2204301 && conn != 0xf2204311 && conn != 0xf2208001 && conn != 0xf2244001 && conn != 0xf2244301 && conn != 0xf2244311 && conn != 0xf4204011 && conn != 0xf4208011 && conn != 0xf4248011 &&
+	    conn != 0xf2045ff2 &&
+	    conn != 0xf2045f14 && conn != 0xf207df14 && conn != 0xf2205004) {
+		NV_ERROR(dev, "Unknown DCB 1.5 entry, please report\n");
+
+		/* cause output setting to fail for !TV, so message is seen */
+		if ((conn & 0xf) != 0x1)
+			dcb->entries = 0;
+
+		return false;
+	}
+	/* most of the below is a "best guess" atm */
+	entry->type = conn & 0xf;
+	if (entry->type == 2)
+		/* another way of specifying straps based lvds... */
+		entry->type = OUTPUT_LVDS;
+	if (entry->type == 4) { /* digital */
+		if (conn & 0x10)
+			entry->type = OUTPUT_LVDS;
+		else
+			entry->type = OUTPUT_TMDS;
+	}
+	/* what's in bits 5-13? could be some encoder maker thing, in tv case */
+	entry->i2c_index = (conn >> 14) & 0xf;
+	/* raw heads field is in range 0-1, so move to 1-2 */
+	entry->heads = ((conn >> 18) & 0x7) + 1;
+	entry->location = (conn >> 21) & 0xf;
+	/* unused: entry->bus = (conn >> 25) & 0x7; */
+	/* set or to be same as heads -- hopefully safe enough */
+	entry->or = entry->heads;
+	entry->duallink_possible = false;
+
+	switch (entry->type) {
+	case OUTPUT_ANALOG:
+		entry->crtconf.maxfreq = (conf & 0xffff) * 10;
+		break;
+	case OUTPUT_LVDS:
+		/* this is probably buried in conn's unknown bits */
+		/* this will upset EDID-ful models, if they exist */
+		entry->lvdsconf.use_straps_for_mode = true;
+		entry->lvdsconf.use_power_scripts = true;
+		break;
+	case OUTPUT_TMDS:
+		/* invent a DVI-A output, by copying the fields of the DVI-D
+		 * output; reported to work by math_b on an NV20(!) */
+		fabricate_vga_output(dcb, entry->i2c_index, entry->heads);
+	}
+
+	return true;
+}
+
+static bool parse_dcb_entry(struct drm_device *dev, struct bios_parsed_dcb *bdcb,
+			    uint32_t conn, uint32_t conf)
+{
+	struct dcb_entry *entry = new_dcb_entry(&bdcb->dcb);
+	bool ret;
+
+	if (bdcb->version >= 0x20)
+		ret = parse_dcb20_entry(dev, bdcb, conn, conf, entry);
+	else
+		ret = parse_dcb15_entry(dev, &bdcb->dcb, conn, conf, entry);
+	if (!ret)
+		return ret;
+
+	read_dcb_i2c_entry(dev, bdcb->version, bdcb->i2c_table,
+			   entry->i2c_index, &bdcb->dcb.i2c[entry->i2c_index]);
+
+	return true;
+}
+
+void merge_like_dcb_entries(struct drm_device *dev, struct parsed_dcb *dcb)
+{
+	/* DCB v2.0 lists each output combination separately.
+	 * Here we merge compatible entries to have fewer outputs, with more options
+	 */
+
+	int i, newentries = 0;
+
+	for (i = 0; i < dcb->entries; i++) {
+		struct dcb_entry *ient = &dcb->entry[i];
+		int j;
+
+		for (j = i + 1; j < dcb->entries; j++) {
+			struct dcb_entry *jent = &dcb->entry[j];
+
+			if (jent->type == 100) /* already merged entry */
+				continue;
+
+			/* merge heads field when all other fields the same */
+			if (jent->i2c_index == ient->i2c_index &&
+			    jent->type == ient->type &&
+			    jent->location == ient->location &&
+			    jent->or == ient->or) {
+				NV_TRACE(dev, "Merging DCB entries %d and %d\n",
+					 i, j);
+				ient->heads |= jent->heads;
+				jent->type = 100; /* dummy value */
+			}
+		}
+	}
+
+	/* Compact entries merged into others out of dcb */
+	for (i = 0; i < dcb->entries; i++) {
+		if (dcb->entry[i].type == 100)
+			continue;
+
+		if (newentries != i) {
+			dcb->entry[newentries] = dcb->entry[i];
+			dcb->entry[newentries].index = newentries;
+		}
+		newentries++;
+	}
+
+	dcb->entries = newentries;
+}
+
+static int parse_dcb_table(struct drm_device *dev, struct nvbios *bios, bool twoHeads)
+{
+	struct bios_parsed_dcb *bdcb = &bios->bdcb;
+	struct parsed_dcb *dcb;
+	uint16_t dcbptr, i2ctabptr = 0;
+	uint8_t *dcbtable;
+	uint8_t headerlen = 0x4, entries = DCB_MAX_NUM_ENTRIES;
+	bool configblock = true;
+	int recordlength = 8, confofs = 4;
+	int i;
+
+	dcb = bios->pub.dcb = &bdcb->dcb;
+	dcb->entries = 0;
+
+	/* get the offset from 0x36 */
+	dcbptr = ROM16(bios->data[0x36]);
+
+	if (dcbptr == 0x0) {
+		NV_WARN(dev, "No output data (DCB) found in BIOS, "
+			       "assuming a CRT output exists\n");
+		/* this situation likely means a really old card, pre DCB */
+		fabricate_vga_output(dcb, LEGACY_I2C_CRT, 1);
+		return 0;
+	}
+
+	dcbtable = &bios->data[dcbptr];
+
+	/* get DCB version */
+	bdcb->version = dcbtable[0];
+	NV_TRACE(dev, "Found Display Configuration Block version %d.%d\n",
+		 bdcb->version >> 4, bdcb->version & 0xf);
+
+	if (bdcb->version >= 0x20) { /* NV17+ */
+		uint32_t sig;
+
+		if (bdcb->version >= 0x30) { /* NV40+ */
+			headerlen = dcbtable[1];
+			entries = dcbtable[2];
+			recordlength = dcbtable[3];
+			i2ctabptr = ROM16(dcbtable[4]);
+			sig = ROM32(dcbtable[6]);
+			if (bdcb->version == 0x40)	/* G80 */
+				bdcb->init8e_table_ptr =
+					ROM16(dcbtable[10]);
+		} else {
+			i2ctabptr = ROM16(dcbtable[2]);
+			sig = ROM32(dcbtable[4]);
+			headerlen = 8;
+		}
+
+		if (sig != 0x4edcbdcb) {
+			NV_ERROR(dev, "Bad Display Configuration Block "
+					"signature (%08X)\n", sig);
+			return -EINVAL;
+		}
+	} else if (bdcb->version >= 0x15) { /* some NV11 and NV20 */
+		char sig[8] = { 0 };
+
+		strncpy(sig, (char *)&dcbtable[-7], 7);
+		i2ctabptr = ROM16(dcbtable[2]);
+		recordlength = 10;
+		confofs = 6;
+
+		if (strcmp(sig, "DEV_REC")) {
+			NV_ERROR(dev, "Bad Display Configuration Block "
+					"signature (%s)\n", sig);
+			return -EINVAL;
+		}
+	} else {
+		/* v1.4 (some NV15/16, NV11+) seems the same as v1.5, but always
+		 * has the same single (crt) entry, even when tv-out present, so
+		 * the conclusion is this version cannot really be used.
+		 * v1.2 tables (some NV6/10, and NV15+) normally have the same
+		 * 5 entries, which are not specific to the card and so no use.
+		 * v1.2 does have an I2C table that read_dcb_i2c_table can
+		 * handle, but cards exist (nv11 in #14821) with a bad i2c table
+		 * pointer, so use the indices parsed in parse_bmp_structure.
+		 * v1.1 (NV5+, maybe some NV4) is entirely unhelpful
+		 */
+		NV_TRACEWARN(dev, "No useful information in BIOS output table; "
+				  "adding all possible outputs\n");
+		fabricate_vga_output(dcb, LEGACY_I2C_CRT, 1);
+		if (bios->tmds.output0_script_ptr ||
+		    bios->tmds.output1_script_ptr)
+			fabricate_dvi_i_output(dcb, twoHeads);
+		return 0;
+	}
+
+	if (!i2ctabptr)
+		NV_WARN(dev, "No pointer to DCB I2C port table\n");
+	else {
+		bdcb->i2c_table = &bios->data[i2ctabptr];
+		if (bdcb->version >= 0x30)
+			bdcb->i2c_default_indices = bdcb->i2c_table[4];
+	}
+
+	if (entries > DCB_MAX_NUM_ENTRIES)
+		entries = DCB_MAX_NUM_ENTRIES;
+
+	for (i = 0; i < entries; i++) {
+		uint32_t connection, config = 0;
+
+		connection = ROM32(dcbtable[headerlen + recordlength * i]);
+		if (configblock)
+			config = ROM32(dcbtable[headerlen + confofs + recordlength * i]);
+
+		/* Should we allow discontinuous DCBs? Certainly DCB I2C tables can be discontinuous */
+		if ((connection & 0x0000000f) == 0x0000000f) /* end of records */
+			break;
+		if (connection == 0x00000000) /* seen on an NV11 with DCB v1.5 */
+			break;
+
+		NV_TRACEWARN(dev, "Raw DCB entry %d: %08x %08x\n",
+			     dcb->entries, connection, config);
+
+		if (!parse_dcb_entry(dev, bdcb, connection, config))
+			break;
+	}
+
+	/* apart for v2.1+ not being known for requiring merging, this
+	 * guarantees dcbent->index is the index of the entry in the rom image
+	 */
+	if (bdcb->version < 0x21)
+		merge_like_dcb_entries(dev, dcb);
+
+	return (dcb->entries ? 0 : -ENXIO);
+}
+
+static void fixup_legacy_i2c(struct nvbios *bios)
+{
+	struct parsed_dcb *dcb = &bios->bdcb.dcb;
+	int i;
+
+	for (i = 0; i < dcb->entries; i++) {
+		if (dcb->entry[i].i2c_index == LEGACY_I2C_CRT)
+			dcb->entry[i].i2c_index = bios->legacy.i2c_indices.crt;
+		if (dcb->entry[i].i2c_index == LEGACY_I2C_PANEL)
+			dcb->entry[i].i2c_index = bios->legacy.i2c_indices.panel;
+	}
+}
+
+static int load_nv17_hwsq_ucode_entry(struct drm_device *dev, struct nvbios *bios, uint16_t hwsq_offset, int entry)
+{
+	/* The header following the "HWSQ" signature has the number of entries,
+	 * and the entry size
+	 *
+	 * An entry consists of a dword to write to the sequencer control reg
+	 * (0x00001304), followed by the ucode bytes, written sequentially,
+	 * starting at reg 0x00001400
+	 */
+
+	uint8_t bytes_to_write;
+	uint16_t hwsq_entry_offset;
+	int i;
+
+	if (bios->data[hwsq_offset] <= entry) {
+		NV_ERROR(dev, "Too few entries in HW sequencer table for "
+				"requested entry\n");
+		return -ENOENT;
+	}
+
+	bytes_to_write = bios->data[hwsq_offset + 1];
+
+	if (bytes_to_write != 36) {
+		NV_ERROR(dev, "Unknown HW sequencer entry size\n");
+		return -EINVAL;
+	}
+
+	NV_TRACE(dev, "Loading NV17 power sequencing microcode\n");
+
+	hwsq_entry_offset = hwsq_offset + 2 + entry * bytes_to_write;
+
+	/* set sequencer control */
+	bios_wr32(dev, 0x00001304, ROM32(bios->data[hwsq_entry_offset]));
+	bytes_to_write -= 4;
+
+	/* write ucode */
+	for (i = 0; i < bytes_to_write; i += 4)
+		bios_wr32(dev, 0x00001400 + i, ROM32(bios->data[hwsq_entry_offset + i + 4]));
+
+	/* twiddle NV_PBUS_DEBUG_4 */
+	bios_wr32(dev, NV_PBUS_DEBUG_4, bios_rd32(dev, NV_PBUS_DEBUG_4) | 0x18);
+
+	return 0;
+}
+
+static int load_nv17_hw_sequencer_ucode(struct drm_device *dev, struct nvbios *bios)
+{
+	/* BMP based cards, from NV17, need a microcode loading to correctly
+	 * control the GPIO etc for LVDS panels
+	 *
+	 * BIT based cards seem to do this directly in the init scripts
+	 *
+	 * The microcode entries are found by the "HWSQ" signature.
+	 */
+
+	const uint8_t hwsq_signature[] = { 'H', 'W', 'S', 'Q' };
+	int hwsq_offset;
+
+	if (!(hwsq_offset = findstr(bios->data, bios->length, hwsq_signature,
+				    sizeof(hwsq_signature))))
+		return 0;
+
+	/* always use entry 0? */
+	return load_nv17_hwsq_ucode_entry(dev, bios,
+					  hwsq_offset + sizeof(hwsq_signature), 0);
+}
+
+uint8_t * nouveau_bios_embedded_edid(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	const uint8_t edid_sig[] = { 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00 };
+	uint16_t offset = 0, newoffset;
+	int searchlen = NV_PROM_SIZE;
+
+	if (bios->fp.edid)
+		return bios->fp.edid;
+
+	while (searchlen) {
+		if (!(newoffset = findstr(&bios->data[offset], searchlen, edid_sig, 8)))
+			return NULL;
+		offset += newoffset;
+		if (!nv_cksum(&bios->data[offset], EDID1_LEN))
+			break;
+
+		searchlen -= offset;
+		offset++;
+	}
+
+	NV_TRACE(dev, "Found EDID in BIOS\n");
+
+	return (bios->fp.edid = &bios->data[offset]);
+}
+
+bool NVInitVBIOS(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+
+	memset(bios, 0, sizeof(struct nvbios));
+
+	if (!NVShadowVBIOS(dev, bios->data))
+		return false;
+
+	bios->length = bios->data[2] * 512;
+	if (bios->length > NV_PROM_SIZE)
+		bios->length = NV_PROM_SIZE;
+
+	return true;
+}
+
+int nouveau_parse_vbios_struct(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	const uint8_t bit_signature[] = { 0xff, 0xb8, 'B', 'I', 'T' };
+	const uint8_t bmp_signature[] = { 0xff, 0x7f, 'N', 'V', 0x0 };
+	int offset;
+
+	if ((offset = findstr(bios->data, bios->length, bit_signature, sizeof(bit_signature)))) {
+		NV_TRACE(dev, "BIT BIOS found\n");
+		return parse_bit_structure(dev, bios, offset + 6);
+	}
+	if ((offset = findstr(bios->data, bios->length, bmp_signature, sizeof(bmp_signature)))) {
+		NV_TRACE(dev, "BMP BIOS found\n");
+		return parse_bmp_structure(dev, bios, offset);
+	}
+
+	NV_ERROR(dev, "No known BIOS signature found\n");
+
+	return -ENODEV;
+}
+
+int nouveau_run_vbios_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	int ret = 0;
+
+	NVLockVgaCrtcs(dev, false);
+	if (nv_two_heads(dev))
+		NVSetOwner(dev, crtchead);
+
+	if (bios->major_version < 5)	/* BMP only */
+		load_nv17_hw_sequencer_ucode(dev, bios);
+
+	parse_init_tables(dev, bios);
+
+	if (bios->major_version < 5)
+		/* feature_byte on BMP is poor, but init always sets CR4B */
+		bios->is_mobile = NVReadVgaCrtc(dev, 0, NV_CIO_CRE_4B) & 0x40;
+
+	/* all BIT systems need p_f_m_t for digital_min_front_porch */
+	if (bios->is_mobile || bios->major_version >= 5)
+		ret = parse_fp_mode_table(dev, bios);
+
+	NVLockVgaCrtcs(dev, true);
+
+	return ret;
+}
+
+int nouveau_parse_bios(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nvbios *bios = &dev_priv->VBIOS;
+	uint32_t saved_nv_pextdev_boot_0;
+	int ret;
+
+	if (!NVInitVBIOS(dev))
+		return -ENODEV;
+	if ((ret = nouveau_parse_vbios_struct(dev)))
+		return ret;
+	if ((ret = parse_dcb_table(dev, bios, nv_two_heads(dev))))
+		return ret;
+	fixup_legacy_i2c(bios);
+
+	if (!bios->major_version)	/* we don't run version 0 bios */
+		return 0;
+
+	/* these will need remembering across a suspend */
+	saved_nv_pextdev_boot_0 = bios_rd32(dev, NV_PEXTDEV_BOOT_0);
+	saved_nv_pfb_cfg0 = bios_rd32(dev, NV_PFB_CFG0);
+
+	/* init script execution disabled */
+	bios->execute = false;
+
+	bios_wr32(dev, NV_PEXTDEV_BOOT_0, saved_nv_pextdev_boot_0);
+
+	dev_priv->vbios = &bios->pub;
+
+	if ((ret = nouveau_run_vbios_init(dev))) {
+		dev_priv->vbios = NULL;
+		return ret;
+	}
+
+	/* allow subsequent scripts to execute */
+	bios->execute = true;
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_bios.h b/drivers/gpu/drm/nouveau/nouveau_bios.h
new file mode 100644
index 0000000..b7e0f32
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_bios.h
@@ -0,0 +1,223 @@
+/*
+ * Copyright 2007-2008 Nouveau Project
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __NOUVEAU_BIOS_H__
+#define __NOUVEAU_BIOS_H__
+
+#include "nvreg.h"
+#include "nouveau_i2c.h"
+
+#define DCB_MAX_NUM_ENTRIES 16
+#define DCB_MAX_NUM_I2C_ENTRIES 16
+
+#define DCB_LOC_ON_CHIP 0
+
+struct dcb_entry {
+	int index;	/* may not be raw dcb index if merging has happened */
+	uint8_t type;
+	uint8_t i2c_index;
+	uint8_t heads;
+	uint8_t bus;
+	uint8_t location;
+	uint8_t or;
+	bool duallink_possible;
+	union {
+		struct {
+			int maxfreq;
+		} crtconf;
+		struct {
+			bool use_straps_for_mode;
+			bool use_power_scripts;
+		} lvdsconf;
+	};
+	bool i2c_upper_default;
+};
+
+struct dcb_i2c_entry {
+	uint8_t port_type;
+	uint8_t read, write;
+	struct nouveau_i2c_chan *chan;
+};
+
+struct parsed_dcb {
+	int entries;
+	struct dcb_entry entry[DCB_MAX_NUM_ENTRIES];
+	struct dcb_i2c_entry i2c[DCB_MAX_NUM_I2C_ENTRIES];
+};
+
+struct bios_parsed_dcb {
+	uint8_t version;
+
+	struct parsed_dcb dcb;
+
+	uint16_t init8e_table_ptr;
+	uint8_t *i2c_table;
+	uint8_t i2c_default_indices;
+};
+
+enum nouveau_encoder_type
+{
+	/* 0-3 match DCB types */
+	OUTPUT_NONE = 4,
+	OUTPUT_ANALOG = 0,
+	OUTPUT_TMDS = 2,
+	OUTPUT_LVDS = 3,
+	OUTPUT_TV = 1,
+	OUTPUT_ANY = 5,
+};
+
+enum nouveau_or {
+	OUTPUT_A = (1 << 0),
+	OUTPUT_B = (1 << 1),
+	OUTPUT_C = (1 << 2)
+};
+
+enum LVDS_script {
+	/* Order *does* matter here */
+	LVDS_INIT = 1,
+	LVDS_RESET,
+	LVDS_BACKLIGHT_ON,
+	LVDS_BACKLIGHT_OFF,
+	LVDS_PANEL_ON,
+	LVDS_PANEL_OFF
+};
+
+/* changing these requires matching changes to reg tables in nv_get_clock */
+#define MAX_PLL_TYPES	4
+enum pll_types {
+	NVPLL,
+	MPLL,
+	VPLL1,
+	VPLL2
+};
+
+struct pll_lims {
+	struct {
+		int minfreq;
+		int maxfreq;
+		int min_inputfreq;
+		int max_inputfreq;
+
+		uint8_t min_m;
+		uint8_t max_m;
+		uint8_t min_n;
+		uint8_t max_n;
+	} vco1, vco2;
+
+	uint8_t max_log2p;
+	/*
+	 * for most pre nv50 cards setting a log2P of 7 (the common max_log2p
+	 * value) is no different to 6 (at least for vplls) so allowing the MNP
+	 * calc to use 7 causes the generated clock to be out by a factor of 2.
+	 * however, max_log2p cannot be fixed-up during parsing as the
+	 * unmodified max_log2p value is still needed for setting mplls, hence
+	 * an additional max_usable_log2p member
+	 */
+	uint8_t max_usable_log2p;
+	uint8_t log2p_bias;
+	int refclk;
+};
+
+struct nouveau_bios_info {
+	struct parsed_dcb *dcb;
+
+	uint8_t chip_version;
+
+	uint32_t dactestval;
+	uint8_t digital_min_front_porch;
+	bool fp_no_ddc;
+};
+
+struct nvbios {
+	struct nouveau_bios_info pub;
+
+	uint8_t data[NV_PROM_SIZE];
+	unsigned int length;
+	bool execute;
+
+	uint8_t major_version;
+	uint8_t feature_byte;
+	bool is_mobile;
+
+	uint32_t fmaxvco, fminvco;
+
+	bool old_style_init;
+	uint16_t init_script_tbls_ptr;
+	uint16_t extra_init_script_tbl_ptr;
+	uint16_t macro_index_tbl_ptr;
+	uint16_t macro_tbl_ptr;
+	uint16_t condition_tbl_ptr;
+	uint16_t io_condition_tbl_ptr;
+	uint16_t io_flag_condition_tbl_ptr;
+	uint16_t init_function_tbl_ptr;
+
+	uint16_t pll_limit_tbl_ptr;
+	uint16_t ram_restrict_tbl_ptr;
+
+	struct bios_parsed_dcb bdcb;
+
+	struct {
+		int head;
+		uint16_t script_table_ptr;
+	} display;
+
+	struct {
+		uint16_t fptablepointer;	/* also used by tmds */
+		uint16_t fpxlatetableptr;
+		int xlatwidth;
+		uint16_t lvdsmanufacturerpointer;
+		uint16_t fpxlatemanufacturertableptr;
+		uint16_t mode_ptr;
+		uint16_t xlated_entry;
+		bool power_off_for_reset;
+		bool reset_after_pclk_change;
+		bool dual_link;
+		bool link_c_increment;
+		bool BITbit1;
+		int duallink_transition_clk;
+		uint8_t *edid;
+
+		/* will need resetting after suspend */
+		int last_script_invoc;
+		bool lvds_init_run;
+	} fp;
+
+	struct {
+		uint16_t output0_script_ptr;
+		uint16_t output1_script_ptr;
+	} tmds;
+
+	struct {
+		uint16_t mem_init_tbl_ptr;
+		uint16_t sdr_seq_tbl_ptr;
+		uint16_t ddr_seq_tbl_ptr;
+
+		struct {
+			uint8_t crt, tv, panel;
+		} i2c_indices;
+
+		uint16_t lvds_single_a_script_ptr;
+	} legacy;
+};
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/nouveau_bo.c b/drivers/gpu/drm/nouveau/nouveau_bo.c
new file mode 100644
index 0000000..0f80857
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_bo.c
@@ -0,0 +1,415 @@
+/*
+ * Copyright 2007 Dave Airlied
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+/*
+ * Authors: Dave Airlied <airlied@linux.ie>
+ *	    Ben Skeggs   <darktama@iinet.net.au>
+ *	    Jeremy Kolb  <jkolb@brandeis.edu>
+ */
+
+#include "drmP.h"
+#include "nouveau_drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+
+static struct drm_ttm_backend *
+nouveau_bo_create_ttm_backend_entry(struct drm_device * dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	switch (dev_priv->gart_info.type) {
+	case NOUVEAU_GART_AGP:
+		return drm_agp_init_ttm(dev);
+	case NOUVEAU_GART_SGDMA:
+		return nouveau_sgdma_init_ttm(dev);
+	default:
+		NV_ERROR(dev, "Unknown GART type %d\n", dev_priv->gart_info.type);
+		break;
+	}
+
+	return NULL;
+}
+
+static int
+nouveau_bo_fence_type(struct drm_buffer_object *bo,
+		      uint32_t *fclass, uint32_t *type)
+{
+	/* When we get called, *fclass is set to the requested fence class */
+	*type = 1;
+	return 0;
+
+}
+
+static int
+nouveau_bo_invalidate_caches(struct drm_device *dev, uint64_t buffer_flags)
+{
+	/* We'll do this from user space. */
+	return 0;
+}
+
+static int
+nouveau_bo_init_mem_type(struct drm_device *dev, uint32_t type,
+			 struct drm_mem_type_manager *man)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	switch (type) {
+	case DRM_BO_MEM_LOCAL:
+		man->flags = _DRM_FLAG_MEMTYPE_MAPPABLE |
+			     _DRM_FLAG_MEMTYPE_CACHED;
+		man->drm_bus_maptype = 0;
+		break;
+	case DRM_BO_MEM_VRAM:
+		man->flags = _DRM_FLAG_MEMTYPE_FIXED |
+			     _DRM_FLAG_MEMTYPE_MAPPABLE |
+			     _DRM_FLAG_NEEDS_IOREMAP;
+		man->io_addr = NULL;
+		man->drm_bus_maptype = _DRM_FRAME_BUFFER;
+		man->io_offset = drm_get_resource_start(dev, 1);
+		man->io_size = drm_get_resource_len(dev, 1);
+		if (man->io_size > nouveau_mem_fb_amount(dev))
+			man->io_size = nouveau_mem_fb_amount(dev);
+		man->gpu_offset = dev_priv->vm_vram_base;
+		break;
+	case DRM_BO_MEM_PRIV0:
+		/* Unmappable VRAM */
+		man->flags = _DRM_FLAG_MEMTYPE_CMA;
+		man->drm_bus_maptype = 0;
+		break;
+	case DRM_BO_MEM_TT:
+		switch (dev_priv->gart_info.type) {
+		case NOUVEAU_GART_AGP:
+			man->flags = _DRM_FLAG_MEMTYPE_MAPPABLE |
+				     _DRM_FLAG_MEMTYPE_CSELECT |
+				     _DRM_FLAG_NEEDS_IOREMAP;
+			man->drm_bus_maptype = _DRM_AGP;
+			break;
+		case NOUVEAU_GART_SGDMA:
+			man->flags = _DRM_FLAG_MEMTYPE_MAPPABLE |
+				     _DRM_FLAG_MEMTYPE_CSELECT |
+				     _DRM_FLAG_MEMTYPE_CMA;
+			man->drm_bus_maptype = _DRM_SCATTER_GATHER;
+			break;
+		default:
+			NV_ERROR(dev, "Unknown GART type: %d\n",
+				 dev_priv->gart_info.type);
+			return -EINVAL;
+		}
+
+		man->io_offset  = dev_priv->gart_info.aper_base;
+		man->io_size    = dev_priv->gart_info.aper_size;
+		man->io_addr   = NULL;
+		man->gpu_offset = dev_priv->vm_gart_base;
+		break;
+	default:
+		NV_ERROR(dev, "Unsupported memory type %u\n", (unsigned)type);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static uint64_t
+nouveau_bo_evict_flags(struct drm_buffer_object *bo)
+{
+	switch (bo->mem.mem_type) {
+	case DRM_BO_MEM_LOCAL:
+	case DRM_BO_MEM_TT:
+		return DRM_BO_FLAG_MEM_LOCAL;
+	default:
+		return DRM_BO_FLAG_MEM_TT | DRM_BO_FLAG_CACHED;
+	}
+	return 0;
+}
+
+
+/* GPU-assisted copy using NV_MEMORY_TO_MEMORY_FORMAT, can access
+ * DRM_BO_MEM_{VRAM,PRIV0,TT} directly.
+ */
+static inline uint32_t
+nouveau_bo_mem_ctxdma(struct nouveau_channel *chan, struct drm_bo_mem_reg *mem)
+{
+	if (mem->mem_type == DRM_BO_MEM_TT)
+		return chan->gart_handle;
+
+	return chan->vram_handle;
+}
+
+static int
+nouveau_bo_move_m2mf(struct drm_buffer_object *bo, int evict, int no_wait,
+		     struct drm_bo_mem_reg *old_mem,
+		     struct drm_bo_mem_reg *new_mem)
+{
+	struct drm_device *dev = bo->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan;
+	uint64_t src_offset, dst_offset;
+	uint32_t page_count;
+
+	chan = nouveau_fence_channel(dev, bo->new_fence_class);
+	if (!chan) {
+		NV_ERROR(dev, "channel %d non-existant, using kchan\n",
+			 bo->fence_class);
+
+		chan = dev_priv->channel;
+		if (!chan)
+			return -EINVAL;
+	}
+
+	src_offset = old_mem->mm_node->start << PAGE_SHIFT;
+	dst_offset = new_mem->mm_node->start << PAGE_SHIFT;
+	if (dev_priv->card_type >= NV_50 &&
+	    !(new_mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_NOVM)) {
+		/* It's quite possibly safe to use bo->offset for src */
+		if (old_mem->mem_type == DRM_BO_MEM_TT)
+			src_offset += dev_priv->vm_gart_base;
+		else
+			src_offset += dev_priv->vm_vram_base;
+
+		if (new_mem->mem_type == DRM_BO_MEM_TT)
+			dst_offset += dev_priv->vm_gart_base;
+		else
+			dst_offset += dev_priv->vm_vram_base;
+	}
+
+	RING_SPACE(chan, 3);
+	BEGIN_RING(chan, NvSubM2MF, NV_MEMORY_TO_MEMORY_FORMAT_DMA_SOURCE, 2);
+	OUT_RING  (chan, nouveau_bo_mem_ctxdma(chan, old_mem));
+	OUT_RING  (chan, nouveau_bo_mem_ctxdma(chan, new_mem));
+
+	if (dev_priv->card_type >= NV_50) {
+		RING_SPACE(chan, 4);
+		BEGIN_RING(chan, NvSubM2MF, 0x0200, 1);
+		OUT_RING  (chan, 1);
+		BEGIN_RING(chan, NvSubM2MF, 0x021c, 1);
+		OUT_RING  (chan, 1);
+	}
+
+	page_count = new_mem->num_pages;
+	while (page_count) {
+		int line_count = (page_count > 2047) ? 2047 : page_count;
+
+		if (dev_priv->card_type >= NV_50) {
+			RING_SPACE(chan, 3);
+			BEGIN_RING(chan, NvSubM2MF, 0x0238, 2);
+			OUT_RING  (chan, upper_32_bits(src_offset));
+			OUT_RING  (chan, upper_32_bits(dst_offset));
+		}
+		RING_SPACE(chan, 11);
+		BEGIN_RING(chan, NvSubM2MF,
+				 NV_MEMORY_TO_MEMORY_FORMAT_OFFSET_IN, 8);
+		OUT_RING  (chan, lower_32_bits(src_offset));
+		OUT_RING  (chan, lower_32_bits(dst_offset));
+		OUT_RING  (chan, PAGE_SIZE); /* src_pitch */
+		OUT_RING  (chan, PAGE_SIZE); /* dst_pitch */
+		OUT_RING  (chan, PAGE_SIZE); /* line_length */
+		OUT_RING  (chan, line_count);
+		OUT_RING  (chan, (1<<8)|(1<<0));
+		OUT_RING  (chan, 0);
+		BEGIN_RING(chan, NvSubM2MF, NV_MEMORY_TO_MEMORY_FORMAT_NOP, 1);
+		OUT_RING  (chan, 0);
+
+		page_count -= line_count;
+		src_offset += (PAGE_SIZE * line_count);
+		dst_offset += (PAGE_SIZE * line_count);
+	}
+
+	return drm_bo_move_accel_cleanup(bo, evict, no_wait, chan->id,
+					 DRM_FENCE_TYPE_EXE, 0, new_mem);
+}
+
+/* Flip pages into the GART and move if we can. */
+static int
+nouveau_bo_move_flipd(struct drm_buffer_object *bo, int evict, int no_wait,
+		      struct drm_bo_mem_reg *new_mem)
+{
+	struct drm_device *dev = bo->dev;
+	struct drm_bo_mem_reg tmp_mem;
+	int ret;
+
+	tmp_mem = *new_mem;
+	tmp_mem.mm_node = NULL;
+	tmp_mem.proposed_flags = (DRM_BO_FLAG_MEM_TT |
+				  DRM_BO_FLAG_CACHED |
+				  DRM_BO_FLAG_FORCE_CACHING);
+
+	ret = drm_bo_mem_space(bo, &tmp_mem, no_wait);
+	if (ret)
+		return ret;
+
+	ret = drm_ttm_bind(bo->ttm, &tmp_mem);
+	if (ret)
+		goto out_cleanup;
+
+	ret = nouveau_bo_move_m2mf(bo, 1, no_wait, &bo->mem, &tmp_mem);
+	if (ret)
+		goto out_cleanup;
+
+	ret = drm_bo_move_ttm(bo, evict, no_wait, new_mem);
+
+out_cleanup:
+	if (tmp_mem.mm_node) {
+		mutex_lock(&dev->struct_mutex);
+		if (tmp_mem.mm_node != bo->pinned_node)
+			drm_mm_put_block(tmp_mem.mm_node);
+		tmp_mem.mm_node = NULL;
+		mutex_unlock(&dev->struct_mutex);
+	}
+
+	return ret;
+}
+
+static int
+nouveau_bo_move_flips(struct drm_buffer_object *bo, int evict, int no_wait,
+		      struct drm_bo_mem_reg *new_mem)
+{
+	struct drm_device *dev = bo->dev;
+	struct drm_bo_mem_reg tmp_mem;
+	int ret = 0;
+
+	tmp_mem = bo->mem;
+	tmp_mem.mm_node = NULL;
+	tmp_mem.proposed_flags = DRM_BO_FLAG_MEM_TT;
+	ret = drm_bo_mem_space(bo, &tmp_mem, no_wait);
+	if (ret)
+		return ret;
+
+	if (!bo->ttm) {
+		ret = drm_bo_add_ttm(bo);
+		if (ret)
+			goto out_cleanup;
+	}
+
+	ret = drm_bo_move_ttm(bo, evict, no_wait, &tmp_mem);
+	if (ret)
+		goto out_cleanup;
+
+	ret = nouveau_bo_move_m2mf(bo, 1, no_wait, &bo->mem, new_mem);
+	if (ret)
+		goto out_cleanup;
+
+out_cleanup:
+	if (tmp_mem.mm_node) {
+		mutex_lock(&dev->struct_mutex);
+		if (tmp_mem.mm_node != bo->pinned_node)
+			drm_mm_put_block(tmp_mem.mm_node);
+		tmp_mem.mm_node = NULL;
+		mutex_lock(&dev->struct_mutex);
+	}
+
+	return ret;
+}
+
+static int
+nouveau_bo_move(struct drm_buffer_object *bo, int evict, int no_wait,
+		struct drm_bo_mem_reg *new_mem)
+{
+	struct drm_nouveau_private *dev_priv = bo->dev->dev_private;
+	struct drm_bo_mem_reg *old_mem = &bo->mem;
+	int ret;
+
+	if (dev_priv->init_state != NOUVEAU_CARD_INIT_DONE)
+		return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+
+	if (dev_priv->card_type == NV_50 &&
+	    (new_mem->mem_type == DRM_BO_MEM_VRAM ||
+	     new_mem->mem_type == DRM_BO_MEM_PRIV0) &&
+	    !(new_mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_NOVM)) {
+		uint64_t offset = new_mem->mm_node->start << PAGE_SHIFT;
+		unsigned tile = 0;
+
+		if (new_mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_TILE) {
+			if (new_mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_ZTILE)
+				tile = 0x00002800;
+			else
+				tile = 0x00007000;
+		}
+
+		ret = nv50_mem_vm_bind_linear(bo->dev,
+					      offset + dev_priv->vm_vram_base,
+					      new_mem->size, tile, offset);
+		if (ret)
+			return ret;
+	}
+
+	if (old_mem->flags & DRM_BO_FLAG_CLEAN) {
+		return drm_bo_move_accel_cleanup(bo, 1, no_wait,
+						 bo->new_fence_class,
+						 DRM_FENCE_TYPE_EXE, 0,
+						 new_mem);
+	}
+
+	if (dev_priv->card_type == NV_50 &&
+	    new_mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_TILE)
+		return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+
+	if (new_mem->mem_type == DRM_BO_MEM_LOCAL) {
+		if (old_mem->mem_type == DRM_BO_MEM_LOCAL)
+			return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+		if (nouveau_bo_move_flipd(bo, evict, no_wait, new_mem))
+			return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+	}
+	else
+	if (old_mem->mem_type == DRM_BO_MEM_LOCAL) {
+		if (nouveau_bo_move_flips(bo, evict, no_wait, new_mem))
+			return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+	}
+	else {
+		if (nouveau_bo_move_m2mf(bo, evict, no_wait, old_mem, new_mem))
+			return drm_bo_move_memcpy(bo, evict, no_wait, new_mem);
+	}
+
+	return 0;
+}
+
+static void
+nouveau_bo_flush_ttm(struct drm_ttm *ttm)
+{
+}
+
+static uint32_t nouveau_mem_prios[]  = {
+	DRM_BO_MEM_PRIV0,
+	DRM_BO_MEM_VRAM,
+	DRM_BO_MEM_TT,
+	DRM_BO_MEM_LOCAL
+};
+static uint32_t nouveau_busy_prios[] = {
+	DRM_BO_MEM_TT,
+	DRM_BO_MEM_PRIV0,
+	DRM_BO_MEM_VRAM,
+	DRM_BO_MEM_LOCAL
+};
+
+struct drm_bo_driver nouveau_bo_driver = {
+	.mem_type_prio = nouveau_mem_prios,
+	.mem_busy_prio = nouveau_busy_prios,
+	.num_mem_type_prio = sizeof(nouveau_mem_prios)/sizeof(uint32_t),
+	.num_mem_busy_prio = sizeof(nouveau_busy_prios)/sizeof(uint32_t),
+	.create_ttm_backend_entry = nouveau_bo_create_ttm_backend_entry,
+	.fence_type = nouveau_bo_fence_type,
+	.invalidate_caches = nouveau_bo_invalidate_caches,
+	.init_mem_type = nouveau_bo_init_mem_type,
+	.evict_flags = nouveau_bo_evict_flags,
+	.move = nouveau_bo_move,
+	.ttm_cache_flush= nouveau_bo_flush_ttm,
+	.command_stream_barrier = NULL
+};
diff --git a/drivers/gpu/drm/nouveau/nouveau_calc.c b/drivers/gpu/drm/nouveau/nouveau_calc.c
new file mode 100644
index 0000000..a319ad4
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_calc.c
@@ -0,0 +1,622 @@
+/*
+ * Copyright 1993-2003 NVIDIA, Corporation
+ * Copyright 2007-2009 Stuart Bennett
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF
+ * OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_hw.h"
+
+/****************************************************************************\
+*                                                                            *
+* The video arbitration routines calculate some "magic" numbers.  Fixes      *
+* the snow seen when accessing the framebuffer without it.                   *
+* It just works (I hope).                                                    *
+*                                                                            *
+\****************************************************************************/
+
+struct nv_fifo_info {
+	int graphics_lwm;
+	int video_lwm;
+	int graphics_burst_size;
+	int video_burst_size;
+	bool valid;
+};
+
+struct nv_sim_state {
+	int pclk_khz;
+	int mclk_khz;
+	int nvclk_khz;
+	int pix_bpp;
+	bool enable_mp;
+	bool enable_video;
+	int mem_page_miss;
+	int mem_latency;
+	int memory_type;
+	int memory_width;
+};
+
+static void
+nv4CalcArbitration(struct nv_fifo_info *fifo, struct nv_sim_state *arb)
+{
+	int pagemiss, cas, width, video_enable, bpp;
+	int nvclks, mclks, pclks, vpagemiss, crtpagemiss, vbs;
+	int found, mclk_extra, mclk_loop, cbs, m1, p1;
+	int mclk_freq, pclk_freq, nvclk_freq, mp_enable;
+	int us_m, us_n, us_p, video_drain_rate, crtc_drain_rate;
+	int vpm_us, us_video, vlwm, video_fill_us, cpm_us, us_crt, clwm;
+
+	pclk_freq = arb->pclk_khz;
+	mclk_freq = arb->mclk_khz;
+	nvclk_freq = arb->nvclk_khz;
+	pagemiss = arb->mem_page_miss;
+	cas = arb->mem_latency;
+	width = arb->memory_width >> 6;
+	video_enable = arb->enable_video;
+	bpp = arb->pix_bpp;
+	mp_enable = arb->enable_mp;
+	clwm = 0;
+	vlwm = 0;
+	cbs = 128;
+	pclks = 2;
+	nvclks = 2;
+	nvclks += 2;
+	nvclks += 1;
+	mclks = 5;
+	mclks += 3;
+	mclks += 1;
+	mclks += cas;
+	mclks += 1;
+	mclks += 1;
+	mclks += 1;
+	mclks += 1;
+	mclk_extra = 3;
+	nvclks += 2;
+	nvclks += 1;
+	nvclks += 1;
+	nvclks += 1;
+	if (mp_enable)
+		mclks += 4;
+	nvclks += 0;
+	pclks += 0;
+	found = 0;
+	vbs = 0;
+	while (found != 1) {
+		fifo->valid = true;
+		found = 1;
+		mclk_loop = mclks + mclk_extra;
+		us_m = mclk_loop * 1000 * 1000 / mclk_freq;
+		us_n = nvclks * 1000 * 1000 / nvclk_freq;
+		us_p = nvclks * 1000 * 1000 / pclk_freq;
+		if (video_enable) {
+			video_drain_rate = pclk_freq * 2;
+			crtc_drain_rate = pclk_freq * bpp / 8;
+			vpagemiss = 2;
+			vpagemiss += 1;
+			crtpagemiss = 2;
+			vpm_us = vpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+			if (nvclk_freq * 2 > mclk_freq * width)
+				video_fill_us = cbs * 1000 * 1000 / 16 / nvclk_freq;
+			else
+				video_fill_us = cbs * 1000 * 1000 / (8 * width) / mclk_freq;
+			us_video = vpm_us + us_m + us_n + us_p + video_fill_us;
+			vlwm = us_video * video_drain_rate / (1000 * 1000);
+			vlwm++;
+			vbs = 128;
+			if (vlwm > 128)
+				vbs = 64;
+			if (vlwm > (256 - 64))
+				vbs = 32;
+			if (nvclk_freq * 2 > mclk_freq * width)
+				video_fill_us = vbs * 1000 * 1000 / 16 / nvclk_freq;
+			else
+				video_fill_us = vbs * 1000 * 1000 / (8 * width) / mclk_freq;
+			cpm_us = crtpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+			us_crt = us_video + video_fill_us + cpm_us + us_m + us_n + us_p;
+			clwm = us_crt * crtc_drain_rate / (1000 * 1000);
+			clwm++;
+		} else {
+			crtc_drain_rate = pclk_freq * bpp / 8;
+			crtpagemiss = 2;
+			crtpagemiss += 1;
+			cpm_us = crtpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+			us_crt = cpm_us + us_m + us_n + us_p;
+			clwm = us_crt * crtc_drain_rate / (1000 * 1000);
+			clwm++;
+		}
+		m1 = clwm + cbs - 512;
+		p1 = m1 * pclk_freq / mclk_freq;
+		p1 = p1 * bpp / 8;
+		if ((p1 < m1 && m1 > 0) ||
+		    (video_enable && (clwm > 511 || vlwm > 255)) ||
+		    (!video_enable && clwm > 519)) {
+			fifo->valid = false;
+			found = !mclk_extra;
+			mclk_extra--;
+		}
+		if (clwm < 384)
+			clwm = 384;
+		if (vlwm < 128)
+			vlwm = 128;
+		fifo->graphics_lwm = clwm;
+		fifo->graphics_burst_size = 128;
+		fifo->video_lwm = vlwm + 15;
+		fifo->video_burst_size = vbs;
+	}
+}
+
+static void
+nv10CalcArbitration(struct nv_fifo_info *fifo, struct nv_sim_state *arb)
+{
+	int pagemiss, width, video_enable, bpp;
+	int nvclks, mclks, pclks, vpagemiss, crtpagemiss;
+	int nvclk_fill;
+	int found, mclk_extra, mclk_loop, cbs, m1;
+	int mclk_freq, pclk_freq, nvclk_freq, mp_enable;
+	int us_m, us_m_min, us_n, us_p, crtc_drain_rate;
+	int vus_m;
+	int vpm_us, us_video, cpm_us, us_crt, clwm;
+	int clwm_rnd_down;
+	int m2us, us_pipe_min, p1clk, p2;
+	int min_mclk_extra;
+	int us_min_mclk_extra;
+
+	pclk_freq = arb->pclk_khz;	/* freq in KHz */
+	mclk_freq = arb->mclk_khz;
+	nvclk_freq = arb->nvclk_khz;
+	pagemiss = arb->mem_page_miss;
+	width = arb->memory_width / 64;
+	video_enable = arb->enable_video;
+	bpp = arb->pix_bpp;
+	mp_enable = arb->enable_mp;
+	clwm = 0;
+	cbs = 512;
+	pclks = 4;	/* lwm detect. */
+	nvclks = 3;	/* lwm -> sync. */
+	nvclks += 2;	/* fbi bus cycles (1 req + 1 busy) */
+	mclks = 1;	/* 2 edge sync.  may be very close to edge so just put one. */
+	mclks += 1;	/* arb_hp_req */
+	mclks += 5;	/* ap_hp_req   tiling pipeline */
+	mclks += 2;	/* tc_req     latency fifo */
+	mclks += 2;	/* fb_cas_n_  memory request to fbio block */
+	mclks += 7;	/* sm_d_rdv   data returned from fbio block */
+
+	/* fb.rd.d.Put_gc   need to accumulate 256 bits for read */
+	if (arb->memory_type == 0) {
+		if (arb->memory_width == 64)	/* 64 bit bus */
+			mclks += 4;
+		else
+			mclks += 2;
+	} else if (arb->memory_width == 64)	/* 64 bit bus */
+		mclks += 2;
+	else
+		mclks += 1;
+
+	if (!video_enable && arb->memory_width == 128) {
+		mclk_extra = (bpp == 32) ? 31 : 42;	/* Margin of error */
+		min_mclk_extra = 17;
+	} else {
+		mclk_extra = (bpp == 32) ? 8 : 4;	/* Margin of error */
+		/* mclk_extra = 4; *//* Margin of error */
+		min_mclk_extra = 18;
+	}
+
+	nvclks += 1;	/* 2 edge sync.  may be very close to edge so just put one. */
+	nvclks += 1;	/* fbi_d_rdv_n */
+	nvclks += 1;	/* Fbi_d_rdata */
+	nvclks += 1;	/* crtfifo load */
+
+	if (mp_enable)
+		mclks += 4;	/* Mp can get in with a burst of 8. */
+	/* Extra clocks determined by heuristics */
+
+	nvclks += 0;
+	pclks += 0;
+	found = 0;
+	while (found != 1) {
+		fifo->valid = true;
+		found = 1;
+		mclk_loop = mclks + mclk_extra;
+		us_m = mclk_loop * 1000 * 1000 / mclk_freq;	/* Mclk latency in us */
+		us_m_min = mclks * 1000 * 1000 / mclk_freq;	/* Minimum Mclk latency in us */
+		us_min_mclk_extra = min_mclk_extra * 1000 * 1000 / mclk_freq;
+		us_n = nvclks * 1000 * 1000 / nvclk_freq;	/* nvclk latency in us */
+		us_p = pclks * 1000 * 1000 / pclk_freq;	/* nvclk latency in us */
+		us_pipe_min = us_m_min + us_n + us_p;
+
+		vus_m = mclk_loop * 1000 * 1000 / mclk_freq;	/* Mclk latency in us */
+
+		if (video_enable) {
+			crtc_drain_rate = pclk_freq * bpp / 8;	/* MB/s */
+
+			vpagemiss = 1;	/* self generating page miss */
+			vpagemiss += 1;	/* One higher priority before */
+
+			crtpagemiss = 2;	/* self generating page miss */
+			if (mp_enable)
+				crtpagemiss += 1;	/* if MA0 conflict */
+
+			vpm_us = vpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+
+			us_video = vpm_us + vus_m;	/* Video has separate read return path */
+
+			cpm_us = crtpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+			us_crt = us_video	/* Wait for video */
+				 + cpm_us	/* CRT Page miss */
+				 + us_m + us_n + us_p;	/* other latency */
+
+			clwm = us_crt * crtc_drain_rate / (1000 * 1000);
+			clwm++;	/* fixed point <= float_point - 1.  Fixes that */
+		} else {
+			crtc_drain_rate = pclk_freq * bpp / 8;	/* bpp * pclk/8 */
+
+			crtpagemiss = 1;	/* self generating page miss */
+			crtpagemiss += 1;	/* MA0 page miss */
+			if (mp_enable)
+				crtpagemiss += 1;	/* if MA0 conflict */
+			cpm_us = crtpagemiss * pagemiss * 1000 * 1000 / mclk_freq;
+			us_crt = cpm_us + us_m + us_n + us_p;
+			clwm = us_crt * crtc_drain_rate / (1000 * 1000);
+			clwm++;	/* fixed point <= float_point - 1.  Fixes that */
+
+			/* Finally, a heuristic check when width == 64 bits */
+			if (width == 1) {
+				nvclk_fill = nvclk_freq * 8;
+				if (crtc_drain_rate * 100 >= nvclk_fill * 102)
+					clwm = 0xfff;	/* Large number to fail */
+				else if (crtc_drain_rate * 100 >= nvclk_fill * 98) {
+					clwm = 1024;
+					cbs = 512;
+				}
+			}
+		}
+
+		/*
+		 * Overfill check:
+		 */
+
+		clwm_rnd_down = (clwm / 8) * 8;
+		if (clwm_rnd_down < clwm)
+			clwm += 8;
+
+		m1 = clwm + cbs - 1024;	/* Amount of overfill */
+		m2us = us_pipe_min + us_min_mclk_extra;
+
+		/* pclk cycles to drain */
+		p1clk = m2us * pclk_freq / (1000 * 1000);
+		p2 = p1clk * bpp / 8;	/* bytes drained. */
+
+		if (p2 < m1 && m1 > 0) {
+			fifo->valid = false;
+			found = 0;
+			if (min_mclk_extra == 0) {
+				if (cbs <= 32)
+					found = 1;	/* Can't adjust anymore! */
+				else
+					cbs = cbs / 2;	/* reduce the burst size */
+			} else
+				min_mclk_extra--;
+		} else if (clwm > 1023) {	/* Have some margin */
+			fifo->valid = false;
+			found = 0;
+			if (min_mclk_extra == 0)
+				found = 1;	/* Can't adjust anymore! */
+			else
+				min_mclk_extra--;
+		}
+
+		if (clwm < (1024 - cbs + 8))
+			clwm = 1024 - cbs + 8;
+		/*  printf("CRT LWM: prog: 0x%x, bs: 256\n", clwm); */
+		fifo->graphics_lwm = clwm;
+		fifo->graphics_burst_size = cbs;
+
+		fifo->video_lwm = 1024;
+		fifo->video_burst_size = 512;
+	}
+}
+
+void
+nv4_10UpdateArbitrationSettings(struct drm_device *dev, int VClk, int bpp,
+				int *burst, int *lwm)
+{
+	struct nv_fifo_info fifo_data;
+	struct nv_sim_state sim_data;
+	int MClk = nouveau_hw_get_clock(dev, MPLL);
+	int NVClk = nouveau_hw_get_clock(dev, NVPLL);
+	uint32_t cfg1 = nvReadFB(dev, NV_PFB_CFG1);
+
+	sim_data.pclk_khz = VClk;
+	sim_data.mclk_khz = MClk;
+	sim_data.nvclk_khz = NVClk;
+	sim_data.pix_bpp = bpp;
+	sim_data.enable_mp = false;
+	if ((dev->pci_device & 0xffff) == 0x01a0 /*CHIPSET_NFORCE*/ ||
+	    (dev->pci_device & 0xffff) == 0x01f0 /*CHIPSET_NFORCE2*/) {
+		uint32_t type;
+
+		pci_read_config_dword(pci_get_bus_and_slot(0, 1), 0x7c, &type);
+
+		sim_data.enable_video = false;
+		sim_data.memory_type = (type >> 12) & 1;
+		sim_data.memory_width = 64;
+		sim_data.mem_latency = 3;
+		sim_data.mem_page_miss = 10;
+	} else {
+		sim_data.enable_video = (nv_arch(dev) != NV_04);
+		sim_data.memory_type = nvReadFB(dev, NV_PFB_CFG0) & 0x1;
+		sim_data.memory_width = (nvReadEXTDEV(dev, NV_PEXTDEV_BOOT_0) & 0x10) ? 128 : 64;
+		sim_data.mem_latency = cfg1 & 0xf;
+		sim_data.mem_page_miss = ((cfg1 >> 4) & 0xf) + ((cfg1 >> 31) & 0x1);
+	}
+
+	if (nv_arch(dev) == NV_04)
+		nv4CalcArbitration(&fifo_data, &sim_data);
+	else
+		nv10CalcArbitration(&fifo_data, &sim_data);
+
+	if (fifo_data.valid) {
+		int b = fifo_data.graphics_burst_size >> 4;
+		*burst = 0;
+		while (b >>= 1)
+			(*burst)++;
+		*lwm = fifo_data.graphics_lwm >> 3;
+	}
+}
+
+void
+nv30UpdateArbitrationSettings(int *burst, int *lwm)
+{
+	unsigned int fifo_size, burst_size, graphics_lwm;
+
+	fifo_size = 2048;
+	burst_size = 512;
+	graphics_lwm = fifo_size - burst_size;
+
+	*burst = 0;
+	burst_size >>= 5;
+	while (burst_size >>= 1)
+		(*burst)++;
+	*lwm = graphics_lwm >> 3;
+}
+
+void
+nouveau_calc_arb(struct drm_device *dev, int vclk, int bpp, int *burst, int *lwm)
+{
+	if (nv_arch(dev) < NV_30)
+		nv4_10UpdateArbitrationSettings(dev, vclk, bpp, burst, lwm);
+	else if ((dev->pci_device & 0xfff0) == 0x0240 /*CHIPSET_C51*/ ||
+		 (dev->pci_device & 0xfff0) == 0x03d0 /*CHIPSET_C512*/) {
+		*burst = 128;
+		*lwm = 0x0480;
+	} else
+		nv30UpdateArbitrationSettings(burst, lwm);
+}
+
+static int
+getMNP_single(struct drm_device *dev, struct pll_lims *pll_lim, int clk,
+	      struct nouveau_pll_vals *bestpv)
+{
+	/* Find M, N and P for a single stage PLL
+	 *
+	 * Note that some bioses (NV3x) have lookup tables of precomputed MNP
+	 * values, but we're too lazy to use those atm
+	 *
+	 * "clk" parameter in kHz
+	 * returns calculated clock
+	 */
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int cv = dev_priv->vbios->chip_version;
+	int minvco = pll_lim->vco1.minfreq, maxvco = pll_lim->vco1.maxfreq;
+	int minM = pll_lim->vco1.min_m, maxM = pll_lim->vco1.max_m;
+	int minN = pll_lim->vco1.min_n, maxN = pll_lim->vco1.max_n;
+	int minU = pll_lim->vco1.min_inputfreq, maxU = pll_lim->vco1.max_inputfreq;
+	int maxlog2P = pll_lim->max_usable_log2p;
+	int crystal = pll_lim->refclk;
+	int M, N, log2P, P;
+	int clkP, calcclk;
+	int delta, bestdelta = INT_MAX;
+	int bestclk = 0;
+
+	/* this division verified for nv20, nv18, nv28 (Haiku), and nv34 */
+	/* possibly correlated with introduction of 27MHz crystal */
+	if (cv < 0x17 || cv == 0x1a || cv == 0x20) {
+		if (clk > 250000)
+			maxM = 6;
+		if (clk > 340000)
+			maxM = 2;
+	} else if (cv < 0x40) {
+		if (clk > 150000)
+			maxM = 6;
+		if (clk > 200000)
+			maxM = 4;
+		if (clk > 340000)
+			maxM = 2;
+	}
+
+	if ((clk << maxlog2P) < minvco) {
+		minvco = clk << maxlog2P;
+		maxvco = minvco * 2;
+	}
+	if (clk + clk/200 > maxvco)	/* +0.5% */
+		maxvco = clk + clk/200;
+
+	/* NV34 goes maxlog2P->0, NV20 goes 0->maxlog2P */
+	for (log2P = 0; log2P <= maxlog2P; log2P++) {
+		P = 1 << log2P;
+		clkP = clk * P;
+
+		if (clkP < minvco)
+			continue;
+		if (clkP > maxvco)
+			return bestclk;
+
+		for (M = minM; M <= maxM; M++) {
+			if (crystal/M < minU)
+				return bestclk;
+			if (crystal/M > maxU)
+				continue;
+
+			/* add crystal/2 to round better */
+			N = (clkP * M + crystal/2) / crystal;
+
+			if (N < minN)
+				continue;
+			if (N > maxN)
+				break;
+
+			/* more rounding additions */
+			calcclk = ((N * crystal + P/2) / P + M/2) / M;
+			delta = abs(calcclk - clk);
+			/* we do an exhaustive search rather than terminating
+			 * on an optimality condition...
+			 */
+			if (delta < bestdelta) {
+				bestdelta = delta;
+				bestclk = calcclk;
+				bestpv->N1 = N;
+				bestpv->M1 = M;
+				bestpv->log2P = log2P;
+				if (delta == 0)	/* except this one */
+					return bestclk;
+			}
+		}
+	}
+
+	return bestclk;
+}
+
+static int
+getMNP_double(struct drm_device *dev, struct pll_lims *pll_lim, int clk,
+	      struct nouveau_pll_vals *bestpv)
+{
+	/* Find M, N and P for a two stage PLL
+	 *
+	 * Note that some bioses (NV30+) have lookup tables of precomputed MNP
+	 * values, but we're too lazy to use those atm
+	 *
+	 * "clk" parameter in kHz
+	 * returns calculated clock
+	 */
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int chip_version = dev_priv->vbios->chip_version;
+	int minvco1 = pll_lim->vco1.minfreq, maxvco1 = pll_lim->vco1.maxfreq;
+	int minvco2 = pll_lim->vco2.minfreq, maxvco2 = pll_lim->vco2.maxfreq;
+	int minU1 = pll_lim->vco1.min_inputfreq, minU2 = pll_lim->vco2.min_inputfreq;
+	int maxU1 = pll_lim->vco1.max_inputfreq, maxU2 = pll_lim->vco2.max_inputfreq;
+	int minM1 = pll_lim->vco1.min_m, maxM1 = pll_lim->vco1.max_m;
+	int minN1 = pll_lim->vco1.min_n, maxN1 = pll_lim->vco1.max_n;
+	int minM2 = pll_lim->vco2.min_m, maxM2 = pll_lim->vco2.max_m;
+	int minN2 = pll_lim->vco2.min_n, maxN2 = pll_lim->vco2.max_n;
+	int maxlog2P = pll_lim->max_usable_log2p;
+	int crystal = pll_lim->refclk;
+	bool fixedgain2 = (minM2 == maxM2 && minN2 == maxN2);
+	int M1, N1, M2, N2, log2P;
+	int clkP, calcclk1, calcclk2, calcclkout;
+	int delta, bestdelta = INT_MAX;
+	int bestclk = 0;
+
+	int vco2 = (maxvco2 - maxvco2/200) / 2;
+	for (log2P = 0; clk && log2P < maxlog2P && clk <= (vco2 >> log2P); log2P++)
+		;
+	clkP = clk << log2P;
+
+	if (maxvco2 < clk + clk/200)	/* +0.5% */
+		maxvco2 = clk + clk/200;
+
+	for (M1 = minM1; M1 <= maxM1; M1++) {
+		if (crystal/M1 < minU1)
+			return bestclk;
+		if (crystal/M1 > maxU1)
+			continue;
+
+		for (N1 = minN1; N1 <= maxN1; N1++) {
+			calcclk1 = crystal * N1 / M1;
+			if (calcclk1 < minvco1)
+				continue;
+			if (calcclk1 > maxvco1)
+				break;
+
+			for (M2 = minM2; M2 <= maxM2; M2++) {
+				if (calcclk1/M2 < minU2)
+					break;
+				if (calcclk1/M2 > maxU2)
+					continue;
+
+				/* add calcclk1/2 to round better */
+				N2 = (clkP * M2 + calcclk1/2) / calcclk1;
+				if (N2 < minN2)
+					continue;
+				if (N2 > maxN2)
+					break;
+
+				if (!fixedgain2) {
+					if (chip_version < 0x60)
+						if (N2/M2 < 4 || N2/M2 > 10)
+							continue;
+
+					calcclk2 = calcclk1 * N2 / M2;
+					if (calcclk2 < minvco2)
+						break;
+					if (calcclk2 > maxvco2)
+						continue;
+				} else
+					calcclk2 = calcclk1;
+
+				calcclkout = calcclk2 >> log2P;
+				delta = abs(calcclkout - clk);
+				/* we do an exhaustive search rather than terminating
+				 * on an optimality condition...
+				 */
+				if (delta < bestdelta) {
+					bestdelta = delta;
+					bestclk = calcclkout;
+					bestpv->N1 = N1;
+					bestpv->M1 = M1;
+					bestpv->N2 = N2;
+					bestpv->M2 = M2;
+					bestpv->log2P = log2P;
+					if (delta == 0)	/* except this one */
+						return bestclk;
+				}
+			}
+		}
+	}
+
+	return bestclk;
+}
+
+int
+nouveau_calc_pll_mnp(struct drm_device *dev, struct pll_lims *pll_lim, int clk,
+		     struct nouveau_pll_vals *pv)
+{
+	int outclk;
+
+	if (!pll_lim->vco2.maxfreq)
+		outclk = getMNP_single(dev, pll_lim, clk, pv);
+	else
+		outclk = getMNP_double(dev, pll_lim, clk, pv);
+
+	if (!outclk)
+		NV_ERROR(dev, "Could not find a compatible set of PLL values\n");
+
+	return outclk;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_connector.h b/drivers/gpu/drm/nouveau/nouveau_connector.h
new file mode 100644
index 0000000..052d9aa
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_connector.h
@@ -0,0 +1,51 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_CONNECTOR_H__
+#define __NOUVEAU_CONNECTOR_H__
+
+#include "nouveau_i2c.h"
+
+struct nouveau_connector {
+	struct drm_connector base;
+
+	struct drm_display_mode *native_mode;
+	bool digital;
+
+	struct nouveau_i2c_chan *i2c_chan;
+
+	int scaling_mode;
+
+	bool use_dithering;
+
+	struct nouveau_encoder *(*to_encoder) (struct nouveau_connector *connector, bool digital);
+};
+#define to_nouveau_connector(x) container_of((x), struct nouveau_connector, base)
+
+int nv50_connector_create(struct drm_device *dev, int i2c_index, int type);
+void nv50_connector_detect_all(struct drm_device *dev);
+
+#endif /* __NOUVEAU_CONNECTOR_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_crtc.h b/drivers/gpu/drm/nouveau/nouveau_crtc.h
new file mode 100644
index 0000000..5104431
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_crtc.h
@@ -0,0 +1,74 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_CRTC_H__
+#define __NOUVEAU_CRTC_H__
+
+struct nouveau_crtc {
+	struct drm_crtc base;
+
+	int index;
+
+	struct drm_mode_set mode_set;
+
+	struct drm_display_mode *mode;
+	bool use_dithering;
+
+	struct {
+		uint32_t offset;
+	} fb;
+
+	struct {
+		struct drm_gem_object *gem;
+		bool visible;
+		uint32_t offset;
+		void (*set_offset)(struct nouveau_crtc *, uint32_t offset);
+		void (*set_pos)(struct nouveau_crtc *, int x, int y);
+		void (*hide)(struct nouveau_crtc *, bool update);
+		void (*show)(struct nouveau_crtc *, bool update);
+	} cursor;
+
+	struct {
+		struct mem_block *mem;
+		uint16_t r[256];
+		uint16_t g[256];
+		uint16_t b[256];
+		int depth;
+	} lut;
+
+	int (*set_dither) (struct nouveau_crtc *crtc, bool update);
+	int (*set_scale) (struct nouveau_crtc *crtc, int mode, bool update);
+	int (*set_clock) (struct nouveau_crtc *crtc, struct drm_display_mode *);
+	int (*set_clock_mode) (struct nouveau_crtc *crtc);
+	int (*destroy) (struct nouveau_crtc *crtc);
+};
+#define to_nouveau_crtc(x) container_of((x), struct nouveau_crtc, base)
+
+int nv50_crtc_create(struct drm_device *dev, int index);
+int nv50_cursor_init(struct nouveau_crtc *);
+void nv50_cursor_fini(struct nouveau_crtc *);
+
+#endif /* __NOUVEAU_CRTC_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_display.c b/drivers/gpu/drm/nouveau/nouveau_display.c
new file mode 100644
index 0000000..8096bb5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_display.c
@@ -0,0 +1,114 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_fb.h"
+#include "nouveau_fbcon.h"
+
+static void
+nouveau_user_framebuffer_destroy(struct drm_framebuffer *drm_fb)
+{
+	struct nouveau_framebuffer *fb = to_nouveau_framebuffer(drm_fb);
+	struct drm_device *dev = drm_fb->dev;
+
+	if (drm_fb->fbdev)
+		nouveau_fbcon_remove(dev, drm_fb);
+
+	if (fb->gem) {
+		mutex_lock(&dev->struct_mutex);
+		drm_gem_object_unreference(fb->gem);
+		mutex_unlock(&dev->struct_mutex);
+	}
+
+	drm_framebuffer_cleanup(drm_fb);
+	kfree(fb);
+}
+
+static int
+nouveau_user_framebuffer_create_handle(struct drm_framebuffer *drm_fb,
+				       struct drm_file *file_priv,
+				       unsigned int *handle)
+{
+	struct nouveau_framebuffer *fb = to_nouveau_framebuffer(drm_fb);
+
+	return drm_gem_handle_create(file_priv, fb->gem, handle);
+}
+
+static const struct drm_framebuffer_funcs nouveau_framebuffer_funcs = {
+	.destroy = nouveau_user_framebuffer_destroy,
+	.create_handle = nouveau_user_framebuffer_create_handle,
+};
+
+struct drm_framebuffer *
+nouveau_framebuffer_create(struct drm_device *dev, struct drm_gem_object *gem,
+			   struct drm_mode_fb_cmd *mode_cmd)
+{
+	struct nouveau_framebuffer *fb;
+	int ret;
+
+	fb = kzalloc(sizeof(struct nouveau_framebuffer), GFP_KERNEL);
+	if (!fb)
+		return NULL;
+
+	ret = drm_framebuffer_init(dev, &fb->base, &nouveau_framebuffer_funcs);
+	if (ret) {
+		kfree(fb);
+		return NULL;
+	}
+
+	drm_helper_mode_fill_fb_struct(&fb->base, mode_cmd);
+
+	fb->gem = gem;
+	return &fb->base;
+}
+
+static struct drm_framebuffer *
+nouveau_user_framebuffer_create(struct drm_device *dev,
+				struct drm_file *file_priv,
+				struct drm_mode_fb_cmd *mode_cmd)
+{
+	struct drm_framebuffer *fb;
+	struct drm_gem_object *gem;
+
+	gem = drm_gem_object_lookup(dev, file_priv, mode_cmd->handle);
+	if (!gem)
+		return NULL;
+
+	fb = nouveau_framebuffer_create(dev, gem, mode_cmd);
+	if (!fb) {
+		drm_gem_object_unreference(gem);
+		return NULL;
+	}
+
+	return fb;
+}
+
+const struct drm_mode_config_funcs nouveau_mode_config_funcs = {
+	.fb_create = nouveau_user_framebuffer_create,
+	.fb_changed = nouveau_fbcon_probe,
+};
+
diff --git a/drivers/gpu/drm/nouveau/nouveau_dma.c b/drivers/gpu/drm/nouveau/nouveau_dma.c
new file mode 100644
index 0000000..83b2f5e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.c
@@ -0,0 +1,209 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+
+int
+nouveau_dma_channel_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct mem_block *pushbuf = NULL;
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	/* On !mm_enabled, we can't map a GART push buffer into kernel
+	 * space easily - so we'll just use VRAM.
+	 */
+	pushbuf = nouveau_mem_alloc(dev, 0, 0x8000, NOUVEAU_MEM_NOVM |
+				    NOUVEAU_MEM_FB | NOUVEAU_MEM_MAPPED,
+				    (struct drm_file *)-2);
+	if (!pushbuf) {
+		NV_ERROR(dev, "Failed to allocate DMA push buffer\n");
+		return -ENOMEM;
+	}
+
+	ret = nouveau_fifo_alloc(dev, &dev_priv->channel, (struct drm_file *)-2,
+				 pushbuf, NvDmaFB, NvDmaTT);
+	if (ret) {
+		NV_ERROR(dev, "Error allocating GPU channel: %d\n", ret);
+		return ret;
+	}
+
+	if (!dev_priv->mm_enabled) {
+		ret = nouveau_dma_channel_setup(dev_priv->channel);
+		if (ret) {
+			nouveau_fifo_free(dev_priv->channel);
+			dev_priv->channel = NULL;
+			return ret;
+		}
+	}
+	
+	NV_DEBUG(dev, "Using FIFO channel %d\n", dev_priv->channel->id);
+	return 0;
+}
+
+void
+nouveau_dma_channel_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	NV_DEBUG(dev, "\n");
+
+	if (dev_priv->channel) {
+		nouveau_fifo_free(dev_priv->channel);
+		dev_priv->channel = NULL;
+	}
+}
+
+int
+nouveau_dma_channel_setup(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *m2mf = NULL;
+	int ret, i;
+
+	/* Create NV_MEMORY_TO_MEMORY_FORMAT for buffer moves */
+	ret = nouveau_gpuobj_gr_new(chan, dev_priv->card_type < NV_50 ?
+				    0x0039 : 0x5039, &m2mf);
+	if (ret)
+		return ret;
+
+	ret = nouveau_gpuobj_ref_add(dev, chan, NvM2MF, m2mf, NULL);
+	if (ret)
+		return ret;
+
+	/* NV_MEMORY_TO_MEMORY_FORMAT requires a notifier object */
+	ret = nouveau_notifier_alloc(chan, NvNotify0, 1, &chan->m2mf_ntfy);
+	if (ret)
+		return ret;
+
+	/* Map push buffer */
+	if (dev_priv->mm_enabled) {
+		ret = drm_bo_kmap(chan->pushbuf_mem->bo, 0,
+				  chan->pushbuf_mem->bo->mem.num_pages,
+				  &chan->pushbuf_mem->kmap);
+		if (ret)
+			return ret;
+		chan->dma.pushbuf = chan->pushbuf_mem->kmap.virtual;
+	} else {
+		drm_core_ioremap(chan->pushbuf_mem->map, dev);
+		if (!chan->pushbuf_mem->map->handle) {
+			NV_ERROR(dev, "Failed to ioremap push buffer\n");
+			return -EINVAL;
+		}
+		chan->dma.pushbuf = (void *)chan->pushbuf_mem->map->handle;
+	}
+
+	/* Map M2MF notifier object - fbcon. */
+	if (drm_core_check_feature(dev, DRIVER_MODESET)) {
+		ret = drm_bo_kmap(chan->notifier_block->bo, 0,
+				  chan->notifier_block->bo->mem.num_pages,
+				  &chan->notifier_block->kmap);
+		if (ret)
+			return ret;
+		chan->m2mf_ntfy_map  = chan->notifier_block->kmap.virtual;
+		chan->m2mf_ntfy_map += chan->m2mf_ntfy;
+	}
+
+	/* Initialise DMA vars */
+	chan->dma.max  = (chan->pushbuf_mem->size >> 2) - 2;
+	chan->dma.put  = 0;
+	chan->dma.cur  = chan->dma.put;
+	chan->dma.free = chan->dma.max - chan->dma.cur;
+
+	/* Insert NOPS for NOUVEAU_DMA_SKIPS */
+	RING_SPACE(chan, NOUVEAU_DMA_SKIPS);
+	for (i = 0; i < NOUVEAU_DMA_SKIPS; i++)
+		OUT_RING (chan, 0);
+
+	/* Initialise NV_MEMORY_TO_MEMORY_FORMAT */
+	RING_SPACE(chan, 4);
+	BEGIN_RING(chan, NvSubM2MF, NV_MEMORY_TO_MEMORY_FORMAT_NAME, 1);
+	OUT_RING  (chan, NvM2MF);
+	BEGIN_RING(chan, NvSubM2MF, NV_MEMORY_TO_MEMORY_FORMAT_DMA_NOTIFY, 1);
+	OUT_RING  (chan, NvNotify0);
+
+	/* Sit back and pray the channel works.. */
+	FIRE_RING (chan);
+
+	return 0;
+}
+
+int
+nouveau_dma_wait(struct nouveau_channel *chan, int size)
+{
+	const int us_timeout = 100000;
+	int ret = -EBUSY, i;
+
+	for (i = 0; i < us_timeout; i++) {
+		uint32_t get = READ_GET();
+
+		if (chan->dma.put >= get) {
+			chan->dma.free = chan->dma.max - chan->dma.cur;
+
+			if (chan->dma.free < size) {
+				OUT_RING(chan, 0x20000000|chan->pushbuf_base);
+				if (get <= NOUVEAU_DMA_SKIPS) {
+					/*corner case - will be idle*/
+					if (chan->dma.put <= NOUVEAU_DMA_SKIPS)
+						WRITE_PUT(NOUVEAU_DMA_SKIPS + 1);
+
+					for (; i < us_timeout; i++) {
+						get = READ_GET();
+						if (get > NOUVEAU_DMA_SKIPS)
+							break;
+
+						DRM_UDELAY(1);
+					}
+
+					if (i >= us_timeout)
+						break;
+				}
+
+				WRITE_PUT(NOUVEAU_DMA_SKIPS);
+				chan->dma.cur  =
+				chan->dma.put  = NOUVEAU_DMA_SKIPS;
+				chan->dma.free = get - (NOUVEAU_DMA_SKIPS + 1);
+			}
+		} else {
+			chan->dma.free = get - chan->dma.cur - 1;
+		}
+
+		if (chan->dma.free >= size) {
+			ret = 0;
+			break;
+		}
+
+		DRM_UDELAY(1);
+	}
+
+	return ret;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_dma.h b/drivers/gpu/drm/nouveau/nouveau_dma.h
new file mode 100644
index 0000000..4383883
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_DMA_H__
+#define __NOUVEAU_DMA_H__
+
+typedef enum {
+	NvSubM2MF	= 0,
+	NvSub2D		= 1
+} nouveau_subchannel_id_t;
+
+typedef enum {
+	NvM2MF		= 0x80000001,
+	NvDmaFB		= 0x80000002,
+	NvDmaTT		= 0x80000003,
+	NvNotify0       = 0x80000004,
+	Nv2D		= 0x80000005,
+} nouveau_object_handle_t;
+
+#define NV_MEMORY_TO_MEMORY_FORMAT                                    0x00000039
+#define NV_MEMORY_TO_MEMORY_FORMAT_NAME                               0x00000000
+#define NV_MEMORY_TO_MEMORY_FORMAT_SET_REF                            0x00000050
+#define NV_MEMORY_TO_MEMORY_FORMAT_NOP                                0x00000100
+#define NV_MEMORY_TO_MEMORY_FORMAT_NOTIFY                             0x00000104
+#define NV_MEMORY_TO_MEMORY_FORMAT_NOTIFY_STYLE_WRITE                 0x00000000
+#define NV_MEMORY_TO_MEMORY_FORMAT_NOTIFY_STYLE_WRITE_LE_AWAKEN       0x00000001
+#define NV_MEMORY_TO_MEMORY_FORMAT_DMA_NOTIFY                         0x00000180
+#define NV_MEMORY_TO_MEMORY_FORMAT_DMA_SOURCE                         0x00000184
+#define NV_MEMORY_TO_MEMORY_FORMAT_OFFSET_IN                          0x0000030c
+
+#define NV50_MEMORY_TO_MEMORY_FORMAT                                  0x00005039
+#define NV50_MEMORY_TO_MEMORY_FORMAT_UNK200                           0x00000200
+#define NV50_MEMORY_TO_MEMORY_FORMAT_UNK21C                           0x0000021c
+#define NV50_MEMORY_TO_MEMORY_FORMAT_OFFSET_IN_HIGH                   0x00000238
+#define NV50_MEMORY_TO_MEMORY_FORMAT_OFFSET_OUT_HIGH                  0x0000023c
+
+static inline int
+RING_SPACE(struct nouveau_channel *chan, int size)
+{
+	if (chan->dma.free < size) {
+		int ret;
+
+		ret = nouveau_dma_wait(chan, size);
+		if (ret)
+			return ret;
+	}
+
+	chan->dma.free -= size;
+	return 0;
+}
+
+static inline void
+OUT_RING(struct nouveau_channel *chan, int data)
+{
+	chan->dma.pushbuf[chan->dma.cur++] = data;
+}
+
+static inline void
+BEGIN_RING(struct nouveau_channel *chan, int subc, int mthd, int size)
+{
+	OUT_RING(chan, (subc << 13) | (size << 18) | mthd);
+}
+
+#define READ_GET() ((nvchan_rd32(0x44) - chan->pushbuf_base) >> 2)
+#define WRITE_PUT(val) nvchan_wr32(0x40, ((val) << 2) + chan->pushbuf_base)
+
+static inline void
+FIRE_RING(struct nouveau_channel *chan)
+{
+	if (chan->dma.cur == chan->dma.put)
+		return;
+	chan->accel_done = true;
+
+	DRM_MEMORYBARRIER();
+	chan->dma.put = chan->dma.cur;
+	WRITE_PUT(chan->dma.put);
+}
+
+/* This should allow easy switching to a real fifo in the future. */
+#define OUT_MODE(mthd, val) do {				\
+	nv50_display_command(dev, mthd, val); 	        	\
+} while(0)
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/nouveau_drv.c b/drivers/gpu/drm/nouveau/nouveau_drv.c
new file mode 100644
index 0000000..578983e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_drv.c
@@ -0,0 +1,194 @@
+/*
+ * Copyright 2005 Stephane Marchesin.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+#include "drm_pciids.h"
+
+MODULE_PARM_DESC(noagp, "Disable AGP");
+int nouveau_noagp = 0;
+module_param_named(noagp, nouveau_noagp, int, 0400);
+
+MODULE_PARM_DESC(mm_enabled, "Enable TTM/GEM memory manager");
+int nouveau_mm_enabled = 0;
+module_param_named(mm_enabled, nouveau_mm_enabled, int, 0400);
+
+MODULE_PARM_DESC(modeset, "Enable kernel modesetting (>=GeForce 8)");
+int nouveau_modeset = -1; /* kms */
+module_param_named(modeset, nouveau_modeset, int, 0400);
+
+MODULE_PARM_DESC(duallink, "Allow dual-link TMDS (>=GeForce 8)");
+int nouveau_duallink = 0;
+module_param_named(duallink, nouveau_duallink, int, 0400);
+
+MODULE_PARM_DESC(uscript, "Execute output scripts (>=GeForce 8)");
+int nouveau_uscript = 0;
+module_param_named(uscript, nouveau_uscript, int, 0400);
+
+int nouveau_fbpercrtc = 0;
+#if 0
+module_param_named(fbpercrtc, nouveau_fbpercrtc, int, 0400);
+#endif
+
+static struct pci_device_id pciidlist[] = {
+	{
+		PCI_DEVICE(PCI_VENDOR_ID_NVIDIA, PCI_ANY_ID),
+		.class = PCI_BASE_CLASS_DISPLAY << 16,
+		.class_mask  = 0xff << 16,
+	},
+	{
+		PCI_DEVICE(PCI_VENDOR_ID_NVIDIA_SGS, PCI_ANY_ID),
+		.class = PCI_BASE_CLASS_DISPLAY << 16,
+		.class_mask  = 0xff << 16,
+	},
+	{}
+};
+
+MODULE_DEVICE_TABLE(pci, pciidlist);
+
+static struct drm_driver driver;
+
+static int __devinit
+nouveau_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	return drm_get_dev(pdev, ent, &driver);
+}
+
+static void
+nouveau_pci_remove(struct pci_dev *pdev)
+{
+	struct drm_device *dev = pci_get_drvdata(pdev);
+
+	drm_put_dev(dev);
+}
+
+static int
+nouveau_pci_suspend(struct pci_dev *pdev,  pm_message_t state)
+{
+	struct drm_device *dev = pci_get_drvdata(pdev);
+	(void)dev;
+	return -ENODEV;
+}
+
+static int
+nouveau_pci_resume(struct pci_dev *pdev)
+{
+	struct drm_device *dev = pci_get_drvdata(pdev);
+	(void)dev;
+	return -ENODEV;
+}
+
+extern struct drm_ioctl_desc nouveau_ioctls[];
+extern int nouveau_max_ioctl;
+
+static struct drm_driver driver = {
+	.driver_features =
+		DRIVER_USE_AGP | DRIVER_PCI_DMA | DRIVER_SG |
+		DRIVER_HAVE_IRQ | DRIVER_IRQ_SHARED,
+	.load = nouveau_load,
+	.firstopen = nouveau_firstopen,
+	.lastclose = nouveau_lastclose,
+	.unload = nouveau_unload,
+	.preclose = nouveau_preclose,
+	.irq_preinstall = nouveau_irq_preinstall,
+	.irq_postinstall = nouveau_irq_postinstall,
+	.irq_uninstall = nouveau_irq_uninstall,
+	.irq_handler = nouveau_irq_handler,
+	.reclaim_buffers = drm_core_reclaim_buffers,
+	.get_map_ofs = drm_core_get_map_ofs,
+	.get_reg_ofs = drm_core_get_reg_ofs,
+	.ioctls = nouveau_ioctls,
+	.fops = {
+		.owner = THIS_MODULE,
+		.open = drm_open,
+		.release = drm_release,
+		.ioctl = drm_ioctl,
+		.mmap = drm_mmap,
+		.poll = drm_poll,
+		.fasync = drm_fasync,
+#if defined(CONFIG_COMPAT)
+		.compat_ioctl = nouveau_compat_ioctl,
+#endif
+	},
+	.pci_driver = {
+		.name = DRIVER_NAME,
+		.id_table = pciidlist,
+		.probe = nouveau_pci_probe,
+		.remove = nouveau_pci_remove,
+		.suspend = nouveau_pci_suspend,
+		.resume = nouveau_pci_resume
+	},
+
+	.gem_init_object = nouveau_gem_object_new,
+	.gem_free_object = nouveau_gem_object_del,
+        .bo_driver = &nouveau_bo_driver,
+        .fence_driver = &nouveau_fence_driver,
+
+	.name = DRIVER_NAME,
+	.desc = DRIVER_DESC,
+#ifdef GIT_REVISION
+	.date = GIT_REVISION,
+#else
+	.date = DRIVER_DATE,
+#endif
+	.major = DRIVER_MAJOR,
+	.minor = DRIVER_MINOR,
+	.patchlevel = DRIVER_PATCHLEVEL,
+};
+
+static int __init nouveau_init(void)
+{
+	driver.num_ioctls = nouveau_max_ioctl;
+
+	if (nouveau_modeset == -1)
+#if defined(CONFIG_DRM_NOUVEAU_KMS)
+		nouveau_modeset = 1;
+#else
+		nouveau_modeset = 0;
+#endif
+
+	if (nouveau_modeset == 1) {
+		driver.driver_features |= DRIVER_MODESET;
+		nouveau_mm_enabled = 1;
+	}
+
+	if (nouveau_mm_enabled == 1)
+		driver.driver_features |= DRIVER_GEM;
+
+	return drm_init(&driver);
+}
+
+static void __exit nouveau_exit(void)
+{
+	drm_exit(&driver);
+}
+
+module_init(nouveau_init);
+module_exit(nouveau_exit);
+
+MODULE_AUTHOR(DRIVER_AUTHOR);
+MODULE_DESCRIPTION(DRIVER_DESC);
+MODULE_LICENSE("GPL and additional rights");
diff --git a/drivers/gpu/drm/nouveau/nouveau_drv.h b/drivers/gpu/drm/nouveau/nouveau_drv.h
new file mode 100644
index 0000000..13d6f9d
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_drv.h
@@ -0,0 +1,834 @@
+/*
+ * Copyright 2005 Stephane Marchesin.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __NOUVEAU_DRV_H__
+#define __NOUVEAU_DRV_H__
+
+#define DRIVER_AUTHOR		"Stephane Marchesin"
+#define DRIVER_EMAIL		"dri-devel@lists.sourceforge.net"
+
+#define DRIVER_NAME		"nouveau"
+#define DRIVER_DESC		"nVidia Riva/TNT/GeForce"
+#define DRIVER_DATE		"20060213"
+
+#define DRIVER_MAJOR		0
+#define DRIVER_MINOR		0
+#define DRIVER_PATCHLEVEL	12
+
+#define NOUVEAU_FAMILY   0x0000FFFF
+#define NOUVEAU_FLAGS    0xFFFF0000
+
+#include "nouveau_drm.h"
+#include "nouveau_reg.h"
+#include "nouveau_bios.h"
+
+#define DRM_NOUVEAU_BO_FLAG_NOVM  0x8000000000000000ULL
+#define DRM_NOUVEAU_BO_FLAG_TILE  0x4000000000000000ULL
+#define DRM_NOUVEAU_BO_FLAG_ZTILE 0x2000000000000000ULL
+
+#define MAX_NUM_DCB_ENTRIES 16
+
+struct nouveau_gem_object {
+	struct list_head entry;
+
+	struct drm_gem_object *gem;
+	struct drm_buffer_object *bo;
+	bool mappable;
+};
+
+static inline struct nouveau_gem_object *
+nouveau_gem_object(struct drm_gem_object *gem)
+{
+	return gem ? gem->driver_private : NULL;
+}
+
+struct mem_block {
+	struct mem_block *next;
+	struct mem_block *prev;
+	uint64_t start;
+	uint64_t size;
+	struct drm_file *file_priv; /* NULL: free, -1: heap, other: real files */
+	int flags;
+	struct drm_local_map *map;
+	drm_handle_t map_handle;
+
+	struct drm_buffer_object *bo;
+	struct drm_bo_kmap_obj kmap;
+};
+
+enum nouveau_flags {
+	NV_NFORCE   =0x10000000,
+	NV_NFORCE2  =0x20000000
+};
+
+#define NVOBJ_ENGINE_SW		0
+#define NVOBJ_ENGINE_GR		1
+#define NVOBJ_ENGINE_INT	0xdeadbeef
+
+#define NVOBJ_FLAG_ALLOW_NO_REFS	(1 << 0)
+#define NVOBJ_FLAG_ZERO_ALLOC		(1 << 1)
+#define NVOBJ_FLAG_ZERO_FREE		(1 << 2)
+#define NVOBJ_FLAG_FAKE			(1 << 3)
+struct nouveau_gpuobj {
+	struct list_head list;
+
+	int im_channel;
+	struct mem_block *im_pramin;
+	struct mem_block *im_backing;
+	int im_bound;
+
+	uint32_t flags;
+	int refcount;
+
+	uint32_t engine;
+	uint32_t class;
+
+	void (*dtor)(struct drm_device *, struct nouveau_gpuobj *);
+	void *priv;
+};
+
+struct nouveau_gpuobj_ref {
+	struct list_head list;
+
+	struct nouveau_gpuobj *gpuobj;
+	uint32_t instance;
+
+	int channel;
+	int handle;
+};
+
+struct nouveau_channel
+{
+	struct drm_device *dev;
+	int id;
+
+	/* owner of this fifo */
+	struct drm_file *file_priv;
+	/* mapping of the fifo itself */
+	struct drm_local_map *map;
+	/* mapping of the regs controling the fifo */
+	struct drm_local_map *user;
+
+	/* Fencing */
+	uint32_t next_sequence;
+
+	/* DMA push buffer */
+	struct nouveau_gpuobj_ref *pushbuf;
+	struct mem_block          *pushbuf_mem;
+	uint32_t                   pushbuf_base;
+
+	/* Notifier memory */
+	struct mem_block *notifier_block;
+	struct mem_block *notifier_heap;
+	struct drm_local_map *notifier_map;
+
+	/* PFIFO context */
+	struct nouveau_gpuobj_ref *ramfc;
+
+	/* PGRAPH context */
+	/* XXX may be merge 2 pointers as private data ??? */
+	struct nouveau_gpuobj_ref *ramin_grctx;
+	void *pgraph_ctx;
+
+	/* NV50 VM */
+	struct nouveau_gpuobj     *vm_pd;
+	struct nouveau_gpuobj_ref *vm_gart_pt;
+	struct nouveau_gpuobj_ref **vm_vram_pt;
+
+	/* Objects */
+	struct nouveau_gpuobj_ref *ramin; /* Private instmem */
+	struct mem_block          *ramin_heap; /* Private PRAMIN heap */
+	struct nouveau_gpuobj_ref *ramht; /* Hash table */
+	struct list_head           ramht_refs; /* Objects referenced by RAMHT */
+
+	/* GPU object info for stuff used in-kernel (mm_enabled) */
+	uint32_t m2mf_ntfy;
+	volatile uint32_t *m2mf_ntfy_map;
+	uint32_t vram_handle;
+	uint32_t gart_handle;
+	bool accel_done;
+
+	/* Push buffer state (only for drm's channel on !mm_enabled) */
+	struct {
+		int max;
+		int free;
+		int cur;
+		int put;
+		
+		volatile uint32_t *pushbuf;
+	} dma;
+};
+
+struct nouveau_config {
+	struct {
+		int location;
+		int size;
+	} cmdbuf;
+};
+
+struct nouveau_instmem_engine {
+	void	*priv;
+
+	int	(*init)(struct drm_device *dev);
+	void	(*takedown)(struct drm_device *dev);
+
+	int	(*populate)(struct drm_device *, struct nouveau_gpuobj *,
+			    uint32_t *size);
+	void	(*clear)(struct drm_device *, struct nouveau_gpuobj *);
+	int	(*bind)(struct drm_device *, struct nouveau_gpuobj *);
+	int	(*unbind)(struct drm_device *, struct nouveau_gpuobj *);
+	void	(*prepare_access)(struct drm_device *, bool write);
+	void	(*finish_access)(struct drm_device *);
+};
+
+struct nouveau_mc_engine {
+	int  (*init)(struct drm_device *dev);
+	void (*takedown)(struct drm_device *dev);
+};
+
+struct nouveau_timer_engine {
+	int      (*init)(struct drm_device *dev);
+	void     (*takedown)(struct drm_device *dev);
+	uint64_t (*read)(struct drm_device *dev);
+};
+
+struct nouveau_fb_engine {
+	int  (*init)(struct drm_device *dev);
+	void (*takedown)(struct drm_device *dev);
+};
+
+struct nouveau_fifo_engine {
+	void *priv;
+
+	int  channels;
+
+	int  (*init)(struct drm_device *);
+	void (*takedown)(struct drm_device *);
+
+	int  (*channel_id)(struct drm_device *);
+
+	int  (*create_context)(struct nouveau_channel *);
+	void (*destroy_context)(struct nouveau_channel *);
+	int  (*load_context)(struct nouveau_channel *);
+	int  (*save_context)(struct nouveau_channel *);
+};
+
+struct nouveau_pgraph_engine {
+	int  (*init)(struct drm_device *);
+	void (*takedown)(struct drm_device *);
+
+	void (*fifo_access)(struct drm_device *, bool);
+
+	int  (*create_context)(struct nouveau_channel *);
+	void (*destroy_context)(struct nouveau_channel *);
+	int  (*load_context)(struct nouveau_channel *);
+	int  (*save_context)(struct nouveau_channel *);
+};
+
+struct nouveau_engine {
+	struct nouveau_instmem_engine instmem;
+	struct nouveau_mc_engine      mc;
+	struct nouveau_timer_engine   timer;
+	struct nouveau_fb_engine      fb;
+	struct nouveau_pgraph_engine  graph;
+	struct nouveau_fifo_engine    fifo;
+};
+
+#define NOUVEAU_MAX_CHANNEL_NR 128
+struct drm_nouveau_private {
+	enum {
+		NOUVEAU_CARD_INIT_DOWN,
+		NOUVEAU_CARD_INIT_DONE,
+		NOUVEAU_CARD_INIT_FAILED
+	} init_state;
+
+	int mm_enabled;
+
+	/* the card type, takes NV_* as values */
+	int card_type;
+	/* exact chipset, derived from NV_PMC_BOOT_0 */
+	int chipset;
+	int flags;
+
+	struct drm_local_map *mmio;
+	struct drm_local_map *fb;
+	struct drm_local_map *ramin_map;
+	struct drm_local_map *ramin;
+
+	int fifo_alloc_count;
+	struct nouveau_channel *fifos[NOUVEAU_MAX_CHANNEL_NR];
+
+	struct nouveau_engine engine;
+	struct nouveau_channel *channel;
+
+	/* RAMIN configuration, RAMFC, RAMHT and RAMRO offsets */
+	struct nouveau_gpuobj *ramht;
+	uint32_t ramin_rsvd_vram;
+	uint32_t ramht_offset;
+	uint32_t ramht_size;
+	uint32_t ramht_bits;
+	uint32_t ramfc_offset;
+	uint32_t ramfc_size;
+	uint32_t ramro_offset;
+	uint32_t ramro_size;
+
+	/* base physical adresses */
+	uint64_t fb_phys;
+	uint64_t fb_available_size;
+
+	struct {
+		enum {
+			NOUVEAU_GART_NONE = 0,
+			NOUVEAU_GART_AGP,
+			NOUVEAU_GART_SGDMA
+		} type;
+		uint64_t aper_base;
+		uint64_t aper_size;
+
+		struct nouveau_gpuobj *sg_ctxdma;
+		struct page *sg_dummy_page;
+		dma_addr_t sg_dummy_bus;
+
+		/* nottm hack */
+		struct drm_ttm_backend *sg_be;
+		unsigned long sg_handle;
+	} gart_info;
+
+	/* G8x/G9x virtual address space */
+	uint64_t vm_gart_base;
+	uint64_t vm_gart_size;
+	uint64_t vm_vram_base;
+	uint64_t vm_vram_size;
+	uint64_t vm_end;
+	struct nouveau_gpuobj **vm_vram_pt;
+	int vm_vram_pt_nr;
+
+	/* the mtrr covering the FB */
+	int fb_mtrr;
+
+	struct mem_block *agp_heap;
+	struct mem_block *fb_heap;
+	struct mem_block *fb_nomap_heap;
+	struct mem_block *ramin_heap;
+	struct mem_block *pci_heap;
+
+        /* context table pointed to be NV_PGRAPH_CHANNEL_CTX_TABLE (0x400780) */
+        uint32_t ctx_table_size;
+	struct nouveau_gpuobj_ref *ctx_table;
+
+	struct nouveau_config config;
+
+	struct list_head gpuobj_list;
+
+	bool in_modeset;
+
+	struct nvbios VBIOS;
+	struct nouveau_bios_info *vbios;
+
+	struct nouveau_suspend_resume {
+		uint32_t fifo_mode;
+		uint32_t graph_ctx_control;
+		uint32_t graph_state;
+		uint32_t *ramin_copy;
+		uint64_t ramin_size;
+	} susres;
+
+	struct mutex submit_mutex;
+
+	struct backlight_device *backlight;
+
+	struct drm_gem_object *sfb_gem;
+	struct mem_block *sfb;
+	uint64_t sfbhack_handle;
+	uint64_t sfbhack_size;
+};
+
+#define NOUVEAU_CHECK_INITIALISED_WITH_RETURN do {            \
+	struct drm_nouveau_private *nv = dev->dev_private;    \
+	if (nv->init_state != NOUVEAU_CARD_INIT_DONE) {       \
+		NV_ERROR(dev, "called without init\n");       \
+		return -EINVAL;                               \
+	}                                                     \
+} while(0)
+
+#define NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN do {             \
+	struct drm_nouveau_private *nv = dev->dev_private;    \
+	if (!nv->mm_enabled) {                                \
+		NV_ERROR(dev, "invalid - using legacy mm\n"); \
+		return -EINVAL;                               \
+	}                                                     \
+} while(0)
+
+#define NOUVEAU_CHECK_MM_DISABLED_WITH_RETURN do {            \
+	struct drm_nouveau_private *nv = dev->dev_private;    \
+	if (nv->mm_enabled) {                                 \
+		NV_ERROR(dev, "invalid - using kernel mm\n"); \
+		return -EINVAL;                               \
+	}                                                     \
+} while(0)
+
+#define NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(id,cl,ch) do {      \
+	struct drm_nouveau_private *nv = dev->dev_private;       \
+	if (!nouveau_fifo_owner(dev, (cl), (id))) {              \
+		NV_ERROR(dev, "pid %d doesn't own channel %d\n", \
+			 DRM_CURRENTPID, (id));                  \
+		return -EPERM;                                   \
+	}                                                        \
+	(ch) = nv->fifos[(id)];                                  \
+} while(0)
+
+/* nouveau_state.c */
+extern void nouveau_preclose(struct drm_device *dev, struct drm_file *);
+extern int  nouveau_load(struct drm_device *, unsigned long flags);
+extern int  nouveau_firstopen(struct drm_device *);
+extern void nouveau_lastclose(struct drm_device *);
+extern int  nouveau_unload(struct drm_device *);
+extern int  nouveau_ioctl_getparam(struct drm_device *, void *data,
+				   struct drm_file *);
+extern int  nouveau_ioctl_setparam(struct drm_device *, void *data,
+				   struct drm_file *);
+extern bool nouveau_wait_until(struct drm_device *, uint64_t timeout,
+			       uint32_t reg, uint32_t mask, uint32_t val);
+extern void nouveau_wait_for_idle(struct drm_device *);
+extern int  nouveau_card_init(struct drm_device *);
+extern int  nouveau_ioctl_card_init(struct drm_device *, void *data,
+				    struct drm_file *);
+extern int  nouveau_ioctl_suspend(struct drm_device *, void *data,
+				  struct drm_file *);
+extern int  nouveau_ioctl_resume(struct drm_device *, void *data,
+				 struct drm_file *);
+
+/* nouveau_mem.c */
+extern int  nouveau_mem_init_heap(struct mem_block **, uint64_t start,
+				 uint64_t size);
+extern struct mem_block *nouveau_mem_alloc_block(struct mem_block *,
+						 uint64_t size, int align2,
+						 struct drm_file *, int tail);
+extern void nouveau_mem_takedown(struct mem_block **heap);
+extern void nouveau_mem_free_block(struct mem_block *);
+extern uint64_t nouveau_mem_fb_amount(struct drm_device *);
+extern void nouveau_mem_release(struct drm_file *, struct mem_block *heap);
+extern int  nouveau_ioctl_mem_alloc(struct drm_device *, void *data,
+				    struct drm_file *);
+extern int  nouveau_ioctl_mem_free(struct drm_device *, void *data,
+				   struct drm_file *);
+extern int  nouveau_ioctl_mem_tile(struct drm_device *, void *data,
+				   struct drm_file *);
+extern struct mem_block* nouveau_mem_alloc(struct drm_device *,
+					   int alignment, uint64_t size,
+					   int flags, struct drm_file *);
+extern void nouveau_mem_free(struct drm_device *dev, struct mem_block*);
+extern int  nouveau_mem_init(struct drm_device *);
+extern int  nouveau_mem_init_ttm(struct drm_device *);
+extern void nouveau_mem_close(struct drm_device *);
+extern int  nv50_mem_vm_bind_linear(struct drm_device *, uint64_t virt,
+				    uint32_t size, uint32_t flags,
+				    uint64_t phys);
+extern void nv50_mem_vm_unbind(struct drm_device *, uint64_t virt,
+			       uint32_t size);
+
+/* nouveau_notifier.c */
+extern int  nouveau_notifier_init_channel(struct nouveau_channel *);
+extern void nouveau_notifier_takedown_channel(struct nouveau_channel *);
+extern int  nouveau_notifier_alloc(struct nouveau_channel *, uint32_t handle,
+				   int cout, uint32_t *offset);
+extern int  nouveau_ioctl_notifier_alloc(struct drm_device *, void *data,
+					 struct drm_file *);
+extern int  nouveau_ioctl_notifier_free(struct drm_device *, void *data,
+					struct drm_file *);
+
+/* nouveau_fifo.c */
+extern int  nouveau_fifo_init(struct drm_device *);
+extern int  nouveau_fifo_ctx_size(struct drm_device *);
+extern void nouveau_fifo_cleanup(struct drm_device *, struct drm_file *);
+extern int  nouveau_fifo_owner(struct drm_device *, struct drm_file *,
+			       int channel);
+extern int  nouveau_fifo_alloc(struct drm_device *dev,
+			       struct nouveau_channel **chan,
+			       struct drm_file *file_priv,
+			       struct mem_block *pushbuf,
+			       uint32_t fb_ctxdma, uint32_t tt_ctxdma);
+extern void nouveau_fifo_free(struct nouveau_channel *);
+extern int  nouveau_channel_idle(struct nouveau_channel *chan);
+
+/* nouveau_object.c */
+extern int  nouveau_gpuobj_early_init(struct drm_device *);
+extern int  nouveau_gpuobj_init(struct drm_device *);
+extern void nouveau_gpuobj_takedown(struct drm_device *);
+extern void nouveau_gpuobj_late_takedown(struct drm_device *);
+extern int nouveau_gpuobj_channel_init(struct nouveau_channel *,
+				       uint32_t vram_h, uint32_t tt_h);
+extern void nouveau_gpuobj_channel_takedown(struct nouveau_channel *);
+extern int nouveau_gpuobj_new(struct drm_device *, struct nouveau_channel *,
+			      int size, int align, uint32_t flags,
+			      struct nouveau_gpuobj **);
+extern int nouveau_gpuobj_del(struct drm_device *, struct nouveau_gpuobj **);
+extern int nouveau_gpuobj_ref_add(struct drm_device *, struct nouveau_channel *,
+				  uint32_t handle, struct nouveau_gpuobj *,
+				  struct nouveau_gpuobj_ref **);
+extern int nouveau_gpuobj_ref_del(struct drm_device *,
+				  struct nouveau_gpuobj_ref **);
+extern int nouveau_gpuobj_ref_find(struct nouveau_channel *, uint32_t handle,
+				   struct nouveau_gpuobj_ref **ref_ret);
+extern int nouveau_gpuobj_new_ref(struct drm_device *,
+				  struct nouveau_channel *alloc_chan,
+				  struct nouveau_channel *ref_chan,
+				  uint32_t handle, int size, int align,
+				  uint32_t flags, struct nouveau_gpuobj_ref **);
+extern int nouveau_gpuobj_new_fake(struct drm_device *,
+				   uint32_t p_offset, uint32_t b_offset,
+				   uint32_t size, uint32_t flags,
+				   struct nouveau_gpuobj **,
+				   struct nouveau_gpuobj_ref**);
+extern int nouveau_gpuobj_dma_new(struct nouveau_channel *, int class,
+				  uint64_t offset, uint64_t size, int access,
+				  int target, struct nouveau_gpuobj **);
+extern int nouveau_gpuobj_gart_dma_new(struct nouveau_channel *,
+				       uint64_t offset, uint64_t size,
+				       int access, struct nouveau_gpuobj **,
+				       uint32_t *o_ret);
+extern int nouveau_gpuobj_gr_new(struct nouveau_channel *, int class,
+				 struct nouveau_gpuobj **);
+extern int nouveau_ioctl_grobj_alloc(struct drm_device *, void *data,
+				     struct drm_file *);
+extern int nouveau_ioctl_gpuobj_free(struct drm_device *, void *data,
+				     struct drm_file *);
+
+/* nouveau_irq.c */
+extern irqreturn_t nouveau_irq_handler(DRM_IRQ_ARGS);
+extern void        nouveau_irq_preinstall(struct drm_device *);
+extern int         nouveau_irq_postinstall(struct drm_device *);
+extern void        nouveau_irq_uninstall(struct drm_device *);
+
+/* nouveau_sgdma.c */
+extern int nouveau_sgdma_init(struct drm_device *);
+extern void nouveau_sgdma_takedown(struct drm_device *);
+extern int nouveau_sgdma_get_page(struct drm_device *, uint32_t offset,
+				  uint32_t *page);
+extern struct drm_ttm_backend *nouveau_sgdma_init_ttm(struct drm_device *);
+extern int nouveau_sgdma_nottm_hack_init(struct drm_device *);
+extern void nouveau_sgdma_nottm_hack_takedown(struct drm_device *);
+
+/* nouveau_dma.c */
+extern int  nouveau_dma_channel_init(struct drm_device *);
+extern void nouveau_dma_channel_takedown(struct drm_device *);
+extern int  nouveau_dma_channel_setup(struct nouveau_channel *);
+extern int  nouveau_dma_wait(struct nouveau_channel *, int size);
+
+/* nouveau_backlight.c */
+extern int nouveau_backlight_init(struct drm_device *);
+extern void nouveau_backlight_exit(struct drm_device *);
+
+/* nouveau_bios.c */
+extern int nouveau_parse_bios(struct drm_device *);
+extern int get_pll_limits(struct drm_device *, uint32_t limit_match,
+			  struct pll_lims *);
+extern int nouveau_bios_run_display_table(struct drm_device *,
+					  struct dcb_entry *, int pxclk);
+bool nouveau_bios_fp_mode(struct drm_device *, struct drm_display_mode *);
+
+/* nv04_fb.c */
+extern int  nv04_fb_init(struct drm_device *);
+extern void nv04_fb_takedown(struct drm_device *);
+
+/* nv10_fb.c */
+extern int  nv10_fb_init(struct drm_device *);
+extern void nv10_fb_takedown(struct drm_device *);
+
+/* nv40_fb.c */
+extern int  nv40_fb_init(struct drm_device *);
+extern void nv40_fb_takedown(struct drm_device *);
+
+/* nv04_fifo.c */
+extern int  nv04_fifo_channel_id(struct drm_device *);
+extern int  nv04_fifo_create_context(struct nouveau_channel *);
+extern void nv04_fifo_destroy_context(struct nouveau_channel *);
+extern int  nv04_fifo_load_context(struct nouveau_channel *);
+extern int  nv04_fifo_save_context(struct nouveau_channel *);
+
+/* nv10_fifo.c */
+extern int  nv10_fifo_channel_id(struct drm_device *);
+extern int  nv10_fifo_create_context(struct nouveau_channel *);
+extern void nv10_fifo_destroy_context(struct nouveau_channel *);
+extern int  nv10_fifo_load_context(struct nouveau_channel *);
+extern int  nv10_fifo_save_context(struct nouveau_channel *);
+
+/* nv40_fifo.c */
+extern int  nv40_fifo_init(struct drm_device *);
+extern int  nv40_fifo_create_context(struct nouveau_channel *);
+extern void nv40_fifo_destroy_context(struct nouveau_channel *);
+extern int  nv40_fifo_load_context(struct nouveau_channel *);
+extern int  nv40_fifo_save_context(struct nouveau_channel *);
+
+/* nv50_fifo.c */
+extern int  nv50_fifo_init(struct drm_device *);
+extern void nv50_fifo_takedown(struct drm_device *);
+extern int  nv50_fifo_channel_id(struct drm_device *);
+extern int  nv50_fifo_create_context(struct nouveau_channel *);
+extern void nv50_fifo_destroy_context(struct nouveau_channel *);
+extern int  nv50_fifo_load_context(struct nouveau_channel *);
+extern int  nv50_fifo_save_context(struct nouveau_channel *);
+
+/* nv04_graph.c */
+extern void nouveau_nv04_context_switch(struct drm_device *);
+extern int  nv04_graph_init(struct drm_device *);
+extern void nv04_graph_takedown(struct drm_device *);
+extern void nv04_graph_fifo_access(struct drm_device *, bool);
+extern int  nv04_graph_create_context(struct nouveau_channel *);
+extern void nv04_graph_destroy_context(struct nouveau_channel *);
+extern int  nv04_graph_load_context(struct nouveau_channel *);
+extern int  nv04_graph_save_context(struct nouveau_channel *);
+
+/* nv10_graph.c */
+extern void nouveau_nv10_context_switch(struct drm_device *);
+extern int  nv10_graph_init(struct drm_device *);
+extern void nv10_graph_takedown(struct drm_device *);
+extern int  nv10_graph_create_context(struct nouveau_channel *);
+extern void nv10_graph_destroy_context(struct nouveau_channel *);
+extern int  nv10_graph_load_context(struct nouveau_channel *);
+extern int  nv10_graph_save_context(struct nouveau_channel *);
+
+/* nv20_graph.c */
+extern int  nv20_graph_create_context(struct nouveau_channel *);
+extern void nv20_graph_destroy_context(struct nouveau_channel *);
+extern int  nv20_graph_load_context(struct nouveau_channel *);
+extern int  nv20_graph_save_context(struct nouveau_channel *);
+extern int  nv20_graph_init(struct drm_device *);
+extern void nv20_graph_takedown(struct drm_device *);
+extern int  nv30_graph_init(struct drm_device *);
+
+/* nv40_graph.c */
+extern int  nv40_graph_init(struct drm_device *);
+extern void nv40_graph_takedown(struct drm_device *);
+extern int  nv40_graph_create_context(struct nouveau_channel *);
+extern void nv40_graph_destroy_context(struct nouveau_channel *);
+extern int  nv40_graph_load_context(struct nouveau_channel *);
+extern int  nv40_graph_save_context(struct nouveau_channel *);
+
+/* nv50_graph.c */
+extern int  nv50_graph_init(struct drm_device *);
+extern void nv50_graph_takedown(struct drm_device *);
+extern void nv50_graph_fifo_access(struct drm_device *, bool);
+extern int  nv50_graph_create_context(struct nouveau_channel *);
+extern void nv50_graph_destroy_context(struct nouveau_channel *);
+extern int  nv50_graph_load_context(struct nouveau_channel *);
+extern int  nv50_graph_save_context(struct nouveau_channel *);
+
+/* nv04_instmem.c */
+extern int  nv04_instmem_init(struct drm_device *);
+extern void nv04_instmem_takedown(struct drm_device *);
+extern int  nv04_instmem_populate(struct drm_device *, struct nouveau_gpuobj *,
+				  uint32_t *size);
+extern void nv04_instmem_clear(struct drm_device *, struct nouveau_gpuobj *);
+extern int  nv04_instmem_bind(struct drm_device *, struct nouveau_gpuobj *);
+extern int  nv04_instmem_unbind(struct drm_device *, struct nouveau_gpuobj *);
+extern void nv04_instmem_prepare_access(struct drm_device *, bool write);
+extern void nv04_instmem_finish_access(struct drm_device *);
+
+/* nv50_instmem.c */
+extern int  nv50_instmem_init(struct drm_device *);
+extern void nv50_instmem_takedown(struct drm_device *);
+extern int  nv50_instmem_populate(struct drm_device *, struct nouveau_gpuobj *,
+				  uint32_t *size);
+extern void nv50_instmem_clear(struct drm_device *, struct nouveau_gpuobj *);
+extern int  nv50_instmem_bind(struct drm_device *, struct nouveau_gpuobj *);
+extern int  nv50_instmem_unbind(struct drm_device *, struct nouveau_gpuobj *);
+extern void nv50_instmem_prepare_access(struct drm_device *, bool write);
+extern void nv50_instmem_finish_access(struct drm_device *);
+
+/* nv04_mc.c */
+extern int  nv04_mc_init(struct drm_device *);
+extern void nv04_mc_takedown(struct drm_device *);
+
+/* nv40_mc.c */
+extern int  nv40_mc_init(struct drm_device *);
+extern void nv40_mc_takedown(struct drm_device *);
+
+/* nv50_mc.c */
+extern int  nv50_mc_init(struct drm_device *);
+extern void nv50_mc_takedown(struct drm_device *);
+
+/* nv04_timer.c */
+extern int  nv04_timer_init(struct drm_device *);
+extern uint64_t nv04_timer_read(struct drm_device *);
+extern void nv04_timer_takedown(struct drm_device *);
+
+extern long nouveau_compat_ioctl(struct file *file, unsigned int cmd,
+				 unsigned long arg);
+
+/* nouveau_buffer.c */
+extern struct drm_bo_driver nouveau_bo_driver;
+
+/* nouveau_fence.c */
+extern struct drm_fence_driver nouveau_fence_driver;
+extern void nouveau_fence_handler(struct drm_device *dev, int channel);
+extern struct nouveau_channel *
+nouveau_fence_channel(struct drm_device *dev, uint32_t fence_class);
+
+/* nouveau_gem.c */
+extern int nouveau_gem_object_new(struct drm_gem_object *);
+extern void nouveau_gem_object_del(struct drm_gem_object *);
+extern int nouveau_gem_new(struct drm_device *, struct nouveau_channel *,
+			   int size, int align, uint32_t domain,
+			   struct drm_gem_object **);
+extern int nouveau_gem_pin(struct drm_gem_object *, uint32_t domain);
+extern int nouveau_gem_unpin(struct drm_gem_object *);
+extern int nouveau_gem_ioctl_new(struct drm_device *, void *,
+				 struct drm_file *);
+extern int nouveau_gem_ioctl_pushbuf(struct drm_device *, void *,
+				     struct drm_file *);
+extern int nouveau_gem_ioctl_pushbuf_call(struct drm_device *, void *,
+					  struct drm_file *);
+extern int nouveau_gem_ioctl_pin(struct drm_device *, void *,
+				 struct drm_file *);
+extern int nouveau_gem_ioctl_unpin(struct drm_device *, void *,
+				   struct drm_file *);
+extern int nouveau_gem_ioctl_tile(struct drm_device *, void *,
+				  struct drm_file *);
+extern int nouveau_gem_ioctl_mmap(struct drm_device *, void *,
+				  struct drm_file *);
+extern int nouveau_gem_ioctl_cpu_prep(struct drm_device *, void *,
+				      struct drm_file *);
+extern int nouveau_gem_ioctl_cpu_fini(struct drm_device *, void *,
+				      struct drm_file *);
+
+#define NVDEV ((struct drm_nouveau_private *)dev->dev_private)
+#if defined(__powerpc__)
+#define nv_out32(map,reg,val) out_be32((void __iomem *)NVDEV->map->handle + (reg), (val))
+#define nv_out16(map,reg,val) out_be16((void __iomem *)NVDEV->map->handle + (reg), (val))
+#define nv_in32(map,reg) in_be32((void __iomem *)NVDEV->map->handle + (reg))
+#define nv_in16(map,reg) in_be16((void __iomem *)NVDEV->map->handle + (reg))
+#else
+#define nv_out32(map,reg,val) DRM_WRITE32(NVDEV->map, (reg), (val))
+#define nv_out16(map,reg,val) DRM_WRITE16(NVDEV->map, (reg), (val))
+#define nv_in32(map,reg) DRM_READ32(NVDEV->map, (reg))
+#define nv_in16(map,reg) DRM_READ16(NVDEV->map, (reg))
+#endif
+#define nv_out08(map,reg,val) DRM_WRITE8(NVDEV->map, (reg), (val))
+#define nv_in08(map,reg) DRM_READ8(NVDEV->map, (reg))
+
+/* channel control reg access */
+#if defined(__powerpc__)
+#define nvchan_wr32(reg,val) out_be32((void __iomem *)chan->user->handle + (reg), (val))
+#define nvchan_rd32(reg) in_be32((void __iomem *)chan->user->handle + (reg))
+#else
+#define nvchan_wr32(reg,val) DRM_WRITE32(chan->user, (reg), (val))
+#define nvchan_rd32(reg) DRM_READ32(chan->user, (reg))
+#endif
+
+
+/* register access */
+#define nv_rd32(reg) nv_in32(mmio, (reg))
+#define nv_wr32(reg,val) nv_out32(mmio, (reg), (val))
+#define nv_rd16(reg) nv_in16(mmio, (reg))
+#define nv_wr16(reg,val) nv_out16(mmio, (reg), (val))
+#define nv_rd08(reg) nv_in08(mmio, (reg))
+#define nv_wr08(reg,val) nv_out08(mmio, (reg), (val))
+#define nv_wait(reg,mask,val) nouveau_wait_until(dev, 1000000000ULL, (reg),    \
+						 (mask), (val))
+
+/* VRAM access */
+#define nv_rv32(reg) 0 /* vram */
+#define nv_wv32(reg,val)
+#define nv_rf32(reg) 0 /* fb bar, *not* same as vram in all cases.. */
+#define nv_wf32(reg,val)
+
+/* PRAMIN access */
+#define nv_ri32(reg) nv_in32(ramin_map, (reg))
+#define nv_wi32(reg,val) nv_out32(ramin_map, (reg), (val))
+/* object access */
+#define INSTANCE_RD(o,i) nv_ri32((o)->im_pramin->start + ((i)<<2))
+#define INSTANCE_WR(o,i,v) nv_wi32((o)->im_pramin->start + ((i)<<2), (v))
+
+/* logging */
+#define NV_PRINTK(level, d, fmt, arg...) \
+	printk(level "nouveau %s: " fmt, pci_name(d->pdev), ##arg)
+#define NV_DEBUG(d, fmt, arg...) do {                                          \
+	if (drm_debug) {                                                       \
+		NV_PRINTK(KERN_DEBUG, d, "%s:%d - " fmt, __func__,             \
+			  __LINE__, ##arg);                                    \
+	}                                                                      \
+} while(0)
+#define NV_ERROR(d, fmt, arg...) NV_PRINTK(KERN_ERR, d, fmt, ##arg)
+#define NV_INFO(d, fmt, arg...) NV_PRINTK(KERN_INFO, d, fmt, ##arg)
+#define NV_TRACEWARN(d, fmt, arg...) NV_PRINTK(KERN_NOTICE, d, fmt, ##arg)
+#define NV_TRACE(d, fmt, arg...) NV_PRINTK(KERN_INFO, d, fmt, ##arg)
+#define NV_WARN(d, fmt, arg...) NV_PRINTK(KERN_WARNING, d, fmt, ##arg)
+
+static inline enum nouveau_card_type
+nv_arch(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	switch (dev_priv->chipset & 0xf0) {
+	case 0x00:
+		return NV_04;
+	case 0x10:
+		return NV_10;
+	case 0x20:
+		return NV_20;
+	case 0x30:
+		return NV_30;
+	case 0x40:
+	case 0x60:
+		return NV_40;
+	case 0x50:
+	case 0x80:
+	case 0x90:
+	case 0xa0:
+		return NV_50;
+	default:
+		return NV_UNKNOWN;
+	}
+}
+
+static inline bool
+nv_two_heads(struct drm_device *dev)
+{
+	const int impl = dev->pci_device & 0x0ff0;
+
+	if (nv_arch(dev) >= NV_10 && impl != 0x0100 &&
+	    impl != 0x0150 && impl != 0x01a0 && impl != 0x0200)
+		return true;
+
+	return false;
+}
+
+static inline bool
+nv_gf4_disp_arch(struct drm_device *dev)
+{
+	return nv_two_heads(dev) && (dev->pci_device & 0x0ff0) != 0x0110;
+}
+
+static inline bool
+nv_two_reg_pll(struct drm_device *dev)
+{
+	const int impl = dev->pci_device & 0x0ff0;
+
+	if (impl == 0x0310 || impl == 0x0340 || nv_arch(dev) >= NV_40)
+		return true;
+	return false;
+}
+
+#endif /* __NOUVEAU_DRV_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_encoder.h b/drivers/gpu/drm/nouveau/nouveau_encoder.h
new file mode 100644
index 0000000..d9dc976
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_encoder.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_OUTPUT_H__
+#define __NOUVEAU_OUTPUT_H__
+
+struct nouveau_encoder {
+	struct drm_encoder base;
+
+	struct dcb_entry *dcb;
+	int or;
+
+	bool dual_link;
+
+	int (*set_clock_mode) (struct nouveau_encoder *encoder,
+			       struct drm_display_mode *mode);
+};
+#define to_nouveau_encoder(x) container_of((x), struct nouveau_encoder, base)
+
+int nv50_sor_create(struct drm_device *dev, struct dcb_entry *entry);
+int nv50_dac_create(struct drm_device *dev, struct dcb_entry *entry);
+
+#endif /* __NOUVEAU_OUTPUT_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_fb.h b/drivers/gpu/drm/nouveau/nouveau_fb.h
new file mode 100644
index 0000000..88ffdc0
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_fb.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_FB_H__
+#define __NOUVEAU_FB_H__
+
+struct nouveau_framebuffer {
+	struct drm_framebuffer base;
+	struct drm_gem_object *gem;
+	struct drm_bo_kmap_obj kmap;
+};
+
+#define to_nouveau_framebuffer(x) container_of((x), struct nouveau_framebuffer, base)
+
+extern const struct drm_mode_config_funcs nouveau_mode_config_funcs;
+
+struct drm_framebuffer *
+nouveau_framebuffer_create(struct drm_device *, struct drm_gem_object *,
+			   struct drm_mode_fb_cmd *);
+
+#endif /* __NOUVEAU_FB_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_fbcon.c b/drivers/gpu/drm/nouveau/nouveau_fbcon.c
new file mode 100644
index 0000000..38d929d
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_fbcon.c
@@ -0,0 +1,946 @@
+/*
+ * Copyright © 2007 David Airlie
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *     David Airlie
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/mm.h>
+#include <linux/tty.h>
+#include <linux/slab.h>
+#include <linux/sysrq.h>
+#include <linux/delay.h>
+#include <linux/fb.h>
+#include <linux/init.h>
+
+#include "drmP.h"
+#include "drm.h"
+#include "drm_crtc.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+#include "nouveau_crtc.h"
+#include "nouveau_fb.h"
+#include "nouveau_fbcon.h"
+
+extern int nouveau_fbpercrtc;
+
+static int nouveau_fbcon_setcolreg(unsigned regno, unsigned red, unsigned green,
+				   unsigned blue, unsigned transp,
+				   struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_crtc *crtc;
+	int i;
+
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		struct nouveau_crtc *nouveau_crtc = to_nouveau_crtc(crtc);
+		struct drm_mode_set *modeset = &nouveau_crtc->mode_set;
+		struct drm_framebuffer *fb = modeset->fb;
+
+		for (i = 0; i < par->crtc_count; i++)
+			if (crtc->base.id == par->crtc_ids[i])
+				break;
+
+		if (i == par->crtc_count)
+			continue;
+
+
+		if (regno > 255)
+			return 1;
+
+		if (fb->depth == 8) {
+			/* TODO */
+		}
+
+		if (regno < 16) {
+			switch (fb->depth) {
+			case 15:
+				fb->pseudo_palette[regno] = ((red & 0xf800) >> 1) |
+					((green & 0xf800) >>  6) |
+					((blue & 0xf800) >> 11);
+				break;
+			case 16:
+				fb->pseudo_palette[regno] = (red & 0xf800) |
+					((green & 0xfc00) >>  5) |
+					((blue  & 0xf800) >> 11);
+				break;
+			case 24:
+			case 32:
+				fb->pseudo_palette[regno] = ((red & 0xff00) << 8) |
+					(green & 0xff00) |
+					((blue  & 0xff00) >> 8);
+				break;
+			}
+		}
+	}
+	return 0;
+}
+
+static int nouveau_fbcon_check_var(struct fb_var_screeninfo *var,
+				   struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct nouveau_framebuffer *nouveau_fb = par->nouveau_fb;
+	struct drm_device *dev = par->dev;
+	struct drm_framebuffer *fb = &nouveau_fb->base;
+	int depth;
+
+	if (var->pixclock == -1 || !var->pixclock)
+		return -EINVAL;
+
+	/* Need to resize the fb object !!! */
+	if (var->xres > fb->width || var->yres > fb->height) {
+		NV_ERROR(dev, "Requested width/height is greater than current fb object %dx%d > %dx%d\n",var->xres,var->yres,fb->width,fb->height);
+		NV_ERROR(dev, "Need resizing code.\n");
+		return -EINVAL;
+	}
+
+	switch (var->bits_per_pixel) {
+	case 16:
+		depth = (var->green.length == 6) ? 16 : 15;
+		break;
+	case 32:
+		depth = (var->transp.length > 0) ? 32 : 24;
+		break;
+	default:
+		depth = var->bits_per_pixel;
+		break;
+	}
+
+	switch (depth) {
+	case 8:
+		var->red.offset = 0;
+		var->green.offset = 0;
+		var->blue.offset = 0;
+		var->red.length = 8;
+		var->green.length = 8;
+		var->blue.length = 8;
+		var->transp.length = 0;
+		var->transp.offset = 0;
+		break;
+	case 15:
+		var->red.offset = 10;
+		var->green.offset = 5;
+		var->blue.offset = 0;
+		var->red.length = 5;
+		var->green.length = 5;
+		var->blue.length = 5;
+		var->transp.length = 1;
+		var->transp.offset = 15;
+		break;
+	case 16:
+		var->red.offset = 11;
+		var->green.offset = 5;
+		var->blue.offset = 0;
+		var->red.length = 5;
+		var->green.length = 6;
+		var->blue.length = 5;
+		var->transp.length = 0;
+		var->transp.offset = 0;
+		break;
+	case 24:
+		var->red.offset = 16;
+		var->green.offset = 8;
+		var->blue.offset = 0;
+		var->red.length = 8;
+		var->green.length = 8;
+		var->blue.length = 8;
+		var->transp.length = 0;
+		var->transp.offset = 0;
+		break;
+	case 32:
+		var->red.offset = 16;
+		var->green.offset = 8;
+		var->blue.offset = 0;
+		var->red.length = 8;
+		var->green.length = 8;
+		var->blue.length = 8;
+		var->transp.length = 8;
+		var->transp.offset = 24;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/* this will let fbcon do the mode init */
+/* FIXME: take mode config lock? */
+static int nouveau_fbcon_set_par(struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct fb_var_screeninfo *var = &info->var;
+	int i;
+
+	NV_DEBUG(dev, "%d %d\n", var->xres, var->pixclock);
+
+	if (var->pixclock != -1) {
+
+		NV_ERROR(dev, "PIXEL CLCOK SET\n");
+		return -EINVAL;
+	} else {
+		struct drm_crtc *crtc;
+		int ret;
+
+		list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+			struct nouveau_crtc *nouveau_crtc = to_nouveau_crtc(crtc);
+
+			for (i = 0; i < par->crtc_count; i++)
+				if (crtc->base.id == par->crtc_ids[i])
+					break;
+
+			if (i == par->crtc_count)
+				continue;
+
+			if (crtc->fb == nouveau_crtc->mode_set.fb) {
+				mutex_lock(&dev->mode_config.mutex);
+				ret = crtc->funcs->set_config(&nouveau_crtc->mode_set);
+				mutex_unlock(&dev->mode_config.mutex);
+				if (ret)
+					return ret;
+			}
+		}
+		return 0;
+	}
+}
+
+static int nouveau_fbcon_pan_display(struct fb_var_screeninfo *var,
+				     struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_mode_set *modeset;
+	struct drm_crtc *crtc;
+	struct nouveau_crtc *nouveau_crtc;
+	int ret = 0;
+	int i;
+
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		for (i = 0; i < par->crtc_count; i++)
+			if (crtc->base.id == par->crtc_ids[i])
+				break;
+
+		if (i == par->crtc_count)
+			continue;
+
+		nouveau_crtc = to_nouveau_crtc(crtc);
+		modeset = &nouveau_crtc->mode_set;
+
+		modeset->x = var->xoffset;
+		modeset->y = var->yoffset;
+
+		if (modeset->num_connectors) {
+			mutex_lock(&dev->mode_config.mutex);
+			ret = crtc->funcs->set_config(modeset);
+			mutex_unlock(&dev->mode_config.mutex);
+			if (!ret) {
+				info->var.xoffset = var->xoffset;
+				info->var.yoffset = var->yoffset;
+			}
+		}
+	}
+
+	return ret;
+}
+
+static void nouveau_fbcon_on(struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_crtc *crtc;
+	struct drm_encoder *encoder;
+	int i;
+
+	/*
+	 * For each CRTC in this fb, find all associated encoders
+	 * and turn them off, then turn off the CRTC.
+	 */
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		struct drm_crtc_helper_funcs *crtc_funcs = crtc->helper_private;
+
+		for (i = 0; i < par->crtc_count; i++)
+			if (crtc->base.id == par->crtc_ids[i])
+				break;
+
+		crtc_funcs->dpms(crtc, DRM_MODE_DPMS_ON);
+
+		/* Found a CRTC on this fb, now find encoders */
+		list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
+			if (encoder->crtc == crtc) {
+				struct drm_encoder_helper_funcs *encoder_funcs;
+				encoder_funcs = encoder->helper_private;
+				encoder_funcs->dpms(encoder, DRM_MODE_DPMS_ON);
+			}
+		}
+	}
+}
+
+static void nouveau_fbcon_off(struct fb_info *info, int dpms_mode)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_crtc *crtc;
+	struct drm_encoder *encoder;
+	int i;
+
+	/*
+	 * For each CRTC in this fb, find all associated encoders
+	 * and turn them off, then turn off the CRTC.
+	 */
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		struct drm_crtc_helper_funcs *crtc_funcs = crtc->helper_private;
+
+		for (i = 0; i < par->crtc_count; i++)
+			if (crtc->base.id == par->crtc_ids[i])
+				break;
+
+		/* Found a CRTC on this fb, now find encoders */
+		list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
+			if (encoder->crtc == crtc) {
+				struct drm_encoder_helper_funcs *encoder_funcs;
+				encoder_funcs = encoder->helper_private;
+				encoder_funcs->dpms(encoder, dpms_mode);
+			}
+		}
+		if (dpms_mode == DRM_MODE_DPMS_OFF)
+			crtc_funcs->dpms(crtc, dpms_mode);
+	}
+}
+
+static int nouveau_fbcon_blank(int blank, struct fb_info *info)
+{
+	switch (blank) {
+	case FB_BLANK_UNBLANK:
+		nouveau_fbcon_on(info);
+		break;
+	case FB_BLANK_NORMAL:
+		nouveau_fbcon_off(info, DRM_MODE_DPMS_STANDBY);
+		break;
+	case FB_BLANK_HSYNC_SUSPEND:
+		nouveau_fbcon_off(info, DRM_MODE_DPMS_STANDBY);
+		break;
+	case FB_BLANK_VSYNC_SUSPEND:
+		nouveau_fbcon_off(info, DRM_MODE_DPMS_SUSPEND);
+		break;
+	case FB_BLANK_POWERDOWN:
+		nouveau_fbcon_off(info, DRM_MODE_DPMS_OFF);
+		break;
+	}
+	return 0;
+}
+
+static struct fb_ops nouveau_fbcon_ops = {
+	.owner = THIS_MODULE,
+	.fb_check_var = nouveau_fbcon_check_var,
+	.fb_set_par = nouveau_fbcon_set_par,
+	.fb_setcolreg = nouveau_fbcon_setcolreg,
+	.fb_fillrect = cfb_fillrect,
+	.fb_copyarea = cfb_copyarea,
+	.fb_imageblit = cfb_imageblit,
+	.fb_pan_display = nouveau_fbcon_pan_display,
+	.fb_blank = nouveau_fbcon_blank,
+};
+
+/**
+ * Curretly it is assumed that the old framebuffer is reused.
+ *
+ * LOCKING
+ * caller should hold the mode config lock.
+ *
+ */
+int nouveau_fbcon_resize(struct drm_device *dev, struct drm_crtc *crtc)
+{
+	struct fb_info *info;
+	struct drm_framebuffer *fb;
+	struct drm_display_mode *mode = crtc->desired_mode;
+
+	fb = crtc->fb;
+	if (!fb)
+		return 1;
+
+	info = fb->fbdev;
+	if (!info)
+		return 1;
+
+	if (!mode)
+		return 1;
+
+	info->var.xres = mode->hdisplay;
+	info->var.right_margin = mode->hsync_start - mode->hdisplay;
+	info->var.hsync_len = mode->hsync_end - mode->hsync_start;
+	info->var.left_margin = mode->htotal - mode->hsync_end;
+	info->var.yres = mode->vdisplay;
+	info->var.lower_margin = mode->vsync_start - mode->vdisplay;
+	info->var.vsync_len = mode->vsync_end - mode->vsync_start;
+	info->var.upper_margin = mode->vtotal - mode->vsync_end;
+	info->var.pixclock = 10000000 / mode->htotal * 1000 / mode->vtotal * 100;
+	/* avoid overflow */
+	info->var.pixclock = info->var.pixclock * 1000 / mode->vrefresh;
+
+	return 0;
+}
+EXPORT_SYMBOL(nouveau_fbcon_resize);
+
+static struct drm_mode_set kernelfb_mode;
+
+static int nouveau_fbcon_panic(struct notifier_block *n, unsigned long ununsed,
+			       void *panic_str)
+{
+	printk("panic occurred, switching back to text console\n");
+
+	nouveau_fbcon_restore();
+	return 0;
+}
+
+static struct notifier_block paniced = {
+	.notifier_call = nouveau_fbcon_panic,
+};
+
+static int nouveau_fbcon_create(struct drm_device *dev, uint32_t fb_width,
+				uint32_t fb_height, uint32_t surface_width,
+				uint32_t surface_height,
+				struct nouveau_framebuffer **nouveau_fb_p)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct fb_info *info;
+	struct nouveau_fbcon_par *par;
+	struct drm_framebuffer *fb;
+	struct nouveau_framebuffer *nouveau_fb;
+	struct drm_mode_fb_cmd mode_cmd;
+	struct drm_gem_object *gem = NULL;
+	struct nouveau_gem_object *ngem;
+	struct device *device = &dev->pdev->dev;
+	struct fb_fillrect rect;
+	int size, ret;
+
+	mode_cmd.width = surface_width;
+	mode_cmd.height = surface_height;
+
+	mode_cmd.bpp = 32;
+	mode_cmd.pitch = ALIGN(mode_cmd.width, 64) * ((mode_cmd.bpp + 1) / 8);
+	mode_cmd.depth = 24;
+
+	size = mode_cmd.pitch * mode_cmd.height;
+	size = ALIGN(size, PAGE_SIZE);
+
+	ret = nouveau_gem_new(dev, NULL, size, 0, NOUVEAU_GEM_DOMAIN_VRAM, &gem);
+	if (ret) {
+		printk(KERN_ERR "failed to allocate framebuffer\n");
+		ret = -ENOMEM;
+		goto out;
+	}
+	ngem = gem->driver_private;
+
+	ret = nouveau_gem_pin(gem, NOUVEAU_GEM_DOMAIN_VRAM);
+	mutex_lock(&dev->struct_mutex);
+	if (ret) {
+		NV_ERROR(dev, "failed to pin fb: %d\n", ret);
+		goto out_unref;
+	}
+
+	fb = nouveau_framebuffer_create(dev, gem, &mode_cmd);
+	if (!fb) {
+		ret = -ENOMEM;
+		NV_ERROR(dev, "failed to allocate fb.\n");
+		goto out_unref;
+	}
+
+	list_add(&fb->filp_head, &dev->mode_config.fb_kernel_list);
+
+	nouveau_fb = to_nouveau_framebuffer(fb);
+	*nouveau_fb_p = nouveau_fb;
+
+	ret = drm_bo_kmap(ngem->bo, 0, ngem->bo->mem.num_pages,
+			  &nouveau_fb->kmap);
+	if (ret) {
+		NV_ERROR(dev, "failed to kmap fb: %d\n", ret);
+		goto out_unref;
+	}
+
+	info = framebuffer_alloc(sizeof(struct nouveau_fbcon_par), device);
+	if (!info) {
+		ret = -ENOMEM;
+		goto out_unref;
+	}
+
+	par = info->par;
+
+	strcpy(info->fix.id, "nouveaudrmfb");
+	info->fix.type = FB_TYPE_PACKED_PIXELS;
+	info->fix.visual = FB_VISUAL_TRUECOLOR;
+	info->fix.type_aux = 0;
+	info->fix.xpanstep = 1; /* doing it in hw */
+	info->fix.ypanstep = 1; /* doing it in hw */
+	info->fix.ywrapstep = 0;
+	info->fix.accel = FB_ACCEL_I830;
+	info->fix.type_aux = 0;
+
+	info->flags = FBINFO_DEFAULT;
+
+	info->fbops = &nouveau_fbcon_ops;
+
+	info->fix.line_length = fb->pitch;
+	info->fix.smem_start = dev->mode_config.fb_base + ngem->bo->offset -
+			       dev_priv->vm_vram_base;
+	info->fix.smem_len = size;
+
+	info->flags = FBINFO_DEFAULT;
+
+	info->screen_base = nouveau_fb->kmap.virtual;
+	info->screen_size = size;
+
+//	memset(info->screen_base, 0, size);
+
+	info->pseudo_palette = fb->pseudo_palette;
+	info->var.xres_virtual = fb->width;
+	info->var.yres_virtual = fb->height;
+	info->var.bits_per_pixel = fb->bits_per_pixel;
+	info->var.xoffset = 0;
+	info->var.yoffset = 0;
+	info->var.activate = FB_ACTIVATE_NOW;
+	info->var.height = -1;
+	info->var.width = -1;
+
+	info->var.xres = fb_width;
+	info->var.yres = fb_height;
+
+	/* FIXME: we really shouldn't expose mmio space at all */
+	info->fix.mmio_start = pci_resource_start(dev->pdev, 1);
+	info->fix.mmio_len = pci_resource_len(dev->pdev, 1);
+
+	info->pixmap.size = 64*1024;
+	info->pixmap.buf_align = 8;
+	info->pixmap.access_align = 32;
+	info->pixmap.flags = FB_PIXMAP_SYSTEM;
+	info->pixmap.scan_align = 1;
+
+	switch(fb->depth) {
+	case 8:
+		info->var.red.offset = 0;
+		info->var.green.offset = 0;
+		info->var.blue.offset = 0;
+		info->var.red.length = 8; /* 8bit DAC */
+		info->var.green.length = 8;
+		info->var.blue.length = 8;
+		info->var.transp.offset = 0;
+		info->var.transp.length = 0;
+		break;
+	case 15:
+		info->var.red.offset = 10;
+		info->var.green.offset = 5;
+		info->var.blue.offset = 0;
+		info->var.red.length = 5;
+		info->var.green.length = 5;
+		info->var.blue.length = 5;
+		info->var.transp.offset = 15;
+		info->var.transp.length = 1;
+		break;
+	case 16:
+		info->var.red.offset = 11;
+		info->var.green.offset = 5;
+		info->var.blue.offset = 0;
+		info->var.red.length = 5;
+		info->var.green.length = 6;
+		info->var.blue.length = 5;
+		info->var.transp.offset = 0;
+		break;
+	case 24:
+		info->var.red.offset = 16;
+		info->var.green.offset = 8;
+		info->var.blue.offset = 0;
+		info->var.red.length = 8;
+		info->var.green.length = 8;
+		info->var.blue.length = 8;
+		info->var.transp.offset = 0;
+		info->var.transp.length = 0;
+		break;
+	case 32:
+		info->var.red.offset = 16;
+		info->var.green.offset = 8;
+		info->var.blue.offset = 0;
+		info->var.red.length = 8;
+		info->var.green.length = 8;
+		info->var.blue.length = 8;
+		info->var.transp.offset = 24;
+		info->var.transp.length = 8;
+		break;
+	default:
+		break;
+	}
+
+	fb->fbdev = info;
+
+	par->nouveau_fb = nouveau_fb;
+	par->dev = dev;
+
+	switch (dev_priv->card_type) {
+	case NV_50:
+		nv50_fbcon_accel_init(info);
+		break;
+	default:
+		break;
+	};
+
+	/* Clear the entire fbcon.  The drm will program every connector
+	 * with it's preferred mode.  If the sizes differ, one display will
+	 * quite likely have garbage around the console.
+	 */
+	rect.dx = rect.dy = 0;
+	rect.width = surface_width;
+	rect.height = surface_height;
+	rect.color = 0;
+	rect.rop = ROP_COPY;
+	info->fbops->fb_fillrect(info, &rect);
+
+	/* To allow resizeing without swapping buffers */
+	printk("allocated %dx%d fb: 0x%lx, bo %p\n", nouveau_fb->base.width,
+	       nouveau_fb->base.height, ngem->bo->offset, gem);
+
+	mutex_unlock(&dev->struct_mutex);
+	return 0;
+
+out_unref:
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+out:
+	return ret;
+}
+
+static int nouveau_fbcon_multi_fb_probe_crtc(struct drm_device *dev,
+					     struct drm_crtc *crtc)
+{
+	struct nouveau_crtc *nouveau_crtc = to_nouveau_crtc(crtc);
+	struct nouveau_framebuffer *nouveau_fb;
+	struct drm_framebuffer *fb;
+	struct drm_connector *connector;
+	struct fb_info *info;
+	struct nouveau_fbcon_par *par;
+	struct drm_mode_set *modeset;
+	unsigned int width, height;
+	int new_fb = 0;
+	int ret, i, conn_count;
+
+	if (!drm_helper_crtc_in_use(crtc))
+		return 0;
+
+	if (!crtc->desired_mode)
+		return 0;
+
+	width = crtc->desired_mode->hdisplay;
+	height = crtc->desired_mode->vdisplay;
+
+	/* is there an fb bound to this crtc already */
+	if (!nouveau_crtc->mode_set.fb) {
+		ret = nouveau_fbcon_create(dev, width, height, width, height, &nouveau_fb);
+		if (ret)
+			return -EINVAL;
+		new_fb = 1;
+	} else {
+		fb = nouveau_crtc->mode_set.fb;
+		nouveau_fb = to_nouveau_framebuffer(fb);
+		if ((nouveau_fb->base.width < width) || (nouveau_fb->base.height < height))
+			return -EINVAL;
+	}
+
+	info = nouveau_fb->base.fbdev;
+	par = info->par;
+
+	modeset = &nouveau_crtc->mode_set;
+	modeset->fb = &nouveau_fb->base;
+	conn_count = 0;
+	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
+		if (connector->encoder) {
+			if (connector->encoder->crtc == modeset->crtc) {
+				modeset->connectors[conn_count] = connector;
+				conn_count++;
+				if (conn_count > NOUVEAUFB_CONN_LIMIT)
+					BUG();
+			}
+		}
+	}
+
+	for (i = conn_count; i < NOUVEAUFB_CONN_LIMIT; i++)
+		modeset->connectors[i] = NULL;
+
+	par->crtc_ids[0] = crtc->base.id;
+
+	modeset->num_connectors = conn_count;
+	if (modeset->mode != modeset->crtc->desired_mode)
+		modeset->mode = modeset->crtc->desired_mode;
+
+	par->crtc_count = 1;
+
+	if (new_fb) {
+		info->var.pixclock = -1;
+		if (register_framebuffer(info) < 0)
+			return -EINVAL;
+	} else
+		nouveau_fbcon_set_par(info);
+
+	printk(KERN_INFO "fb%d: %s frame buffer device\n", info->node,
+	       info->fix.id);
+
+	/* Switch back to kernel console on panic */
+	kernelfb_mode = *modeset;
+	atomic_notifier_chain_register(&panic_notifier_list, &paniced);
+	printk(KERN_INFO "registered panic notifier\n");
+
+	return 0;
+}
+
+static int nouveau_fbcon_multi_fb_probe(struct drm_device *dev)
+{
+
+	struct drm_crtc *crtc;
+	int ret = 0;
+
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		ret = nouveau_fbcon_multi_fb_probe_crtc(dev, crtc);
+		if (ret)
+			return ret;
+	}
+	return ret;
+}
+
+static int nouveau_fbcon_single_fb_probe(struct drm_device *dev)
+{
+	struct drm_crtc *crtc;
+	struct drm_connector *connector;
+	unsigned int fb_width = (unsigned)-1, fb_height = (unsigned)-1;
+	unsigned int surface_width = 0, surface_height = 0;
+	int new_fb = 0;
+	int crtc_count = 0;
+	int ret, i, conn_count = 0;
+	struct nouveau_framebuffer *nouveau_fb;
+	struct fb_info *info;
+	struct nouveau_fbcon_par *par;
+	struct drm_mode_set *modeset = NULL;
+
+	NV_DEBUG(dev, "\n");
+
+	/* Get a count of crtcs now in use and new min/maxes width/heights */
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		if (!drm_helper_crtc_in_use(crtc))
+			continue;
+
+		crtc_count++;
+		if (!crtc->desired_mode)
+			continue;
+
+		/* Smallest mode determines console size... */
+		if (crtc->desired_mode->hdisplay < fb_width)
+			fb_width = crtc->desired_mode->hdisplay;
+
+		if (crtc->desired_mode->vdisplay < fb_height)
+			fb_height = crtc->desired_mode->vdisplay;
+
+		/* ... but largest for memory allocation dimensions */
+		if (crtc->desired_mode->hdisplay > surface_width)
+			surface_width = crtc->desired_mode->hdisplay;
+
+		if (crtc->desired_mode->vdisplay > surface_height)
+			surface_height = crtc->desired_mode->vdisplay;
+	}
+
+	if (crtc_count == 0 || fb_width == -1 || fb_height == -1) {
+		/* hmm everyone went away - assume VGA cable just fell out
+		   and will come back later. */
+		NV_DEBUG(dev, "no CRTCs available?\n");
+		return 0;
+	}
+
+//fail
+	/* Find the fb for our new config */
+	if (list_empty(&dev->mode_config.fb_kernel_list)) {
+		NV_DEBUG(dev, "creating new fb (console size %dx%d, "
+			  "buffer size %dx%d)\n", fb_width, fb_height,
+			  surface_width, surface_height);
+		ret = nouveau_fbcon_create(dev, fb_width, fb_height, surface_width,
+				     surface_height, &nouveau_fb);
+		if (ret)
+			return -EINVAL;
+		new_fb = 1;
+	} else {
+		struct drm_framebuffer *fb;
+
+		fb = list_first_entry(&dev->mode_config.fb_kernel_list,
+				      struct drm_framebuffer, filp_head);
+		nouveau_fb = to_nouveau_framebuffer(fb);
+
+		/* if someone hotplugs something bigger than we have already
+		 * allocated, we are pwned.  As really we can't resize an
+		 * fbdev that is in the wild currently due to fbdev not really
+		 * being designed for the lower layers moving stuff around
+		 * under it.
+		 * - so in the grand style of things - punt.
+		 */
+		if ((fb->width < surface_width) ||
+		    (fb->height < surface_height)) {
+			NV_ERROR(dev, "fb not large enough for console\n");
+			return -EINVAL;
+		}
+	}
+// fail
+
+	info = nouveau_fb->base.fbdev;
+	par = info->par;
+
+	crtc_count = 0;
+	/*
+	 * For each CRTC, set up the connector list for the CRTC's mode
+	 * set configuration.
+	 */
+	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+		struct nouveau_crtc *nouveau_crtc = to_nouveau_crtc(crtc);
+
+		modeset = &nouveau_crtc->mode_set;
+		modeset->fb = &nouveau_fb->base;
+		conn_count = 0;
+		list_for_each_entry(connector, &dev->mode_config.connector_list,
+				    head) {
+			if (!connector->encoder)
+				continue;
+
+			if(connector->encoder->crtc == modeset->crtc) {
+				modeset->connectors[conn_count++] = connector;
+				if (conn_count > NOUVEAUFB_CONN_LIMIT)
+					BUG();
+			}
+		}
+
+		/* Zero out remaining connector pointers */
+		for (i = conn_count; i < NOUVEAUFB_CONN_LIMIT; i++)
+			modeset->connectors[i] = NULL;
+
+		par->crtc_ids[crtc_count++] = crtc->base.id;
+
+		modeset->num_connectors = conn_count;
+		if (modeset->mode != modeset->crtc->desired_mode)
+			modeset->mode = modeset->crtc->desired_mode;
+	}
+	par->crtc_count = crtc_count;
+
+	if (new_fb) {
+		info->var.pixclock = -1;
+		if (register_framebuffer(info) < 0)
+			return -EINVAL;
+	} else
+		nouveau_fbcon_set_par(info);
+
+	printk(KERN_INFO "fb%d: %s frame buffer device\n", info->node,
+	       info->fix.id);
+
+	/* Switch back to kernel console on panic */
+	kernelfb_mode = *modeset;
+	atomic_notifier_chain_register(&panic_notifier_list, &paniced);
+	printk(KERN_INFO "registered panic notifier\n");
+
+	return 0;
+}
+
+/**
+ * nouveau_fbcon_restore - restore the framebuffer console (kernel) config
+ *
+ * Restore's the kernel's fbcon mode, used for lastclose & panic paths.
+ */
+void nouveau_fbcon_restore(void)
+{
+	drm_crtc_helper_set_config(&kernelfb_mode);
+}
+
+static void nouveau_fbcon_sysrq(int dummy1, struct tty_struct *dummy3)
+{
+        nouveau_fbcon_restore();
+}
+
+static struct sysrq_key_op sysrq_nouveau_fbcon_restore_op = {
+        .handler = nouveau_fbcon_sysrq,
+        .help_msg = "force fb",
+        .action_msg = "force restore of fb console",
+};
+
+int nouveau_fbcon_probe(struct drm_device *dev)
+{
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	/* something has changed in the lower levels of hell - deal with it
+	   here */
+
+	/* two modes : a) 1 fb to rule all crtcs.
+	               b) one fb per crtc.
+	   two actions 1) new connected device
+	               2) device removed.
+	   case a/1 : if the fb surface isn't big enough - resize the surface fb.
+	              if the fb size isn't big enough - resize fb into surface.
+		      if everything big enough configure the new crtc/etc.
+	   case a/2 : undo the configuration
+	              possibly resize down the fb to fit the new configuration.
+           case b/1 : see if it is on a new crtc - setup a new fb and add it.
+	   case b/2 : teardown the new fb.
+	*/
+
+	/* mode a first */
+	/* search for an fb */
+	if (nouveau_fbpercrtc) {
+		ret = nouveau_fbcon_multi_fb_probe(dev);
+	} else {
+		ret = nouveau_fbcon_single_fb_probe(dev);
+	}
+
+	register_sysrq_key('g', &sysrq_nouveau_fbcon_restore_op);
+
+	return ret;
+}
+EXPORT_SYMBOL(nouveau_fbcon_probe);
+
+int nouveau_fbcon_remove(struct drm_device *dev, struct drm_framebuffer *fb)
+{
+	struct nouveau_framebuffer *nouveau_fb = to_nouveau_framebuffer(fb);
+	struct fb_info *info;
+
+	if (!fb)
+		return -EINVAL;
+
+	info = fb->fbdev;
+
+	if (info) {
+		unregister_framebuffer(info);
+		drm_bo_kunmap(&nouveau_fb->kmap);
+		framebuffer_release(info);
+	}
+
+	atomic_notifier_chain_unregister(&panic_notifier_list, &paniced);
+	memset(&kernelfb_mode, 0, sizeof(struct drm_mode_set));
+	return 0;
+}
+EXPORT_SYMBOL(nouveau_fbcon_remove);
+MODULE_LICENSE("GPL and additional rights");
diff --git a/drivers/gpu/drm/nouveau/nouveau_fbcon.h b/drivers/gpu/drm/nouveau/nouveau_fbcon.h
new file mode 100644
index 0000000..471d2e8
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_fbcon.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NOUVEAU_FBCON_H__
+#define __NOUVEAU_FBCON_H__
+
+#define NOUVEAUFB_CONN_LIMIT 4
+
+struct nouveau_fbcon_par {
+	struct drm_device *dev;
+	struct drm_display_mode *our_mode;
+	struct nouveau_framebuffer *nouveau_fb;
+	int crtc_count;
+	/* crtc currently bound to this */
+	uint32_t crtc_ids[2];
+};
+
+int nouveau_fbcon_probe(struct drm_device *dev);
+int nouveau_fbcon_remove(struct drm_device *dev, struct drm_framebuffer *fb);
+void nouveau_fbcon_restore(void);
+
+int nv50_fbcon_accel_init(struct fb_info *info);
+
+#endif /* __NV50_FBCON_H__ */
+
diff --git a/drivers/gpu/drm/nouveau/nouveau_fence.c b/drivers/gpu/drm/nouveau/nouveau_fence.c
new file mode 100644
index 0000000..a24c137
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_fence.c
@@ -0,0 +1,126 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+
+struct nouveau_channel *
+nouveau_fence_channel(struct drm_device *dev, uint32_t class)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (class == 0)
+		class = dev_priv->channel->id;
+
+	return dev_priv->fifos[class];
+}
+
+static int
+nouveau_fence_has_irq(struct drm_device *dev, uint32_t class, uint32_t flags)
+{
+	NV_DEBUG(dev, "class=%d, flags=0x%08x\n", class, flags);
+
+	return 0;
+}
+
+static int
+nouveau_fence_emit(struct drm_device *dev, uint32_t class, uint32_t flags,
+		   uint32_t *breadcrumb, uint32_t *native_type)
+{
+	struct nouveau_channel *chan = nouveau_fence_channel(dev, class);
+	int ret;
+
+	NV_DEBUG(dev, "class=%d, flags=0x%08x\n", class, flags);
+
+	ret = RING_SPACE(chan, 2);
+	if (ret)
+		return ret;
+
+	*breadcrumb  = ++chan->next_sequence;
+	*native_type = DRM_FENCE_TYPE_EXE;
+
+	NV_DEBUG(dev, "emit 0x%08x\n", *breadcrumb);
+
+	BEGIN_RING(chan, NvSubM2MF, NV_MEMORY_TO_MEMORY_FORMAT_SET_REF, 1);
+	OUT_RING  (chan, *breadcrumb);
+	FIRE_RING (chan);
+
+	return 0;
+}
+
+static void
+nouveau_fence_poll(struct drm_device *dev, uint32_t class, uint32_t waiting_types)
+{
+	struct drm_fence_class_manager *fc = &dev->fm.fence_class[class];
+	struct nouveau_channel *chan = nouveau_fence_channel(dev, class);
+
+	NV_DEBUG(dev, "class=%d\n", class);
+	NV_DEBUG(dev, "pending: 0x%08x 0x%08x\n", waiting_types, fc->waiting_types);
+
+	if (!chan) {
+		static int warn_once = 0;
+		if (!warn_once) {
+		NV_ERROR(dev, "AIII channel %d inactive\n", class);
+		warn_once = 1;
+		}
+		return;
+	}
+
+	if (1) {
+		uint32_t sequence = nvchan_rd32(0x48);
+
+		NV_DEBUG(dev, "got 0x%08x\n", sequence);
+		drm_fence_handler(dev, class, sequence, waiting_types, 0);
+	}
+}
+
+void
+nouveau_fence_handler(struct drm_device *dev, int channel)
+{
+	struct drm_fence_manager *fm = &dev->fm;
+	struct drm_fence_class_manager *fc = &fm->fence_class[channel];
+
+	NV_DEBUG(dev, "class=%d\n", channel);
+
+	write_lock(&fm->lock);
+	nouveau_fence_poll(dev, channel, fc->waiting_types);
+	write_unlock(&fm->lock);
+}
+
+struct drm_fence_driver nouveau_fence_driver = {
+	.num_classes	= 8,
+	.wrap_diff	= (1 << 30),
+	.flush_diff	= (1 << 29),
+	.sequence_mask	= 0xffffffffU,
+	.has_irq	= nouveau_fence_has_irq,
+	.emit		= nouveau_fence_emit,
+	.flush          = NULL,
+	.poll           = nouveau_fence_poll,
+	.needed_flush   = NULL,
+	.wait           = NULL
+};
diff --git a/drivers/gpu/drm/nouveau/nouveau_fifo.c b/drivers/gpu/drm/nouveau/nouveau_fifo.c
new file mode 100644
index 0000000..670ee1f
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_fifo.c
@@ -0,0 +1,692 @@
+/*
+ * Copyright 2005-2006 Stephane Marchesin
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+#include "nouveau_dma.h"
+
+
+/* returns the size of fifo context */
+int nouveau_fifo_ctx_size(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+
+	if (dev_priv->card_type >= NV_40)
+		return 128;
+	else if (dev_priv->card_type >= NV_17)
+		return 64;
+	else
+		return 32;
+}
+
+/***********************************
+ * functions doing the actual work
+ ***********************************/
+
+static int nouveau_fifo_instmem_configure(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	nv_wr32(NV03_PFIFO_RAMHT,
+			(0x03 << 24) /* search 128 */ |
+			((dev_priv->ramht_bits - 9) << 16) |
+			(dev_priv->ramht_offset >> 8)
+			);
+
+	nv_wr32(NV03_PFIFO_RAMRO, dev_priv->ramro_offset>>8);
+
+	switch(dev_priv->card_type)
+	{
+		case NV_40:
+			switch (dev_priv->chipset) {
+			case 0x47:
+			case 0x49:
+			case 0x4b:
+				nv_wr32(0x2230, 1);
+				break;
+			default:
+				break;
+			}
+			nv_wr32(NV40_PFIFO_RAMFC, 0x30002);
+			break;
+		case NV_44:
+			nv_wr32(NV40_PFIFO_RAMFC, ((nouveau_mem_fb_amount(dev)-512*1024+dev_priv->ramfc_offset)>>16) |
+					(2 << 16));
+			break;
+		case NV_30:
+		case NV_20:
+		case NV_17:
+			nv_wr32(NV03_PFIFO_RAMFC, (dev_priv->ramfc_offset>>8) |
+					(1 << 16) /* 64 Bytes entry*/);
+			/* XXX nvidia blob set bit 18, 21,23 for nv20 & nv30 */
+			break;
+		case NV_11:
+		case NV_10:
+		case NV_04:
+			nv_wr32(NV03_PFIFO_RAMFC, dev_priv->ramfc_offset>>8);
+			break;
+	}
+
+	return 0;
+}
+
+int nouveau_fifo_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PFIFO);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PFIFO);
+
+	/* Enable PFIFO error reporting */
+	nv_wr32(NV03_PFIFO_INTR_0, 0xFFFFFFFF);
+	nv_wr32(NV03_PFIFO_INTR_EN_0, 0xFFFFFFFF);
+
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000000);
+
+	ret = nouveau_fifo_instmem_configure(dev);
+	if (ret) {
+		NV_ERROR(dev, "Failed to configure instance memory\n");
+		return ret;
+	}
+
+	/* FIXME remove all the stuff that's done in nouveau_fifo_alloc */
+
+	NV_DEBUG(dev, "Setting defaults for remaining PFIFO regs\n");
+
+	/* All channels into PIO mode */
+	nv_wr32(NV04_PFIFO_MODE, 0x00000000);
+
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000000);
+	/* Channel 0 active, PIO mode */
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH1, 0x00000000);
+	/* PUT and GET to 0 */
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUT, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_GET, 0x00000000);
+	/* No cmdbuf object */
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_INSTANCE, 0x00000000);
+	nv_wr32(NV03_PFIFO_CACHE0_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE0_PULL0, 0x00000000);
+	nv_wr32(NV04_PFIFO_SIZE, 0x0000FFFF);
+	nv_wr32(NV04_PFIFO_CACHE1_HASH, 0x0000FFFF);
+	nv_wr32(NV04_PFIFO_CACHE0_PULL1, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_CTL, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_STATE, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_ENGINE, 0x00000000);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_FETCH, NV_PFIFO_CACHE1_DMA_FETCH_TRIG_112_BYTES |
+				      NV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES |
+				      NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_4 |
+#ifdef __BIG_ENDIAN
+				      NV_PFIFO_CACHE1_BIG_ENDIAN |
+#endif
+				      0x00000000);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH, 0x00000001);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL1, 0x00000001);
+
+	/* FIXME on NV04 */
+	if (dev_priv->card_type >= NV_10) {
+		nv_wr32(NV10_PGRAPH_CTX_USER, 0x0);
+		nv_wr32(NV04_PFIFO_DELAY_0, 0xff /* retrycount*/ );
+		if (dev_priv->card_type >= NV_40)
+			nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x00002001);
+		else
+			nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10110000);
+	} else {
+		nv_wr32(NV04_PGRAPH_CTX_USER, 0x0);
+		nv_wr32(NV04_PFIFO_DELAY_0, 0xff /* retrycount*/ );
+		nv_wr32(NV04_PGRAPH_CTX_CONTROL, 0x10110000);
+	}
+
+	nv_wr32(NV04_PFIFO_DMA_TIMESLICE, 0x001fffff);
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000001);
+	return 0;
+}
+
+static int
+nouveau_fifo_pushbuf_ctxdma_init(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct mem_block *pb = chan->pushbuf_mem;
+	struct nouveau_gpuobj *pushbuf = NULL;
+	int ret;
+
+	if (pb->flags & NOUVEAU_MEM_AGP) {
+		ret = nouveau_gpuobj_gart_dma_new(chan, pb->start, pb->size,
+						  NV_DMA_ACCESS_RO,
+						  &pushbuf,
+						  &chan->pushbuf_base);
+	} else
+	if (pb->flags & NOUVEAU_MEM_PCI) {
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     pb->start, pb->size,
+					     NV_DMA_ACCESS_RO,
+					     NV_DMA_TARGET_PCI_NONLINEAR,
+					     &pushbuf);
+		chan->pushbuf_base = 0;
+	} else if (dev_priv->card_type != NV_04) {
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     pb->start, pb->size,
+					     NV_DMA_ACCESS_RO,
+					     NV_DMA_TARGET_VIDMEM, &pushbuf);
+		chan->pushbuf_base = 0;
+	} else {
+		/* NV04 cmdbuf hack, from original ddx.. not sure of it's
+		 * exact reason for existing :)  PCI access to cmdbuf in
+		 * VRAM.
+		 */
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     pb->start +
+					       drm_get_resource_start(dev, 1),
+					     pb->size, NV_DMA_ACCESS_RO,
+					     NV_DMA_TARGET_PCI, &pushbuf);
+		chan->pushbuf_base = 0;
+	}
+
+	if ((ret = nouveau_gpuobj_ref_add(dev, chan, 0, pushbuf,
+					  &chan->pushbuf))) {
+		NV_ERROR(dev, "Error referencing push buffer ctxdma: %d\n", ret);
+		if (pushbuf != dev_priv->gart_info.sg_ctxdma)
+			nouveau_gpuobj_del(dev, &pushbuf);
+		return ret;
+	}
+
+	return 0;
+}
+
+static struct mem_block *
+nouveau_fifo_user_pushbuf_alloc(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_config *config = &dev_priv->config;
+	struct mem_block *pb;
+	int pb_min_size = max(NV03_FIFO_SIZE, PAGE_SIZE);
+
+	/* Defaults for unconfigured values */
+	if (!dev_priv->mm_enabled) {
+		if (!config->cmdbuf.location)
+			config->cmdbuf.location = NOUVEAU_MEM_FB;
+		if (!config->cmdbuf.size || config->cmdbuf.size < pb_min_size)
+			config->cmdbuf.size = pb_min_size;
+	} else {
+		config->cmdbuf.location = NOUVEAU_MEM_AGP;
+		config->cmdbuf.size = 0x10000;
+	}
+
+	pb = nouveau_mem_alloc(dev, 0, config->cmdbuf.size,
+			       config->cmdbuf.location | NOUVEAU_MEM_MAPPED |
+			       NOUVEAU_MEM_NOVM, (struct drm_file *)-2);
+	if (!pb) {
+		NV_ERROR(dev, "Couldn't allocate DMA push buffer\n");
+		return NULL;
+	}
+
+	return pb;
+}
+
+/* allocates and initializes a fifo for user space consumption */
+int
+nouveau_fifo_alloc(struct drm_device *dev, struct nouveau_channel **chan_ret,
+		   struct drm_file *file_priv, struct mem_block *pushbuf,
+		   uint32_t vram_handle, uint32_t tt_handle)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	struct nouveau_channel *chan;
+	int channel, user;
+	int ret;
+
+	/*
+	 * Alright, here is the full story
+	 * Nvidia cards have multiple hw fifo contexts (praise them for that,
+	 * no complicated crash-prone context switches)
+	 * We allocate a new context for each app and let it write to it directly
+	 * (woo, full userspace command submission !)
+	 * When there are no more contexts, you lost
+	 */
+	for (channel = 0; channel < engine->fifo.channels; channel++) {
+		if (dev_priv->fifos[channel] == NULL)
+			break;
+	}
+
+	/* no more fifos. you lost. */
+	if (channel == engine->fifo.channels)
+		return -EINVAL;
+
+	dev_priv->fifos[channel] = drm_calloc(1, sizeof(struct nouveau_channel),
+					      DRM_MEM_DRIVER);
+	if (!dev_priv->fifos[channel])
+		return -ENOMEM;
+	dev_priv->fifo_alloc_count++;
+	chan = dev_priv->fifos[channel];
+	chan->dev = dev;
+	chan->id = channel;
+	chan->file_priv = file_priv;
+	chan->pushbuf_mem = pushbuf;
+	chan->vram_handle = vram_handle;
+	chan->gart_handle = tt_handle;
+
+	NV_INFO(dev, "Allocating FIFO number %d\n", channel);
+
+	/* Locate channel's user control regs */
+	if (dev_priv->card_type < NV_40)
+		user = NV03_USER(channel);
+	else
+	if (dev_priv->card_type < NV_50)
+		user = NV40_USER(channel);
+	else
+		user = NV50_USER(channel);
+
+	ret = drm_addmap(dev, drm_get_resource_start(dev, 0) + user, 
+			 PAGE_SIZE, _DRM_REGISTERS, _DRM_DRIVER |
+			 (dev_priv->mm_enabled ? _DRM_READ_ONLY : 0),
+			 &chan->user);
+
+	/* Allocate space for per-channel fixed notifier memory */
+	ret = nouveau_notifier_init_channel(chan);
+	if (ret) {
+		NV_ERROR(dev, "ntfy %d\n", ret);
+		nouveau_fifo_free(chan);
+		return ret;
+	}
+
+	/* Setup channel's default objects */
+	ret = nouveau_gpuobj_channel_init(chan, vram_handle, tt_handle);
+	if (ret) {
+		NV_ERROR(dev, "gpuobj %d\n", ret);
+		nouveau_fifo_free(chan);
+		return ret;
+	}
+
+	/* Create a dma object for the push buffer */
+	ret = nouveau_fifo_pushbuf_ctxdma_init(chan);
+	if (ret) {
+		NV_ERROR(dev, "pbctxdma %d\n", ret);
+		nouveau_fifo_free(chan);
+		return ret;
+	}
+
+	engine->graph.fifo_access(dev, false);
+	nouveau_wait_for_idle(dev);
+
+	/* disable the fifo caches */
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH, nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH)&(~0x1));
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000000);
+
+	/* Create a graphics context for new channel */
+	ret = engine->graph.create_context(chan);
+	if (ret) {
+		nouveau_fifo_free(chan);
+		return ret;
+	}
+
+	/* Construct inital RAMFC for new channel */
+	ret = engine->fifo.create_context(chan);
+	if (ret) {
+		nouveau_fifo_free(chan);
+		return ret;
+	}
+
+	/* setup channel's default get/put values
+	 * XXX: quite possibly extremely pointless..
+	 */
+	nvchan_wr32(0x44, chan->pushbuf_base);
+	nvchan_wr32(0x40, chan->pushbuf_base);
+
+	/* If this is the first channel, setup PFIFO ourselves.  For any
+	 * other case, the GPU will handle this when it switches contexts.
+	 */
+	if (dev_priv->card_type < NV_50 &&
+	    dev_priv->fifo_alloc_count == 1) {
+		ret = engine->fifo.load_context(chan);
+		if (ret) {
+			nouveau_fifo_free(chan);
+			return ret;
+		}
+
+		ret = engine->graph.load_context(chan);
+		if (ret) {
+			nouveau_fifo_free(chan);
+			return ret;
+		}
+	}
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) | 1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL1, 0x00000001);
+
+	/* reenable the fifo caches */
+	nv_wr32(NV03_PFIFO_CACHES, 1);
+
+	engine->graph.fifo_access(dev, true);
+
+	if (dev_priv->mm_enabled) {
+		ret = nouveau_dma_channel_setup(chan);
+		if (ret) {
+			nouveau_fifo_free(chan);
+			return ret;
+		}
+	}
+
+	NV_INFO(dev, "%s: initialised FIFO %d\n", __func__, channel);
+	*chan_ret = chan;
+	return 0;
+}
+
+int
+nouveau_channel_idle(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	uint32_t caches;
+	int idle;
+
+	if (!chan) {
+		NV_ERROR(dev, "no channel...\n");
+		return 1;
+	}
+
+	caches = nv_rd32(NV03_PFIFO_CACHES);
+	nv_wr32(NV03_PFIFO_CACHES, caches & ~1);
+
+	if (engine->fifo.channel_id(dev) != chan->id) {
+		struct nouveau_gpuobj *ramfc =
+			chan->ramfc ? chan->ramfc->gpuobj : NULL;
+
+		if (!ramfc) {
+			NV_ERROR(dev, "No RAMFC for channel %d\n", chan->id);
+			return 1;
+		}
+
+		engine->instmem.prepare_access(dev, false);
+		if (INSTANCE_RD(ramfc, 0) != INSTANCE_RD(ramfc, 1))
+			idle = 0;
+		else
+			idle = 1;
+		engine->instmem.finish_access(dev);
+	} else {
+		idle = (nv_rd32(NV04_PFIFO_CACHE1_DMA_GET) ==
+			nv_rd32(NV04_PFIFO_CACHE1_DMA_PUT));
+	}
+
+	nv_wr32(NV03_PFIFO_CACHES, caches);
+	return idle;
+}
+
+/* stops a fifo */
+void nouveau_fifo_free(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	uint64_t t_start;
+	bool timeout = false;
+	int ret;
+
+	NV_INFO(dev, "%s: freeing fifo %d\n", __func__, chan->id);
+
+	/* Give the channel a chance to idle, wait 2s (hopefully) */
+	t_start = engine->timer.read(dev);
+	while (!nouveau_channel_idle(chan)) {
+		if (engine->timer.read(dev) - t_start > 2000000000ULL) {
+			NV_ERROR(dev, "Failed to idle channel %d.  "
+				      "Prepare for strangeness..\n", chan->id);
+			timeout = true;
+			break;
+		}
+	}
+
+	/* Wait on a fence until channel goes idle, this ensures the engine
+	 * has finished with the last push buffer completely before we destroy
+	 * the channel.
+	 */
+	if (!timeout && dev_priv->mm_enabled) {
+		struct drm_fence_object *fence = NULL;
+
+		ret = drm_fence_object_create(dev, chan->id, DRM_FENCE_TYPE_EXE,
+					      DRM_FENCE_FLAG_EMIT, &fence);
+		if (ret == 0)
+			ret = drm_fence_object_wait(fence, 0, 1,
+						    DRM_FENCE_TYPE_EXE);
+
+		if (ret) {
+			NV_ERROR(dev, "Failed to fence channel %d.  "
+				      "Prepare for strangeness..\n", chan->id);
+			timeout = true;
+		}
+	}
+
+	/* Ensure all outstanding fences are signaled.  They should be if the
+	 * above attempts at idling were OK, but if we failed this'll tell TTM
+	 * we're done with the buffers.
+	 */
+	if (dev_priv->mm_enabled) {
+		drm_fence_handler(dev, chan->id, chan->next_sequence,
+				  DRM_FENCE_TYPE_EXE, 0);
+	}
+
+	/*XXX: Maybe should wait for PGRAPH to finish with the stuff it fetched
+	 *     from CACHE1 too?
+	 *25/3/2009: handled in the mm_enabled case
+	 */
+
+	/* disable the fifo caches */
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH, nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH)&(~0x1));
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000000);
+
+	// FIXME XXX needs more code
+
+	engine->fifo.destroy_context(chan);
+
+	/* Cleanup PGRAPH state */
+	engine->graph.destroy_context(chan);
+
+	/* reenable the fifo caches */
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) | 1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000001);
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000001);
+
+	/* Deallocate push buffer */
+	nouveau_gpuobj_ref_del(dev, &chan->pushbuf);
+	if (chan->pushbuf_mem) {
+		nouveau_mem_free(dev, chan->pushbuf_mem);
+		chan->pushbuf_mem = NULL;
+	}
+
+	/* Destroy objects belonging to the channel */
+	nouveau_gpuobj_channel_takedown(chan);
+
+	nouveau_notifier_takedown_channel(chan);
+
+	if (chan->user)
+		drm_rmmap(dev, chan->user);
+
+	dev_priv->fifos[chan->id] = NULL;
+	dev_priv->fifo_alloc_count--;
+	drm_free(chan, sizeof(*chan), DRM_MEM_DRIVER);
+}
+
+/* cleanups all the fifos from file_priv */
+void nouveau_fifo_cleanup(struct drm_device *dev, struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	int i;
+
+	NV_DEBUG(dev, "clearing FIFO enables from file_priv\n");
+	for(i = 0; i < engine->fifo.channels; i++) {
+		struct nouveau_channel *chan = dev_priv->fifos[i];
+
+		if (chan && chan->file_priv == file_priv)
+			nouveau_fifo_free(chan);
+	}
+}
+
+int
+nouveau_fifo_owner(struct drm_device *dev, struct drm_file *file_priv,
+		   int channel)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+
+	if (channel >= engine->fifo.channels)
+		return 0;
+	if (dev_priv->fifos[channel] == NULL)
+		return 0;
+	return (dev_priv->fifos[channel]->file_priv == file_priv);
+}
+
+/***********************************
+ * ioctls wrapping the functions
+ ***********************************/
+
+static int nouveau_ioctl_fifo_alloc(struct drm_device *dev, void *data,
+				    struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_channel_alloc *init = data;
+	struct drm_map_list *entry;
+	struct nouveau_channel *chan;
+	struct mem_block *pushbuf = NULL;
+	int res;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+
+	if (init->fb_ctxdma_handle == ~0 || init->tt_ctxdma_handle == ~0)
+		return -EINVAL;
+
+	pushbuf = nouveau_fifo_user_pushbuf_alloc(dev);
+	if (!pushbuf)
+		return -ENOMEM;
+
+	res = nouveau_fifo_alloc(dev, &chan, file_priv, pushbuf,
+				 init->fb_ctxdma_handle,
+				 init->tt_ctxdma_handle);
+	if (res)
+		return res;
+	init->channel  = chan->id;
+
+	if (!dev_priv->mm_enabled) {
+		init->put_base = chan->pushbuf_base;
+
+		/* make the fifo available to user space */
+		/* first, the fifo control regs */
+		entry = drm_find_matching_map(dev, chan->user);
+		if (!entry)
+			return -EINVAL;
+		init->ctrl = entry->user_token;
+		init->ctrl_size = chan->user->size;
+
+		/* pass back FIFO map info to the caller */
+		init->cmdbuf      = chan->pushbuf_mem->map_handle;
+		init->cmdbuf_size = chan->pushbuf_mem->size;
+
+		init->nr_subchan = 0;
+	} else {
+		init->subchan[0].handle = NvM2MF;
+		if (dev_priv->card_type < NV_50)
+			init->subchan[0].grclass = 0x5039;
+		else
+			init->subchan[0].grclass = 0x0039;
+		init->nr_subchan = 1;
+	}
+
+	/* and the notifier block */
+	if (!dev_priv->mm_enabled) {
+		init->notifier = chan->notifier_block->map_handle;
+	} else {
+		entry = drm_find_matching_map(dev, chan->notifier_map);
+		if (!entry) {
+			nouveau_fifo_free(chan);
+			return -EFAULT;
+		}
+
+		init->notifier = entry->user_token;
+	}
+	init->notifier_size = chan->notifier_block->size;
+
+	return 0;
+}
+
+static int nouveau_ioctl_fifo_free(struct drm_device *dev, void *data,
+				   struct drm_file *file_priv)
+{
+	struct drm_nouveau_channel_free *cfree = data;
+	struct nouveau_channel *chan;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(cfree->channel, file_priv, chan);
+
+	nouveau_fifo_free(chan);
+	return 0;
+}
+
+/***********************************
+ * finally, the ioctl table
+ ***********************************/
+
+struct drm_ioctl_desc nouveau_ioctls[] = {
+	DRM_IOCTL_DEF(DRM_NOUVEAU_CARD_INIT, nouveau_ioctl_card_init, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GETPARAM, nouveau_ioctl_getparam, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_SETPARAM, nouveau_ioctl_setparam, DRM_AUTH|DRM_MASTER|DRM_ROOT_ONLY),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_CHANNEL_ALLOC, nouveau_ioctl_fifo_alloc, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_CHANNEL_FREE, nouveau_ioctl_fifo_free, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GROBJ_ALLOC, nouveau_ioctl_grobj_alloc, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_NOTIFIEROBJ_ALLOC, nouveau_ioctl_notifier_alloc, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GPUOBJ_FREE, nouveau_ioctl_gpuobj_free, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_MEM_ALLOC, nouveau_ioctl_mem_alloc, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_MEM_FREE, nouveau_ioctl_mem_free, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_MEM_TILE, nouveau_ioctl_mem_tile, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_SUSPEND, nouveau_ioctl_suspend, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_RESUME, nouveau_ioctl_resume, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_NEW, nouveau_gem_ioctl_new, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_PUSHBUF, nouveau_gem_ioctl_pushbuf, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_PUSHBUF_CALL, nouveau_gem_ioctl_pushbuf_call, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_PIN, nouveau_gem_ioctl_pin, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_UNPIN, nouveau_gem_ioctl_unpin, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_MMAP, nouveau_gem_ioctl_mmap, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_CPU_PREP, nouveau_gem_ioctl_cpu_prep, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_CPU_FINI, nouveau_gem_ioctl_cpu_fini, DRM_AUTH),
+	DRM_IOCTL_DEF(DRM_NOUVEAU_GEM_TILE, nouveau_gem_ioctl_tile, DRM_AUTH),
+};
+
+int nouveau_max_ioctl = DRM_ARRAY_SIZE(nouveau_ioctls);
diff --git a/drivers/gpu/drm/nouveau/nouveau_gem.c b/drivers/gpu/drm/nouveau/nouveau_gem.c
new file mode 100644
index 0000000..66e35dc
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_gem.c
@@ -0,0 +1,729 @@
+/*
+ * Copyright (C) 2008 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+#include "drmP.h"
+#include "drm.h"
+
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+#include "nouveau_dma.h"
+
+#define nouveau_gem_pushbuf_sync(chan) 0
+
+int
+nouveau_gem_object_new(struct drm_gem_object *gem)
+{
+	struct nouveau_gem_object *ngem;
+
+	ngem = drm_calloc(1, sizeof(*ngem), DRM_MEM_DRIVER);
+	if (!ngem)
+		return -ENOMEM;
+	ngem->gem = gem;
+
+	INIT_LIST_HEAD(&ngem->entry);
+
+	gem->driver_private = ngem;
+	return 0;
+}
+
+void
+nouveau_gem_object_del(struct drm_gem_object *gem)
+{
+	struct nouveau_gem_object *ngem = gem->driver_private;
+
+	if (ngem->bo) {
+		drm_bo_takedown_vm_locked(ngem->bo);
+		drm_bo_usage_deref_locked(&ngem->bo);
+	}
+
+	drm_free(ngem, sizeof(*ngem), DRM_MEM_DRIVER);
+}
+
+int
+nouveau_gem_new(struct drm_device *dev, struct nouveau_channel *chan,
+		int size, int align, uint32_t domain,
+		struct drm_gem_object **pgem)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	uint64_t flags;
+	int ret;
+
+	flags  = DRM_BO_FLAG_READ | DRM_BO_FLAG_WRITE;
+	flags |= DRM_BO_FLAG_MAPPABLE;
+	flags |= DRM_BO_FLAG_MEM_LOCAL;
+	if (dev_priv->gart_info.type != NOUVEAU_GART_AGP)
+		flags |= DRM_BO_FLAG_CACHED;
+
+	size = (size + (PAGE_SIZE-1)) & ~(PAGE_SIZE-1);
+	if (dev_priv->card_type == NV_50) {
+		size = (size + 65535) & ~65535;
+		if (align < (65536 / PAGE_SIZE))
+			align = (65536 / PAGE_SIZE);
+
+		if (domain & NOUVEAU_GEM_DOMAIN_TILE) {
+			flags |= DRM_NOUVEAU_BO_FLAG_TILE;
+			if (domain & NOUVEAU_GEM_DOMAIN_TILE_ZETA)
+				flags |= DRM_NOUVEAU_BO_FLAG_ZTILE;
+		}
+	}
+
+	gem = drm_gem_object_alloc(dev, size);
+	if (!gem)
+		return -ENOMEM;
+	ngem = gem->driver_private;
+	ngem->mappable = true;
+
+	ret = drm_buffer_object_create(dev, size, drm_bo_type_device, flags,
+				       0, align, 0, &ngem->bo);
+	if (ret)
+		goto out;
+
+	if (domain & (NOUVEAU_GEM_DOMAIN_VRAM | NOUVEAU_GEM_DOMAIN_GART)) {
+		int class = chan ? chan->id : 0;
+
+		flags = 0;
+		if (domain & NOUVEAU_GEM_DOMAIN_VRAM) {
+			flags |= DRM_BO_FLAG_MEM_VRAM;
+			if (flags & NOUVEAU_GEM_DOMAIN_NOMAP) {
+				flags |= DRM_BO_FLAG_MEM_PRIV0;
+				ngem->mappable = false;
+			}
+		}
+		if (domain & NOUVEAU_GEM_DOMAIN_GART)
+			flags |= DRM_BO_FLAG_MEM_TT;
+
+		ret = drm_bo_do_validate(ngem->bo, flags, DRM_BO_MASK_MEMTYPE,
+					 DRM_BO_HINT_DONT_FENCE, class);
+	}
+
+out:
+	if (ret) {
+		mutex_lock(&dev->struct_mutex);
+		drm_gem_object_unreference(gem);
+		mutex_unlock(&dev->struct_mutex);
+		return ret;
+	}
+
+	*pgem = gem;
+	return 0;
+}
+
+int
+nouveau_gem_pin(struct drm_gem_object *gem, uint32_t domain)
+{
+	struct nouveau_gem_object *ngem = gem->driver_private;
+	uint64_t flags, mask;
+	int ret;
+
+	flags = mask = DRM_BO_FLAG_NO_EVICT;
+	if (domain) {
+		mask |= DRM_BO_MASK_MEM;
+		if (domain & NOUVEAU_GEM_DOMAIN_VRAM)
+			flags |= DRM_BO_FLAG_MEM_VRAM;
+		if (domain & NOUVEAU_GEM_DOMAIN_GART)
+			flags |= DRM_BO_FLAG_MEM_TT;
+	}
+
+	ret = drm_bo_do_validate(ngem->bo, flags, mask,
+				 DRM_BO_HINT_DONT_FENCE, 0);
+	return ret;
+}
+
+int
+nouveau_gem_unpin(struct drm_gem_object *gem)
+{
+	struct nouveau_gem_object *ngem = gem->driver_private;
+	int ret;
+
+	ret = drm_bo_do_validate(ngem->bo, 0, DRM_BO_FLAG_NO_EVICT,
+				 DRM_BO_HINT_DONT_FENCE, 0);
+	return ret;
+}
+
+int
+nouveau_gem_ioctl_new(struct drm_device *dev, void *data,
+		      struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_new *req = data;
+	struct nouveau_gem_object *ngem = NULL;
+	struct drm_gem_object *gem;
+	struct nouveau_channel *chan = NULL;
+	int ret = 0;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	if (req->channel_hint) {
+		NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(req->channel_hint,
+						     file_priv, chan);
+	}
+
+	req->size = roundup(req->size, PAGE_SIZE);
+
+	ret = nouveau_gem_new(dev, chan, req->size, req->align, req->domain,
+			      &gem);
+	if (ret)
+		return ret;
+	ngem = gem->driver_private;
+
+	req->offset = ngem->bo->offset;
+	if (ngem->bo->mem.mem_type == DRM_BO_MEM_VRAM ||
+	    ngem->bo->mem.mem_type == DRM_BO_MEM_PRIV0)
+		req->domain = NOUVEAU_GEM_DOMAIN_VRAM;
+	else
+	if (ngem->bo->mem.mem_type == DRM_BO_MEM_TT)
+		req->domain = NOUVEAU_GEM_DOMAIN_GART;
+	else
+		req->domain = 0;
+
+	ret = drm_gem_handle_create(file_priv, ngem->gem, &req->handle);
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_handle_unreference(ngem->gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	if (ret)
+		drm_gem_object_unreference(ngem->gem);
+	return ret;
+}
+
+static int
+nouveau_gem_set_domain(struct nouveau_channel *chan, struct drm_gem_object *gem,
+		       uint32_t read_domains, uint32_t write_domains,
+		       uint32_t valid_domains)
+{
+	struct nouveau_gem_object *ngem = gem->driver_private;
+	struct drm_buffer_object *bo = ngem->bo;
+	uint64_t mask = DRM_BO_MASK_MEM | DRM_BO_FLAG_READ | DRM_BO_FLAG_WRITE;
+	uint64_t flags;
+	int ret;
+
+	if (!valid_domains || (!read_domains && !write_domains))
+		return -EINVAL;
+
+	if (write_domains) {
+		if ((valid_domains & NOUVEAU_GEM_DOMAIN_VRAM) &&
+		    (write_domains & NOUVEAU_GEM_DOMAIN_VRAM))
+			flags = DRM_BO_FLAG_MEM_VRAM;
+		else
+		if ((valid_domains & NOUVEAU_GEM_DOMAIN_GART) &&
+		    (write_domains & NOUVEAU_GEM_DOMAIN_GART))
+			flags = DRM_BO_FLAG_MEM_TT;
+		else
+			return -EINVAL;
+	} else {
+		if ((valid_domains & NOUVEAU_GEM_DOMAIN_VRAM) &&
+		    (read_domains & NOUVEAU_GEM_DOMAIN_VRAM) &&
+		    (bo->mem.mem_type == DRM_BO_MEM_VRAM ||
+		     bo->mem.mem_type == DRM_BO_MEM_PRIV0))
+			flags = DRM_BO_FLAG_MEM_VRAM;
+		else
+		if ((valid_domains & NOUVEAU_GEM_DOMAIN_GART) &&
+		    (read_domains & NOUVEAU_GEM_DOMAIN_GART) &&
+		    bo->mem.mem_type == DRM_BO_MEM_TT)
+			flags = DRM_BO_FLAG_MEM_TT;
+		else
+		if ((valid_domains & NOUVEAU_GEM_DOMAIN_VRAM) &&
+		    (read_domains & NOUVEAU_GEM_DOMAIN_VRAM))
+			flags = DRM_BO_FLAG_MEM_VRAM;
+		else
+			flags = DRM_BO_FLAG_MEM_TT;
+	}
+
+	if ((flags & (DRM_BO_FLAG_MEM_VRAM)) && !ngem->mappable)
+		flags |= DRM_BO_FLAG_MEM_PRIV0;
+
+	if (read_domains)
+		flags |= DRM_BO_FLAG_READ;
+
+	if (write_domains)
+		flags |= DRM_BO_FLAG_WRITE;
+
+	ret = drm_bo_do_validate(ngem->bo, flags, mask, 0, chan->id);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int
+nouveau_gem_pushbuf_bo_validate(struct nouveau_channel *chan,
+				struct drm_file *file_priv,
+				struct drm_nouveau_gem_pushbuf_bo *b,
+				uint64_t user_bo, int nr_buffers,
+				struct drm_fence_object **fence,
+				int *apply_relocs)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gem_object *ngem;
+	struct list_head validated, *entry, *tmp;
+	int ret, i;
+
+	INIT_LIST_HEAD(&validated);
+
+	ret = drm_fence_object_create(dev, chan->id, DRM_FENCE_TYPE_EXE,
+				      0, fence);
+	if (ret)
+		return ret;
+
+	if (nr_buffers == 0)
+		return 0;
+
+	if (apply_relocs)
+		*apply_relocs = 0;
+
+	mutex_lock(&dev_priv->submit_mutex);
+
+	for (i = 0; i < nr_buffers; i++, b++) {
+		struct nouveau_gem_object *ngem;
+		struct drm_gem_object *gem;
+
+		gem = drm_gem_object_lookup(dev, file_priv, b->handle);
+		if (!gem) {
+			NV_ERROR(dev, "Unknown handle 0x%08x\n", b->handle);
+			ret = -EINVAL;
+			break;
+		}
+		ngem = gem->driver_private;
+
+		ret = nouveau_gem_set_domain(chan, gem, b->read_domains,
+					     b->write_domains,
+					     b->valid_domains);
+		if (ret)
+			break;
+
+		list_add_tail(&ngem->entry, &validated);
+
+		if (ngem->bo->offset == b->presumed_offset &&
+		    (((ngem->bo->mem.mem_type == DRM_BO_MEM_VRAM ||
+		       ngem->bo->mem.mem_type == DRM_BO_MEM_PRIV0) &&
+		      b->presumed_domain & NOUVEAU_GEM_DOMAIN_VRAM) ||
+		     (ngem->bo->mem.mem_type == DRM_BO_MEM_TT &&
+		      b->presumed_domain & NOUVEAU_GEM_DOMAIN_GART)))
+			continue;
+
+		if (ngem->bo->mem.mem_type == DRM_BO_MEM_TT)
+			b->presumed_domain = NOUVEAU_GEM_DOMAIN_GART;
+		else
+			b->presumed_domain = NOUVEAU_GEM_DOMAIN_VRAM;
+		b->presumed_offset = ngem->bo->offset;
+		b->presumed_ok = 0;
+		if (apply_relocs)
+			(*apply_relocs)++;
+
+		if (DRM_COPY_TO_USER((void __user *)user_bo + (i * sizeof(*b)),
+				     b, sizeof(*b))) {
+			ret = -EFAULT;
+			break;
+		}
+	}
+
+	mutex_lock(&dev->struct_mutex);
+	list_for_each_safe(entry, tmp, &validated) {
+		ngem = list_entry(entry, struct nouveau_gem_object, entry);
+		drm_gem_object_unreference(ngem->gem);
+		list_del(&ngem->entry);
+	}
+	mutex_unlock(&dev->struct_mutex);
+
+	if (!ret)
+		ret = drm_fence_buffer_objects(dev, NULL, 0, *fence, fence);
+
+	if (ret) {
+		drm_putback_buffer_objects(dev);
+		drm_fence_usage_deref_unlocked(fence);
+	}
+
+	mutex_unlock(&dev_priv->submit_mutex);
+	return ret;
+}
+
+static int
+nouveau_gem_pushbuf_reloc_apply(struct nouveau_channel *chan,
+				struct drm_nouveau_gem_pushbuf_reloc *reloc,
+				struct drm_nouveau_gem_pushbuf_bo *bo,
+				uint32_t *pushbuf, int nr_relocs,
+				int nr_buffers, int nr_dwords)
+{
+	struct drm_device *dev = chan->dev;
+	int i;
+	
+	for (i = 0; i < nr_relocs; i++) {
+		struct drm_nouveau_gem_pushbuf_reloc *r = &reloc[i];
+		struct drm_nouveau_gem_pushbuf_bo *b;
+		uint32_t data;
+
+		if (r->bo_index >= nr_buffers || r->reloc_index >= nr_dwords) {
+			NV_ERROR(dev, "Bad relocation %d\n", i);
+			NV_ERROR(dev, "  bo: %d max %d\n", r->bo_index, nr_buffers);
+			NV_ERROR(dev, "  id: %d max %d\n", r->reloc_index, nr_dwords);
+			return -EINVAL;
+		}
+
+		b = &bo[r->bo_index];
+		if (b->presumed_ok)
+			continue;
+
+		if (r->flags & NOUVEAU_GEM_RELOC_LOW)
+			data = b->presumed_offset + r->data;
+		else
+		if (r->flags & NOUVEAU_GEM_RELOC_HIGH)
+			data = (b->presumed_offset + r->data) >> 32;
+		else
+			data = r->data;
+
+		if (r->flags & NOUVEAU_GEM_RELOC_OR) {
+			if (b->presumed_domain == NOUVEAU_GEM_DOMAIN_GART)
+				data |= r->tor;
+			else
+				data |= r->vor;
+		}
+
+		pushbuf[r->reloc_index] = data;
+	}
+
+	return 0;
+}
+
+static inline void *
+u_memcpya(uint64_t user, unsigned nmemb, unsigned size)
+{
+	void *mem;
+
+	mem = drm_alloc(nmemb * size, DRM_MEM_DRIVER);
+	if (!mem)
+		return (void *)-ENOMEM;
+
+	if (DRM_COPY_FROM_USER(mem, (void __user *)user, nmemb * size)) {
+		drm_free(mem, nmemb * size, DRM_MEM_DRIVER);
+		return (void *)-EFAULT;
+	}
+
+	return mem;
+}
+
+int
+nouveau_gem_ioctl_pushbuf(struct drm_device *dev, void *data,
+			  struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_pushbuf *req = data;
+	struct drm_nouveau_gem_pushbuf_bo *bo = NULL;
+	struct drm_nouveau_gem_pushbuf_reloc *reloc = NULL;
+	struct drm_fence_object *fence = NULL;
+	struct nouveau_channel *chan;
+	uint32_t *pushbuf = NULL;
+	int ret = 0, i;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+	NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(req->channel, file_priv, chan);
+
+	if (req->nr_dwords >= chan->dma.max ||
+	    req->nr_buffers > NOUVEAU_GEM_MAX_BUFFERS ||
+	    req->nr_relocs > NOUVEAU_GEM_MAX_RELOCS) {
+		NV_ERROR(dev, "Pushbuf config exceeds limits:\n");
+		NV_ERROR(dev, "  dwords : %d max %d\n", req->nr_dwords,
+			 chan->dma.max - 1);
+		NV_ERROR(dev, "  buffers: %d max %d\n", req->nr_buffers,
+			 NOUVEAU_GEM_MAX_BUFFERS);
+		NV_ERROR(dev, "  relocs : %d max %d\n", req->nr_relocs,
+			 NOUVEAU_GEM_MAX_RELOCS);
+		return -EINVAL;
+	}
+
+	pushbuf = u_memcpya(req->dwords, req->nr_dwords, sizeof(uint32_t));
+	if (IS_ERR(pushbuf))
+		return (unsigned long)pushbuf;
+
+	bo = u_memcpya(req->buffers, req->nr_buffers, sizeof(*bo));
+	if (IS_ERR(bo)) {
+		drm_free(pushbuf, req->nr_dwords * sizeof(uint32_t),
+			 DRM_MEM_DRIVER);
+		return (unsigned long)bo;
+	}
+
+	reloc = u_memcpya(req->relocs, req->nr_relocs, sizeof(*reloc));
+	if (IS_ERR(reloc)) {
+		drm_free(bo, req->nr_buffers * sizeof(*bo), DRM_MEM_DRIVER);
+		drm_free(pushbuf, req->nr_dwords * sizeof(uint32_t),
+			 DRM_MEM_DRIVER);
+		return (unsigned long)reloc;
+	}
+
+	/* Validate buffer list */
+	ret = nouveau_gem_pushbuf_bo_validate(chan, file_priv, bo,
+					      req->buffers, req->nr_buffers,
+					      &fence, NULL);
+	if (ret)
+		goto out;
+
+	/* Apply any relocations that are required */
+	ret = nouveau_gem_pushbuf_reloc_apply(chan, reloc, bo, pushbuf,
+					      req->nr_relocs, req->nr_buffers,
+					      req->nr_dwords);
+	if (ret)
+		goto out;
+
+	/* Emit push buffer to the hw
+	 *XXX: OMG ALSO YUCK!!!
+	 */
+	ret = RING_SPACE(chan, req->nr_dwords);
+	if (ret)
+		goto out;
+
+	for (i = 0; i < req->nr_dwords; i++)
+		OUT_RING (chan, pushbuf[i]);
+
+	ret = drm_fence_object_emit(fence, 0, chan->id,
+				    DRM_FENCE_TYPE_EXE);
+	if (ret) {
+		/*XXX*/
+	}
+
+	if (nouveau_gem_pushbuf_sync(chan)) {
+		ret = drm_fence_object_wait(fence, 0, 1, 1);
+		if (ret) {
+			for (i = 0; i < req->nr_dwords; i++)
+				NV_ERROR(dev, "0x%08x\n", pushbuf[i]);
+			NV_ERROR(dev, "^^ above push buffer is fail :(\n");
+		}
+	}
+
+	FIRE_RING(chan);
+
+out:
+	if (fence)
+		drm_fence_usage_deref_unlocked(&fence);
+
+	drm_free(pushbuf, req->nr_dwords * sizeof(uint32_t), DRM_MEM_DRIVER);
+	drm_free(bo, req->nr_buffers * sizeof(uint32_t), DRM_MEM_DRIVER);
+	drm_free(reloc, req->nr_relocs * sizeof(uint32_t), DRM_MEM_DRIVER);
+
+	return ret;
+}
+
+int
+nouveau_gem_ioctl_pushbuf_call(struct drm_device *dev, void *data,
+			       struct drm_file *file_priv)
+{
+	return -ENODEV;
+}
+
+int
+nouveau_gem_ioctl_pin(struct drm_device *dev, void *data,
+		      struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_pin *req = data;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	int ret = 0;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	gem = drm_gem_object_lookup(dev, file_priv, req->handle);
+	if (!gem)
+		return -EINVAL;
+	ngem = gem->driver_private;
+
+	ret = nouveau_gem_pin(gem, req->domain);
+	if (ret)
+		goto out;
+
+	req->offset = ngem->bo->offset;
+	req->domain = 0;
+	if (ngem->bo->mem.mem_type == DRM_BO_MEM_VRAM ||
+	    ngem->bo->mem.mem_type == DRM_BO_MEM_PRIV0)
+		req->domain |= NOUVEAU_GEM_DOMAIN_VRAM;
+	else
+	if (ngem->bo->mem.mem_type == DRM_BO_MEM_TT)
+		req->domain |= NOUVEAU_GEM_DOMAIN_GART;
+
+out:
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	return ret;
+}
+
+int
+nouveau_gem_ioctl_unpin(struct drm_device *dev, void *data,
+			struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_pin *req = data;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	gem = drm_gem_object_lookup(dev, file_priv, req->handle);
+	if (!gem)
+		return -EINVAL;
+	ngem = gem->driver_private;
+
+	ret = drm_bo_do_validate(ngem->bo, 0, DRM_BO_FLAG_NO_EVICT,
+				 DRM_BO_HINT_DONT_FENCE, 0);
+
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	return ret;
+}
+
+int
+nouveau_gem_ioctl_mmap(struct drm_device *dev, void *data,
+		       struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_mmap *req = data;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	unsigned long addr;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	gem = drm_gem_object_lookup(dev, file_priv, req->handle);
+	if (!gem)
+		return -EINVAL;
+	ngem = gem->driver_private;
+
+	if (!ngem->mappable)
+		return -EINVAL;
+
+	if (ngem->bo->mem.mem_type == DRM_BO_MEM_LOCAL) {
+		ret = drm_bo_do_validate(ngem->bo, DRM_BO_FLAG_MEM_TT,
+					 DRM_BO_MASK_MEMTYPE,
+					 DRM_BO_HINT_DONT_FENCE, 0);
+		if (ret) {
+			mutex_lock(&dev->struct_mutex);
+			drm_gem_object_unreference(gem);
+			mutex_unlock(&dev->struct_mutex);
+			return ret;
+		}
+	}
+
+	down_write(&current->mm->mmap_sem);
+	addr = do_mmap_pgoff(file_priv->filp, 0, ngem->bo->mem.size,
+			     PROT_READ | PROT_WRITE, MAP_SHARED,
+			     ngem->bo->map_list.hash.key);
+	up_write(&current->mm->mmap_sem);
+
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	if (IS_ERR((void *)addr))
+		return addr;
+	req->vaddr = (uint64_t)addr;
+
+	return 0;
+}
+
+int
+nouveau_gem_ioctl_cpu_prep(struct drm_device *dev, void *data,
+			   struct drm_file *file_priv)
+{
+	struct drm_nouveau_gem_mmap *req = data;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	gem = drm_gem_object_lookup(dev, file_priv, req->handle);
+	if (!gem)
+		return -EINVAL;
+	ngem = gem->driver_private;
+
+	mutex_lock(&ngem->bo->mutex);
+	ret = drm_bo_wait(ngem->bo, 0, 0, 0, 0);
+	mutex_unlock(&ngem->bo->mutex);
+
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	return ret;
+}
+
+int
+nouveau_gem_ioctl_cpu_fini(struct drm_device *dev, void *data,
+			   struct drm_file *file_priv)
+{
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	return 0;
+}
+
+int
+nouveau_gem_ioctl_tile(struct drm_device *dev, void *data,
+		       struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_gem_tile *req = data;
+	struct nouveau_gem_object *ngem;
+	struct drm_gem_object *gem;
+	unsigned offset, tile = 0;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_ENABLED_WITH_RETURN;
+
+	gem = drm_gem_object_lookup(dev, file_priv, req->handle);
+	if (!gem)
+		return -EINVAL;
+	ngem = gem->driver_private;
+
+	offset  = ngem->bo->offset + req->delta;
+	offset -= dev_priv->vm_vram_base;
+
+	if (req->flags & NOUVEAU_MEM_TILE) {
+		if (req->flags & NOUVEAU_MEM_TILE_ZETA)
+			tile = 0x00002800;
+		else
+			tile = 0x00007000;
+	}
+
+	ret = nv50_mem_vm_bind_linear(dev, ngem->bo->offset + req->delta,
+				      req->size, tile, offset);
+	if (ret)
+		return ret;
+
+	mutex_lock(&dev->struct_mutex);
+	drm_gem_object_unreference(gem);
+	mutex_unlock(&dev->struct_mutex);
+
+	return 0;
+}
+
diff --git a/drivers/gpu/drm/nouveau/nouveau_hw.c b/drivers/gpu/drm/nouveau/nouveau_hw.c
new file mode 100644
index 0000000..ca03e70
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_hw.c
@@ -0,0 +1,1019 @@
+/*
+ * Copyright 2006 Dave Airlie
+ * Copyright 2007 Maarten Maathuis
+ * Copyright 2007-2009 Stuart Bennett
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF
+ * OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_hw.h"
+
+#define CHIPSET_NFORCE 0x01a0
+#define CHIPSET_NFORCE2 0x01f0
+
+/*
+ * misc hw access wrappers/control functions
+ */
+
+void
+NVWriteVgaSeq(struct drm_device *dev, int head, uint8_t index, uint8_t value)
+{
+	NVWritePRMVIO(dev, head, NV_PRMVIO_SRX, index);
+	NVWritePRMVIO(dev, head, NV_PRMVIO_SR, value);
+}
+
+uint8_t
+NVReadVgaSeq(struct drm_device *dev, int head, uint8_t index)
+{
+	NVWritePRMVIO(dev, head, NV_PRMVIO_SRX, index);
+	return NVReadPRMVIO(dev, head, NV_PRMVIO_SR);
+}
+
+void
+NVWriteVgaGr(struct drm_device *dev, int head, uint8_t index, uint8_t value)
+{
+	NVWritePRMVIO(dev, head, NV_PRMVIO_GRX, index);
+	NVWritePRMVIO(dev, head, NV_PRMVIO_GX, value);
+}
+
+uint8_t
+NVReadVgaGr(struct drm_device *dev, int head, uint8_t index)
+{
+	NVWritePRMVIO(dev, head, NV_PRMVIO_GRX, index);
+	return NVReadPRMVIO(dev, head, NV_PRMVIO_GX);
+}
+
+/* CR44 takes values 0 (head A), 3 (head B) and 4 (heads tied)
+ * it affects only the 8 bit vga io regs, which we access using mmio at
+ * 0xc{0,2}3c*, 0x60{1,3}3*, and 0x68{1,3}3d*
+ * in general, the set value of cr44 does not matter: reg access works as
+ * expected and values can be set for the appropriate head by using a 0x2000
+ * offset as required
+ * however:
+ * a) pre nv40, the head B range of PRMVIO regs at 0xc23c* was not exposed and
+ *    cr44 must be set to 0 or 3 for accessing values on the correct head
+ *    through the common 0xc03c* addresses
+ * b) in tied mode (4) head B is programmed to the values set on head A, and
+ *    access using the head B addresses can have strange results, ergo we leave
+ *    tied mode in init once we know to what cr44 should be restored on exit
+ *
+ * the owner parameter is slightly abused:
+ * 0 and 1 are treated as head values and so the set value is (owner * 3)
+ * other values are treated as literal values to set
+ */
+void
+NVSetOwner(struct drm_device *dev, int owner)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (owner == 1)
+		owner *= 3;
+
+	/* CR44 is always changed on CRTC0 */
+	NVWriteVgaCrtc(dev, 0, NV_CIO_CRE_44, owner);
+	if (dev_priv->chipset == 0x11) {	/* set me harder */
+		NVWriteVgaCrtc(dev, 0, NV_CIO_CRE_2E, owner);
+		NVWriteVgaCrtc(dev, 0, NV_CIO_CRE_2E, owner);
+	}
+}
+
+void
+NVBlankScreen(struct drm_device *dev, int head, bool blank)
+{
+	unsigned char seq1;
+
+	if (nv_two_heads(dev))
+		NVSetOwner(dev, head);
+
+	seq1 = NVReadVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX);
+
+	NVVgaSeqReset(dev, head, true);
+	if (blank)
+		NVWriteVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX, seq1 | 0x20);
+	else
+		NVWriteVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX, seq1 & ~0x20);
+	NVVgaSeqReset(dev, head, false);
+}
+
+/*
+ * PLL setting
+ */
+
+static int
+powerctrl_1_shift(int chip_version, int reg)
+{
+	int shift = -4;
+
+	if (chip_version < 0x17 || chip_version == 0x1a || chip_version == 0x20)
+		return shift;
+
+	switch (reg) {
+	case NV_RAMDAC_VPLL2:
+		shift += 4;
+	case NV_PRAMDAC_VPLL_COEFF:
+		shift += 4;
+	case NV_PRAMDAC_MPLL_COEFF:
+		shift += 4;
+	case NV_PRAMDAC_NVPLL_COEFF:
+		shift += 4;
+	}
+
+	/*
+	 * the shift for vpll regs is only used for nv3x chips with a single
+	 * stage pll
+	 */
+	if (shift > 4 && (chip_version < 0x32 || chip_version == 0x35 ||
+			  chip_version == 0x36 || chip_version >= 0x40))
+		shift = -4;
+
+	return shift;
+}
+
+static void
+setPLL_single(struct drm_device *dev, uint32_t reg, struct nouveau_pll_vals *pv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int chip_version = dev_priv->vbios->chip_version;
+	uint32_t oldpll = NVReadRAMDAC(dev, 0, reg);
+	int oldN = (oldpll >> 8) & 0xff, oldM = oldpll & 0xff;
+	uint32_t pll = (oldpll & 0xfff80000) | pv->log2P << 16 | pv->NM1;
+	uint32_t saved_powerctrl_1 = 0;
+	int shift_powerctrl_1 = powerctrl_1_shift(chip_version, reg);
+
+	if (oldpll == pll)
+		return;	/* already set */
+
+	if (shift_powerctrl_1 >= 0) {
+		saved_powerctrl_1 = nvReadMC(dev, NV_PBUS_POWERCTRL_1);
+		nvWriteMC(dev, NV_PBUS_POWERCTRL_1,
+			(saved_powerctrl_1 & ~(0xf << shift_powerctrl_1)) |
+			1 << shift_powerctrl_1);
+	}
+
+	if (oldM && pv->M1 && (oldN / oldM < pv->N1 / pv->M1))
+		/* upclock -- write new post divider first */
+		NVWriteRAMDAC(dev, 0, reg, pv->log2P << 16 | (oldpll & 0xffff));
+	else
+		/* downclock -- write new NM first */
+		NVWriteRAMDAC(dev, 0, reg, (oldpll & 0xffff0000) | pv->NM1);
+
+	if (chip_version < 0x17 && chip_version != 0x11)
+		/* wait a bit on older chips */
+		msleep(64);
+	NVReadRAMDAC(dev, 0, reg);
+
+	/* then write the other half as well */
+	NVWriteRAMDAC(dev, 0, reg, pll);
+
+	if (shift_powerctrl_1 >= 0)
+		nvWriteMC(dev, NV_PBUS_POWERCTRL_1, saved_powerctrl_1);
+}
+
+static uint32_t
+new_ramdac580(uint32_t reg1, bool ss, uint32_t ramdac580)
+{
+	bool head_a = (reg1 == NV_PRAMDAC_VPLL_COEFF);
+
+	if (ss)	/* single stage pll mode */
+		ramdac580 |= head_a ? NV_RAMDAC_580_VPLL1_ACTIVE :
+				      NV_RAMDAC_580_VPLL2_ACTIVE;
+	else
+		ramdac580 &= head_a ? ~NV_RAMDAC_580_VPLL1_ACTIVE :
+				      ~NV_RAMDAC_580_VPLL2_ACTIVE;
+
+	return ramdac580;
+}
+
+static void
+setPLL_double_highregs(struct drm_device *dev, uint32_t reg1,
+		       struct nouveau_pll_vals *pv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int chip_version = dev_priv->vbios->chip_version;
+	bool nv3035 = chip_version == 0x30 || chip_version == 0x35;
+	uint32_t reg2 = reg1 + ((reg1 == NV_RAMDAC_VPLL2) ? 0x5c : 0x70);
+	uint32_t oldpll1 = NVReadRAMDAC(dev, 0, reg1);
+	uint32_t oldpll2 = !nv3035 ? NVReadRAMDAC(dev, 0, reg2) : 0;
+	uint32_t pll1 = (oldpll1 & 0xfff80000) | pv->log2P << 16 | pv->NM1;
+	uint32_t pll2 = (oldpll2 & 0x7fff0000) | 1 << 31 | pv->NM2;
+	uint32_t oldramdac580 = 0, ramdac580 = 0;
+	bool single_stage = !pv->NM2 || pv->N2 == pv->M2;	/* nv41+ only */
+	uint32_t saved_powerctrl_1 = 0, savedc040 = 0;
+	int shift_powerctrl_1 = powerctrl_1_shift(chip_version, reg1);
+
+	/* model specific additions to generic pll1 and pll2 set up above */
+	if (nv3035) {
+		pll1 = (pll1 & 0xfcc7ffff) | (pv->N2 & 0x18) << 21 |
+		       (pv->N2 & 0x7) << 19 | 8 << 4 | (pv->M2 & 7) << 4;
+		pll2 = 0;
+	}
+	if (chip_version > 0x40 && reg1 >= NV_PRAMDAC_VPLL_COEFF) { /* !nv40 */
+		oldramdac580 = NVReadRAMDAC(dev, 0, NV_PRAMDAC_580);
+		ramdac580 = new_ramdac580(reg1, single_stage, oldramdac580);
+		if (oldramdac580 != ramdac580)
+			oldpll1 = ~0;	/* force mismatch */
+		if (single_stage)
+			/* magic value used by nvidia in single stage mode */
+			pll2 |= 0x011f;
+	}
+	if (chip_version > 0x70)
+		/* magic bits set by the blob (but not the bios) on g71-73 */
+		pll1 = (pll1 & 0x7fffffff) | (single_stage ? 0x4 : 0xc) << 28;
+
+	if (oldpll1 == pll1 && oldpll2 == pll2)
+		return;	/* already set */
+
+	if (shift_powerctrl_1 >= 0) {
+		saved_powerctrl_1 = nvReadMC(dev, NV_PBUS_POWERCTRL_1);
+		nvWriteMC(dev, NV_PBUS_POWERCTRL_1,
+			(saved_powerctrl_1 & ~(0xf << shift_powerctrl_1)) |
+			1 << shift_powerctrl_1);
+	}
+
+	if (chip_version >= 0x40) {
+		int shift_c040 = 14;
+
+		switch (reg1) {
+		case NV_PRAMDAC_MPLL_COEFF:
+			shift_c040 += 2;
+		case NV_PRAMDAC_NVPLL_COEFF:
+			shift_c040 += 2;
+		case NV_RAMDAC_VPLL2:
+			shift_c040 += 2;
+		case NV_PRAMDAC_VPLL_COEFF:
+			shift_c040 += 2;
+		}
+
+		savedc040 = nvReadMC(dev, 0xc040);
+		if (shift_c040 != 14)
+			nvWriteMC(dev, 0xc040, savedc040 & ~(3 << shift_c040));
+	}
+
+	if (oldramdac580 != ramdac580)
+		NVWriteRAMDAC(dev, 0, NV_PRAMDAC_580, ramdac580);
+
+	if (!nv3035)
+		NVWriteRAMDAC(dev, 0, reg2, pll2);
+	NVWriteRAMDAC(dev, 0, reg1, pll1);
+
+	if (shift_powerctrl_1 >= 0)
+		nvWriteMC(dev, NV_PBUS_POWERCTRL_1, saved_powerctrl_1);
+	if (chip_version >= 0x40)
+		nvWriteMC(dev, 0xc040, savedc040);
+}
+
+static void
+setPLL_double_lowregs(struct drm_device *dev, uint32_t NMNMreg,
+		      struct nouveau_pll_vals *pv)
+{
+	/* When setting PLLs, there is a merry game of disabling and enabling
+	 * various bits of hardware during the process. This function is a
+	 * synthesis of six nv4x traces, nearly each card doing a subtly
+	 * different thing. With luck all the necessary bits for each card are
+	 * combined herein. Without luck it deviates from each card's formula
+	 * so as to not work on any :)
+	 */
+
+	uint32_t Preg = NMNMreg - 4;
+	bool mpll = Preg == 0x4020;
+	uint32_t oldPval = nvReadMC(dev, Preg);
+	uint32_t NMNM = pv->NM2 << 16 | pv->NM1;
+	uint32_t Pval = (oldPval & (mpll ? ~(0x11 << 16) : ~(1 << 16))) |
+			0xc << 28 | pv->log2P << 16;
+	uint32_t saved4600 = 0;
+	/* some cards have different maskc040s */
+	uint32_t maskc040 = ~(3 << 14), savedc040;
+	bool single_stage = !pv->NM2 || pv->N2 == pv->M2;
+
+	if (nvReadMC(dev, NMNMreg) == NMNM && (oldPval & 0xc0070000) == Pval)
+		return;
+
+	if (Preg == 0x4000)
+		maskc040 = ~0x333;
+	if (Preg == 0x4058)
+		maskc040 = ~(0xc << 24);
+
+	if (mpll) {
+		struct pll_lims pll_lim;
+		uint8_t Pval2;
+
+		if (get_pll_limits(dev, Preg, &pll_lim))
+			return;
+
+		Pval2 = pv->log2P + pll_lim.log2p_bias;
+		if (Pval2 > pll_lim.max_log2p)
+			Pval2 = pll_lim.max_log2p;
+		Pval |= 1 << 28 | Pval2 << 20;
+
+		saved4600 = nvReadMC(dev, 0x4600);
+		nvWriteMC(dev, 0x4600, saved4600 | 8 << 28);
+	}
+	if (single_stage)
+		Pval |= mpll ? 1 << 12 : 1 << 8;
+
+	nvWriteMC(dev, Preg, oldPval | 1 << 28);
+	nvWriteMC(dev, Preg, Pval & ~(4 << 28));
+	if (mpll) {
+		Pval |= 8 << 20;
+		nvWriteMC(dev, 0x4020, Pval & ~(0xc << 28));
+		nvWriteMC(dev, 0x4038, Pval & ~(0xc << 28));
+	}
+
+	savedc040 = nvReadMC(dev, 0xc040);
+	nvWriteMC(dev, 0xc040, savedc040 & maskc040);
+
+	nvWriteMC(dev, NMNMreg, NMNM);
+	if (NMNMreg == 0x4024)
+		nvWriteMC(dev, 0x403c, NMNM);
+
+	nvWriteMC(dev, Preg, Pval);
+	if (mpll) {
+		Pval &= ~(8 << 20);
+		nvWriteMC(dev, 0x4020, Pval);
+		nvWriteMC(dev, 0x4038, Pval);
+		nvWriteMC(dev, 0x4600, saved4600);
+	}
+
+	nvWriteMC(dev, 0xc040, savedc040);
+
+	if (mpll) {
+		nvWriteMC(dev, 0x4020, Pval & ~(1 << 28));
+		nvWriteMC(dev, 0x4038, Pval & ~(1 << 28));
+	}
+}
+
+void
+nouveau_hw_setpll(struct drm_device *dev, uint32_t reg1,
+		  struct nouveau_pll_vals *pv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int cv = dev_priv->vbios->chip_version;
+
+	if (cv == 0x30 || cv == 0x31 || cv == 0x35 || cv == 0x36 ||
+	    cv >= 0x40) {
+		if (reg1 > 0x405c)
+			setPLL_double_highregs(dev, reg1, pv);
+		else
+			setPLL_double_lowregs(dev, reg1, pv);
+	} else
+		setPLL_single(dev, reg1, pv);
+}
+
+/*
+ * PLL getting
+ */
+
+static void
+nouveau_hw_decode_pll(struct drm_device *dev, uint32_t reg1, uint32_t pll1,
+		      uint32_t pll2, struct nouveau_pll_vals *pllvals)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* to force parsing as single stage (i.e. nv40 vplls) pass pll2 as 0 */
+
+	/* log2P is & 0x7 as never more than 7, and nv30/35 only uses 3 bits */
+	pllvals->log2P = (pll1 >> 16) & 0x7;
+	pllvals->N2 = pllvals->M2 = 1;
+
+	if (reg1 <= 0x405c) {
+		pllvals->NM1 = pll2 & 0xffff;
+		/* single stage NVPLL and VPLLs use 1 << 8, MPLL uses 1 << 12 */
+		if (!(pll1 & 0x1100))
+			pllvals->NM2 = pll2 >> 16;
+	} else {
+		pllvals->NM1 = pll1 & 0xffff;
+		if (nv_two_reg_pll(dev) && pll2 & NV31_RAMDAC_ENABLE_VCO2)
+			pllvals->NM2 = pll2 & 0xffff;
+		else if (dev_priv->chipset == 0x30 || dev_priv->chipset == 0x35) {
+			pllvals->M1 &= 0xf; /* only 4 bits */
+			if (pll1 & NV30_RAMDAC_ENABLE_VCO2) {
+				pllvals->M2 = (pll1 >> 4) & 0x7;
+				pllvals->N2 = ((pll1 >> 21) & 0x18) |
+					      ((pll1 >> 19) & 0x7);
+			}
+		}
+	}
+}
+
+int
+nouveau_hw_get_pllvals(struct drm_device *dev, enum pll_types plltype,
+		       struct nouveau_pll_vals *pllvals)
+{
+	const uint32_t nv04_regs[MAX_PLL_TYPES] = { NV_PRAMDAC_NVPLL_COEFF,
+						    NV_PRAMDAC_MPLL_COEFF,
+						    NV_PRAMDAC_VPLL_COEFF,
+						    NV_RAMDAC_VPLL2 };
+	const uint32_t nv40_regs[MAX_PLL_TYPES] = { 0x4000,
+						    0x4020,
+						    NV_PRAMDAC_VPLL_COEFF,
+						    NV_RAMDAC_VPLL2 };
+	uint32_t reg1, pll1, pll2 = 0;
+	struct pll_lims pll_lim;
+	int ret;
+
+	NV_ERROR(dev, "two_reg_pll\n");
+
+	if (nv_arch(dev) < NV_40)
+		reg1 = nv04_regs[plltype];
+	else
+		reg1 = nv40_regs[plltype];
+
+	pll1 = nvReadMC(dev, reg1);
+
+	if (reg1 <= 0x405c)
+		pll2 = nvReadMC(dev, reg1 + 4);
+	else if (1) { //dev_priv->two_reg_pll) {
+		uint32_t reg2 = reg1 + (reg1 == NV_RAMDAC_VPLL2 ? 0x5c : 0x70);
+
+		pll2 = nvReadMC(dev, reg2);
+	}
+
+	if (nv_arch(dev) == 0x40 && reg1 >= NV_PRAMDAC_VPLL_COEFF) {
+		uint32_t ramdac580 = NVReadRAMDAC(dev, 0, NV_PRAMDAC_580);
+
+		/* check whether vpll has been forced into single stage mode */
+		if (reg1 == NV_PRAMDAC_VPLL_COEFF) {
+			if (ramdac580 & NV_RAMDAC_580_VPLL1_ACTIVE)
+				pll2 = 0;
+		} else
+			if (ramdac580 & NV_RAMDAC_580_VPLL2_ACTIVE)
+				pll2 = 0;
+	}
+
+	nouveau_hw_decode_pll(dev, reg1, pll1, pll2, pllvals);
+
+	if ((ret = get_pll_limits(dev, plltype, &pll_lim)))
+		return ret;
+
+	pllvals->refclk = pll_lim.refclk;
+
+	return 0;
+}
+
+int
+nouveau_hw_pllvals_to_clk(struct nouveau_pll_vals *pv)
+{
+	/* Avoid divide by zero if called at an inappropriate time */
+	if (!pv->M1 || !pv->M2)
+		return 0;
+
+	return (pv->N1 * pv->N2 * pv->refclk / (pv->M1 * pv->M2) >> pv->log2P);
+}
+
+int
+nouveau_hw_get_clock(struct drm_device *dev, enum pll_types plltype)
+{
+	struct nouveau_pll_vals pllvals;
+
+	if (plltype == MPLL && (dev->pci_device & 0x0ff0) == CHIPSET_NFORCE) {
+		uint32_t mpllP;
+
+		pci_read_config_dword(pci_get_bus_and_slot(0, 3), 0x6c, &mpllP);
+		if (!mpllP)
+			mpllP = 4;
+
+		return 400000 / mpllP;
+	} else
+	if (plltype == MPLL && (dev->pci_device & 0xff0) == CHIPSET_NFORCE2) {
+		uint32_t clock;
+
+		pci_read_config_dword(pci_get_bus_and_slot(0, 5), 0x4c, &clock);
+		return clock;
+	}
+
+	nouveau_hw_get_pllvals(dev, plltype, &pllvals);
+
+	return nouveau_hw_pllvals_to_clk(&pllvals);
+}
+
+static void
+nouveau_hw_fix_bad_vpll(struct drm_device *dev, int head)
+{
+	/* the vpll on an unused head can come up with a random value, way
+	 * beyond the pll limits.  for some reason this causes the chip to
+	 * lock up when reading the dac palette regs, so set a valid pll here
+	 * when such a condition detected.  only seen on nv11 to date
+	 */
+
+	struct pll_lims pll_lim;
+	struct nouveau_pll_vals pv;
+	uint32_t pllreg = head ? NV_RAMDAC_VPLL2 : NV_PRAMDAC_VPLL_COEFF;
+
+	if (get_pll_limits(dev, head ? VPLL2 : VPLL1, &pll_lim))
+		return;
+	nouveau_hw_get_pllvals(dev, head ? VPLL2 : VPLL1, &pv);
+
+	if (pv.M1 >= pll_lim.vco1.min_m && pv.M1 <= pll_lim.vco1.max_m &&
+	    pv.N1 >= pll_lim.vco1.min_n && pv.N1 <= pll_lim.vco1.max_n &&
+	    pv.log2P <= pll_lim.max_log2p)
+		return;
+
+	NV_WARN(dev, "VPLL %d outwith limits, attempting to fix\n", head + 1);
+
+	/* set lowest clock within static limits */
+	pv.M1 = pll_lim.vco1.max_m;
+	pv.N1 = pll_lim.vco1.min_n;
+	pv.log2P = pll_lim.max_usable_log2p;
+	nouveau_hw_setpll(dev, pllreg, &pv);
+}
+
+/*
+ * vga font save/restore
+ */
+
+void
+nouveau_hw_save_vga_fonts(struct drm_device *dev, bool save)
+{
+	bool graphicsmode;
+	uint8_t misc, gr4, gr5, gr6, seq2, seq4;
+	int i;
+
+	NV_ERROR(dev, "FIXME saved_vga_font\n");
+	if (nv_two_heads(dev))
+		NVSetOwner(dev, 0);
+
+	NVSetEnablePalette(dev, 0, true);
+	graphicsmode = NVReadVgaAttr(dev, 0, NV_CIO_AR_MODE_INDEX) & 1;
+	NVSetEnablePalette(dev, 0, false);
+
+	if (graphicsmode)	/* graphics mode => framebuffer => no need to save */
+		return;
+
+	NV_INFO(dev, "%sing VGA fonts\n", save ? "Sav" : "Restor");
+	if (nv_two_heads(dev))
+		NVBlankScreen(dev, 1, true);
+	NVBlankScreen(dev, 0, true);
+
+	/* save control regs */
+	misc = NVReadPRMVIO(dev, 0, NV_PRMVIO_MISC__READ);
+	seq2 = NVReadVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX);
+	seq4 = NVReadVgaSeq(dev, 0, NV_VIO_SR_MEM_MODE_INDEX);
+	gr4 = NVReadVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX);
+	gr5 = NVReadVgaGr(dev, 0, NV_VIO_GX_MODE_INDEX);
+	gr6 = NVReadVgaGr(dev, 0, NV_VIO_GX_MISC_INDEX);
+
+	NVWritePRMVIO(dev, 0, NV_PRMVIO_MISC__WRITE, 0x67);
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_MEM_MODE_INDEX, 0x6);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_MODE_INDEX, 0x0);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_MISC_INDEX, 0x5);
+
+	/* store font in plane 0 */
+#if 0
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX, 0x1);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX, 0x0);
+	for (i = 0; i < 16384; i++)
+		if (save)
+			dev_priv->saved_vga_font[0][i] = nv_rf32(i * 4);
+		else
+			nv_wf32(i * 4, dev_priv->saved_vga_font[0][i]);
+
+	/* store font in plane 1 */
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX, 0x2);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX, 0x1);
+	for (i = 0; i < 16384; i++)
+		if (save)
+			dev_priv->saved_vga_font[1][i] = nv_rf32(i * 4);
+		else
+			nv_wf32(i * 4, dev_priv->saved_vga_font[1][i]);
+
+	/* store font in plane 2 */
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX, 0x4);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX, 0x2);
+	for (i = 0; i < 16384; i++)
+		if (save)
+			dev_priv->saved_vga_font[2][i] = nv_rf32(i * 4);
+		else
+			nv_wf32(i * 4, dev_priv->saved_vga_font[2][i]);
+
+	/* store font in plane 3 */
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX, 0x8);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX, 0x3);
+	for (i = 0; i < 16384; i++)
+		if (save)
+			dev_priv->saved_vga_font[3][i] = nv_rf32(i * 4);
+		else
+			nv_wf32(i * 4, dev_priv->saved_vga_font[3][i]);
+#endif
+
+	/* restore control regs */
+	NVWritePRMVIO(dev, 0, NV_PRMVIO_MISC__WRITE, misc);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_READ_MAP_INDEX, gr4);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_MODE_INDEX, gr5);
+	NVWriteVgaGr(dev, 0, NV_VIO_GX_MISC_INDEX, gr6);
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_PLANE_MASK_INDEX, seq2);
+	NVWriteVgaSeq(dev, 0, NV_VIO_SR_MEM_MODE_INDEX, seq4);
+
+	if (nv_two_heads(dev))
+		NVBlankScreen(dev, 1, false);
+	NVBlankScreen(dev, 0, false);
+}
+
+/*
+ * mode state save/load
+ */
+
+static void
+rd_cio_state(struct drm_device *dev, int head,
+	     struct nv04_crtc_reg *crtcstate, int index)
+{
+	crtcstate->CRTC[index] = NVReadVgaCrtc(dev, head, index);
+}
+
+static void
+wr_cio_state(struct drm_device *dev, int head,
+	     struct nv04_crtc_reg *crtcstate, int index)
+{
+	NVWriteVgaCrtc(dev, head, index, crtcstate->CRTC[index]);
+}
+
+static void
+nv_save_state_ramdac(struct drm_device *dev, int head,
+		     struct nv04_mode_state *state)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	int i;
+
+	if (nv_arch(dev) >= NV_10)
+		regp->nv10_cursync = NVReadRAMDAC(dev, head, NV_RAMDAC_NV10_CURSYNC);
+
+	nouveau_hw_get_pllvals(dev, head ? VPLL2 : VPLL1, &regp->pllvals);
+	state->pllsel = NVReadRAMDAC(dev, 0, NV_PRAMDAC_PLL_COEFF_SELECT);
+	if (nv_two_heads(dev))
+		state->sel_clk = NVReadRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK);
+	if (dev_priv->chipset == 0x11)
+		regp->dither = NVReadRAMDAC(dev, head, NV_RAMDAC_DITHER_NV11);
+
+	regp->ramdac_gen_ctrl = NVReadRAMDAC(dev, head, NV_PRAMDAC_GENERAL_CONTROL);
+
+	if (nv_gf4_disp_arch(dev))
+		regp->ramdac_630 = NVReadRAMDAC(dev, head, NV_PRAMDAC_630);
+	if (dev_priv->chipset >= 0x30)
+		regp->ramdac_634 = NVReadRAMDAC(dev, head, NV_PRAMDAC_634);
+
+	for (i = 0; i < 7; i++) {
+		uint32_t ramdac_reg = NV_PRAMDAC_FP_VDISPLAY_END + (i * 4);
+		regp->fp_vert_regs[i] = NVReadRAMDAC(dev, head, ramdac_reg);
+		regp->fp_horiz_regs[i] = NVReadRAMDAC(dev, head, ramdac_reg + 0x20);
+	}
+
+	if (nv_gf4_disp_arch(dev)) {
+		regp->dither = NVReadRAMDAC(dev, head, NV_RAMDAC_FP_DITHER);
+		for (i = 0; i < 3; i++) {
+			regp->dither_regs[i] = NVReadRAMDAC(dev, head, NV_PRAMDAC_850 + i * 4);
+			regp->dither_regs[i + 3] = NVReadRAMDAC(dev, head, NV_PRAMDAC_85C + i * 4);
+		}
+	}
+
+	regp->fp_control = NVReadRAMDAC(dev, head, NV_PRAMDAC_FP_TG_CONTROL);
+	regp->fp_debug_0 = NVReadRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_0);
+	if (!nv_gf4_disp_arch(dev) && head == 0) {
+		/* early chips don't allow access to PRAMDAC_TMDS_* without
+		 * the head A FPCLK on (nv11 even locks up) */
+		NVWriteRAMDAC(dev, 0, NV_PRAMDAC_FP_DEBUG_0, regp->fp_debug_0 &
+			      ~NV_PRAMDAC_FP_DEBUG_0_PWRDOWN_FPCLK);
+	}
+	regp->fp_debug_1 = NVReadRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_1);
+	regp->fp_debug_2 = NVReadRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_2);
+
+	if (nv_arch(dev) == NV_40) {
+		regp->ramdac_a20 = NVReadRAMDAC(dev, head, NV_PRAMDAC_A20);
+		regp->ramdac_a24 = NVReadRAMDAC(dev, head, NV_PRAMDAC_A24);
+		regp->ramdac_a34 = NVReadRAMDAC(dev, head, NV_PRAMDAC_A34);
+	}
+}
+
+static void
+nv_load_state_ramdac(struct drm_device *dev, int head,
+		     struct nv04_mode_state *state)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	uint32_t pllreg = head ? NV_RAMDAC_VPLL2 : NV_PRAMDAC_VPLL_COEFF;
+	int i;
+
+	if (nv_arch(dev) >= NV_10)
+		NVWriteRAMDAC(dev, head, NV_RAMDAC_NV10_CURSYNC, regp->nv10_cursync);
+
+	nouveau_hw_setpll(dev, pllreg, &regp->pllvals);
+	NVWriteRAMDAC(dev, 0, NV_PRAMDAC_PLL_COEFF_SELECT, state->pllsel);
+	if (nv_two_heads(dev))
+		NVWriteRAMDAC(dev, 0, NV_PRAMDAC_SEL_CLK, state->sel_clk);
+	if (dev_priv->chipset == 0x11)
+		NVWriteRAMDAC(dev, head, NV_RAMDAC_DITHER_NV11, regp->dither);
+
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_GENERAL_CONTROL, regp->ramdac_gen_ctrl);
+
+	if (nv_gf4_disp_arch(dev))
+		NVWriteRAMDAC(dev, head, NV_PRAMDAC_630, regp->ramdac_630);
+	if (dev_priv->chipset >= 0x30)
+		NVWriteRAMDAC(dev, head, NV_PRAMDAC_634, regp->ramdac_634);
+
+	for (i = 0; i < 7; i++) {
+		uint32_t ramdac_reg = NV_PRAMDAC_FP_VDISPLAY_END + (i * 4);
+
+		NVWriteRAMDAC(dev, head, ramdac_reg, regp->fp_vert_regs[i]);
+		NVWriteRAMDAC(dev, head, ramdac_reg + 0x20, regp->fp_horiz_regs[i]);
+	}
+
+	if (nv_gf4_disp_arch(dev)) {
+		NVWriteRAMDAC(dev, head, NV_RAMDAC_FP_DITHER, regp->dither);
+		for (i = 0; i < 3; i++) {
+			NVWriteRAMDAC(dev, head, NV_PRAMDAC_850 + i * 4, regp->dither_regs[i]);
+			NVWriteRAMDAC(dev, head, NV_PRAMDAC_85C + i * 4, regp->dither_regs[i + 3]);
+		}
+	}
+
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_FP_TG_CONTROL, regp->fp_control);
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_0, regp->fp_debug_0);
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_1, regp->fp_debug_1);
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_FP_DEBUG_2, regp->fp_debug_2);
+
+	if (nv_arch(dev) == NV_40) {
+		NVWriteRAMDAC(dev, head, NV_PRAMDAC_A20, regp->ramdac_a20);
+		NVWriteRAMDAC(dev, head, NV_PRAMDAC_A24, regp->ramdac_a24);
+		NVWriteRAMDAC(dev, head, NV_PRAMDAC_A34, regp->ramdac_a34);
+	}
+}
+
+static void
+nv_save_state_vga(struct drm_device *dev, int head,
+		  struct nv04_mode_state *state)
+{
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	int i;
+
+	regp->MiscOutReg = NVReadPRMVIO(dev, head, NV_PRMVIO_MISC__READ);
+
+	for (i = 0; i < 25; i++)
+		rd_cio_state(dev, head, regp, i);
+
+	NVSetEnablePalette(dev, head, true);
+	for (i = 0; i < 21; i++)
+		regp->Attribute[i] = NVReadVgaAttr(dev, head, i);
+	NVSetEnablePalette(dev, head, false);
+
+	for (i = 0; i < 9; i++)
+		regp->Graphics[i] = NVReadVgaGr(dev, head, i);
+
+	for (i = 0; i < 5; i++)
+		regp->Sequencer[i] = NVReadVgaSeq(dev, head, i);
+}
+
+static void
+nv_load_state_vga(struct drm_device *dev, int head,
+		  struct nv04_mode_state *state)
+{
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	int i;
+
+	NVWritePRMVIO(dev, head, NV_PRMVIO_MISC__WRITE, regp->MiscOutReg);
+
+	for (i = 0; i < 5; i++)
+		NVWriteVgaSeq(dev, head, i, regp->Sequencer[i]);
+
+	nv_lock_vga_crtc_base(dev, head, false);
+	for (i = 0; i < 25; i++)
+		wr_cio_state(dev, head, regp, i);
+	nv_lock_vga_crtc_base(dev, head, true);
+
+	for (i = 0; i < 9; i++)
+		NVWriteVgaGr(dev, head, i, regp->Graphics[i]);
+
+	NVSetEnablePalette(dev, head, true);
+	for (i = 0; i < 21; i++)
+		NVWriteVgaAttr(dev, head, i, regp->Attribute[i]);
+	NVSetEnablePalette(dev, head, false);
+}
+
+static void
+nv_save_state_ext(struct drm_device *dev, int head,
+		  struct nv04_mode_state *state)
+{
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	int i;
+
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_LCD__INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_RPC0_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_RPC1_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_LSR_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_PIXEL_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_HEB__INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_ENH_INDEX);
+
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_FF_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_FFLWM__INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_21);
+	if (nv_arch(dev) >= NV_30)
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_47);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR0_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR1_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR2_INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_ILACE__INDEX);
+
+	if (nv_arch(dev) >= NV_10) {
+		regp->crtc_830 = NVReadCRTC(dev, head, NV_PCRTC_830);
+		regp->crtc_834 = NVReadCRTC(dev, head, NV_PCRTC_834);
+		if (nv_arch(dev) == NV_40) {
+			regp->crtc_850 = NVReadCRTC(dev, head, NV_PCRTC_850);
+			regp->gpio_ext = NVReadCRTC(dev, head, NV_PCRTC_GPIO_EXT);
+		}
+		if (nv_two_heads(dev))
+			regp->crtc_eng_ctrl = NVReadCRTC(dev, head, NV_PCRTC_ENGINE_CTRL);
+		regp->cursor_cfg = NVReadCRTC(dev, head, NV_PCRTC_CURSOR_CONFIG);
+	}
+
+	regp->crtc_cfg = NVReadCRTC(dev, head, NV_PCRTC_CONFIG);
+
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_SCRATCH3__INDEX);
+	rd_cio_state(dev, head, regp, NV_CIO_CRE_SCRATCH4__INDEX);
+	if (nv_arch(dev) >= NV_10) {
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_EBR_INDEX);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_CSB);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_4B);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_TVOUT_LATENCY);
+	}
+	/* NV11 and NV20 don't have this, they stop at 0x52. */
+	if (nv_gf4_disp_arch(dev)) {
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_53);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_54);
+
+		for (i = 0; i < 0x10; i++)
+			regp->CR58[i] = NVReadVgaCrtc5758(dev, head, i);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_59);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_5B);
+
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_85);
+		rd_cio_state(dev, head, regp, NV_CIO_CRE_86);
+	}
+
+	regp->fb_start = NVReadCRTC(dev, head, NV_PCRTC_START);
+}
+
+static void
+nv_load_state_ext(struct drm_device *dev, int head,
+		  struct nv04_mode_state *state)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv04_crtc_reg * regp = &state->crtc_reg[head];
+	int i;
+
+	if (nv_arch(dev) >= NV_10) {
+		if (nv_two_heads(dev))
+			/* setting ENGINE_CTRL (EC) *must* come before
+			 * CIO_CRE_LCD, as writing CRE_LCD sets bits 16 & 17 in
+			 * EC that should not be overwritten by writing stale EC
+			 */
+			NVWriteCRTC(dev, head, NV_PCRTC_ENGINE_CTRL, regp->crtc_eng_ctrl);
+
+		nvWriteVIDEO(dev, NV_PVIDEO_STOP, 1);
+		nvWriteVIDEO(dev, NV_PVIDEO_INTR_EN, 0);
+		nvWriteVIDEO(dev, NV_PVIDEO_OFFSET_BUFF(0), 0);
+		nvWriteVIDEO(dev, NV_PVIDEO_OFFSET_BUFF(1), 0);
+		nvWriteVIDEO(dev, NV_PVIDEO_LIMIT(0), dev_priv->fb_available_size - 1);
+		nvWriteVIDEO(dev, NV_PVIDEO_LIMIT(1), dev_priv->fb_available_size - 1);
+		nvWriteVIDEO(dev, NV_PVIDEO_UVPLANE_LIMIT(0), dev_priv->fb_available_size - 1);
+		nvWriteVIDEO(dev, NV_PVIDEO_UVPLANE_LIMIT(1), dev_priv->fb_available_size - 1);
+		nvWriteMC(dev, NV_PBUS_POWERCTRL_2, 0);
+
+		NVWriteCRTC(dev, head, NV_PCRTC_CURSOR_CONFIG, regp->cursor_cfg);
+		NVWriteCRTC(dev, head, NV_PCRTC_830, regp->crtc_830);
+		NVWriteCRTC(dev, head, NV_PCRTC_834, regp->crtc_834);
+		if (nv_arch(dev) == NV_40) {
+			NVWriteCRTC(dev, head, NV_PCRTC_850, regp->crtc_850);
+			NVWriteCRTC(dev, head, NV_PCRTC_GPIO_EXT, regp->gpio_ext);
+		}
+
+		if (nv_arch(dev) == NV_40) {
+			uint32_t reg900 = NVReadRAMDAC(dev, head, NV_PRAMDAC_900);
+			if (regp->crtc_cfg == NV_PCRTC_CONFIG_START_ADDRESS_HSYNC)
+				NVWriteRAMDAC(dev, head, NV_PRAMDAC_900, reg900 | 0x10000);
+			else
+				NVWriteRAMDAC(dev, head, NV_PRAMDAC_900, reg900 & ~0x10000);
+		}
+	}
+
+	NVWriteCRTC(dev, head, NV_PCRTC_CONFIG, regp->crtc_cfg);
+
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_RPC0_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_RPC1_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_LSR_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_PIXEL_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_LCD__INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_HEB__INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_ENH_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_FF_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_FFLWM__INDEX);
+	if (nv_arch(dev) >= NV_30)
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_47);
+
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR0_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR1_INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_HCUR_ADDR2_INDEX);
+	if (nv_arch(dev) == NV_40)
+		nv_fix_nv40_hw_cursor(dev, head);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_ILACE__INDEX);
+
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_SCRATCH3__INDEX);
+	wr_cio_state(dev, head, regp, NV_CIO_CRE_SCRATCH4__INDEX);
+	if (nv_arch(dev) >= NV_10) {
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_EBR_INDEX);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_CSB);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_4B);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_TVOUT_LATENCY);
+	}
+	/* NV11 and NV20 stop at 0x52. */
+	if (nv_gf4_disp_arch(dev)) {
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_53);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_54);
+
+		for (i = 0; i < 0x10; i++)
+			NVWriteVgaCrtc5758(dev, head, i, regp->CR58[i]);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_59);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_5B);
+
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_85);
+		wr_cio_state(dev, head, regp, NV_CIO_CRE_86);
+	}
+
+	NVWriteCRTC(dev, head, NV_PCRTC_START, regp->fb_start);
+
+	/* Setting 1 on this value gives you interrupts for every vblank period. */
+	NVWriteCRTC(dev, head, NV_PCRTC_INTR_EN_0, 0);
+	NVWriteCRTC(dev, head, NV_PCRTC_INTR_0, NV_PCRTC_INTR_0_VBLANK);
+}
+
+static void
+nv_save_state_palette(struct drm_device *dev, int head,
+		      struct nv04_mode_state *state)
+{
+	int head_offset = head * NV_PRMDIO_SIZE, i;
+
+	nv_wr08(NV_PRMDIO_PIXEL_MASK + head_offset, NV_PRMDIO_PIXEL_MASK_MASK);
+	nv_wr08(NV_PRMDIO_READ_MODE_ADDRESS + head_offset, 0x0);
+
+	for (i = 0; i < 768; i++) {
+		state->crtc_reg[head].DAC[i] = nv_rd08(NV_PRMDIO_PALETTE_DATA + head_offset);
+	}
+
+	NVSetEnablePalette(dev, head, false);
+}
+
+void
+nouveau_hw_load_state_palette(struct drm_device *dev, int head,
+			      struct nv04_mode_state *state)
+{
+	int head_offset = head * NV_PRMDIO_SIZE, i;
+
+	nv_wr08(NV_PRMDIO_PIXEL_MASK + head_offset, NV_PRMDIO_PIXEL_MASK_MASK);
+	nv_wr08(NV_PRMDIO_WRITE_MODE_ADDRESS + head_offset, 0x0);
+
+	for (i = 0; i < 768; i++) {
+		nv_wr08(NV_PRMDIO_PALETTE_DATA + head_offset, state->crtc_reg[head].DAC[i]);
+	}
+
+	NVSetEnablePalette(dev, head, false);
+}
+
+void nouveau_hw_save_state(struct drm_device *dev, int head,
+			   struct nv04_mode_state *state)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->chipset == 0x11)
+		/* NB: no attempt is made to restore the bad pll later on */
+		nouveau_hw_fix_bad_vpll(dev, head);
+	nv_save_state_ramdac(dev, head, state);
+	nv_save_state_vga(dev, head, state);
+	nv_save_state_palette(dev, head, state);
+	nv_save_state_ext(dev, head, state);
+}
+
+void nouveau_hw_load_state(struct drm_device *dev, int head,
+			   struct nv04_mode_state *state)
+{
+	NVVgaProtect(dev, head, true);
+	nv_load_state_ramdac(dev, head, state);
+	nv_load_state_ext(dev, head, state);
+	nouveau_hw_load_state_palette(dev, head, state);
+	nv_load_state_vga(dev, head, state);
+	NVVgaProtect(dev, head, false);
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_hw.h b/drivers/gpu/drm/nouveau/nouveau_hw.h
new file mode 100644
index 0000000..03aa876
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_hw.h
@@ -0,0 +1,530 @@
+/*
+ * Copyright 2008 Stuart Bennett
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF
+ * OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef __NOUVEAU_HW_H__
+#define __NOUVEAU_HW_H__
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+
+#define MASK(field) ((0xffffffff >> (31 - ((1?field) - (0?field)))) << (0?field))
+#define XLATE(src, srclowbit, outfield) ((((src) >> (srclowbit)) << (0?outfield)) & MASK(outfield))
+
+struct nouveau_pll_vals {
+	union {
+		struct {
+#ifdef __BIG_ENDIAN
+			uint8_t N1, M1, N2, M2;
+#else
+			uint8_t M1, N1, M2, N2;
+#endif
+		};
+		struct {
+			uint16_t NM1, NM2;
+		} __attribute__((packed));
+	};
+	int log2P;
+
+	int refclk;
+};
+
+struct nv04_crtc_reg {
+	unsigned char MiscOutReg;     /* */
+	uint8_t CRTC[0x9f];
+	uint8_t CR58[0x10];
+	uint8_t Sequencer[5];
+	uint8_t Graphics[9];
+	uint8_t Attribute[21];
+	unsigned char DAC[768];       /* Internal Colorlookuptable */
+
+	/* PCRTC regs */
+	uint32_t fb_start;
+	uint32_t crtc_cfg;
+	uint32_t cursor_cfg;
+	uint32_t gpio_ext;
+	uint32_t crtc_830;
+	uint32_t crtc_834;
+	uint32_t crtc_850;
+	uint32_t crtc_eng_ctrl;
+
+	/* PRAMDAC regs */
+	uint32_t nv10_cursync;
+	struct nouveau_pll_vals pllvals;
+	uint32_t ramdac_gen_ctrl;
+	uint32_t ramdac_630;
+	uint32_t ramdac_634;
+	uint32_t fp_horiz_regs[7];
+	uint32_t fp_vert_regs[7];
+	uint32_t dither;
+	uint32_t fp_control;
+	uint32_t dither_regs[6];
+	uint32_t fp_debug_0;
+	uint32_t fp_debug_1;
+	uint32_t fp_debug_2;
+	uint32_t ramdac_a20;
+	uint32_t ramdac_a24;
+	uint32_t ramdac_a34;
+};
+
+struct nv04_output_reg {
+	uint32_t output;
+	int head;
+};
+
+struct nv04_mode_state {
+	uint32_t bpp;
+	uint32_t width;
+	uint32_t height;
+	uint32_t interlace;
+	uint32_t repaint0;
+	uint32_t repaint1;
+	uint32_t screen;
+	uint32_t scale;
+	uint32_t dither;
+	uint32_t extra;
+	uint32_t fifo;
+	uint32_t pixel;
+	uint32_t horiz;
+	int arbitration0;
+	int arbitration1;
+	uint32_t pll;
+	uint32_t pllB;
+	uint32_t vpll;
+	uint32_t vpll2;
+	uint32_t vpllB;
+	uint32_t vpll2B;
+	uint32_t pllsel;
+	uint32_t sel_clk;
+	uint32_t general;
+	uint32_t crtcOwner;
+	uint32_t head;
+	uint32_t head2;
+	uint32_t cursorConfig;
+	uint32_t cursor0;
+	uint32_t cursor1;
+	uint32_t cursor2;
+	uint32_t timingH;
+	uint32_t timingV;
+	uint32_t displayV;
+	uint32_t crtcSync;
+
+	struct nv04_crtc_reg crtc_reg[2];
+};
+
+void NVWriteVgaSeq(struct drm_device *, int head, uint8_t index, uint8_t value);
+uint8_t NVReadVgaSeq(struct drm_device *, int head, uint8_t index);
+void NVWriteVgaGr(struct drm_device *, int head, uint8_t index, uint8_t value);
+uint8_t NVReadVgaGr(struct drm_device *, int head, uint8_t index);
+void NVSetOwner(struct drm_device *, int owner);
+void NVBlankScreen(struct drm_device *, int head, bool blank);
+void nouveau_hw_setpll(struct drm_device *, uint32_t reg1,
+		       struct nouveau_pll_vals *pv);
+int nouveau_hw_get_pllvals(struct drm_device *, enum pll_types plltype,
+			   struct nouveau_pll_vals *pllvals);
+int nouveau_hw_pllvals_to_clk(struct nouveau_pll_vals *pllvals);
+int nouveau_hw_get_clock(struct drm_device *, enum pll_types plltype);
+void nouveau_hw_save_vga_fonts(struct drm_device *, bool save);
+void nouveau_hw_save_state(struct drm_device *, int head,
+			   struct nv04_mode_state *state);
+void nouveau_hw_load_state(struct drm_device *, int head,
+			   struct nv04_mode_state *state);
+void nouveau_hw_load_state_palette(struct drm_device *, int head,
+				   struct nv04_mode_state *state);
+
+/* nouveau_calc.c */
+extern void nouveau_calc_arb(struct drm_device *, int vclk, int bpp,
+			     int *burst, int *lwm);
+extern int nouveau_calc_pll_mnp(struct drm_device *, struct pll_lims *pll_lim,
+				int clk, struct nouveau_pll_vals *pv);
+
+static inline uint32_t
+nvReadMC(struct drm_device *dev, uint32_t reg)
+{
+	uint32_t val = nv_rd32(reg);
+	NV_DEBUG(dev, "nvReadMC: reg %08x val %08x\n", reg, val);
+	return val;
+}
+
+static inline void
+nvWriteMC(struct drm_device *dev, uint32_t reg, uint32_t val)
+{
+	NV_DEBUG(dev, "nvWriteMC: reg %08x val %08x\n", reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t
+nvReadVIDEO(struct drm_device *dev, uint32_t reg)
+{
+	uint32_t val = nv_rd32(reg);
+	NV_DEBUG(dev, "nvReadVIDEO: reg %08x val %08x\n", reg, val);
+	return val;
+}
+
+static inline void
+nvWriteVIDEO(struct drm_device *dev, uint32_t reg, uint32_t val)
+{
+	NV_DEBUG(dev, "nvWriteVIDEO: reg %08x val %08x\n", reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t
+nvReadFB(struct drm_device *dev, uint32_t reg)
+{
+	uint32_t val = nv_rd32(reg);
+	NV_DEBUG(dev, "nvReadFB: reg %08x val %08x\n", reg, val);
+	return val;
+}
+
+static inline void
+nvWriteFB(struct drm_device *dev, uint32_t reg, uint32_t val)
+{
+	NV_DEBUG(dev, "nvWriteFB: reg %08x val %08x\n", reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t
+nvReadEXTDEV(struct drm_device *dev, uint32_t reg)
+{
+	uint32_t val = nv_rd32(reg);
+	NV_DEBUG(dev, "nvReadEXTDEV: reg %08x val %08x\n", reg, val);
+	return val;
+}
+
+static inline void
+nvWriteEXTDEV(struct drm_device *dev, uint32_t reg, uint32_t val)
+{
+	NV_DEBUG(dev, "nvWriteEXTDEV: reg %08x val %08x\n", reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t NVRead(struct drm_device *dev, uint32_t reg)
+{
+	NV_DEBUG(dev, "NVRead: reg %08x val %08x\n", reg, (uint32_t)nv_rd32(reg));
+	return nv_rd32(reg);
+}
+
+static inline void NVWrite(struct drm_device *dev, uint32_t reg, uint32_t val)
+{
+	NV_DEBUG(dev, "NVWrite: reg %08x val %08x\n", reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t NVReadCRTC(struct drm_device *dev, int head, uint32_t reg)
+{
+	if (head)
+		reg += NV_PCRTC0_SIZE;
+	NV_DEBUG(dev, "NVReadCRTC: head %d reg %08x val %08x\n", head, reg, nv_rd32(reg));
+	return nv_rd32(reg);
+}
+
+static inline void NVWriteCRTC(struct drm_device *dev, int head, uint32_t reg, uint32_t val)
+{
+	if (head)
+		reg += NV_PCRTC0_SIZE;
+	NV_DEBUG(dev, "NVWriteCRTC: head %d reg %08x val %08x\n", head, reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint32_t NVReadRAMDAC(struct drm_device *dev, int head, uint32_t reg)
+{
+	if (head)
+		reg += NV_PRAMDAC0_SIZE;
+	NV_DEBUG(dev, "NVReadRamdac: head %d reg %08x val %08x\n", head, reg, nv_rd32(reg));
+	return nv_rd32(reg);
+}
+
+static inline void
+NVWriteRAMDAC(struct drm_device *dev, int head, uint32_t reg, uint32_t val)
+{
+	if (head)
+		reg += NV_PRAMDAC0_SIZE;
+	NV_DEBUG(dev, "NVWriteRamdac: head %d reg %08x val %08x\n", head, reg, val);
+	nv_wr32(reg, val);
+}
+
+static inline uint8_t nv_read_tmds(struct drm_device *dev, int or, int dl, uint8_t address)
+{
+	int ramdac = (or & OUTPUT_C) >> 2;
+
+	NVWriteRAMDAC(dev, ramdac, NV_PRAMDAC_FP_TMDS_CONTROL + dl * 8,
+	NV_PRAMDAC_FP_TMDS_CONTROL_WRITE_DISABLE | address);
+	return NVReadRAMDAC(dev, ramdac, NV_PRAMDAC_FP_TMDS_DATA + dl * 8);
+}
+
+static inline void
+nv_write_tmds(struct drm_device *dev, int or, int dl, uint8_t address, uint8_t data)
+{
+	int ramdac = (or & OUTPUT_C) >> 2;
+
+	NVWriteRAMDAC(dev, ramdac, NV_PRAMDAC_FP_TMDS_DATA + dl * 8, data);
+	NVWriteRAMDAC(dev, ramdac, NV_PRAMDAC_FP_TMDS_CONTROL + dl * 8, address);
+}
+
+static inline void
+NVWriteVgaCrtc(struct drm_device *dev, int head, uint8_t index, uint8_t value)
+{
+	NV_DEBUG(dev, "NVWriteVgaCrtc: head %d index 0x%02x data 0x%02x\n", head, index, value);
+	nv_wr08(NV_PRMCIO_CRX__COLOR + head * NV_PRMCIO_SIZE, index);
+	nv_wr08(NV_PRMCIO_CR__COLOR + head * NV_PRMCIO_SIZE, value);
+}
+
+static inline uint8_t NVReadVgaCrtc(struct drm_device *dev, int head, uint8_t index)
+{
+	nv_wr08(NV_PRMCIO_CRX__COLOR + head * NV_PRMCIO_SIZE, index);
+	NV_DEBUG(dev, "NVReadVgaCrtc: head %d index 0x%02x data 0x%02x\n", head, index, nv_rd08(NV_PRMCIO_CR__COLOR + head * NV_PRMCIO_SIZE));
+	return nv_rd08(NV_PRMCIO_CR__COLOR + head * NV_PRMCIO_SIZE);
+}
+
+/* CR57 and CR58 are a fun pair of regs. CR57 provides an index (0-0xf) for CR58
+ * I suspect they in fact do nothing, but are merely a way to carry useful
+ * per-head variables around
+ *
+ * Known uses:
+ * CR57		CR58
+ * 0x00		index to the appropriate dcb entry (or 7f for inactive)
+ * 0x02		dcb entry's "or" value (or 00 for inactive)
+ * 0x03		bit0 set for dual link (LVDS, possibly elsewhere too)
+ * 0x08 or 0x09	pxclk in MHz
+ * 0x0f		laptop panel info -	low nibble for PEXTDEV_BOOT_0 strap
+ * 					high nibble for xlat strap value
+ */
+
+static inline void
+NVWriteVgaCrtc5758(struct drm_device *dev, int head, uint8_t index, uint8_t value)
+{
+	NVWriteVgaCrtc(dev, head, NV_CIO_CRE_57, index);
+	NVWriteVgaCrtc(dev, head, NV_CIO_CRE_58, value);
+}
+
+static inline uint8_t NVReadVgaCrtc5758(struct drm_device *dev, int head, uint8_t index)
+{
+	NVWriteVgaCrtc(dev, head, NV_CIO_CRE_57, index);
+	return NVReadVgaCrtc(dev, head, NV_CIO_CRE_58);
+}
+
+static inline uint8_t NVReadPRMVIO(struct drm_device *dev, int head, uint32_t reg)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* Only NV4x have two pvio ranges; other twoHeads cards MUST call
+	 * NVSetOwner for the relevant head to be programmed */
+	if (head && dev_priv->card_type == NV_40)
+		reg += NV_PRMVIO_SIZE;
+
+	NV_DEBUG(dev, "NVReadPRMVIO: head %d reg %08x val %02x\n", head, reg, nv_rd08(reg));
+	return nv_rd08(reg);
+}
+
+static inline void
+NVWritePRMVIO(struct drm_device *dev, int head, uint32_t reg, uint8_t value)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* Only NV4x have two pvio ranges; other twoHeads cards MUST call
+	 * NVSetOwner for the relevant head to be programmed */
+	if (head && dev_priv->card_type == NV_40)
+		reg += NV_PRMVIO_SIZE;
+
+	NV_DEBUG(dev, "NVWritePRMVIO: head %d reg %08x val %02x\n", head, reg, value);
+	nv_wr08(reg, value);
+}
+
+static inline void NVSetEnablePalette(struct drm_device *dev, int head, bool enable)
+{
+	nv_rd08(NV_PRMCIO_INP0__COLOR + head * NV_PRMCIO_SIZE);
+	nv_wr08(NV_PRMCIO_ARX + head * NV_PRMCIO_SIZE, enable ? 0 : 0x20);
+}
+
+static inline bool NVGetEnablePalette(struct drm_device *dev, int head)
+{
+	nv_rd08(NV_PRMCIO_INP0__COLOR + head * NV_PRMCIO_SIZE);
+	return !(nv_rd08(NV_PRMCIO_ARX + head * NV_PRMCIO_SIZE) & 0x20);
+}
+
+static inline void NVWriteVgaAttr(struct drm_device *dev, int head, uint8_t index, uint8_t value)
+{
+	if (NVGetEnablePalette(dev, head))
+		index &= ~0x20;
+	else
+		index |= 0x20;
+
+	nv_rd08(NV_PRMCIO_INP0__COLOR + head * NV_PRMCIO_SIZE);
+	NV_DEBUG(dev, "NVWriteVgaAttr: head %d index 0x%02x data 0x%02x\n", head, index, value);
+	nv_wr08(NV_PRMCIO_ARX + head * NV_PRMCIO_SIZE, index);
+	nv_wr08(NV_PRMCIO_AR__WRITE + head * NV_PRMCIO_SIZE, value);
+}
+
+static inline uint8_t NVReadVgaAttr(struct drm_device *dev, int head, uint8_t index)
+{
+	if (NVGetEnablePalette(dev, head))
+		index &= ~0x20;
+	else
+		index |= 0x20;
+
+	nv_rd08(NV_PRMCIO_INP0__COLOR + head * NV_PRMCIO_SIZE);
+	nv_wr08(NV_PRMCIO_ARX + head * NV_PRMCIO_SIZE, index);
+	NV_DEBUG(dev, "NVReadVgaAttr: head %d index 0x%02x data 0x%02x\n", head, index, nv_rd08(NV_PRMCIO_AR__READ + head * NV_PRMCIO_SIZE));
+	return nv_rd08(NV_PRMCIO_AR__READ + head * NV_PRMCIO_SIZE);
+}
+
+static inline void NVVgaSeqReset(struct drm_device *dev, int head, bool start)
+{
+	NVWriteVgaSeq(dev, head, NV_VIO_SR_RESET_INDEX, start ? 0x1 : 0x3);
+}
+
+static inline void NVVgaProtect(struct drm_device *dev, int head, bool protect)
+{
+	uint8_t seq1 = NVReadVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX);
+
+	if (protect) {
+		NVVgaSeqReset(dev, head, true);
+		NVWriteVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX, seq1 | 0x20);
+	} else {
+		/* Reenable sequencer, then turn on screen */
+		NVWriteVgaSeq(dev, head, NV_VIO_SR_CLOCK_INDEX, seq1 & ~0x20);   /* reenable display */
+		NVVgaSeqReset(dev, head, false);
+	}
+	NVSetEnablePalette(dev, head, protect);
+}
+
+static inline bool
+nv_heads_tied(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->chipset == 0x11)
+		return !!(nvReadMC(dev, NV_PBUS_DEBUG_1) & (1 << 28));
+
+	return (NVReadVgaCrtc(dev, 0, NV_CIO_CRE_44) & 0x4);
+}
+
+/* makes cr0-7 on the specified head read-only */
+static inline bool
+nv_lock_vga_crtc_base(struct drm_device *dev, int head, bool lock)
+{
+	uint8_t cr11 = NVReadVgaCrtc(dev, head, NV_CIO_CR_VRE_INDEX);
+	bool waslocked = cr11 & 0x80;
+
+	if (lock)
+		cr11 |= 0x80;
+	else
+		cr11 &= ~0x80;
+	NVWriteVgaCrtc(dev, head, NV_CIO_CR_VRE_INDEX, cr11);
+
+	return waslocked;
+}
+
+static inline void
+nv_lock_vga_crtc_shadow(struct drm_device *dev, int head, int lock)
+{
+	/* shadow lock: connects 0x60?3d? regs to "real" 0x3d? regs
+         * bit7: unlocks HDT, HBS, HBE, HRS, HRE, HEB
+         * bit6: seems to have some effect on CR09 (double scan, VBS_9)
+         * bit5: unlocks HDE
+         * bit4: unlocks VDE
+         * bit3: unlocks VDT, OVL, VRS, ?VRE?, VBS, VBE, LSR, EBR
+         * bit2: same as bit 1 of 0x60?804
+         * bit0: same as bit 0 of 0x60?804
+         */
+
+	uint8_t cr21 = lock;
+
+	if (lock < 0)
+		/* 0xfa is generic "unlock all" mask */
+		cr21 = NVReadVgaCrtc(dev, head, NV_CIO_CRE_21) | 0xfa;
+
+	NVWriteVgaCrtc(dev, head, NV_CIO_CRE_21, cr21);
+}
+
+/* renders the extended crtc regs (cr19+) on all crtcs impervious:
+ * immutable and unreadable
+ */
+static inline bool
+NVLockVgaCrtcs(struct drm_device *dev, bool lock)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	bool waslocked = !NVReadVgaCrtc(dev, 0, NV_CIO_SR_LOCK_INDEX);
+
+	NVWriteVgaCrtc(dev, 0, NV_CIO_SR_LOCK_INDEX,
+		       lock ? NV_CIO_SR_LOCK_VALUE : NV_CIO_SR_UNLOCK_RW_VALUE);
+	/* NV11 has independently lockable extended crtcs, except when tied */
+	if (dev_priv->chipset == 0x11 && !nv_heads_tied(dev))
+		NVWriteVgaCrtc(dev, 1, NV_CIO_SR_LOCK_INDEX,
+			       lock ? NV_CIO_SR_LOCK_VALUE :
+				      NV_CIO_SR_UNLOCK_RW_VALUE);
+
+	return waslocked;
+}
+
+static inline void
+nv_fix_nv40_hw_cursor(struct drm_device *dev, int head)
+{
+	/* on some nv40 (such as the "true" (in the NV_PFB_BOOT_0 sense) nv40,
+	 * the gf6800gt) a hardware bug requires a write to PRAMDAC_CURSOR_POS
+	 * for changes to the CRTC CURCTL regs to take effect, whether changing
+	 * the pixmap location, or just showing/hiding the cursor
+	 */
+	volatile uint32_t curpos = NVReadRAMDAC(dev, head,
+						NV_PRAMDAC_CU_START_POS);
+	NVWriteRAMDAC(dev, head, NV_PRAMDAC_CU_START_POS, curpos);
+}
+
+static inline void
+nv_show_cursor(struct drm_device *dev, int head, bool show)
+{
+	NV_ERROR(dev, "FIXME ModeReg\n");
+#if 0
+	uint8_t *curctl1 =
+		&pNv->ModeReg.crtc_reg[head].CRTC[NV_CIO_CRE_HCUR_ADDR1_INDEX];
+
+	if (show)
+		*curctl1 |= MASK(NV_CIO_CRE_HCUR_ADDR1_ENABLE);
+	else
+		*curctl1 &= ~MASK(NV_CIO_CRE_HCUR_ADDR1_ENABLE);
+	NVWriteVgaCrtc(dev, head, NV_CIO_CRE_HCUR_ADDR1_INDEX, *curctl1);
+
+	if (dev_priv->card_type == NV_40)
+		nv_fix_nv40_hw_cursor(dev, head);
+#endif
+}
+
+static inline uint32_t
+nv_pitch_align(struct drm_device *dev, uint32_t width, int bpp)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int mask;
+
+	if (bpp == 15)
+		bpp = 16;
+	if (bpp == 24)
+		bpp = 8;
+
+	/* Alignment requirements taken from the Haiku driver */
+	if (dev_priv->card_type == NV_04)
+		mask = 128 / bpp - 1;
+	else
+		mask = 512 / bpp - 1;
+
+	return (width + mask) & ~mask;
+}
+
+#endif	/* __NOUVEAU_HW_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_i2c.c b/drivers/gpu/drm/nouveau/nouveau_i2c.c
new file mode 100644
index 0000000..93cdc61
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_i2c.c
@@ -0,0 +1,222 @@
+/*
+ * Copyright 2009 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_i2c.h"
+#include "nouveau_hw.h"
+
+static void
+nv04_i2c_setscl(void *data, int state)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+	uint8_t val;
+
+	val = (NVReadVgaCrtc(dev, 0, i2c->wr) & 0xd0) | (state ? 0x20 : 0);
+	NVWriteVgaCrtc(dev, 0, i2c->wr, val | 0x01);
+}
+
+static void
+nv04_i2c_setsda(void *data, int state)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+	uint8_t val;
+		
+	val = (NVReadVgaCrtc(dev, 0, i2c->wr) & 0xe0) | (state ? 0x10 : 0);
+	NVWriteVgaCrtc(dev, 0, i2c->wr, val | 0x01);
+}
+
+static int
+nv04_i2c_getscl(void *data)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	return !!(NVReadVgaCrtc(dev, 0, i2c->rd) & 4);
+}
+
+static int
+nv04_i2c_getsda(void *data)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	return !!(NVReadVgaCrtc(dev, 0, i2c->rd) & 8);
+}
+
+static int
+nv50_i2c_getscl(void *data)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	return !!(nv_rd32(i2c->rd) & 1);
+}
+
+
+static int
+nv50_i2c_getsda(void *data)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	return !!(nv_rd32(i2c->rd) & 2);
+}
+
+static void
+nv50_i2c_setscl(void *data, int state)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	nv_wr32(i2c->wr, 4 | (i2c->data ? 2 : 0) | (state ? 1 : 0));
+}
+
+static void
+nv50_i2c_setsda(void *data, int state)
+{
+	struct nouveau_i2c_chan *i2c = data;
+	struct drm_device *dev = i2c->dev;
+
+	nv_wr32(i2c->wr, (nv_rd32(i2c->rd) & 1) | 4 | (state ? 2 : 0));
+	i2c->data = state;
+}
+
+int
+nouveau_i2c_new(struct drm_device *dev, const char *name, unsigned index,
+		struct nouveau_i2c_chan **pi2c)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct dcb_i2c_entry *dcbi2c = &dev_priv->vbios->dcb->i2c[index];
+	struct nouveau_i2c_chan *i2c;
+	int ret;
+
+	if (dcbi2c->chan) {
+		*pi2c = dcbi2c->chan;
+		return 0;
+	}
+
+	i2c = drm_calloc(1, sizeof(*i2c), DRM_MEM_DRIVER);
+	if (i2c == NULL)
+		return -ENOMEM;
+
+	snprintf(i2c->adapter.name, I2C_NAME_SIZE, "nouveau %s", name);
+	i2c->adapter.owner = THIS_MODULE;
+	i2c->adapter.algo_data = &i2c->algo;
+	i2c->dev = dev;
+
+	switch (dcbi2c->port_type) {
+	case 0:
+	case 4:
+		i2c->algo.setsda = nv04_i2c_setsda;
+		i2c->algo.setscl = nv04_i2c_setscl;
+		i2c->algo.getsda = nv04_i2c_getsda;
+		i2c->algo.getscl = nv04_i2c_getscl;
+		i2c->rd = dcbi2c->read;
+		i2c->wr = dcbi2c->write;
+		break;
+	case 5:
+		i2c->algo.setsda = nv50_i2c_setsda;
+		i2c->algo.setscl = nv50_i2c_setscl;
+		i2c->algo.getsda = nv50_i2c_getsda;
+		i2c->algo.getscl = nv50_i2c_getscl;
+		/* not 100% convinced this is correct everywhere, but
+		 * the best guess so far..
+		 */
+		if (dcbi2c->read <= 3)
+			i2c->rd = 0xe138 + (dcbi2c->read * 24);
+		else
+		if (dev_priv->chipset < 0x90)
+			i2c->rd = 0xe1e0 + (dcbi2c->read * 24);
+		else
+			i2c->rd = 0xe1d4 + (dcbi2c->read * 32);
+		i2c->wr = i2c->rd;
+		break;
+	default:
+		NV_ERROR(dev, "DCB I2C port type %d unknown\n",
+			 dcbi2c->port_type);
+		drm_free(i2c, sizeof(*i2c), DRM_MEM_DRIVER);
+		return -EINVAL;
+	}
+	i2c->algo.udelay = 20;
+	i2c->algo.timeout = usecs_to_jiffies(2200);
+	i2c->algo.data = i2c;
+
+	i2c_set_adapdata(&i2c->adapter, i2c);
+
+	ret = i2c_bit_add_bus(&i2c->adapter);
+	if (ret) {
+		NV_ERROR(dev, "Failed to register i2c %s\n", name);
+		drm_free(i2c, sizeof(*i2c), DRM_MEM_DRIVER);
+		return ret;
+	}
+
+	*pi2c = dcbi2c->chan = i2c;
+	return 0;
+
+}
+
+void
+nouveau_i2c_del(struct nouveau_i2c_chan **pi2c)
+{
+	struct nouveau_i2c_chan *i2c = *pi2c;
+
+	if (!i2c)
+		return;
+
+	*pi2c = NULL;
+	i2c_del_adapter(&i2c->adapter);
+	drm_free(i2c, sizeof(*i2c), DRM_MEM_DRIVER);
+}
+
+bool
+nouveau_i2c_detect(struct nouveau_connector *connector)
+{
+	/* kindly borrrowed from the intel driver, hope it works. */
+	uint8_t out_buf[] = { 0x0, 0x0};
+	uint8_t buf[2];
+	bool ret;
+	struct i2c_msg msgs[] = {
+		{
+			.addr = 0x50,
+			.flags = 0,
+			.len = 1,
+			.buf = out_buf,
+		},
+		{
+			.addr = 0x50,
+			.flags = I2C_M_RD,
+			.len = 1,
+			.buf = buf,
+		}
+	};
+
+	if (!connector->i2c_chan)
+		return false;
+
+	ret = (i2c_transfer(&connector->i2c_chan->adapter, msgs, 2) == 2);
+	return ret;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_i2c.h b/drivers/gpu/drm/nouveau/nouveau_i2c.h
new file mode 100644
index 0000000..70b1a54
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_i2c.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright 2009 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __NOUVEAU_I2C_H__
+#define __NOUVEAU_I2C_H__
+
+#include <linux/i2c.h>
+#include <linux/i2c-id.h>
+#include <linux/i2c-algo-bit.h>
+
+#include "nouveau_connector.h"
+
+struct nouveau_i2c_chan {
+	struct drm_device *dev;
+	struct i2c_adapter adapter;
+	struct i2c_algo_bit_data algo;
+	unsigned rd;
+	unsigned wr;
+	unsigned data;
+};
+
+int nouveau_i2c_new(struct drm_device *, const char *, unsigned,
+		    struct nouveau_i2c_chan **);
+void nouveau_i2c_del(struct nouveau_i2c_chan **);
+bool nouveau_i2c_detect(struct nouveau_connector *connector);
+
+#endif /* __NOUVEAU_I2C_H__ */
diff --git a/drivers/gpu/drm/nouveau/nouveau_ioc32.c b/drivers/gpu/drm/nouveau/nouveau_ioc32.c
new file mode 100644
index 0000000..f55ae7a
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_ioc32.c
@@ -0,0 +1,72 @@
+/**
+ * \file mga_ioc32.c
+ *
+ * 32-bit ioctl compatibility routines for the MGA DRM.
+ *
+ * \author Dave Airlie <airlied@linux.ie> with code from patches by Egbert Eich
+ *
+ *
+ * Copyright (C) Paul Mackerras 2005
+ * Copyright (C) Egbert Eich 2003,2004
+ * Copyright (C) Dave Airlie 2005
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+#include <linux/compat.h>
+
+#include "drmP.h"
+#include "drm.h"
+
+#include "nouveau_drm.h"
+
+/**
+ * Called whenever a 32-bit process running under a 64-bit kernel
+ * performs an ioctl on /dev/dri/card<n>.
+ *
+ * \param filp file pointer.
+ * \param cmd command.
+ * \param arg user argument.
+ * \return zero on success or negative number on failure.
+ */
+long nouveau_compat_ioctl(struct file *filp, unsigned int cmd,
+			 unsigned long arg)
+{
+	unsigned int nr = DRM_IOCTL_NR(cmd);
+	drm_ioctl_compat_t *fn = NULL;
+	int ret;
+
+	if (nr < DRM_COMMAND_BASE)
+		return drm_compat_ioctl(filp, cmd, arg);
+
+#if 0
+	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(mga_compat_ioctls))
+		fn = nouveau_compat_ioctls[nr - DRM_COMMAND_BASE];
+#endif
+	lock_kernel();	  /* XXX for now */
+	if (fn != NULL)
+		ret = (*fn)(filp, cmd, arg);
+	else
+		ret = drm_ioctl(filp->f_dentry->d_inode, filp, cmd, arg);
+	unlock_kernel();
+
+	return ret;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_irq.c b/drivers/gpu/drm/nouveau/nouveau_irq.c
new file mode 100644
index 0000000..c3ad906
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_irq.c
@@ -0,0 +1,592 @@
+/*
+ * Copyright (C) 2006 Ben Skeggs.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/*
+ * Authors:
+ *   Ben Skeggs <darktama@iinet.net.au>
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_reg.h"
+#include "nouveau_swmthd.h"
+
+/* needed for hotplug irq */
+#include "nouveau_connector.h"
+
+void
+nouveau_irq_preinstall(struct drm_device *dev)
+{
+	/* Master disable */
+	nv_wr32(NV03_PMC_INTR_EN_0, 0);
+}
+
+int
+nouveau_irq_postinstall(struct drm_device *dev)
+{
+	/* Master enable */
+	nv_wr32(NV03_PMC_INTR_EN_0, NV_PMC_INTR_EN_0_MASTER_ENABLE);
+	return 0;
+}
+
+void
+nouveau_irq_uninstall(struct drm_device *dev)
+{
+	/* Master disable */
+	nv_wr32(NV03_PMC_INTR_EN_0, 0);
+}
+
+static void
+nouveau_fifo_irq_handler(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	uint32_t status, reassign;
+
+	reassign = nv_rd32(NV03_PFIFO_CACHES) & 1;
+	while ((status = nv_rd32(NV03_PFIFO_INTR_0))) {
+		uint32_t chid, get;
+
+		nv_wr32(NV03_PFIFO_CACHES, 0);
+
+		chid = engine->fifo.channel_id(dev);
+		get  = nv_rd32(NV03_PFIFO_CACHE1_GET);
+
+		if (status & NV_PFIFO_INTR_CACHE_ERROR) {
+			uint32_t mthd, data;
+			int ptr;
+
+			ptr = get >> 2;
+			if (dev_priv->card_type < NV_40) {
+				mthd = nv_rd32(NV04_PFIFO_CACHE1_METHOD(ptr));
+				data = nv_rd32(NV04_PFIFO_CACHE1_DATA(ptr));
+			} else {
+				mthd = nv_rd32(NV40_PFIFO_CACHE1_METHOD(ptr));
+				data = nv_rd32(NV40_PFIFO_CACHE1_DATA(ptr));
+			}
+
+			NV_INFO(dev, "PFIFO_CACHE_ERROR - "
+				     "Ch %d/%d Mthd 0x%04x Data 0x%08x\n",
+				chid, (mthd >> 13) & 7, mthd & 0x1ffc, data);
+
+			nv_wr32(NV03_PFIFO_CACHE1_GET, get + 4);
+			nv_wr32(NV04_PFIFO_CACHE1_PULL0, 1);
+
+			status &= ~NV_PFIFO_INTR_CACHE_ERROR;
+			nv_wr32(NV03_PFIFO_INTR_0, NV_PFIFO_INTR_CACHE_ERROR);
+		}
+
+		if (status & NV_PFIFO_INTR_DMA_PUSHER) {
+			NV_INFO(dev, "PFIFO_DMA_PUSHER - Ch %d\n", chid);
+
+			status &= ~NV_PFIFO_INTR_DMA_PUSHER;
+			nv_wr32(NV03_PFIFO_INTR_0, NV_PFIFO_INTR_DMA_PUSHER);
+
+			nv_wr32(NV04_PFIFO_CACHE1_DMA_STATE, 0x00000000);
+			if (nv_rd32(NV04_PFIFO_CACHE1_DMA_PUT) != get)
+				nv_wr32(NV04_PFIFO_CACHE1_DMA_GET, get + 4);
+		}
+
+		if (status) {
+			NV_INFO(dev, "Unhandled PFIFO_INTR - 0x%08x\n", status);
+			nv_wr32(NV03_PFIFO_INTR_0, status);
+			nv_wr32(NV03_PMC_INTR_EN_0, 0);
+		}
+
+		nv_wr32(NV03_PFIFO_CACHES, reassign);
+	}
+
+	nv_wr32(NV03_PMC_INTR_0, NV_PMC_INTR_0_PFIFO_PENDING);
+}
+
+struct nouveau_bitfield_names {
+	uint32_t mask;
+	const char * name;
+};
+
+static struct nouveau_bitfield_names nouveau_nstatus_names[] =
+{
+	{ NV04_PGRAPH_NSTATUS_STATE_IN_USE,       "STATE_IN_USE" },
+	{ NV04_PGRAPH_NSTATUS_INVALID_STATE,      "INVALID_STATE" },
+	{ NV04_PGRAPH_NSTATUS_BAD_ARGUMENT,       "BAD_ARGUMENT" },
+	{ NV04_PGRAPH_NSTATUS_PROTECTION_FAULT,   "PROTECTION_FAULT" }
+};
+
+static struct nouveau_bitfield_names nouveau_nstatus_names_nv10[] =
+{
+	{ NV10_PGRAPH_NSTATUS_STATE_IN_USE,       "STATE_IN_USE" },
+	{ NV10_PGRAPH_NSTATUS_INVALID_STATE,      "INVALID_STATE" },
+	{ NV10_PGRAPH_NSTATUS_BAD_ARGUMENT,       "BAD_ARGUMENT" },
+	{ NV10_PGRAPH_NSTATUS_PROTECTION_FAULT,   "PROTECTION_FAULT" }
+};
+
+static struct nouveau_bitfield_names nouveau_nsource_names[] =
+{
+	{ NV03_PGRAPH_NSOURCE_NOTIFICATION,       "NOTIFICATION" },
+	{ NV03_PGRAPH_NSOURCE_DATA_ERROR,         "DATA_ERROR" },
+	{ NV03_PGRAPH_NSOURCE_PROTECTION_ERROR,   "PROTECTION_ERROR" },
+	{ NV03_PGRAPH_NSOURCE_RANGE_EXCEPTION,    "RANGE_EXCEPTION" },
+	{ NV03_PGRAPH_NSOURCE_LIMIT_COLOR,        "LIMIT_COLOR" },
+	{ NV03_PGRAPH_NSOURCE_LIMIT_ZETA,         "LIMIT_ZETA" },
+	{ NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD,       "ILLEGAL_MTHD" },
+	{ NV03_PGRAPH_NSOURCE_DMA_R_PROTECTION,   "DMA_R_PROTECTION" },
+	{ NV03_PGRAPH_NSOURCE_DMA_W_PROTECTION,   "DMA_W_PROTECTION" },
+	{ NV03_PGRAPH_NSOURCE_FORMAT_EXCEPTION,   "FORMAT_EXCEPTION" },
+	{ NV03_PGRAPH_NSOURCE_PATCH_EXCEPTION,    "PATCH_EXCEPTION" },
+	{ NV03_PGRAPH_NSOURCE_STATE_INVALID,      "STATE_INVALID" },
+	{ NV03_PGRAPH_NSOURCE_DOUBLE_NOTIFY,      "DOUBLE_NOTIFY" },
+	{ NV03_PGRAPH_NSOURCE_NOTIFY_IN_USE,      "NOTIFY_IN_USE" },
+	{ NV03_PGRAPH_NSOURCE_METHOD_CNT,         "METHOD_CNT" },
+	{ NV03_PGRAPH_NSOURCE_BFR_NOTIFICATION,   "BFR_NOTIFICATION" },
+	{ NV03_PGRAPH_NSOURCE_DMA_VTX_PROTECTION, "DMA_VTX_PROTECTION" },
+	{ NV03_PGRAPH_NSOURCE_DMA_WIDTH_A,        "DMA_WIDTH_A" },
+	{ NV03_PGRAPH_NSOURCE_DMA_WIDTH_B,        "DMA_WIDTH_B" },
+};
+
+static void
+nouveau_print_bitfield_names(uint32_t value,
+                             const struct nouveau_bitfield_names *namelist,
+                             const int namelist_len)
+{
+	int i;
+	for(i=0; i<namelist_len; ++i) {
+		uint32_t mask = namelist[i].mask;
+		if(value & mask) {
+			printk(" %s", namelist[i].name);
+			value &= ~mask;
+		}
+	}
+	if(value)
+		printk(" (unknown bits 0x%08x)", value);
+}
+
+static int
+nouveau_graph_chid_from_grctx(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t inst, tmp;
+	int i;
+
+	if (dev_priv->card_type < NV_40)
+		return dev_priv->engine.fifo.channels;
+	else
+	if (dev_priv->card_type < NV_50)
+		inst = (nv_rd32(0x40032c) & 0xfffff) << 4;
+	else
+		inst = nv_rd32(0x40032c) & 0xfffff;
+
+	for (i = 0; i < dev_priv->engine.fifo.channels; i++) {
+		struct nouveau_channel *chan = dev_priv->fifos[i];
+
+		if (!chan || !chan->ramin_grctx)
+			continue;
+
+		if (dev_priv->card_type < NV_50) {
+			if (inst == chan->ramin_grctx->instance)
+				break;
+		} else {
+			dev_priv->engine.instmem.prepare_access(dev, false);
+			tmp = INSTANCE_RD(chan->ramin_grctx->gpuobj, 0);
+			dev_priv->engine.instmem.finish_access(dev);
+
+			if (inst == tmp)
+				break;
+		}
+	}
+
+	return i;
+}
+
+static int
+nouveau_graph_trapped_channel(struct drm_device *dev, int *channel_ret)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	int channel;
+
+	if (dev_priv->card_type < NV_10)
+		channel = (nv_rd32(NV04_PGRAPH_TRAPPED_ADDR) >> 24) & 0xf;
+	else
+	if (dev_priv->card_type < NV_40)
+		channel = (nv_rd32(NV04_PGRAPH_TRAPPED_ADDR) >> 20) & 0x1f;
+	else
+		channel = nouveau_graph_chid_from_grctx(dev);
+
+	if (channel >= engine->fifo.channels || !dev_priv->fifos[channel]) {
+		NV_ERROR(dev, "AIII, invalid/inactive channel id %d\n", channel);
+		return -EINVAL;
+	}
+
+	*channel_ret = channel;
+	return 0;
+}
+
+struct nouveau_pgraph_trap {
+	int channel;
+	int class;
+	int subc, mthd, size;
+	uint32_t data, data2;
+	uint32_t nsource, nstatus;
+};
+
+static void
+nouveau_graph_trap_info(struct drm_device *dev,
+			struct nouveau_pgraph_trap *trap)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t address;
+
+	trap->nsource = trap->nstatus = 0;
+	if (dev_priv->card_type < NV_50) {
+		trap->nsource = nv_rd32(NV03_PGRAPH_NSOURCE);
+		trap->nstatus = nv_rd32(NV03_PGRAPH_NSTATUS);
+	}
+
+	if (nouveau_graph_trapped_channel(dev, &trap->channel))
+		trap->channel = -1;
+	address = nv_rd32(NV04_PGRAPH_TRAPPED_ADDR);
+
+	trap->mthd = address & 0x1FFC;
+	trap->data = nv_rd32(NV04_PGRAPH_TRAPPED_DATA);
+	if (dev_priv->card_type < NV_10) {
+		trap->subc  = (address >> 13) & 0x7;
+	} else {
+		trap->subc  = (address >> 16) & 0x7;
+		trap->data2 = nv_rd32(NV10_PGRAPH_TRAPPED_DATA_HIGH);
+	}
+
+	if (dev_priv->card_type < NV_10) {
+		trap->class = nv_rd32(0x400180 + trap->subc*4) & 0xFF;
+	} else if (dev_priv->card_type < NV_40) {
+		trap->class = nv_rd32(0x400160 + trap->subc*4) & 0xFFF;
+	} else if (dev_priv->card_type < NV_50) {
+		trap->class = nv_rd32(0x400160 + trap->subc*4) & 0xFFFF;
+	} else {
+		trap->class = nv_rd32(0x400814);
+	}
+}
+
+static void
+nouveau_graph_dump_trap_info(struct drm_device *dev, const char *id,
+			     struct nouveau_pgraph_trap *trap)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t nsource = trap->nsource, nstatus = trap->nstatus;
+
+	NV_INFO(dev, "%s - nSource:", id);
+	nouveau_print_bitfield_names(nsource, nouveau_nsource_names,
+	                             ARRAY_SIZE(nouveau_nsource_names));
+	printk(", nStatus:");
+	if (dev_priv->card_type < NV_10)
+		nouveau_print_bitfield_names(nstatus, nouveau_nstatus_names,
+	                             ARRAY_SIZE(nouveau_nstatus_names));
+	else
+		nouveau_print_bitfield_names(nstatus, nouveau_nstatus_names_nv10,
+	                             ARRAY_SIZE(nouveau_nstatus_names_nv10));
+	printk("\n");
+
+	NV_INFO(dev, "%s - Ch %d/%d Class 0x%04x Mthd 0x%04x Data 0x%08x:0x%08x\n",
+		 id, trap->channel, trap->subc, trap->class, trap->mthd,
+		 trap->data2, trap->data);
+}
+
+static inline void
+nouveau_pgraph_intr_notify(struct drm_device *dev, uint32_t nsource)
+{
+	struct nouveau_pgraph_trap trap;
+	int unhandled = 0;
+
+	nouveau_graph_trap_info(dev, &trap);
+
+	if (nsource & NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD) {
+		/* NV4 (nvidia TNT 1) reports software methods with
+		 * PGRAPH NOTIFY ILLEGAL_MTHD
+		 */
+		NV_DEBUG(dev, "Got NV04 software method method %x for class %#x\n",
+			  trap.mthd, trap.class);
+
+		if (nouveau_sw_method_execute(dev, trap.class, trap.mthd)) {
+			NV_ERROR(dev, "Unable to execute NV04 software method "
+				       "%x for class %x. Please report.\n",
+				 trap.mthd, trap.class);
+			unhandled = 1;
+		}
+	} else {
+		unhandled = 1;
+	}
+
+	if (unhandled)
+		nouveau_graph_dump_trap_info(dev, "PGRAPH_NOTIFY", &trap);
+}
+
+static inline void
+nouveau_pgraph_intr_error(struct drm_device *dev, uint32_t nsource)
+{
+	struct nouveau_pgraph_trap trap;
+	int unhandled = 0;
+
+	nouveau_graph_trap_info(dev, &trap);
+	trap.nsource = nsource;
+
+	if (nsource & NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD) {
+		if (trap.channel >= 0 && trap.mthd == 0x0150) {
+			nouveau_fence_handler(dev, trap.channel);
+		} else
+		if (nouveau_sw_method_execute(dev, trap.class, trap.mthd)) {
+			unhandled = 1;
+		}
+	} else {
+		unhandled = 1;
+	}
+
+	if (unhandled)
+		nouveau_graph_dump_trap_info(dev, "PGRAPH_ERROR", &trap);
+}
+
+static inline void
+nouveau_pgraph_intr_context_switch(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	uint32_t chid;
+
+	chid = engine->fifo.channel_id(dev);
+	NV_DEBUG(dev, "PGRAPH context switch interrupt channel %x\n", chid);
+
+	switch(dev_priv->card_type) {
+	case NV_04:
+	case NV_05:
+		nouveau_nv04_context_switch(dev);
+		break;
+	case NV_10:
+	case NV_11:
+	case NV_17:
+		nouveau_nv10_context_switch(dev);
+		break;
+	default:
+		NV_ERROR(dev, "Context switch not implemented\n");
+		break;
+	}
+}
+
+static void
+nouveau_pgraph_irq_handler(struct drm_device *dev)
+{
+	uint32_t status;
+
+	while ((status = nv_rd32(NV03_PGRAPH_INTR))) {
+		uint32_t nsource = nv_rd32(NV03_PGRAPH_NSOURCE);
+
+		if (status & NV_PGRAPH_INTR_NOTIFY) {
+			nouveau_pgraph_intr_notify(dev, nsource);
+
+			status &= ~NV_PGRAPH_INTR_NOTIFY;
+			nv_wr32(NV03_PGRAPH_INTR, NV_PGRAPH_INTR_NOTIFY);
+		}
+
+		if (status & NV_PGRAPH_INTR_ERROR) {
+			nouveau_pgraph_intr_error(dev, nsource);
+
+			status &= ~NV_PGRAPH_INTR_ERROR;
+			nv_wr32(NV03_PGRAPH_INTR, NV_PGRAPH_INTR_ERROR);
+		}
+
+		if (status & NV_PGRAPH_INTR_CONTEXT_SWITCH) {
+			nouveau_pgraph_intr_context_switch(dev);
+
+			status &= ~NV_PGRAPH_INTR_CONTEXT_SWITCH;
+			nv_wr32(NV03_PGRAPH_INTR,
+				 NV_PGRAPH_INTR_CONTEXT_SWITCH);
+		}
+
+		if (status) {
+			NV_INFO(dev, "Unhandled PGRAPH_INTR - 0x%08x\n", status);
+			nv_wr32(NV03_PGRAPH_INTR, status);
+		}
+
+		if ((nv_rd32(NV04_PGRAPH_FIFO) & (1 << 0)) == 0)
+			nv_wr32(NV04_PGRAPH_FIFO, 1);
+	}
+
+	nv_wr32(NV03_PMC_INTR_0, NV_PMC_INTR_0_PGRAPH_PENDING);
+}
+
+static void
+nv50_pgraph_irq_handler(struct drm_device *dev)
+{
+	uint32_t status, nsource;
+
+	status = nv_rd32(NV03_PGRAPH_INTR);
+	nsource = nv_rd32(NV03_PGRAPH_NSOURCE);
+
+	if (status & 0x00000020) {
+		nouveau_pgraph_intr_error(dev,
+					  NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD);
+
+		status &= ~0x00000020;
+		nv_wr32(NV03_PGRAPH_INTR, 0x00000020);
+	}
+
+	if (status & 0x00100000) {
+		nouveau_pgraph_intr_error(dev,
+					  NV03_PGRAPH_NSOURCE_DATA_ERROR);
+
+		status &= ~0x00100000;
+		nv_wr32(NV03_PGRAPH_INTR, 0x00100000);
+	}
+
+	if (status & 0x00200000) {
+		int r;
+
+		nouveau_pgraph_intr_error(dev, nsource |
+					  NV03_PGRAPH_NSOURCE_PROTECTION_ERROR);
+
+		NV_ERROR(dev, "magic set 1:\n");
+		for (r = 0x408900; r <= 0x408910; r += 4)
+			NV_ERROR(dev, "\t0x%08x: 0x%08x\n", r, nv_rd32(r));
+		nv_wr32(0x408900, nv_rd32(0x408904) | 0xc0000000);
+		for (r = 0x408e08; r <= 0x408e24; r += 4)
+			NV_ERROR(dev, "\t0x%08x: 0x%08x\n", r, nv_rd32(r));
+		nv_wr32(0x408e08, nv_rd32(0x408e08) | 0xc0000000);
+
+		NV_ERROR(dev, "magic set 2:\n");
+		for (r = 0x409900; r <= 0x409910; r += 4)
+			NV_ERROR(dev, "\t0x%08x: 0x%08x\n", r, nv_rd32(r));
+		nv_wr32(0x409900, nv_rd32(0x409904) | 0xc0000000);
+		for (r = 0x409e08; r <= 0x409e24; r += 4)
+			NV_ERROR(dev, "\t0x%08x: 0x%08x\n", r, nv_rd32(r));
+		nv_wr32(0x409e08, nv_rd32(0x409e08) | 0xc0000000);
+
+		status &= ~0x00200000;
+		nv_wr32(NV03_PGRAPH_NSOURCE, nsource);
+		nv_wr32(NV03_PGRAPH_INTR, 0x00200000);
+	}
+
+	if (status) {
+		NV_INFO(dev, "Unhandled PGRAPH_INTR - 0x%08x\n", status);
+		nv_wr32(NV03_PGRAPH_INTR, status);
+	}
+
+	{
+		const int isb = (1 << 16) | (1 << 0);
+
+		if ((nv_rd32(0x400500) & isb) != isb)
+			nv_wr32(0x400500, nv_rd32(0x400500) | isb);
+	}
+
+	nv_wr32(NV03_PMC_INTR_0, NV_PMC_INTR_0_PGRAPH_PENDING);
+}
+
+static void
+nouveau_crtc_irq_handler(struct drm_device *dev, int crtc)
+{
+	if (crtc & 1)
+		nv_wr32(NV_CRTC0_INTSTAT, NV_CRTC_INTR_VBLANK);
+
+	if (crtc & 2)
+		nv_wr32(NV_CRTC1_INTSTAT, NV_CRTC_INTR_VBLANK);
+}
+
+static void
+nouveau_nv50_display_irq_handler(struct drm_device *dev)
+{
+	uint32_t val = nv_rd32(NV50_PDISPLAY_SUPERVISOR);
+
+	NV_DEBUG(dev, "NV50_PDISPLAY_SUPERVISOR - 0x%08X\n", val);
+
+	/* vblank interrupts */
+	if (val & NV50_PDISPLAY_SUPERVISOR_CRTCn) {
+		nv_wr32(NV50_PDISPLAY_SUPERVISOR, val & NV50_PDISPLAY_SUPERVISOR_CRTCn);
+		val &= ~NV50_PDISPLAY_SUPERVISOR_CRTCn;
+	}
+
+	if (val)
+		NV_ERROR(dev, "unsupported NV50_DISPLAY_INTR - 0x%08X\n", val);
+
+	nv_wr32(NV50_PDISPLAY_SUPERVISOR, val);
+}
+
+static void
+nouveau_nv50_i2c_irq_handler(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "NV50_PCONNECTOR_HOTPLUG_CTRL - 0x%08X\n",
+		 nv_rd32(NV50_PCONNECTOR_HOTPLUG_CTRL));
+
+	/* This seems to be the way to acknowledge an interrupt. */
+	nv_wr32(NV50_PCONNECTOR_HOTPLUG_CTRL, 0x7FFF7FFF);
+
+	/* Do a "dumb" detect all */
+	nv50_connector_detect_all(dev);
+}
+
+irqreturn_t
+nouveau_irq_handler(DRM_IRQ_ARGS)
+{
+	struct drm_device *dev = (struct drm_device*)arg;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t status;
+
+	status = nv_rd32(NV03_PMC_INTR_0);
+	if (!status)
+		return IRQ_NONE;
+
+	if (status & NV_PMC_INTR_0_PFIFO_PENDING) {
+		nouveau_fifo_irq_handler(dev);
+		status &= ~NV_PMC_INTR_0_PFIFO_PENDING;
+	}
+
+	if (status & NV_PMC_INTR_0_PGRAPH_PENDING) {
+		if (dev_priv->card_type >= NV_50)
+			nv50_pgraph_irq_handler(dev);
+		else
+			nouveau_pgraph_irq_handler(dev);
+
+		status &= ~NV_PMC_INTR_0_PGRAPH_PENDING;
+	}
+
+	if (status & NV_PMC_INTR_0_CRTCn_PENDING) {
+		nouveau_crtc_irq_handler(dev, (status>>24)&3);
+		status &= ~NV_PMC_INTR_0_CRTCn_PENDING;
+	}
+
+	if (status & NV_PMC_INTR_0_NV50_DISPLAY_PENDING) {
+		nouveau_nv50_display_irq_handler(dev);
+		status &= ~NV_PMC_INTR_0_NV50_DISPLAY_PENDING;
+	}
+
+	if (status & NV_PMC_INTR_0_NV50_I2C_PENDING) {
+		nouveau_nv50_i2c_irq_handler(dev);
+		status &= ~NV_PMC_INTR_0_NV50_I2C_PENDING;
+	}
+
+	if (status)
+		NV_ERROR(dev, "Unhandled PMC INTR status bits 0x%08x\n", status);
+
+	return IRQ_HANDLED;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_mem.c b/drivers/gpu/drm/nouveau/nouveau_mem.c
new file mode 100644
index 0000000..21bb4d5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_mem.c
@@ -0,0 +1,1073 @@
+/*
+ * Copyright (C) The Weather Channel, Inc.  2002.  All Rights Reserved.
+ * Copyright 2005 Stephane Marchesin
+ *
+ * The Weather Channel (TM) funded Tungsten Graphics to develop the
+ * initial release of the Radeon 8500 driver under the XFree86 license.
+ * This notice must be preserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Keith Whitwell <keith@tungstengraphics.com>
+ */
+
+
+#include "drmP.h"
+#include "drm.h"
+#include "drm_sarea.h"
+#include "nouveau_drv.h"
+
+extern int nouveau_noagp;
+
+static struct mem_block *
+split_block(struct mem_block *p, uint64_t start, uint64_t size,
+	    struct drm_file *file_priv)
+{
+	/* Maybe cut off the start of an existing block */
+	if (start > p->start) {
+		struct mem_block *newblock =
+			drm_alloc(sizeof(*newblock), DRM_MEM_BUFS);
+		if (!newblock)
+			goto out;
+		newblock->start = start;
+		newblock->size = p->size - (start - p->start);
+		newblock->file_priv = NULL;
+		newblock->next = p->next;
+		newblock->prev = p;
+		p->next->prev = newblock;
+		p->next = newblock;
+		p->size -= newblock->size;
+		p = newblock;
+	}
+
+	/* Maybe cut off the end of an existing block */
+	if (size < p->size) {
+		struct mem_block *newblock =
+			drm_alloc(sizeof(*newblock), DRM_MEM_BUFS);
+		if (!newblock)
+			goto out;
+		newblock->start = start + size;
+		newblock->size = p->size - size;
+		newblock->file_priv = NULL;
+		newblock->next = p->next;
+		newblock->prev = p;
+		p->next->prev = newblock;
+		p->next = newblock;
+		p->size = size;
+	}
+
+out:
+	/* Our block is in the middle */
+	p->file_priv = file_priv;
+	return p;
+}
+
+struct mem_block *
+nouveau_mem_alloc_block(struct mem_block *heap, uint64_t size,
+			int align2, struct drm_file *file_priv, int tail)
+{
+	struct mem_block *p;
+	uint64_t mask = (1 << align2) - 1;
+
+	if (!heap)
+		return NULL;
+
+	if (tail) {
+		list_for_each_prev(p, heap) {
+			uint64_t start = ((p->start + p->size) - size) & ~mask;
+
+			if (p->file_priv == 0 && start >= p->start &&
+			    start + size <= p->start + p->size)
+				return split_block(p, start, size, file_priv);
+		}
+	} else {
+		list_for_each(p, heap) {
+			uint64_t start = (p->start + mask) & ~mask;
+
+			if (p->file_priv == 0 &&
+			    start + size <= p->start + p->size)
+				return split_block(p, start, size, file_priv);
+		}
+	}
+
+	return NULL;
+}
+
+static struct mem_block *find_block(struct mem_block *heap, uint64_t start)
+{
+	struct mem_block *p;
+
+	list_for_each(p, heap)
+		if (p->start == start)
+			return p;
+
+	return NULL;
+}
+
+void nouveau_mem_free_block(struct mem_block *p)
+{
+	p->file_priv = NULL;
+
+	/* Assumes a single contiguous range.  Needs a special file_priv in
+	 * 'heap' to stop it being subsumed.
+	 */
+	if (p->next->file_priv == 0) {
+		struct mem_block *q = p->next;
+		p->size += q->size;
+		p->next = q->next;
+		p->next->prev = p;
+		drm_free(q, sizeof(*q), DRM_MEM_BUFS);
+	}
+
+	if (p->prev->file_priv == 0) {
+		struct mem_block *q = p->prev;
+		q->size += p->size;
+		q->next = p->next;
+		q->next->prev = q;
+		drm_free(p, sizeof(*q), DRM_MEM_BUFS);
+	}
+}
+
+/* Initialize.  How to check for an uninitialized heap?
+ */
+int nouveau_mem_init_heap(struct mem_block **heap, uint64_t start,
+			  uint64_t size)
+{
+	struct mem_block *blocks = drm_alloc(sizeof(*blocks), DRM_MEM_BUFS);
+
+	if (!blocks)
+		return -ENOMEM;
+
+	*heap = drm_alloc(sizeof(**heap), DRM_MEM_BUFS);
+	if (!*heap) {
+		drm_free(blocks, sizeof(*blocks), DRM_MEM_BUFS);
+		return -ENOMEM;
+	}
+
+	blocks->start = start;
+	blocks->size = size;
+	blocks->file_priv = NULL;
+	blocks->next = blocks->prev = *heap;
+
+	memset(*heap, 0, sizeof(**heap));
+	(*heap)->file_priv = (struct drm_file *) - 1;
+	(*heap)->next = (*heap)->prev = blocks;
+	return 0;
+}
+
+/*
+ * Free all blocks associated with the releasing file_priv
+ */
+void nouveau_mem_release(struct drm_file *file_priv, struct mem_block *heap)
+{
+	struct mem_block *p;
+
+	if (!heap || !heap->next)
+		return;
+
+	list_for_each(p, heap) {
+		if (p->file_priv == file_priv)
+			p->file_priv = NULL;
+	}
+
+	/* Assumes a single contiguous range.  Needs a special file_priv in
+	 * 'heap' to stop it being subsumed.
+	 */
+	list_for_each(p, heap) {
+		while ((p->file_priv == 0) && (p->next->file_priv == 0) &&
+		       (p->next!=heap)) {
+			struct mem_block *q = p->next;
+			p->size += q->size;
+			p->next = q->next;
+			p->next->prev = p;
+			drm_free(q, sizeof(*q), DRM_MEM_DRIVER);
+		}
+	}
+}
+
+/*
+ * NV50 VM helpers
+ */
+#define VMBLOCK (512*1024*1024)
+static int
+nv50_mem_vm_preinit(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	dev_priv->vm_gart_base = roundup(VMBLOCK, VMBLOCK);
+	dev_priv->vm_gart_size = VMBLOCK;
+
+	dev_priv->vm_vram_base = dev_priv->vm_gart_base + dev_priv->vm_gart_size;
+	dev_priv->vm_vram_size = roundup(nouveau_mem_fb_amount(dev), VMBLOCK);
+	dev_priv->vm_end = dev_priv->vm_vram_base + dev_priv->vm_vram_size;
+
+	NV_DEBUG(dev, "NV50VM: GART 0x%016llx-0x%016llx\n",
+		 dev_priv->vm_gart_base,
+		 dev_priv->vm_gart_base + dev_priv->vm_gart_size - 1);
+	NV_DEBUG(dev, "NV50VM: VRAM 0x%016llx-0x%016llx\n",
+		 dev_priv->vm_vram_base,
+		 dev_priv->vm_vram_base + dev_priv->vm_vram_size - 1);
+	return 0;
+}
+
+static void
+nv50_mem_vm_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int i;
+
+	if (!dev_priv->vm_vram_pt)
+		return;
+
+	for (i = 0; i < dev_priv->vm_vram_pt_nr; i++) {
+		if (!dev_priv->vm_vram_pt[i])
+			break;
+
+		nouveau_gpuobj_del(dev, &dev_priv->vm_vram_pt[i]);
+	}
+
+	drm_free(dev_priv->vm_vram_pt,
+		 dev_priv->vm_vram_pt_nr * sizeof(struct nouveau_gpuobj *),
+		 DRM_MEM_DRIVER);
+	dev_priv->vm_vram_pt = NULL;
+	dev_priv->vm_vram_pt_nr = 0;
+}
+
+static int
+nv50_mem_vm_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	const int nr = dev_priv->vm_vram_size / VMBLOCK;
+	int i, ret;
+
+	dev_priv->vm_vram_pt_nr = nr;
+	dev_priv->vm_vram_pt = drm_calloc(nr, sizeof(struct nouveau_gpuobj *),
+					  DRM_MEM_DRIVER);
+	if (!dev_priv->vm_vram_pt)
+		return -ENOMEM;
+
+	for (i = 0; i < nr; i++) {
+		ret = nouveau_gpuobj_new(dev, NULL, VMBLOCK/65536*8, 0,
+					 NVOBJ_FLAG_ZERO_ALLOC |
+					 NVOBJ_FLAG_ALLOW_NO_REFS,
+					 &dev_priv->vm_vram_pt[i]);
+		if (ret) {
+			NV_ERROR(dev, "Error creating VRAM page tables: %d\n", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int
+nv50_mem_vm_bind_linear(struct drm_device *dev, uint64_t virt, uint32_t size,
+			uint32_t flags, uint64_t phys)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj **pgt;
+	unsigned psz, pfl, pages;
+
+	if (virt >= dev_priv->vm_gart_base &&
+	    (virt + size) < (dev_priv->vm_gart_base + dev_priv->vm_gart_size)) {
+		psz = 12;
+		pgt = &dev_priv->gart_info.sg_ctxdma;
+		pfl = 0x21;
+		virt -= dev_priv->vm_gart_base;
+	} else
+	if (virt >= dev_priv->vm_vram_base &&
+	    (virt + size) < (dev_priv->vm_vram_base + dev_priv->vm_vram_size)) {
+		psz = 16;
+		pgt = dev_priv->vm_vram_pt;
+		pfl = 0x01;
+		virt -= dev_priv->vm_vram_base;
+	} else {
+		NV_ERROR(dev, "Invalid address: 0x%16llx-0x%16llx\n",
+			 virt, virt + size - 1);
+		return -EINVAL;
+	}
+
+	pages = size >> psz;
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	if (flags & 0x80000000) {
+		while (pages--) {
+			struct nouveau_gpuobj *pt = pgt[virt >> 29];
+			unsigned pte = ((virt & 0x1fffffffULL) >> psz) << 1;
+
+			INSTANCE_WR(pt, pte++, 0x00000000);
+			INSTANCE_WR(pt, pte++, 0x00000000);
+
+			virt += (1 << psz);
+		}
+	} else {
+		while (pages--) {
+			struct nouveau_gpuobj *pt = pgt[virt >> 29];
+			unsigned pte = ((virt & 0x1fffffffULL) >> psz) << 1;
+
+			INSTANCE_WR(pt, pte++, phys | pfl);
+			INSTANCE_WR(pt, pte++, flags);
+
+			phys += (1 << psz);
+			virt += (1 << psz);
+		}
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	return 0;
+}
+
+void
+nv50_mem_vm_unbind(struct drm_device *dev, uint64_t virt, uint32_t size)
+{
+	nv50_mem_vm_bind_linear(dev, virt, size, 0x80000000, 0);
+}
+
+/*
+ * Cleanup everything
+ */
+void nouveau_mem_takedown(struct mem_block **heap)
+{
+	struct mem_block *p;
+
+	if (!*heap)
+		return;
+
+	for (p = (*heap)->next; p != *heap;) {
+		struct mem_block *q = p;
+		p = p->next;
+		drm_free(q, sizeof(*q), DRM_MEM_DRIVER);
+	}
+
+	drm_free(*heap, sizeof(**heap), DRM_MEM_DRIVER);
+	*heap = NULL;
+}
+
+void nouveau_mem_close(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->card_type >= NV_50)
+		nv50_mem_vm_takedown(dev);
+
+	if (!dev_priv->mm_enabled) {
+		nouveau_mem_takedown(&dev_priv->agp_heap);
+		nouveau_mem_takedown(&dev_priv->fb_heap);
+		if (dev_priv->pci_heap)
+			nouveau_mem_takedown(&dev_priv->pci_heap);
+	} else {
+		drm_bo_driver_finish(dev);
+	}
+
+	if (dev_priv->fb_mtrr) {
+		drm_mtrr_del(dev_priv->fb_mtrr, drm_get_resource_start(dev, 1),
+			     drm_get_resource_len(dev, 1), DRM_MTRR_WC);
+		dev_priv->fb_mtrr = 0;
+	}
+}
+
+/*XXX won't work on BSD because of pci_read_config_dword */
+static uint32_t
+nouveau_mem_fb_amount_igp(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct pci_dev *bridge;
+	uint32_t mem;
+
+	bridge = pci_get_bus_and_slot(0, PCI_DEVFN(0,1));
+	if (!bridge) {
+		NV_ERROR(dev, "no bridge device\n");
+		return 0;
+	}
+
+	if (dev_priv->flags&NV_NFORCE) {
+		pci_read_config_dword(bridge, 0x7C, &mem);
+		return (uint64_t)(((mem >> 6) & 31) + 1)*1024*1024;
+	} else
+	if(dev_priv->flags&NV_NFORCE2) {
+		pci_read_config_dword(bridge, 0x84, &mem);
+		return (uint64_t)(((mem >> 4) & 127) + 1)*1024*1024;
+	}
+
+	NV_ERROR(dev, "impossible!\n");
+	return 0;
+}
+
+/* returns the amount of FB ram in bytes */
+uint64_t nouveau_mem_fb_amount(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+	switch(dev_priv->card_type)
+	{
+		case NV_04:
+		case NV_05:
+			if (nv_rd32(NV03_BOOT_0) & 0x00000100) {
+				return (((nv_rd32(NV03_BOOT_0) >> 12) & 0xf)*2+2)*1024*1024;
+			} else
+			switch(nv_rd32(NV03_BOOT_0)&NV03_BOOT_0_RAM_AMOUNT)
+			{
+				case NV04_BOOT_0_RAM_AMOUNT_32MB:
+					return 32*1024*1024;
+				case NV04_BOOT_0_RAM_AMOUNT_16MB:
+					return 16*1024*1024;
+				case NV04_BOOT_0_RAM_AMOUNT_8MB:
+					return 8*1024*1024;
+				case NV04_BOOT_0_RAM_AMOUNT_4MB:
+					return 4*1024*1024;
+			}
+			break;
+		case NV_10:
+		case NV_11:
+		case NV_17:
+		case NV_20:
+		case NV_30:
+		case NV_40:
+		case NV_44:
+		case NV_50:
+		default:
+			if (dev_priv->flags & (NV_NFORCE | NV_NFORCE2)) {
+				return nouveau_mem_fb_amount_igp(dev);
+			} else {
+				uint64_t mem;
+
+				mem = (nv_rd32(NV04_FIFO_DATA) &
+				       NV10_FIFO_DATA_RAM_AMOUNT_MB_MASK) >>
+				      NV10_FIFO_DATA_RAM_AMOUNT_MB_SHIFT;
+				return mem*1024*1024;
+			}
+			break;
+	}
+
+	NV_ERROR(dev, "Unable to detect video ram size. Please report your setup to " DRIVER_EMAIL "\n");
+	return 0;
+}
+
+static void nouveau_mem_reset_agp(struct drm_device *dev)
+{
+	uint32_t saved_pci_nv_1, saved_pci_nv_19, pmc_enable;
+
+	saved_pci_nv_1 = nv_rd32(NV04_PBUS_PCI_NV_1);
+	saved_pci_nv_19 = nv_rd32(NV04_PBUS_PCI_NV_19);
+
+	/* clear busmaster bit */
+	nv_wr32(NV04_PBUS_PCI_NV_1, saved_pci_nv_1 & ~0x4);
+	/* clear SBA and AGP bits */
+	nv_wr32(NV04_PBUS_PCI_NV_19, saved_pci_nv_19 & 0xfffff0ff);
+
+	/* power cycle pgraph, if enabled */
+	pmc_enable = nv_rd32(NV03_PMC_ENABLE);
+	if (pmc_enable & NV_PMC_ENABLE_PGRAPH) {
+		nv_wr32(NV03_PMC_ENABLE, pmc_enable & ~NV_PMC_ENABLE_PGRAPH);
+		nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+				NV_PMC_ENABLE_PGRAPH);
+	}
+
+	/* and restore (gives effect of resetting AGP) */
+	nv_wr32(NV04_PBUS_PCI_NV_19, saved_pci_nv_19);
+	nv_wr32(NV04_PBUS_PCI_NV_1, saved_pci_nv_1);
+}
+
+static int
+nouveau_mem_init_agp(struct drm_device *dev, int ttm)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_agp_info info;
+	struct drm_agp_mode mode;
+	int ret;
+
+	if (nouveau_noagp)
+		return 0;
+
+	nouveau_mem_reset_agp(dev);
+
+	ret = drm_agp_acquire(dev);
+	if (ret) {
+		NV_ERROR(dev, "Unable to acquire AGP: %d\n", ret);
+		return ret;
+	}
+
+	ret = drm_agp_info(dev, &info);
+	if (ret) {
+		NV_ERROR(dev, "Unable to get AGP info: %d\n", ret);
+		return ret;
+	}
+
+	/* see agp.h for the AGPSTAT_* modes available */
+	mode.mode = info.mode;
+	ret = drm_agp_enable(dev, mode);
+	if (ret) {
+		NV_ERROR(dev, "Unable to enable AGP: %d\n", ret);
+		return ret;
+	}
+
+	if (!ttm) {
+		struct drm_agp_buffer agp_req;
+		struct drm_agp_binding bind_req;
+
+		agp_req.size = info.aperture_size;
+		agp_req.type = 0;
+		ret = drm_agp_alloc(dev, &agp_req);
+		if (ret) {
+			NV_ERROR(dev, "Unable to alloc AGP: %d\n", ret);
+				return ret;
+		}
+
+		bind_req.handle = agp_req.handle;
+		bind_req.offset = 0;
+		ret = drm_agp_bind(dev, &bind_req);
+		if (ret) {
+			NV_ERROR(dev, "Unable to bind AGP: %d\n", ret);
+			return ret;
+		}
+	}
+
+	dev_priv->gart_info.type	= NOUVEAU_GART_AGP;
+	dev_priv->gart_info.aper_base	= info.aperture_base;
+	dev_priv->gart_info.aper_size	= info.aperture_size;
+	return 0;
+}
+
+int
+nouveau_mem_init_ttm(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t vram_size, bar1_size, text_size;
+	int ret;
+
+	dev_priv->fb_phys = drm_get_resource_start(dev, 1);
+	dev_priv->gart_info.type = NOUVEAU_GART_NONE;
+
+	if (dev_priv->card_type >= NV_50) {
+		ret = nv50_mem_vm_preinit(dev);
+		if (ret)
+			return ret;
+	}
+
+	drm_bo_driver_init(dev);
+
+	/* non-mappable vram */
+	dev_priv->fb_available_size = nouveau_mem_fb_amount(dev);
+	dev_priv->fb_available_size -= dev_priv->ramin_rsvd_vram;
+	vram_size = dev_priv->fb_available_size >> PAGE_SHIFT;
+	bar1_size = drm_get_resource_len(dev, 1) >> PAGE_SHIFT;
+	text_size = (256 * 1024) >> PAGE_SHIFT;
+	if (bar1_size < vram_size) {
+		if (dev_priv->card_type < NV_50 &&
+		    (ret = drm_bo_init_mm(dev, DRM_BO_MEM_PRIV0, bar1_size,
+					  vram_size - bar1_size, 1))) {
+			NV_ERROR(dev, "Failed PRIV0 mm init: %d\n", ret);
+			return ret;
+		}
+		vram_size = bar1_size;
+	}
+
+	/* mappable vram */
+	if ((ret = drm_bo_init_mm(dev, DRM_BO_MEM_VRAM, text_size,
+				  vram_size - text_size, 1))) {
+		NV_ERROR(dev, "Failed VRAM mm init: %d\n", ret);
+		return ret;
+	}
+
+	/* GART */
+#if !defined(__powerpc__) && !defined(__ia64__)
+	if (drm_device_is_agp(dev) && dev->agp) {
+		if ((ret = nouveau_mem_init_agp(dev, 1)))
+			NV_ERROR(dev, "Error initialising AGP: %d\n", ret);
+	}
+#endif
+
+	if (dev_priv->gart_info.type == NOUVEAU_GART_NONE) {
+		if ((ret = nouveau_sgdma_init(dev)))
+			NV_ERROR(dev, "Error initialising PCI SGDMA: %d\n", ret);
+	}
+
+	if ((ret = drm_bo_init_mm(dev, DRM_BO_MEM_TT, 0,
+				  dev_priv->gart_info.aper_size >> PAGE_SHIFT,
+				  1))) {
+		NV_ERROR(dev, "Failed TT mm init: %d\n", ret);
+		return ret;
+	}
+
+	dev_priv->fb_mtrr = drm_mtrr_add(drm_get_resource_start(dev, 1),
+					 drm_get_resource_len(dev, 1),
+					 DRM_MTRR_WC);
+
+	if (dev_priv->card_type >= NV_50) {
+		ret = nv50_mem_vm_init(dev);
+		if (ret) {
+			NV_ERROR(dev, "Error creating VM page tables: %d\n", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int nouveau_mem_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t fb_size, vram_base, gart_base;
+	int ret = 0;
+
+	dev_priv->agp_heap = dev_priv->pci_heap = dev_priv->fb_heap = NULL;
+	dev_priv->fb_phys = 0;
+	dev_priv->gart_info.type = NOUVEAU_GART_NONE;
+
+	/* setup a mtrr over the FB */
+	dev_priv->fb_mtrr = drm_mtrr_add(drm_get_resource_start(dev, 1),
+					 drm_get_resource_len(dev, 1),
+					 DRM_MTRR_WC);
+
+	if (dev_priv->card_type >= NV_50) {
+		ret = nv50_mem_vm_preinit(dev);
+		if (ret)
+			return ret;
+	}
+	gart_base = dev_priv->vm_gart_base;
+	vram_base = dev_priv->vm_vram_base;
+
+	/* Init FB */
+	dev_priv->fb_phys=drm_get_resource_start(dev,1);
+	fb_size = nouveau_mem_fb_amount(dev);
+	fb_size -= dev_priv->ramin_rsvd_vram;
+	dev_priv->fb_available_size = fb_size;
+	NV_DEBUG(dev, "Available VRAM: %dKiB\n", fb_size>>10);
+
+	if (fb_size>256*1024*1024) {
+		/* On cards with > 256Mb, you can't map everything.
+		 * So we create a second FB heap for that type of memory */
+		if (nouveau_mem_init_heap(&dev_priv->fb_heap,
+					  vram_base, 256*1024*1024))
+			return -ENOMEM;
+		if (nouveau_mem_init_heap(&dev_priv->fb_nomap_heap,
+					  vram_base + 256*1024*1024,
+					  fb_size - 256*1024*1024))
+			return -ENOMEM;
+	} else {
+		if (nouveau_mem_init_heap(&dev_priv->fb_heap, vram_base, fb_size))
+			return -ENOMEM;
+		dev_priv->fb_nomap_heap=NULL;
+	}
+
+#if !defined(__powerpc__) && !defined(__ia64__)
+	/* Init AGP / NV50 PCIEGART */
+	if (drm_device_is_agp(dev) && dev->agp) {
+		if ((ret = nouveau_mem_init_agp(dev, 0)))
+			NV_ERROR(dev, "Error initialising AGP: %d\n", ret);
+	}
+#endif
+
+	/*Note: this is *not* just NV50 code, but only used on NV50 for now */
+	if (dev_priv->gart_info.type == NOUVEAU_GART_NONE &&
+	    dev_priv->card_type >= NV_50) {
+		ret = nouveau_sgdma_init(dev);
+		if (!ret) {
+			ret = nouveau_sgdma_nottm_hack_init(dev);
+			if (ret)
+				nouveau_sgdma_takedown(dev);
+		}
+
+		if (ret)
+			NV_ERROR(dev, "Error initialising SG DMA: %d\n", ret);
+	}
+
+	if (dev_priv->gart_info.type != NOUVEAU_GART_NONE) {
+		if (nouveau_mem_init_heap(&dev_priv->agp_heap, gart_base,
+					  dev_priv->gart_info.aper_size)) {
+			if (dev_priv->gart_info.type == NOUVEAU_GART_SGDMA) {
+				nouveau_sgdma_nottm_hack_takedown(dev);
+				nouveau_sgdma_takedown(dev);
+			}
+		}
+	}
+
+	/* NV04-NV40 PCIEGART */
+	if (!dev_priv->agp_heap && dev_priv->card_type < NV_50) {
+		struct drm_scatter_gather sgreq;
+
+		NV_DEBUG(dev, "Allocating sg memory for PCI DMA\n");
+		sgreq.size = 16 << 20; //16MB of PCI scatter-gather zone
+
+		if (drm_sg_alloc(dev, &sgreq)) {
+			NV_ERROR(dev,
+				 "Unable to allocate %ldMB of scatter-gather"
+				 " pages for PCI DMA!",sgreq.size>>20);
+		} else {
+			if (nouveau_mem_init_heap(&dev_priv->pci_heap, 0,
+						  dev->sg->pages * PAGE_SIZE)) {
+				NV_ERROR(dev, "Unable to initialize pci_heap!");
+			}
+		}
+	}
+
+	if (dev_priv->card_type >= NV_50) {
+		ret = nv50_mem_vm_init(dev);
+		if (ret) {
+			NV_ERROR(dev, "Error creating VM page tables: %d\n", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+struct mem_block *
+nouveau_mem_alloc(struct drm_device *dev, int alignment, uint64_t size,
+		  int flags, struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct mem_block *block;
+	int type, tail = !(flags & NOUVEAU_MEM_USER);
+	int ret;
+
+	/*
+	 * Make things easier on ourselves: all allocations are page-aligned.
+	 * We need that to map allocated regions into the user space
+	 */
+	if (alignment < PAGE_SIZE)
+		alignment = PAGE_SIZE;
+
+	/* Align allocation sizes to 64KiB blocks on G8x.  We use a 64KiB
+	 * page size in the GPU VM.
+	 */
+	if (flags & NOUVEAU_MEM_FB && dev_priv->card_type >= NV_50) {
+		size = (size + 65535) & ~65535;
+		if (alignment < 65536)
+			alignment = 65536;
+	}
+
+	/* Further down wants alignment in pages, not bytes */
+	alignment >>= PAGE_SHIFT;
+
+	/* This case will only ever be hit through in-kernel use */
+	if (dev_priv->mm_enabled) {
+		uint64_t memtype = 0;
+
+		size = (size + 65535) & ~65535;
+		if (alignment < (65536 / PAGE_SIZE))
+			alignment = (65536 / PAGE_SIZE);
+
+		block = drm_calloc(1, sizeof(*block), DRM_MEM_DRIVER);
+		if (!block)
+			return NULL;
+
+		if (flags & (NOUVEAU_MEM_FB | NOUVEAU_MEM_FB_ACCEPTABLE)) {
+			memtype |= DRM_BO_FLAG_MEM_VRAM;
+			if (!(flags & NOUVEAU_MEM_MAPPED))
+				memtype |= DRM_BO_FLAG_MEM_PRIV0;
+		}
+		if (flags & NOUVEAU_MEM_AGP)
+			memtype |= DRM_BO_FLAG_MEM_TT;
+		if (flags & NOUVEAU_MEM_NOVM)
+			memtype |= DRM_NOUVEAU_BO_FLAG_NOVM;
+
+		ret = drm_buffer_object_create(dev, size, drm_bo_type_kernel,
+					       DRM_BO_FLAG_READ |
+					       DRM_BO_FLAG_WRITE |
+					       DRM_BO_FLAG_NO_EVICT |
+					       memtype, DRM_BO_HINT_DONT_FENCE,
+					       alignment, 0, &block->bo);
+		if (ret) {
+			drm_free(block, sizeof(*block), DRM_MEM_DRIVER);
+			return NULL;
+		}
+
+		block->start = block->bo->offset;
+		block->size = block->bo->mem.size;
+
+		if (block->bo->mem.mem_type == DRM_BO_MEM_VRAM) {
+			block->flags = NOUVEAU_MEM_FB;
+			if (flags & NOUVEAU_MEM_NOVM) {
+				block->flags |= NOUVEAU_MEM_NOVM;
+				block->start -= dev_priv->vm_vram_base;
+			}
+		} else
+		if (block->bo->mem.mem_type == DRM_BO_MEM_TT) {
+			block->flags = NOUVEAU_MEM_AGP;
+		}
+
+		return block;
+	}
+
+	/*
+	 * Warn about 0 sized allocations, but let it go through. It'll return 1 page
+	 */
+	if (size == 0)
+		NV_WARN(dev, "warning : 0 byte allocation\n");
+
+	/*
+	 * Keep alloc size a multiple of the page size to keep drm_addmap() happy
+	 */
+	if (size & (~PAGE_MASK))
+		size = ((size/PAGE_SIZE) + 1) * PAGE_SIZE;
+
+
+#define NOUVEAU_MEM_ALLOC_AGP {\
+		type=NOUVEAU_MEM_AGP;\
+                block = nouveau_mem_alloc_block(dev_priv->agp_heap, size,\
+                                                alignment, file_priv, tail); \
+                if (block) goto alloc_ok;\
+	        }
+
+#define NOUVEAU_MEM_ALLOC_PCI {\
+                type = NOUVEAU_MEM_PCI;\
+                block = nouveau_mem_alloc_block(dev_priv->pci_heap, size, \
+						alignment, file_priv, tail); \
+                if ( block ) goto alloc_ok;\
+	        }
+
+#define NOUVEAU_MEM_ALLOC_FB {\
+                type=NOUVEAU_MEM_FB;\
+                if (!(flags&NOUVEAU_MEM_MAPPED)) {\
+                        block = nouveau_mem_alloc_block(dev_priv->fb_nomap_heap,\
+                                                        size, alignment, \
+							file_priv, tail); \
+                        if (block) goto alloc_ok;\
+                }\
+                block = nouveau_mem_alloc_block(dev_priv->fb_heap, size,\
+                                                alignment, file_priv, tail);\
+                if (block) goto alloc_ok;\
+	        }
+
+
+	if (flags&NOUVEAU_MEM_FB) NOUVEAU_MEM_ALLOC_FB
+	if (flags&NOUVEAU_MEM_AGP) NOUVEAU_MEM_ALLOC_AGP
+	if (flags&NOUVEAU_MEM_PCI) NOUVEAU_MEM_ALLOC_PCI
+	if (flags&NOUVEAU_MEM_FB_ACCEPTABLE) NOUVEAU_MEM_ALLOC_FB
+	if (flags&NOUVEAU_MEM_AGP_ACCEPTABLE) NOUVEAU_MEM_ALLOC_AGP
+	if (flags&NOUVEAU_MEM_PCI_ACCEPTABLE) NOUVEAU_MEM_ALLOC_PCI
+
+
+	return NULL;
+
+alloc_ok:
+	block->flags=type;
+
+	/* On G8x, map memory into VM */
+	if (block->flags & NOUVEAU_MEM_FB && dev_priv->card_type >= NV_50 &&
+	    !(flags & NOUVEAU_MEM_NOVM)) {
+		unsigned offset = block->start - dev_priv->vm_vram_base;
+		unsigned tile = 0;
+
+		/* The tiling stuff is *not* what NVIDIA does - but both the
+		 * 2D and 3D engines seem happy with this simpler method.
+		 * Should look into why NVIDIA do what they do at some point.
+		 */
+		if (flags & NOUVEAU_MEM_TILE) {
+			if (flags & NOUVEAU_MEM_TILE_ZETA)
+				tile = 0x00002800;
+			else
+				tile = 0x00007000;
+		}
+
+		ret = nv50_mem_vm_bind_linear(dev, block->start, block->size,
+					      tile, offset);
+		if (ret) {
+			NV_ERROR(dev, "error binding into vm: %d\n", ret);
+			nouveau_mem_free_block(block);
+			return NULL;
+		}
+	} else
+	if (block->flags & NOUVEAU_MEM_FB && dev_priv->card_type >= NV_50) {
+		block->start -= dev_priv->vm_vram_base;
+		block->flags |= NOUVEAU_MEM_NOVM;
+	}	
+
+	if (flags & NOUVEAU_MEM_MAPPED)
+	{
+		struct drm_map_list *entry;
+		uint64_t map_offset;
+		int ret = 0;
+
+		block->flags |= NOUVEAU_MEM_MAPPED;
+
+		map_offset = block->start;
+		if (!(block->flags & NOUVEAU_MEM_NOVM)) {
+			if (block->flags & NOUVEAU_MEM_FB)
+				map_offset -= dev_priv->vm_vram_base;
+			else
+			if (block->flags & NOUVEAU_MEM_AGP)
+				map_offset -= dev_priv->vm_gart_base;
+		}
+
+		if (type == NOUVEAU_MEM_AGP) {
+			if (dev_priv->gart_info.type != NOUVEAU_GART_SGDMA)
+			ret = drm_addmap(dev, map_offset, block->size,
+					 _DRM_AGP, 0, &block->map);
+			else
+			ret = drm_addmap(dev, map_offset, block->size,
+					 _DRM_SCATTER_GATHER, 0, &block->map);
+		}
+		else if (type == NOUVEAU_MEM_FB)
+			ret = drm_addmap(dev, map_offset + dev_priv->fb_phys,
+					 block->size, _DRM_FRAME_BUFFER,
+					 0, &block->map);
+		else if (type == NOUVEAU_MEM_PCI)
+			ret = drm_addmap(dev, map_offset, block->size,
+					 _DRM_SCATTER_GATHER, 0, &block->map);
+
+		if (ret) {
+			nouveau_mem_free_block(block);
+			return NULL;
+		}
+
+		entry = drm_find_matching_map(dev, block->map);
+		if (!entry) {
+			nouveau_mem_free_block(block);
+			return NULL;
+		}
+		block->map_handle = entry->user_token;
+	}
+
+	NV_DEBUG(dev, "allocated %lld bytes at 0x%llx type=0x%08x\n",
+		 block->size, block->start, block->flags);
+	return block;
+}
+
+void nouveau_mem_free(struct drm_device* dev, struct mem_block* block)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	NV_DEBUG(dev, "freeing 0x%llx type=0x%08x\n",
+		 block->start, block->flags);
+
+	if (dev_priv->mm_enabled) {
+		if (block->kmap.virtual)
+			drm_bo_kunmap(&block->kmap);
+		drm_bo_usage_deref_unlocked(&block->bo);
+		drm_free(block, sizeof(*block), DRM_MEM_DRIVER);
+		return;
+	}
+
+	if (block->flags&NOUVEAU_MEM_MAPPED)
+		drm_rmmap(dev, block->map);
+
+	/* G8x: Remove pages from vm */
+	if (block->flags & NOUVEAU_MEM_FB && dev_priv->card_type >= NV_50 &&
+	    !(block->flags & NOUVEAU_MEM_NOVM)) {
+		nv50_mem_vm_unbind(dev, block->start, block->size);
+	}
+
+	nouveau_mem_free_block(block);
+}
+
+/*
+ * Ioctls
+ */
+
+int
+nouveau_ioctl_mem_alloc(struct drm_device *dev, void *data,
+			struct drm_file *file_priv)
+{
+	struct drm_nouveau_mem_alloc *alloc = data;
+	struct mem_block *block;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_DISABLED_WITH_RETURN;
+
+	if (alloc->flags & NOUVEAU_MEM_INTERNAL)
+		return -EINVAL;
+
+	block = nouveau_mem_alloc(dev, alloc->alignment, alloc->size,
+				  alloc->flags | NOUVEAU_MEM_USER, file_priv);
+	if (!block)
+		return -ENOMEM;
+	alloc->map_handle=block->map_handle;
+	alloc->offset=block->start;
+	alloc->flags=block->flags;
+
+	return 0;
+}
+
+int
+nouveau_ioctl_mem_free(struct drm_device *dev, void *data,
+		       struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_mem_free *memfree = data;
+	struct mem_block *block;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_DISABLED_WITH_RETURN;
+
+	block=NULL;
+	if (dev_priv->fb_heap && memfree->flags & NOUVEAU_MEM_FB)
+		block = find_block(dev_priv->fb_heap, memfree->offset);
+	else
+	if (dev_priv->agp_heap && memfree->flags & NOUVEAU_MEM_AGP)
+		block = find_block(dev_priv->agp_heap, memfree->offset);
+	else
+	if (dev_priv->pci_heap && memfree->flags & NOUVEAU_MEM_PCI)
+		block = find_block(dev_priv->pci_heap, memfree->offset);
+
+	if (!block)
+		return -EFAULT;
+
+	if (block->file_priv != file_priv)
+		return -EPERM;
+
+	nouveau_mem_free(dev, block);
+	return 0;
+}
+
+int
+nouveau_ioctl_mem_tile(struct drm_device *dev, void *data,
+		       struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_mem_tile *memtile = data;
+	struct mem_block *block = NULL;
+	unsigned offset, tile = 0;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_CHECK_MM_DISABLED_WITH_RETURN;
+
+	if (dev_priv->card_type < NV_50)
+		return -EINVAL;
+	
+	if (memtile->flags & NOUVEAU_MEM_FB)
+		block = find_block(dev_priv->fb_heap, memtile->offset);
+
+	if (!block || (memtile->delta + memtile->size > block->size))
+		return -EINVAL;
+
+	if (block->file_priv != file_priv)
+		return -EPERM;
+
+	offset  = block->start + memtile->delta;	
+	offset -= dev_priv->vm_vram_base;
+
+	if (memtile->flags & NOUVEAU_MEM_TILE) {
+		if (memtile->flags & NOUVEAU_MEM_TILE_ZETA)
+			tile = 0x00002800;
+		else
+			tile = 0x00007000;
+	}
+
+	ret = nv50_mem_vm_bind_linear(dev, block->start + memtile->delta,
+				      memtile->size, tile, offset);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
diff --git a/drivers/gpu/drm/nouveau/nouveau_notifier.c b/drivers/gpu/drm/nouveau/nouveau_notifier.c
new file mode 100644
index 0000000..bc5cb41
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_notifier.c
@@ -0,0 +1,176 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+int
+nouveau_notifier_init_channel(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int flags, ret;
+
+	flags = NOUVEAU_MEM_FB | NOUVEAU_MEM_NOVM | NOUVEAU_MEM_MAPPED;
+
+	chan->notifier_block = nouveau_mem_alloc(dev, 0, PAGE_SIZE, flags,
+						 (struct drm_file *)-2);
+	if (!chan->notifier_block)
+		return -ENOMEM;
+	NV_DEBUG(dev, "Allocated notifier block in 0x%08x\n",
+		 chan->notifier_block->flags);
+
+	if (dev_priv->mm_enabled) {
+		ret = drm_addmap(dev, chan->notifier_block->start +
+				 dev_priv->fb_phys, chan->notifier_block->size,
+				 _DRM_FRAME_BUFFER, 0, &chan->notifier_map);
+		if (ret) {
+			nouveau_mem_free(dev, chan->notifier_block);
+			chan->notifier_block = NULL;
+			return ret;
+		}
+	}
+	
+	ret = nouveau_mem_init_heap(&chan->notifier_heap,
+				    0, chan->notifier_block->size);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+void
+nouveau_notifier_takedown_channel(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+
+	if (chan->notifier_block) {
+		nouveau_mem_free(dev, chan->notifier_block);
+		chan->notifier_block = NULL;
+	}
+
+	nouveau_mem_takedown(&chan->notifier_heap);
+}
+
+static void
+nouveau_notifier_gpuobj_dtor(struct drm_device *dev,
+			     struct nouveau_gpuobj *gpuobj)
+{
+	NV_DEBUG(dev, "\n");
+
+	if (gpuobj->priv)
+		nouveau_mem_free_block(gpuobj->priv);
+}
+
+int
+nouveau_notifier_alloc(struct nouveau_channel *chan, uint32_t handle,
+		       int count, uint32_t *b_offset)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *nobj = NULL;
+	struct mem_block *mem;
+	uint32_t offset;
+	int target, ret;
+
+	if (!chan->notifier_heap) {
+		NV_ERROR(dev, "Channel %d doesn't have a notifier heap!\n",
+			 chan->id);
+		return -EINVAL;
+	}
+
+	mem = nouveau_mem_alloc_block(chan->notifier_heap, count*32, 0,
+				      (struct drm_file *)-2, 0);
+	if (!mem) {
+		NV_ERROR(dev, "Channel %d notifier block full\n", chan->id);
+		return -ENOMEM;
+	}
+	mem->flags = NOUVEAU_MEM_NOTIFIER;
+
+	offset = chan->notifier_block->start;
+	if (chan->notifier_block->flags & NOUVEAU_MEM_FB) {
+		target = NV_DMA_TARGET_VIDMEM;
+	} else
+	if (chan->notifier_block->flags & NOUVEAU_MEM_AGP) {
+		if (dev_priv->gart_info.type == NOUVEAU_GART_SGDMA &&
+		    dev_priv->card_type < NV_50) {
+			ret = nouveau_sgdma_get_page(dev, offset, &offset);
+			if (ret)
+				return ret;
+			target = NV_DMA_TARGET_PCI;
+		} else {
+			target = NV_DMA_TARGET_AGP;
+		}
+	} else
+	if (chan->notifier_block->flags & NOUVEAU_MEM_PCI) {
+		target = NV_DMA_TARGET_PCI_NONLINEAR;
+	} else {
+		NV_ERROR(dev, "Bad DMA target, flags 0x%08x!\n",
+			 chan->notifier_block->flags);
+		return -EINVAL;
+	}
+	offset += mem->start;
+
+	if ((ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					  offset, mem->size,
+					  NV_DMA_ACCESS_RW, target, &nobj))) {
+		nouveau_mem_free_block(mem);
+		NV_ERROR(dev, "Error creating notifier ctxdma: %d\n", ret);
+		return ret;
+	}
+	nobj->dtor   = nouveau_notifier_gpuobj_dtor;
+	nobj->priv   = mem;
+
+	if ((ret = nouveau_gpuobj_ref_add(dev, chan, handle, nobj, NULL))) {
+		nouveau_gpuobj_del(dev, &nobj);
+		nouveau_mem_free_block(mem);
+		NV_ERROR(dev, "Error referencing notifier ctxdma: %d\n", ret);
+		return ret;
+	}
+
+	*b_offset = mem->start;
+	return 0;
+}
+
+int
+nouveau_ioctl_notifier_alloc(struct drm_device *dev, void *data,
+			     struct drm_file *file_priv)
+{
+	struct drm_nouveau_notifierobj_alloc *na = data;
+	struct nouveau_channel *chan;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(na->channel, file_priv, chan);
+
+	ret = nouveau_notifier_alloc(chan, na->handle, na->count, &na->offset);
+	if (ret)
+		return ret;
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_object.c b/drivers/gpu/drm/nouveau/nouveau_object.c
new file mode 100644
index 0000000..5fed5cb
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_object.c
@@ -0,0 +1,1236 @@
+/*
+ * Copyright (C) 2006 Ben Skeggs.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/*
+ * Authors:
+ *   Ben Skeggs <darktama@iinet.net.au>
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+/* NVidia uses context objects to drive drawing operations.
+
+   Context objects can be selected into 8 subchannels in the FIFO,
+   and then used via DMA command buffers.
+
+   A context object is referenced by a user defined handle (CARD32). The HW
+   looks up graphics objects in a hash table in the instance RAM.
+
+   An entry in the hash table consists of 2 CARD32. The first CARD32 contains
+   the handle, the second one a bitfield, that contains the address of the
+   object in instance RAM.
+
+   The format of the second CARD32 seems to be:
+
+   NV4 to NV30:
+
+   15: 0  instance_addr >> 4
+   17:16  engine (here uses 1 = graphics)
+   28:24  channel id (here uses 0)
+   31	  valid (use 1)
+
+   NV40:
+
+   15: 0  instance_addr >> 4   (maybe 19-0)
+   21:20  engine (here uses 1 = graphics)
+   I'm unsure about the other bits, but using 0 seems to work.
+
+   The key into the hash table depends on the object handle and channel id and
+   is given as:
+*/
+static uint32_t
+nouveau_ramht_hash_handle(struct drm_device *dev, int channel, uint32_t handle)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+	uint32_t hash = 0;
+	int i;
+
+	NV_DEBUG(dev, "ch%d handle=0x%08x\n", channel, handle);
+
+	for (i=32;i>0;i-=dev_priv->ramht_bits) {
+		hash ^= (handle & ((1 << dev_priv->ramht_bits) - 1));
+		handle >>= dev_priv->ramht_bits;
+	}
+	if (dev_priv->card_type < NV_50)
+		hash ^= channel << (dev_priv->ramht_bits - 4);
+	hash <<= 3;
+
+	NV_DEBUG(dev, "hash=0x%08x\n", hash);
+	return hash;
+}
+
+static int
+nouveau_ramht_entry_valid(struct drm_device *dev, struct nouveau_gpuobj *ramht,
+			  uint32_t offset)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+	uint32_t ctx = INSTANCE_RD(ramht, (offset + 4)/4);
+
+	if (dev_priv->card_type < NV_40)
+		return ((ctx & NV_RAMHT_CONTEXT_VALID) != 0);
+	return (ctx != 0);
+}
+
+static int
+nouveau_ramht_insert(struct drm_device *dev, struct nouveau_gpuobj_ref *ref)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+	struct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;
+	struct nouveau_channel *chan = dev_priv->fifos[ref->channel];
+	struct nouveau_gpuobj *ramht = chan->ramht ? chan->ramht->gpuobj : NULL;
+	struct nouveau_gpuobj *gpuobj = ref->gpuobj;
+	uint32_t ctx, co, ho;
+
+	if (!ramht) {
+		NV_ERROR(dev, "No hash table!\n");
+		return -EINVAL;
+	}
+
+	if (dev_priv->card_type < NV_40) {
+		ctx = NV_RAMHT_CONTEXT_VALID | (ref->instance >> 4) |
+		      (ref->channel   << NV_RAMHT_CONTEXT_CHANNEL_SHIFT) |
+		      (gpuobj->engine << NV_RAMHT_CONTEXT_ENGINE_SHIFT);
+	} else
+	if (dev_priv->card_type < NV_50) {
+		ctx = (ref->instance >> 4) |
+		      (ref->channel   << NV40_RAMHT_CONTEXT_CHANNEL_SHIFT) |
+		      (gpuobj->engine << NV40_RAMHT_CONTEXT_ENGINE_SHIFT);
+	} else {
+		ctx = (ref->instance  >> 4) |
+		      (gpuobj->engine << NV40_RAMHT_CONTEXT_ENGINE_SHIFT);
+	}
+
+	instmem->prepare_access(dev, true);
+	co = ho = nouveau_ramht_hash_handle(dev, ref->channel, ref->handle);
+	do {
+		if (!nouveau_ramht_entry_valid(dev, ramht, co)) {
+			NV_DEBUG(dev, "insert ch%d 0x%08x: h=0x%08x, c=0x%08x\n",
+				 ref->channel, co, ref->handle, ctx);
+			INSTANCE_WR(ramht, (co + 0)/4, ref->handle);
+			INSTANCE_WR(ramht, (co + 4)/4, ctx);
+
+			list_add_tail(&ref->list, &chan->ramht_refs);
+			instmem->finish_access(dev);
+			return 0;
+		}
+		NV_DEBUG(dev, "collision ch%d 0x%08x: h=0x%08x\n",
+			 ref->channel, co, INSTANCE_RD(ramht, co/4));
+
+		co += 8;
+		if (co >= dev_priv->ramht_size)
+			co = 0;
+	} while (co != ho);
+	instmem->finish_access(dev);
+
+	NV_ERROR(dev, "RAMHT space exhausted. ch=%d\n", ref->channel);
+	return -ENOMEM;
+}
+
+static void
+nouveau_ramht_remove(struct drm_device *dev, struct nouveau_gpuobj_ref *ref)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;
+	struct nouveau_channel *chan = dev_priv->fifos[ref->channel];
+	struct nouveau_gpuobj *ramht = chan->ramht ? chan->ramht->gpuobj : NULL;
+	uint32_t co, ho;
+
+	if (!ramht) {
+		NV_ERROR(dev, "No hash table!\n");
+		return;
+	}
+
+	instmem->prepare_access(dev, true);
+	co = ho = nouveau_ramht_hash_handle(dev, ref->channel, ref->handle);
+	do {
+		if (nouveau_ramht_entry_valid(dev, ramht, co) &&
+		    (ref->handle == INSTANCE_RD(ramht, (co/4)))) {
+			NV_DEBUG(dev, "remove ch%d 0x%08x: h=0x%08x, c=0x%08x\n",
+				 ref->channel, co, ref->handle,
+				 INSTANCE_RD(ramht, (co + 4)));
+			INSTANCE_WR(ramht, (co + 0)/4, 0x00000000);
+			INSTANCE_WR(ramht, (co + 4)/4, 0x00000000);
+
+			list_del(&ref->list);
+			instmem->finish_access(dev);
+			return;
+		}
+
+		co += 8;
+		if (co >= dev_priv->ramht_size)
+			co = 0;
+	} while (co != ho);
+	list_del(&ref->list);
+	instmem->finish_access(dev);
+
+	NV_ERROR(dev, "RAMHT entry not found. ch=%d, handle=0x%08x\n",
+		 ref->channel, ref->handle);
+}
+
+int
+nouveau_gpuobj_new(struct drm_device *dev, struct nouveau_channel *chan,
+		   int size, int align, uint32_t flags,
+		   struct nouveau_gpuobj **gpuobj_ret)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	struct nouveau_gpuobj *gpuobj;
+	struct mem_block *pramin = NULL;
+	int ret;
+
+	NV_DEBUG(dev, "ch%d size=%d align=%d flags=0x%08x\n",
+		 chan ? chan->id : -1, size, align, flags);
+
+	if (!dev_priv || !gpuobj_ret || *gpuobj_ret != NULL)
+		return -EINVAL;
+
+	gpuobj = drm_calloc(1, sizeof(*gpuobj), DRM_MEM_DRIVER);
+	if (!gpuobj)
+		return -ENOMEM;
+	NV_DEBUG(dev, "gpuobj %p\n", gpuobj);
+	gpuobj->flags = flags;
+	gpuobj->im_channel = chan ? chan->id : -1;
+
+	list_add_tail(&gpuobj->list, &dev_priv->gpuobj_list);
+
+	/* Choose between global instmem heap, and per-channel private
+	 * instmem heap.  On <NV50 allow requests for private instmem
+	 * to be satisfied from global heap if no per-channel area
+	 * available.
+	 */
+	if (chan) {
+		if (chan->ramin_heap) {
+			NV_DEBUG(dev, "private heap\n");
+			pramin = chan->ramin_heap;
+		} else
+		if (dev_priv->card_type < NV_50) {
+			NV_DEBUG(dev, "global heap fallback\n");
+			pramin = dev_priv->ramin_heap;
+		}
+	} else {
+		NV_DEBUG(dev, "global heap\n");
+		pramin = dev_priv->ramin_heap;
+	}
+
+	if (!pramin) {
+		NV_ERROR(dev, "No PRAMIN heap!\n");
+		return -EINVAL;
+	}
+
+	if (!chan && (ret = engine->instmem.populate(dev, gpuobj, &size))) {
+		nouveau_gpuobj_del(dev, &gpuobj);
+		return ret;
+	}
+
+	/* Allocate a chunk of the PRAMIN aperture */
+	gpuobj->im_pramin = nouveau_mem_alloc_block(pramin, size,
+						    drm_order(align),
+						    (struct drm_file *)-2, 0);
+	if (!gpuobj->im_pramin) {
+		nouveau_gpuobj_del(dev, &gpuobj);
+		return -ENOMEM;
+	}
+	gpuobj->im_pramin->flags = NOUVEAU_MEM_INSTANCE;
+
+	if (!chan && (ret = engine->instmem.bind(dev, gpuobj))) {
+		nouveau_gpuobj_del(dev, &gpuobj);
+		return ret;
+	}
+
+	if (gpuobj->flags & NVOBJ_FLAG_ZERO_ALLOC) {
+		int i;
+
+		engine->instmem.prepare_access(dev, true);
+		for (i = 0; i < gpuobj->im_pramin->size; i += 4)
+			INSTANCE_WR(gpuobj, i/4, 0);
+		engine->instmem.finish_access(dev);
+	}
+
+	*gpuobj_ret = gpuobj;
+	return 0;
+}
+
+int
+nouveau_gpuobj_early_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	NV_DEBUG(dev, "\n");
+
+	INIT_LIST_HEAD(&dev_priv->gpuobj_list);
+
+	return 0;
+}
+
+int
+nouveau_gpuobj_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	if (dev_priv->card_type < NV_50) {
+		if ((ret = nouveau_gpuobj_new_fake(dev, dev_priv->ramht_offset,
+						   ~0, dev_priv->ramht_size,
+						   NVOBJ_FLAG_ZERO_ALLOC |
+						   NVOBJ_FLAG_ALLOW_NO_REFS,
+						   &dev_priv->ramht, NULL)))
+			return ret;
+	}
+
+	return 0;
+}
+
+void
+nouveau_gpuobj_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	NV_DEBUG(dev, "\n");
+
+	nouveau_gpuobj_del(dev, &dev_priv->ramht);
+}
+
+void
+nouveau_gpuobj_late_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = NULL;
+	struct list_head *entry, *tmp;
+
+	NV_DEBUG(dev, "\n");
+
+	list_for_each_safe(entry, tmp, &dev_priv->gpuobj_list) {
+		gpuobj = list_entry(entry, struct nouveau_gpuobj, list);
+
+		NV_ERROR(dev, "gpuobj %p still exists at takedown, refs=%d\n",
+			 gpuobj, gpuobj->refcount);
+		gpuobj->refcount = 0;
+		nouveau_gpuobj_del(dev, &gpuobj);
+	}
+}
+
+int
+nouveau_gpuobj_del(struct drm_device *dev, struct nouveau_gpuobj **pgpuobj)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	struct nouveau_gpuobj *gpuobj;
+	int i;
+
+	NV_DEBUG(dev, "gpuobj %p\n", pgpuobj ? *pgpuobj : NULL);
+
+	if (!dev_priv || !pgpuobj || !(*pgpuobj))
+		return -EINVAL;
+	gpuobj = *pgpuobj;
+
+	if (gpuobj->refcount != 0) {
+		NV_ERROR(dev, "gpuobj refcount is %d\n", gpuobj->refcount);
+		return -EINVAL;
+	}
+
+	if (gpuobj->flags & NVOBJ_FLAG_ZERO_FREE) {
+		engine->instmem.prepare_access(dev, true);
+		for (i = 0; i < gpuobj->im_pramin->size; i += 4)
+			INSTANCE_WR(gpuobj, i/4, 0);
+		engine->instmem.finish_access(dev);
+	}
+
+	if (gpuobj->dtor)
+		gpuobj->dtor(dev, gpuobj);
+
+	if (gpuobj->im_backing) {
+		if (gpuobj->flags & NVOBJ_FLAG_FAKE)
+			drm_free(gpuobj->im_backing,
+				 sizeof(*gpuobj->im_backing), DRM_MEM_DRIVER);
+		else
+			engine->instmem.clear(dev, gpuobj);
+	}
+
+	if (gpuobj->im_pramin) {
+		if (gpuobj->flags & NVOBJ_FLAG_FAKE)
+			drm_free(gpuobj->im_pramin, sizeof(*gpuobj->im_pramin),
+				 DRM_MEM_DRIVER);
+		else
+			nouveau_mem_free_block(gpuobj->im_pramin);
+	}
+
+	list_del(&gpuobj->list);
+
+	*pgpuobj = NULL;
+	drm_free(gpuobj, sizeof(*gpuobj), DRM_MEM_DRIVER);
+	return 0;
+}
+
+static int
+nouveau_gpuobj_instance_get(struct drm_device *dev,
+			    struct nouveau_channel *chan,
+			    struct nouveau_gpuobj *gpuobj, uint32_t *inst)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *cpramin;
+
+	/* <NV50 use PRAMIN address everywhere */
+	if (dev_priv->card_type < NV_50) {
+		*inst = gpuobj->im_pramin->start;
+		return 0;
+	}
+
+	if (chan && gpuobj->im_channel != chan->id) {
+		NV_ERROR(dev, "Channel mismatch: obj %d, ref %d\n",
+			 gpuobj->im_channel, chan->id);
+		return -EINVAL;
+	}
+
+	/* NV50 channel-local instance */
+	if (chan > 0) {
+		cpramin = chan->ramin->gpuobj;
+		*inst = gpuobj->im_pramin->start - cpramin->im_pramin->start;
+		return 0;
+	}
+
+	/* NV50 global (VRAM) instance */
+	if (gpuobj->im_channel < 0) {
+		/* ...from global heap */
+		if (!gpuobj->im_backing) {
+			NV_ERROR(dev, "AII, no VRAM backing gpuobj\n");
+			return -EINVAL;
+		}
+		*inst = gpuobj->im_backing->start;
+		return 0;
+	} else {
+		/* ...from local heap */
+		cpramin = dev_priv->fifos[gpuobj->im_channel]->ramin->gpuobj;
+		*inst = cpramin->im_backing->start +
+			(gpuobj->im_pramin->start - cpramin->im_pramin->start);
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+int
+nouveau_gpuobj_ref_add(struct drm_device *dev, struct nouveau_channel *chan,
+		       uint32_t handle, struct nouveau_gpuobj *gpuobj,
+		       struct nouveau_gpuobj_ref **ref_ret)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj_ref *ref;
+	uint32_t instance;
+	int ret;
+
+	NV_DEBUG(dev, "ch%d h=0x%08x gpuobj=%p\n",
+		 chan ? chan->id : -1, handle, gpuobj);
+
+	if (!dev_priv || !gpuobj || (ref_ret && *ref_ret != NULL))
+		return -EINVAL;
+
+	if (!chan && !ref_ret)
+		return -EINVAL;
+
+	ret = nouveau_gpuobj_instance_get(dev, chan, gpuobj, &instance);
+	if (ret)
+		return ret;
+
+	ref = drm_calloc(1, sizeof(*ref), DRM_MEM_DRIVER);
+	if (!ref)
+		return -ENOMEM;
+	ref->gpuobj   = gpuobj;
+	ref->channel  = chan ? chan->id : -1;
+	ref->instance = instance;
+
+	if (!ref_ret) {
+		ref->handle = handle;
+
+		ret = nouveau_ramht_insert(dev, ref);
+		if (ret) {
+			drm_free(ref, sizeof(*ref), DRM_MEM_DRIVER);
+			return ret;
+		}
+	} else {
+		ref->handle = ~0;
+		*ref_ret = ref;
+	}
+
+	ref->gpuobj->refcount++;
+	return 0;
+}
+
+int nouveau_gpuobj_ref_del(struct drm_device *dev, struct nouveau_gpuobj_ref **pref)
+{
+	struct nouveau_gpuobj_ref *ref;
+
+	NV_DEBUG(dev, "ref %p\n", pref ? *pref : NULL);
+
+	if (!dev || !pref || *pref == NULL)
+		return -EINVAL;
+	ref = *pref;
+
+	if (ref->handle != ~0)
+		nouveau_ramht_remove(dev, ref);
+
+	if (ref->gpuobj) {
+		ref->gpuobj->refcount--;
+
+		if (ref->gpuobj->refcount == 0) {
+			if (!(ref->gpuobj->flags & NVOBJ_FLAG_ALLOW_NO_REFS))
+				nouveau_gpuobj_del(dev, &ref->gpuobj);
+		}
+	}
+
+	*pref = NULL;
+	drm_free(ref, sizeof(ref), DRM_MEM_DRIVER);
+	return 0;
+}
+
+int
+nouveau_gpuobj_new_ref(struct drm_device *dev,
+		       struct nouveau_channel *oc, struct nouveau_channel *rc,
+		       uint32_t handle, int size, int align, uint32_t flags,
+		       struct nouveau_gpuobj_ref **ref)
+{
+	struct nouveau_gpuobj *gpuobj = NULL;
+	int ret;
+
+	if ((ret = nouveau_gpuobj_new(dev, oc, size, align, flags, &gpuobj)))
+		return ret;
+
+	if ((ret = nouveau_gpuobj_ref_add(dev, rc, handle, gpuobj, ref))) {
+		nouveau_gpuobj_del(dev, &gpuobj);
+		return ret;
+	}
+
+	return 0;
+}
+
+int
+nouveau_gpuobj_ref_find(struct nouveau_channel *chan, uint32_t handle,
+			struct nouveau_gpuobj_ref **ref_ret)
+{
+	struct nouveau_gpuobj_ref *ref;
+	struct list_head *entry, *tmp;
+
+	list_for_each_safe(entry, tmp, &chan->ramht_refs) {
+		ref = list_entry(entry, struct nouveau_gpuobj_ref, list);
+
+		if (ref->handle == handle) {
+			if (ref_ret)
+				*ref_ret = ref;
+			return 0;
+		}
+	}
+
+	return -EINVAL;
+}
+
+int
+nouveau_gpuobj_new_fake(struct drm_device *dev, uint32_t p_offset,
+			uint32_t b_offset, uint32_t size,
+			uint32_t flags, struct nouveau_gpuobj **pgpuobj,
+			struct nouveau_gpuobj_ref **pref)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = NULL;
+	int i;
+
+	NV_DEBUG(dev,
+		 "p_offset=0x%08x b_offset=0x%08x size=0x%08x flags=0x%08x\n",
+		 p_offset, b_offset, size, flags);
+
+	gpuobj = drm_calloc(1, sizeof(*gpuobj), DRM_MEM_DRIVER);
+	if (!gpuobj)
+		return -ENOMEM;
+	NV_DEBUG(dev, "gpuobj %p\n", gpuobj);
+	gpuobj->im_channel = -1;
+	gpuobj->flags      = flags | NVOBJ_FLAG_FAKE;
+
+	list_add_tail(&gpuobj->list, &dev_priv->gpuobj_list);
+
+	if (p_offset != ~0) {
+		gpuobj->im_pramin = drm_calloc(1, sizeof(struct mem_block),
+					       DRM_MEM_DRIVER);
+		if (!gpuobj->im_pramin) {
+			nouveau_gpuobj_del(dev, &gpuobj);
+			return -ENOMEM;
+		}
+		gpuobj->im_pramin->start = p_offset;
+		gpuobj->im_pramin->size  = size;
+	}
+
+	if (b_offset != ~0) {
+		gpuobj->im_backing = drm_calloc(1, sizeof(*gpuobj->im_backing),
+					       DRM_MEM_DRIVER);
+		if (!gpuobj->im_backing) {
+			nouveau_gpuobj_del(dev, &gpuobj);
+			return -ENOMEM;
+		}
+		gpuobj->im_backing->start = b_offset;
+		gpuobj->im_backing->size  = size;
+	}
+
+	if (gpuobj->flags & NVOBJ_FLAG_ZERO_ALLOC) {
+		dev_priv->engine.instmem.prepare_access(dev, true);
+		for (i = 0; i < gpuobj->im_pramin->size; i += 4)
+			INSTANCE_WR(gpuobj, i/4, 0);
+		dev_priv->engine.instmem.finish_access(dev);
+	}
+
+	if (pref) {
+		if ((i = nouveau_gpuobj_ref_add(dev, NULL, 0, gpuobj, pref))) {
+			nouveau_gpuobj_del(dev, &gpuobj);
+			return i;
+		}
+	}
+
+	if (pgpuobj)
+		*pgpuobj = gpuobj;
+	return 0;
+}
+
+
+static int
+nouveau_gpuobj_class_instmem_size(struct drm_device *dev, int class)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/*XXX: dodgy hack for now */
+	if (dev_priv->card_type >= NV_50)
+		return 24;
+	if (dev_priv->card_type >= NV_40)
+		return 32;
+	return 16;
+}
+
+/*
+   DMA objects are used to reference a piece of memory in the
+   framebuffer, PCI or AGP address space. Each object is 16 bytes big
+   and looks as follows:
+
+   entry[0]
+   11:0  class (seems like I can always use 0 here)
+   12    page table present?
+   13    page entry linear?
+   15:14 access: 0 rw, 1 ro, 2 wo
+   17:16 target: 0 NV memory, 1 NV memory tiled, 2 PCI, 3 AGP
+   31:20 dma adjust (bits 0-11 of the address)
+   entry[1]
+   dma limit (size of transfer)
+   entry[X]
+   1     0 readonly, 1 readwrite
+   31:12 dma frame address of the page (bits 12-31 of the address)
+   entry[N]
+   page table terminator, same value as the first pte, as does nvidia
+   rivatv uses 0xffffffff
+
+   Non linear page tables need a list of frame addresses afterwards,
+   the rivatv project has some info on this.
+
+   The method below creates a DMA object in instance RAM and returns a handle
+   to it that can be used to set up context objects.
+*/
+int
+nouveau_gpuobj_dma_new(struct nouveau_channel *chan, int class,
+		       uint64_t offset, uint64_t size, int access,
+		       int target, struct nouveau_gpuobj **gpuobj)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;
+	int ret;
+	uint32_t is_scatter_gather = 0;
+
+	/* Total number of pages covered by the request.
+	 */
+	const unsigned int page_count = (size + PAGE_SIZE - 1) / PAGE_SIZE;
+
+
+	NV_DEBUG(dev, "ch%d class=0x%04x offset=0x%llx size=0x%llx\n",
+		 chan->id, class, offset, size);
+	NV_DEBUG(dev, "access=%d target=%d\n", access, target);
+
+	switch (target) {
+        case NV_DMA_TARGET_AGP:
+                 offset += dev_priv->gart_info.aper_base;
+                 break;
+        case NV_DMA_TARGET_PCI_NONLINEAR:
+                /*assume the "offset" is a virtual memory address*/
+                is_scatter_gather = 1;
+                /*put back the right value*/
+                target = NV_DMA_TARGET_PCI;
+                break;
+        default:
+                break;
+        }
+
+	ret = nouveau_gpuobj_new(dev, chan,
+				 is_scatter_gather ? ((page_count << 2) + 12) : nouveau_gpuobj_class_instmem_size(dev, class),
+				 16,
+				 NVOBJ_FLAG_ZERO_ALLOC | NVOBJ_FLAG_ZERO_FREE,
+				 gpuobj);
+	if (ret) {
+		NV_ERROR(dev, "Error creating gpuobj: %d\n", ret);
+		return ret;
+	}
+
+	instmem->prepare_access(dev, true);
+
+	if (dev_priv->card_type < NV_50) {
+		uint32_t frame, adjust, pte_flags = 0;
+		adjust = offset &  0x00000fff;
+		if (access != NV_DMA_ACCESS_RO)
+				pte_flags |= (1<<1);
+
+		if ( ! is_scatter_gather )
+			{
+			frame  = offset & ~0x00000fff;
+
+			INSTANCE_WR(*gpuobj, 0, ((1<<12) | (1<<13) |
+					(adjust << 20) |
+					 (access << 14) |
+					 (target << 16) |
+					  class));
+			INSTANCE_WR(*gpuobj, 1, size - 1);
+			INSTANCE_WR(*gpuobj, 2, frame | pte_flags);
+			INSTANCE_WR(*gpuobj, 3, frame | pte_flags);
+			}
+		else
+			{
+			/* Intial page entry in the scatter-gather area that
+			 * corresponds to the base offset
+			 */
+			unsigned int idx = offset / PAGE_SIZE;
+
+			uint32_t instance_offset;
+			unsigned int i;
+
+			if ((idx + page_count) > dev->sg->pages) {
+				NV_ERROR(dev, "Requested page range exceedes "
+					      "allocated scatter-gather range!");
+				return -E2BIG;
+			}
+
+			NV_DEBUG(dev, "Creating PCI DMA object using virtual zone starting at %#llx, size %d\n", offset, (uint32_t)size);
+	                INSTANCE_WR(*gpuobj, 0, ((1<<12) | (0<<13) |
+                                (adjust << 20) |
+                                (access << 14) |
+                                (target << 16) |
+                                class));
+			INSTANCE_WR(*gpuobj, 1, (uint32_t) size-1);
+
+
+			/*write starting at the third dword*/
+			instance_offset = 2;
+
+			/*for each PAGE, get its bus address, fill in the page table entry, and advance*/
+			for (i = 0; i < page_count; i++) {
+				if (dev->sg->busaddr[idx] == 0) {
+					dev->sg->busaddr[idx] =
+						pci_map_page(dev->pdev,
+							     dev->sg->pagelist[idx],
+							     0,
+							     PAGE_SIZE,
+							     DMA_BIDIRECTIONAL);
+
+					/* Not a 100% sure this is the right kdev in all cases. */
+					if (dma_mapping_error(&dev->primary->kdev, dev->sg->busaddr[idx])) {
+						instmem->finish_access(dev);
+						return -ENOMEM;
+					}
+				}
+
+				frame = (uint32_t) dev->sg->busaddr[idx];
+				INSTANCE_WR(*gpuobj, instance_offset,
+					    frame | pte_flags);
+
+				idx++;
+				instance_offset ++;
+			}
+			}
+	} else {
+		uint32_t flags0, flags5;
+
+		if (target == NV_DMA_TARGET_VIDMEM) {
+			flags0 = 0x00190000;
+			flags5 = 0x00010000;
+		} else {
+			flags0 = 0x7fc00000;
+			flags5 = 0x00080000;
+		}
+
+		INSTANCE_WR(*gpuobj, 0, flags0 | class);
+		INSTANCE_WR(*gpuobj, 1, offset + size - 1);
+		INSTANCE_WR(*gpuobj, 2, offset);
+		INSTANCE_WR(*gpuobj, 5, flags5);
+	}
+	
+	instmem->finish_access(dev);
+
+	(*gpuobj)->engine = NVOBJ_ENGINE_SW;
+	(*gpuobj)->class  = class;
+	return 0;
+}
+
+int
+nouveau_gpuobj_gart_dma_new(struct nouveau_channel *chan,
+			    uint64_t offset, uint64_t size, int access,
+			    struct nouveau_gpuobj **gpuobj,
+			    uint32_t *o_ret)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	if (dev_priv->gart_info.type == NOUVEAU_GART_AGP ||
+	    (dev_priv->card_type >= NV_50 &&
+	     dev_priv->gart_info.type == NOUVEAU_GART_SGDMA)) {
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     offset, size, access,
+					     NV_DMA_TARGET_AGP, gpuobj);
+		if (o_ret)
+			*o_ret = 0;
+	} else
+	if (dev_priv->gart_info.type == NOUVEAU_GART_SGDMA) {
+		*gpuobj = dev_priv->gart_info.sg_ctxdma;
+		if (offset & ~0xffffffffULL) {
+			NV_ERROR(dev, "obj offset exceeds 32-bits\n");
+			return -EINVAL;
+		}
+		if (o_ret)
+			*o_ret = (uint32_t)offset;
+		ret = (*gpuobj != NULL) ? 0 : -EINVAL;
+	} else {
+		NV_ERROR(dev, "Invalid GART type %d\n", dev_priv->gart_info.type);
+		return -EINVAL;
+	}
+
+	return ret;
+}
+
+/* Context objects in the instance RAM have the following structure.
+ * On NV40 they are 32 byte long, on NV30 and smaller 16 bytes.
+
+   NV4 - NV30:
+
+   entry[0]
+   11:0 class
+   12   chroma key enable
+   13   user clip enable
+   14   swizzle enable
+   17:15 patch config:
+       scrcopy_and, rop_and, blend_and, scrcopy, srccopy_pre, blend_pre
+   18   synchronize enable
+   19   endian: 1 big, 0 little
+   21:20 dither mode
+   23    single step enable
+   24    patch status: 0 invalid, 1 valid
+   25    context_surface 0: 1 valid
+   26    context surface 1: 1 valid
+   27    context pattern: 1 valid
+   28    context rop: 1 valid
+   29,30 context beta, beta4
+   entry[1]
+   7:0   mono format
+   15:8  color format
+   31:16 notify instance address
+   entry[2]
+   15:0  dma 0 instance address
+   31:16 dma 1 instance address
+   entry[3]
+   dma method traps
+
+   NV40:
+   No idea what the exact format is. Here's what can be deducted:
+
+   entry[0]:
+   11:0  class  (maybe uses more bits here?)
+   17    user clip enable
+   21:19 patch config
+   25    patch status valid ?
+   entry[1]:
+   15:0  DMA notifier  (maybe 20:0)
+   entry[2]:
+   15:0  DMA 0 instance (maybe 20:0)
+   24    big endian
+   entry[3]:
+   15:0  DMA 1 instance (maybe 20:0)
+   entry[4]:
+   entry[5]:
+   set to 0?
+*/
+int
+nouveau_gpuobj_gr_new(struct nouveau_channel *chan, int class,
+		      struct nouveau_gpuobj **gpuobj)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	NV_DEBUG(dev, "ch%d class=0x%04x\n", chan->id, class);
+
+	ret = nouveau_gpuobj_new(dev, chan,
+				 nouveau_gpuobj_class_instmem_size(dev, class),
+				 16,
+				 NVOBJ_FLAG_ZERO_ALLOC | NVOBJ_FLAG_ZERO_FREE,
+				 gpuobj);
+	if (ret) {
+		NV_ERROR(dev, "Error creating gpuobj: %d\n", ret);
+		return ret;
+	}
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	if (dev_priv->card_type >= NV_50) {
+		INSTANCE_WR(*gpuobj, 0, class);
+		INSTANCE_WR(*gpuobj, 5, 0x00010000);
+	} else {
+		switch (class) {
+		case NV_CLASS_NULL:
+			INSTANCE_WR(*gpuobj, 0, 0x00001030);
+			INSTANCE_WR(*gpuobj, 1, 0xFFFFFFFF);
+			break;
+		default:
+			if (dev_priv->card_type >= NV_40) {
+				INSTANCE_WR(*gpuobj, 0, class);
+#ifdef __BIG_ENDIAN
+				INSTANCE_WR(*gpuobj, 2, 0x01000000);
+#endif
+			} else {
+#ifdef __BIG_ENDIAN
+				INSTANCE_WR(*gpuobj, 0, class | 0x00080000);
+#else
+				INSTANCE_WR(*gpuobj, 0, class);
+#endif
+			}
+		}
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	(*gpuobj)->engine = NVOBJ_ENGINE_GR;
+	(*gpuobj)->class  = class;
+	return 0;
+}
+
+static int
+nouveau_gpuobj_channel_init_pramin(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *pramin = NULL;
+	int size, base, ret;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	/* Base amount for object storage (4KiB enough?) */
+	size = 0x1000;
+	base = 0;
+
+	/* PGRAPH context */
+
+	if (dev_priv->card_type == NV_50) {
+		/* Various fixed table thingos */
+		size += 0x1400; /* mostly unknown stuff */
+		size += 0x4000; /* vm pd */
+		base  = 0x6000;
+		/* RAMHT, not sure about setting size yet, 32KiB to be safe */
+		size += 0x8000;
+		/* RAMFC */
+		size += 0x1000;
+		/* PGRAPH context */
+		size += 0x70000;
+	}
+
+	NV_DEBUG(dev, "ch%d PRAMIN size: 0x%08x bytes, base alloc=0x%08x\n",
+		 chan->id, size, base);
+	ret = nouveau_gpuobj_new_ref(dev, NULL, NULL, 0, size, 0x1000, 0,
+				     &chan->ramin);
+	if (ret) {
+		NV_ERROR(dev, "Error allocating channel PRAMIN: %d\n", ret);
+		return ret;
+	}
+	pramin = chan->ramin->gpuobj;
+
+	ret = nouveau_mem_init_heap(&chan->ramin_heap,
+				    pramin->im_pramin->start + base, size);
+	if (ret) {
+		NV_ERROR(dev, "Error creating PRAMIN heap: %d\n", ret);
+		nouveau_gpuobj_ref_del(dev, &chan->ramin);
+		return ret;
+	}
+
+	return 0;
+}
+
+int
+nouveau_gpuobj_channel_init(struct nouveau_channel *chan,
+			    uint32_t vram_h, uint32_t tt_h)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;
+	struct nouveau_gpuobj *vram = NULL, *tt = NULL;
+	int ret, i;
+
+	INIT_LIST_HEAD(&chan->ramht_refs);
+
+	NV_DEBUG(dev, "ch%d vram=0x%08x tt=0x%08x\n", chan->id, vram_h, tt_h);
+
+	/* Reserve a block of PRAMIN for the channel
+	 *XXX: maybe on <NV50 too at some point
+	 */
+	if (0 || dev_priv->card_type == NV_50) {
+		ret = nouveau_gpuobj_channel_init_pramin(chan);
+		if (ret) {
+			NV_ERROR(dev, "init pramin\n");
+			return ret;
+		}
+	}
+
+	/* NV50 VM
+	 *  - Allocate per-channel page-directory
+	 *  - Map GART and VRAM into the channel's address space at the
+	 *    locations determined during init.
+	 */
+	if (dev_priv->card_type >= NV_50) {
+		uint32_t vm_offset, pde;
+
+		instmem->prepare_access(dev, true);
+
+		vm_offset = (dev_priv->chipset & 0xf0) == 0x50 ? 0x1400 : 0x200;
+		vm_offset += chan->ramin->gpuobj->im_pramin->start;
+		if ((ret = nouveau_gpuobj_new_fake(dev, vm_offset, ~0, 0x4000,
+						   0, &chan->vm_pd, NULL)))
+			return ret;
+		for (i=0; i<0x4000; i+=8) {
+			INSTANCE_WR(chan->vm_pd, (i+0)/4, 0x00000000);
+			INSTANCE_WR(chan->vm_pd, (i+4)/4, 0xdeadcafe);
+		}
+
+		pde = (dev_priv->vm_gart_base / (512*1024*1024)) * 2;
+		ret = nouveau_gpuobj_ref_add(dev, NULL, 0,
+					     dev_priv->gart_info.sg_ctxdma,
+					     &chan->vm_gart_pt);
+		if (ret) {
+			instmem->finish_access(dev);
+			return ret;
+		}
+		INSTANCE_WR(chan->vm_pd, pde++,
+			    chan->vm_gart_pt->instance | 0x03);
+		INSTANCE_WR(chan->vm_pd, pde++, 0x00000000);
+
+		chan->vm_vram_pt =
+			drm_calloc(dev_priv->vm_vram_pt_nr,
+				   sizeof(struct nouveau_gpuobj_ref *),
+				   DRM_MEM_DRIVER);
+		if (!chan->vm_vram_pt) {
+			instmem->finish_access(dev);
+			return -ENOMEM;
+		}
+
+		pde = (dev_priv->vm_vram_base / (512*1024*1024)) * 2;
+		for (i = 0; i < dev_priv->vm_vram_pt_nr; i++) {
+			ret = nouveau_gpuobj_ref_add(dev, NULL, 0,
+						     dev_priv->vm_vram_pt[i],
+						     &chan->vm_vram_pt[i]);
+			if (ret) {
+				instmem->finish_access(dev);
+				return ret;
+			}
+
+			INSTANCE_WR(chan->vm_pd, pde++,
+				    chan->vm_vram_pt[i]->instance | 0x61);
+			INSTANCE_WR(chan->vm_pd, pde++, 0x00000000);
+		}
+
+		instmem->finish_access(dev);
+	}
+
+	/* RAMHT */
+	if (dev_priv->card_type < NV_50) {
+		ret = nouveau_gpuobj_ref_add(dev, NULL, 0, dev_priv->ramht,
+					     &chan->ramht);
+		if (ret)
+			return ret;
+	} else {
+		ret = nouveau_gpuobj_new_ref(dev, chan, chan, 0,
+					     0x8000, 16,
+					     NVOBJ_FLAG_ZERO_ALLOC,
+					     &chan->ramht);
+		if (ret)
+			return ret;
+	}
+
+	/* VRAM ctxdma */
+	if (dev_priv->card_type >= NV_50) {
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     0, dev_priv->vm_end,
+					     NV_DMA_ACCESS_RW,
+					     NV_DMA_TARGET_AGP, &vram);
+		if (ret) {
+			NV_ERROR(dev, "Error creating VRAM ctxdma: %d\n", ret);
+			return ret;
+		}
+	} else
+	if ((ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					  0, dev_priv->fb_available_size,
+					  NV_DMA_ACCESS_RW,
+					  NV_DMA_TARGET_VIDMEM, &vram))) {
+		NV_ERROR(dev, "Error creating VRAM ctxdma: %d\n", ret);
+		return ret;
+	}
+
+	if ((ret = nouveau_gpuobj_ref_add(dev, chan, vram_h, vram, NULL))) {
+		NV_ERROR(dev, "Error referencing VRAM ctxdma: %d\n", ret);
+		return ret;
+	}
+
+	/* TT memory ctxdma */
+	if (dev_priv->card_type >= NV_50) {
+		tt = vram;
+	} else
+	if (dev_priv->gart_info.type != NOUVEAU_GART_NONE) {
+		ret = nouveau_gpuobj_gart_dma_new(chan, 0,
+						  dev_priv->gart_info.aper_size,
+						  NV_DMA_ACCESS_RW, &tt, NULL);
+	} else
+	if (dev_priv->pci_heap) {
+		ret = nouveau_gpuobj_dma_new(chan, NV_CLASS_DMA_IN_MEMORY,
+					     0, dev->sg->pages * PAGE_SIZE,
+					     NV_DMA_ACCESS_RW,
+					     NV_DMA_TARGET_PCI_NONLINEAR, &tt);
+	} else {
+		NV_ERROR(dev, "Invalid GART type %d\n", dev_priv->gart_info.type);
+		ret = -EINVAL;
+	}
+
+	if (ret) {
+		NV_ERROR(dev, "Error creating TT ctxdma: %d\n", ret);
+		return ret;
+	}
+
+	ret = nouveau_gpuobj_ref_add(dev, chan, tt_h, tt, NULL);
+	if (ret) {
+		NV_ERROR(dev, "Error referencing TT ctxdma: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+void
+nouveau_gpuobj_channel_takedown(struct nouveau_channel *chan)
+{
+	struct drm_nouveau_private *dev_priv = chan->dev->dev_private;
+	struct drm_device *dev = chan->dev;
+	struct list_head *entry, *tmp;
+	struct nouveau_gpuobj_ref *ref;
+	int i;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	if (!chan->ramht_refs.next)
+		return;
+
+	list_for_each_safe(entry, tmp, &chan->ramht_refs) {
+		ref = list_entry(entry, struct nouveau_gpuobj_ref, list);
+
+		nouveau_gpuobj_ref_del(dev, &ref);
+	}
+
+	nouveau_gpuobj_ref_del(dev, &chan->ramht);
+
+	nouveau_gpuobj_del(dev, &chan->vm_pd);
+	nouveau_gpuobj_ref_del(dev, &chan->vm_gart_pt);
+	if (chan->vm_vram_pt) {
+		for (i = 0; i < dev_priv->vm_vram_pt_nr; i++)
+			nouveau_gpuobj_ref_del(dev, &chan->vm_vram_pt[i]);
+		drm_free(chan->vm_vram_pt, dev_priv->vm_vram_pt_nr *
+			 sizeof(struct nouveau_gpuobj_ref *), DRM_MEM_DRIVER);
+	}
+
+	if (chan->ramin_heap)
+		nouveau_mem_takedown(&chan->ramin_heap);
+	if (chan->ramin)
+		nouveau_gpuobj_ref_del(dev, &chan->ramin);
+
+}
+
+int nouveau_ioctl_grobj_alloc(struct drm_device *dev, void *data,
+			      struct drm_file *file_priv)
+{
+	struct nouveau_channel *chan;
+	struct drm_nouveau_grobj_alloc *init = data;
+	struct nouveau_gpuobj *gr = NULL;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(init->channel, file_priv, chan);
+
+	//FIXME: check args, only allow trusted objects to be created
+
+	if (init->handle == ~0)
+		return -EINVAL;
+
+	if (nouveau_gpuobj_ref_find(chan, init->handle, NULL) == 0)
+		return -EEXIST;
+
+	ret = nouveau_gpuobj_gr_new(chan, init->class, &gr);
+	if (ret) {
+		NV_ERROR(dev, "Error creating gr object: %d (%d/0x%08x)\n",
+			 ret, init->channel, init->handle);
+		return ret;
+	}
+
+	if ((ret = nouveau_gpuobj_ref_add(dev, chan, init->handle, gr, NULL))) {
+		NV_ERROR(dev, "Error referencing gr object: %d (%d/0x%08x\n)",
+			 ret, init->channel, init->handle);
+		nouveau_gpuobj_del(dev, &gr);
+		return ret;
+	}
+
+	return 0;
+}
+
+int nouveau_ioctl_gpuobj_free(struct drm_device *dev, void *data,
+			      struct drm_file *file_priv)
+{
+	struct drm_nouveau_gpuobj_free *objfree = data;
+	struct nouveau_gpuobj_ref *ref;
+	struct nouveau_channel *chan;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+	NOUVEAU_GET_USER_CHANNEL_WITH_RETURN(objfree->channel, file_priv, chan);
+
+	if ((ret = nouveau_gpuobj_ref_find(chan, objfree->handle, &ref)))
+		return ret;
+	nouveau_gpuobj_ref_del(dev, &ref);
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_reg.h b/drivers/gpu/drm/nouveau/nouveau_reg.h
new file mode 100644
index 0000000..44337e6
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_reg.h
@@ -0,0 +1,835 @@
+
+
+#define NV03_BOOT_0                                        0x00100000
+#    define NV03_BOOT_0_RAM_AMOUNT                         0x00000003
+#    define NV03_BOOT_0_RAM_AMOUNT_8MB                     0x00000000
+#    define NV03_BOOT_0_RAM_AMOUNT_2MB                     0x00000001
+#    define NV03_BOOT_0_RAM_AMOUNT_4MB                     0x00000002
+#    define NV03_BOOT_0_RAM_AMOUNT_8MB_SDRAM               0x00000003
+#    define NV04_BOOT_0_RAM_AMOUNT_32MB                    0x00000000
+#    define NV04_BOOT_0_RAM_AMOUNT_4MB                     0x00000001
+#    define NV04_BOOT_0_RAM_AMOUNT_8MB                     0x00000002
+#    define NV04_BOOT_0_RAM_AMOUNT_16MB                    0x00000003
+
+#define NV04_FIFO_DATA                                     0x0010020c
+#    define NV10_FIFO_DATA_RAM_AMOUNT_MB_MASK              0xfff00000
+#    define NV10_FIFO_DATA_RAM_AMOUNT_MB_SHIFT             20
+
+#define NV_RAMIN                                           0x00700000
+
+#define NV_RAMHT_HANDLE_OFFSET                             0
+#define NV_RAMHT_CONTEXT_OFFSET                            4
+#    define NV_RAMHT_CONTEXT_VALID                         (1<<31)
+#    define NV_RAMHT_CONTEXT_CHANNEL_SHIFT                 24
+#    define NV_RAMHT_CONTEXT_ENGINE_SHIFT                  16
+#        define NV_RAMHT_CONTEXT_ENGINE_SOFTWARE           0
+#        define NV_RAMHT_CONTEXT_ENGINE_GRAPHICS           1
+#    define NV_RAMHT_CONTEXT_INSTANCE_SHIFT                0
+#    define NV40_RAMHT_CONTEXT_CHANNEL_SHIFT               23
+#    define NV40_RAMHT_CONTEXT_ENGINE_SHIFT                20
+#    define NV40_RAMHT_CONTEXT_INSTANCE_SHIFT              0
+
+/* DMA object defines */
+#define NV_DMA_ACCESS_RW 0
+#define NV_DMA_ACCESS_RO 1
+#define NV_DMA_ACCESS_WO 2
+#define NV_DMA_TARGET_VIDMEM 0
+#define NV_DMA_TARGET_PCI    2
+#define NV_DMA_TARGET_AGP    3
+/* The following is not a real value used by the card, it's changed by
+ * nouveau_object_dma_create */
+#define NV_DMA_TARGET_PCI_NONLINEAR 8
+
+/* Some object classes we care about in the drm */
+#define NV_CLASS_DMA_FROM_MEMORY                           0x00000002
+#define NV_CLASS_DMA_TO_MEMORY                             0x00000003
+#define NV_CLASS_NULL                                      0x00000030
+#define NV_CLASS_DMA_IN_MEMORY                             0x0000003D
+
+#define NV03_USER(i)                             (0x00800000+(i*NV03_USER_SIZE))
+#define NV03_USER__SIZE                                                       16
+#define NV10_USER__SIZE                                                       32
+#define NV03_USER_SIZE                                                0x00010000
+#define NV03_USER_DMA_PUT(i)                     (0x00800040+(i*NV03_USER_SIZE))
+#define NV03_USER_DMA_PUT__SIZE                                               16
+#define NV10_USER_DMA_PUT__SIZE                                               32
+#define NV03_USER_DMA_GET(i)                     (0x00800044+(i*NV03_USER_SIZE))
+#define NV03_USER_DMA_GET__SIZE                                               16
+#define NV10_USER_DMA_GET__SIZE                                               32
+#define NV03_USER_REF_CNT(i)                     (0x00800048+(i*NV03_USER_SIZE))
+#define NV03_USER_REF_CNT__SIZE                                               16
+#define NV10_USER_REF_CNT__SIZE                                               32
+
+#define NV40_USER(i)                             (0x00c00000+(i*NV40_USER_SIZE))
+#define NV40_USER_SIZE                                                0x00001000
+#define NV40_USER_DMA_PUT(i)                     (0x00c00040+(i*NV40_USER_SIZE))
+#define NV40_USER_DMA_PUT__SIZE                                               32
+#define NV40_USER_DMA_GET(i)                     (0x00c00044+(i*NV40_USER_SIZE))
+#define NV40_USER_DMA_GET__SIZE                                               32
+#define NV40_USER_REF_CNT(i)                     (0x00c00048+(i*NV40_USER_SIZE))
+#define NV40_USER_REF_CNT__SIZE                                               32
+
+#define NV50_USER(i)                             (0x00c00000+(i*NV50_USER_SIZE))
+#define NV50_USER_SIZE                                                0x00002000
+#define NV50_USER_DMA_PUT(i)                     (0x00c00040+(i*NV50_USER_SIZE))
+#define NV50_USER_DMA_PUT__SIZE                                              128
+#define NV50_USER_DMA_GET(i)                     (0x00c00044+(i*NV50_USER_SIZE))
+#define NV50_USER_DMA_GET__SIZE                                              128
+/*XXX: I don't think this actually exists.. */
+#define NV50_USER_REF_CNT(i)                     (0x00c00048+(i*NV50_USER_SIZE))
+#define NV50_USER_REF_CNT__SIZE                                              128
+
+#define NV03_FIFO_SIZE                                     0x8000UL
+
+#define NV03_PMC_BOOT_0                                    0x00000000
+#define NV03_PMC_BOOT_1                                    0x00000004
+#define NV03_PMC_INTR_0                                    0x00000100
+#    define NV_PMC_INTR_0_PFIFO_PENDING                       (1<< 8)
+#    define NV_PMC_INTR_0_PGRAPH_PENDING                      (1<<12)
+#    define NV_PMC_INTR_0_NV50_I2C_PENDING                  (1<<21)
+#    define NV_PMC_INTR_0_CRTC0_PENDING                       (1<<24)
+#    define NV_PMC_INTR_0_CRTC1_PENDING                       (1<<25)
+#    define NV_PMC_INTR_0_NV50_DISPLAY_PENDING           (1<<26)
+#    define NV_PMC_INTR_0_CRTCn_PENDING                       (3<<24)
+#define NV03_PMC_INTR_EN_0                                 0x00000140
+#    define NV_PMC_INTR_EN_0_MASTER_ENABLE                    (1<< 0)
+#define NV03_PMC_ENABLE                                    0x00000200
+#    define NV_PMC_ENABLE_PFIFO                               (1<< 8)
+#    define NV_PMC_ENABLE_PGRAPH                              (1<<12)
+/* Disabling the below bit breaks newer (G7X only?) mobile chipsets,
+ * the card will hang early on in the X init process.
+ */
+#    define NV_PMC_ENABLE_UNK13                               (1<<13)
+#define NV40_PMC_BACKLIGHT				   0x000015f0
+#	define NV40_PMC_BACKLIGHT_MASK			   0x001f0000
+#define NV40_PMC_1700                                      0x00001700
+#define NV40_PMC_1704                                      0x00001704
+#define NV40_PMC_1708                                      0x00001708
+#define NV40_PMC_170C                                      0x0000170C
+
+/* probably PMC ? */
+#define NV50_PUNK_BAR0_PRAMIN                              0x00001700
+#define NV50_PUNK_BAR_CFG_BASE                             0x00001704
+#define NV50_PUNK_BAR_CFG_BASE_VALID                          (1<<30)
+#define NV50_PUNK_BAR1_CTXDMA                              0x00001708
+#define NV50_PUNK_BAR1_CTXDMA_VALID                           (1<<31)
+#define NV50_PUNK_BAR3_CTXDMA                              0x0000170C
+#define NV50_PUNK_BAR3_CTXDMA_VALID                           (1<<31)
+#define NV50_PUNK_UNK1710                                  0x00001710
+
+#define NV04_PBUS_PCI_NV_1                                 0x00001804
+#define NV04_PBUS_PCI_NV_19                                0x0000184C
+#define NV04_PBUS_PCI_NV_20				0x00001850
+#	define NV04_PBUS_PCI_NV_20_ROM_SHADOW_DISABLED		(0 << 0)
+#	define NV04_PBUS_PCI_NV_20_ROM_SHADOW_ENABLED		(1 << 0)
+
+#define NV04_PTIMER_INTR_0                                 0x00009100
+#define NV04_PTIMER_INTR_EN_0                              0x00009140
+#define NV04_PTIMER_NUMERATOR                              0x00009200
+#define NV04_PTIMER_DENOMINATOR                            0x00009210
+#define NV04_PTIMER_TIME_0                                 0x00009400
+#define NV04_PTIMER_TIME_1                                 0x00009410
+#define NV04_PTIMER_ALARM_0                                0x00009420
+
+#define NV04_PFB_CFG0                                      0x00100200
+#define NV04_PFB_CFG1                                      0x00100204
+#define NV40_PFB_020C                                      0x0010020C
+#define NV10_PFB_TILE(i)                                   (0x00100240 + (i*16))
+#define NV10_PFB_TILE__SIZE                                8
+#define NV10_PFB_TLIMIT(i)                                 (0x00100244 + (i*16))
+#define NV10_PFB_TSIZE(i)                                  (0x00100248 + (i*16))
+#define NV10_PFB_TSTATUS(i)                                (0x0010024C + (i*16))
+#define NV10_PFB_CLOSE_PAGE2                               0x0010033C
+#define NV40_PFB_TILE(i)                                   (0x00100600 + (i*16))
+#define NV40_PFB_TILE__SIZE_0                              12
+#define NV40_PFB_TILE__SIZE_1                              15
+#define NV40_PFB_TLIMIT(i)                                 (0x00100604 + (i*16))
+#define NV40_PFB_TSIZE(i)                                  (0x00100608 + (i*16))
+#define NV40_PFB_TSTATUS(i)                                (0x0010060C + (i*16))
+#define NV40_PFB_UNK_800					0x00100800
+
+#define NV04_PGRAPH_DEBUG_0                                0x00400080
+#define NV04_PGRAPH_DEBUG_1                                0x00400084
+#define NV04_PGRAPH_DEBUG_2                                0x00400088
+#define NV04_PGRAPH_DEBUG_3                                0x0040008c
+#define NV10_PGRAPH_DEBUG_4                                0x00400090
+#define NV03_PGRAPH_INTR                                   0x00400100
+#define NV03_PGRAPH_NSTATUS                                0x00400104
+#    define NV04_PGRAPH_NSTATUS_STATE_IN_USE                  (1<<11)
+#    define NV04_PGRAPH_NSTATUS_INVALID_STATE                 (1<<12)
+#    define NV04_PGRAPH_NSTATUS_BAD_ARGUMENT                  (1<<13)
+#    define NV04_PGRAPH_NSTATUS_PROTECTION_FAULT              (1<<14)
+#    define NV10_PGRAPH_NSTATUS_STATE_IN_USE                  (1<<23)
+#    define NV10_PGRAPH_NSTATUS_INVALID_STATE                 (1<<24)
+#    define NV10_PGRAPH_NSTATUS_BAD_ARGUMENT                  (1<<25)
+#    define NV10_PGRAPH_NSTATUS_PROTECTION_FAULT              (1<<26)
+#define NV03_PGRAPH_NSOURCE                                0x00400108
+#    define NV03_PGRAPH_NSOURCE_NOTIFICATION                  (1<< 0)
+#    define NV03_PGRAPH_NSOURCE_DATA_ERROR                    (1<< 1)
+#    define NV03_PGRAPH_NSOURCE_PROTECTION_ERROR              (1<< 2)
+#    define NV03_PGRAPH_NSOURCE_RANGE_EXCEPTION               (1<< 3)
+#    define NV03_PGRAPH_NSOURCE_LIMIT_COLOR                   (1<< 4)
+#    define NV03_PGRAPH_NSOURCE_LIMIT_ZETA                    (1<< 5)
+#    define NV03_PGRAPH_NSOURCE_ILLEGAL_MTHD                  (1<< 6)
+#    define NV03_PGRAPH_NSOURCE_DMA_R_PROTECTION              (1<< 7)
+#    define NV03_PGRAPH_NSOURCE_DMA_W_PROTECTION              (1<< 8)
+#    define NV03_PGRAPH_NSOURCE_FORMAT_EXCEPTION              (1<< 9)
+#    define NV03_PGRAPH_NSOURCE_PATCH_EXCEPTION               (1<<10)
+#    define NV03_PGRAPH_NSOURCE_STATE_INVALID                 (1<<11)
+#    define NV03_PGRAPH_NSOURCE_DOUBLE_NOTIFY                 (1<<12)
+#    define NV03_PGRAPH_NSOURCE_NOTIFY_IN_USE                 (1<<13)
+#    define NV03_PGRAPH_NSOURCE_METHOD_CNT                    (1<<14)
+#    define NV03_PGRAPH_NSOURCE_BFR_NOTIFICATION              (1<<15)
+#    define NV03_PGRAPH_NSOURCE_DMA_VTX_PROTECTION            (1<<16)
+#    define NV03_PGRAPH_NSOURCE_DMA_WIDTH_A                   (1<<17)
+#    define NV03_PGRAPH_NSOURCE_DMA_WIDTH_B                   (1<<18)
+#define NV03_PGRAPH_INTR_EN                                0x00400140
+#define NV40_PGRAPH_INTR_EN                                0x0040013C
+#    define NV_PGRAPH_INTR_NOTIFY                             (1<< 0)
+#    define NV_PGRAPH_INTR_MISSING_HW                         (1<< 4)
+#    define NV_PGRAPH_INTR_CONTEXT_SWITCH                     (1<<12)
+#    define NV_PGRAPH_INTR_BUFFER_NOTIFY                      (1<<16)
+#    define NV_PGRAPH_INTR_ERROR                              (1<<20)
+#define NV10_PGRAPH_CTX_CONTROL                            0x00400144
+#define NV10_PGRAPH_CTX_USER                               0x00400148
+#define NV10_PGRAPH_CTX_SWITCH1                            0x0040014C
+#define NV10_PGRAPH_CTX_SWITCH2                            0x00400150
+#define NV10_PGRAPH_CTX_SWITCH3                            0x00400154
+#define NV10_PGRAPH_CTX_SWITCH4                            0x00400158
+#define NV10_PGRAPH_CTX_SWITCH5                            0x0040015C
+#define NV04_PGRAPH_CTX_SWITCH1                            0x00400160
+#define NV10_PGRAPH_CTX_CACHE1                             0x00400160
+#define NV04_PGRAPH_CTX_SWITCH2                            0x00400164
+#define NV04_PGRAPH_CTX_SWITCH3                            0x00400168
+#define NV04_PGRAPH_CTX_SWITCH4                            0x0040016C
+#define NV04_PGRAPH_CTX_CONTROL                            0x00400170
+#define NV04_PGRAPH_CTX_USER                               0x00400174
+#define NV04_PGRAPH_CTX_CACHE1                             0x00400180
+#define NV10_PGRAPH_CTX_CACHE2                             0x00400180
+#define NV03_PGRAPH_CTX_CONTROL                            0x00400190
+#define NV03_PGRAPH_CTX_USER                               0x00400194
+#define NV04_PGRAPH_CTX_CACHE2                             0x004001A0
+#define NV10_PGRAPH_CTX_CACHE3                             0x004001A0
+#define NV04_PGRAPH_CTX_CACHE3                             0x004001C0
+#define NV10_PGRAPH_CTX_CACHE4                             0x004001C0
+#define NV04_PGRAPH_CTX_CACHE4                             0x004001E0
+#define NV10_PGRAPH_CTX_CACHE5                             0x004001E0
+#define NV40_PGRAPH_CTXCTL_0304                            0x00400304
+#define NV40_PGRAPH_CTXCTL_0304_XFER_CTX                   0x00000001
+#define NV40_PGRAPH_CTXCTL_UCODE_STAT                      0x00400308
+#define NV40_PGRAPH_CTXCTL_UCODE_STAT_IP_MASK              0xff000000
+#define NV40_PGRAPH_CTXCTL_UCODE_STAT_IP_SHIFT                     24
+#define NV40_PGRAPH_CTXCTL_UCODE_STAT_OP_MASK              0x00ffffff
+#define NV40_PGRAPH_CTXCTL_0310                            0x00400310
+#define NV40_PGRAPH_CTXCTL_0310_XFER_SAVE                  0x00000020
+#define NV40_PGRAPH_CTXCTL_0310_XFER_LOAD                  0x00000040
+#define NV40_PGRAPH_CTXCTL_030C                            0x0040030c
+#define NV40_PGRAPH_CTXCTL_UCODE_INDEX                     0x00400324
+#define NV40_PGRAPH_CTXCTL_UCODE_DATA                      0x00400328
+#define NV40_PGRAPH_CTXCTL_CUR                             0x0040032c
+#define NV40_PGRAPH_CTXCTL_CUR_LOADED                      0x01000000
+#define NV40_PGRAPH_CTXCTL_CUR_INST_MASK                   0x000FFFFF
+#define NV03_PGRAPH_ABS_X_RAM                              0x00400400
+#define NV03_PGRAPH_ABS_Y_RAM                              0x00400480
+#define NV03_PGRAPH_X_MISC                                 0x00400500
+#define NV03_PGRAPH_Y_MISC                                 0x00400504
+#define NV04_PGRAPH_VALID1                                 0x00400508
+#define NV04_PGRAPH_SOURCE_COLOR                           0x0040050C
+#define NV04_PGRAPH_MISC24_0                               0x00400510
+#define NV03_PGRAPH_XY_LOGIC_MISC0                         0x00400514
+#define NV03_PGRAPH_XY_LOGIC_MISC1                         0x00400518
+#define NV03_PGRAPH_XY_LOGIC_MISC2                         0x0040051C
+#define NV03_PGRAPH_XY_LOGIC_MISC3                         0x00400520
+#define NV03_PGRAPH_CLIPX_0                                0x00400524
+#define NV03_PGRAPH_CLIPX_1                                0x00400528
+#define NV03_PGRAPH_CLIPY_0                                0x0040052C
+#define NV03_PGRAPH_CLIPY_1                                0x00400530
+#define NV03_PGRAPH_ABS_ICLIP_XMAX                         0x00400534
+#define NV03_PGRAPH_ABS_ICLIP_YMAX                         0x00400538
+#define NV03_PGRAPH_ABS_UCLIP_XMIN                         0x0040053C
+#define NV03_PGRAPH_ABS_UCLIP_YMIN                         0x00400540
+#define NV03_PGRAPH_ABS_UCLIP_XMAX                         0x00400544
+#define NV03_PGRAPH_ABS_UCLIP_YMAX                         0x00400548
+#define NV03_PGRAPH_ABS_UCLIPA_XMIN                        0x00400560
+#define NV03_PGRAPH_ABS_UCLIPA_YMIN                        0x00400564
+#define NV03_PGRAPH_ABS_UCLIPA_XMAX                        0x00400568
+#define NV03_PGRAPH_ABS_UCLIPA_YMAX                        0x0040056C
+#define NV04_PGRAPH_MISC24_1                               0x00400570
+#define NV04_PGRAPH_MISC24_2                               0x00400574
+#define NV04_PGRAPH_VALID2                                 0x00400578
+#define NV04_PGRAPH_PASSTHRU_0                             0x0040057C
+#define NV04_PGRAPH_PASSTHRU_1                             0x00400580
+#define NV04_PGRAPH_PASSTHRU_2                             0x00400584
+#define NV10_PGRAPH_DIMX_TEXTURE                           0x00400588
+#define NV10_PGRAPH_WDIMX_TEXTURE                          0x0040058C
+#define NV04_PGRAPH_COMBINE_0_ALPHA                        0x00400590
+#define NV04_PGRAPH_COMBINE_0_COLOR                        0x00400594
+#define NV04_PGRAPH_COMBINE_1_ALPHA                        0x00400598
+#define NV04_PGRAPH_COMBINE_1_COLOR                        0x0040059C
+#define NV04_PGRAPH_FORMAT_0                               0x004005A8
+#define NV04_PGRAPH_FORMAT_1                               0x004005AC
+#define NV04_PGRAPH_FILTER_0                               0x004005B0
+#define NV04_PGRAPH_FILTER_1                               0x004005B4
+#define NV03_PGRAPH_MONO_COLOR0                            0x00400600
+#define NV04_PGRAPH_ROP3                                   0x00400604
+#define NV04_PGRAPH_BETA_AND                               0x00400608
+#define NV04_PGRAPH_BETA_PREMULT                           0x0040060C
+#define NV04_PGRAPH_LIMIT_VIOL_PIX                         0x00400610
+#define NV04_PGRAPH_FORMATS                                0x00400618
+#define NV10_PGRAPH_DEBUG_2                                0x00400620
+#define NV04_PGRAPH_BOFFSET0                               0x00400640
+#define NV04_PGRAPH_BOFFSET1                               0x00400644
+#define NV04_PGRAPH_BOFFSET2                               0x00400648
+#define NV04_PGRAPH_BOFFSET3                               0x0040064C
+#define NV04_PGRAPH_BOFFSET4                               0x00400650
+#define NV04_PGRAPH_BOFFSET5                               0x00400654
+#define NV04_PGRAPH_BBASE0                                 0x00400658
+#define NV04_PGRAPH_BBASE1                                 0x0040065C
+#define NV04_PGRAPH_BBASE2                                 0x00400660
+#define NV04_PGRAPH_BBASE3                                 0x00400664
+#define NV04_PGRAPH_BBASE4                                 0x00400668
+#define NV04_PGRAPH_BBASE5                                 0x0040066C
+#define NV04_PGRAPH_BPITCH0                                0x00400670
+#define NV04_PGRAPH_BPITCH1                                0x00400674
+#define NV04_PGRAPH_BPITCH2                                0x00400678
+#define NV04_PGRAPH_BPITCH3                                0x0040067C
+#define NV04_PGRAPH_BPITCH4                                0x00400680
+#define NV04_PGRAPH_BLIMIT0                                0x00400684
+#define NV04_PGRAPH_BLIMIT1                                0x00400688
+#define NV04_PGRAPH_BLIMIT2                                0x0040068C
+#define NV04_PGRAPH_BLIMIT3                                0x00400690
+#define NV04_PGRAPH_BLIMIT4                                0x00400694
+#define NV04_PGRAPH_BLIMIT5                                0x00400698
+#define NV04_PGRAPH_BSWIZZLE2                              0x0040069C
+#define NV04_PGRAPH_BSWIZZLE5                              0x004006A0
+#define NV03_PGRAPH_STATUS                                 0x004006B0
+#define NV04_PGRAPH_STATUS                                 0x00400700
+#define NV04_PGRAPH_TRAPPED_ADDR                           0x00400704
+#define NV04_PGRAPH_TRAPPED_DATA                           0x00400708
+#define NV04_PGRAPH_SURFACE                                0x0040070C
+#define NV10_PGRAPH_TRAPPED_DATA_HIGH                      0x0040070C
+#define NV04_PGRAPH_STATE                                  0x00400710
+#define NV10_PGRAPH_SURFACE                                0x00400710
+#define NV04_PGRAPH_NOTIFY                                 0x00400714
+#define NV10_PGRAPH_STATE                                  0x00400714
+#define NV10_PGRAPH_NOTIFY                                 0x00400718
+
+#define NV04_PGRAPH_FIFO                                   0x00400720
+
+#define NV04_PGRAPH_BPIXEL                                 0x00400724
+#define NV10_PGRAPH_RDI_INDEX                              0x00400750
+#define NV04_PGRAPH_FFINTFC_ST2                            0x00400754
+#define NV10_PGRAPH_RDI_DATA                               0x00400754
+#define NV04_PGRAPH_DMA_PITCH                              0x00400760
+#define NV10_PGRAPH_FFINTFC_ST2                            0x00400764
+#define NV04_PGRAPH_DVD_COLORFMT                           0x00400764
+#define NV04_PGRAPH_SCALED_FORMAT                          0x00400768
+#define NV10_PGRAPH_DMA_PITCH                              0x00400770
+#define NV10_PGRAPH_DVD_COLORFMT                           0x00400774
+#define NV10_PGRAPH_SCALED_FORMAT                          0x00400778
+#define NV20_PGRAPH_CHANNEL_CTX_TABLE                      0x00400780
+#define NV20_PGRAPH_CHANNEL_CTX_POINTER                    0x00400784
+#define NV20_PGRAPH_CHANNEL_CTX_XFER                       0x00400788
+#define NV20_PGRAPH_CHANNEL_CTX_XFER_LOAD                  0x00000001
+#define NV20_PGRAPH_CHANNEL_CTX_XFER_SAVE                  0x00000002
+#define NV04_PGRAPH_PATT_COLOR0                            0x00400800
+#define NV04_PGRAPH_PATT_COLOR1                            0x00400804
+#define NV04_PGRAPH_PATTERN                                0x00400808
+#define NV04_PGRAPH_PATTERN_SHAPE                          0x00400810
+#define NV04_PGRAPH_CHROMA                                 0x00400814
+#define NV04_PGRAPH_CONTROL0                               0x00400818
+#define NV04_PGRAPH_CONTROL1                               0x0040081C
+#define NV04_PGRAPH_CONTROL2                               0x00400820
+#define NV04_PGRAPH_BLEND                                  0x00400824
+#define NV04_PGRAPH_STORED_FMT                             0x00400830
+#define NV04_PGRAPH_PATT_COLORRAM                          0x00400900
+#define NV40_PGRAPH_TILE0(i)                               (0x00400900 + (i*16))
+#define NV40_PGRAPH_TLIMIT0(i)                             (0x00400904 + (i*16))
+#define NV40_PGRAPH_TSIZE0(i)                              (0x00400908 + (i*16))
+#define NV40_PGRAPH_TSTATUS0(i)                            (0x0040090C + (i*16))
+#define NV10_PGRAPH_TILE(i)                                (0x00400B00 + (i*16))
+#define NV10_PGRAPH_TLIMIT(i)                              (0x00400B04 + (i*16))
+#define NV10_PGRAPH_TSIZE(i)                               (0x00400B08 + (i*16))
+#define NV10_PGRAPH_TSTATUS(i)                             (0x00400B0C + (i*16))
+#define NV04_PGRAPH_U_RAM                                  0x00400D00
+#define NV47_PGRAPH_TILE0(i)                               (0x00400D00 + (i*16))
+#define NV47_PGRAPH_TLIMIT0(i)                             (0x00400D04 + (i*16))
+#define NV47_PGRAPH_TSIZE0(i)                              (0x00400D08 + (i*16))
+#define NV47_PGRAPH_TSTATUS0(i)                            (0x00400D0C + (i*16))
+#define NV04_PGRAPH_V_RAM                                  0x00400D40
+#define NV04_PGRAPH_W_RAM                                  0x00400D80
+#define NV10_PGRAPH_COMBINER0_IN_ALPHA                     0x00400E40
+#define NV10_PGRAPH_COMBINER1_IN_ALPHA                     0x00400E44
+#define NV10_PGRAPH_COMBINER0_IN_RGB                       0x00400E48
+#define NV10_PGRAPH_COMBINER1_IN_RGB                       0x00400E4C
+#define NV10_PGRAPH_COMBINER_COLOR0                        0x00400E50
+#define NV10_PGRAPH_COMBINER_COLOR1                        0x00400E54
+#define NV10_PGRAPH_COMBINER0_OUT_ALPHA                    0x00400E58
+#define NV10_PGRAPH_COMBINER1_OUT_ALPHA                    0x00400E5C
+#define NV10_PGRAPH_COMBINER0_OUT_RGB                      0x00400E60
+#define NV10_PGRAPH_COMBINER1_OUT_RGB                      0x00400E64
+#define NV10_PGRAPH_COMBINER_FINAL0                        0x00400E68
+#define NV10_PGRAPH_COMBINER_FINAL1                        0x00400E6C
+#define NV10_PGRAPH_WINDOWCLIP_HORIZONTAL                  0x00400F00
+#define NV10_PGRAPH_WINDOWCLIP_VERTICAL                    0x00400F20
+#define NV10_PGRAPH_XFMODE0                                0x00400F40
+#define NV10_PGRAPH_XFMODE1                                0x00400F44
+#define NV10_PGRAPH_GLOBALSTATE0                           0x00400F48
+#define NV10_PGRAPH_GLOBALSTATE1                           0x00400F4C
+#define NV10_PGRAPH_PIPE_ADDRESS                           0x00400F50
+#define NV10_PGRAPH_PIPE_DATA                              0x00400F54
+#define NV04_PGRAPH_DMA_START_0                            0x00401000
+#define NV04_PGRAPH_DMA_START_1                            0x00401004
+#define NV04_PGRAPH_DMA_LENGTH                             0x00401008
+#define NV04_PGRAPH_DMA_MISC                               0x0040100C
+#define NV04_PGRAPH_DMA_DATA_0                             0x00401020
+#define NV04_PGRAPH_DMA_DATA_1                             0x00401024
+#define NV04_PGRAPH_DMA_RM                                 0x00401030
+#define NV04_PGRAPH_DMA_A_XLATE_INST                       0x00401040
+#define NV04_PGRAPH_DMA_A_CONTROL                          0x00401044
+#define NV04_PGRAPH_DMA_A_LIMIT                            0x00401048
+#define NV04_PGRAPH_DMA_A_TLB_PTE                          0x0040104C
+#define NV04_PGRAPH_DMA_A_TLB_TAG                          0x00401050
+#define NV04_PGRAPH_DMA_A_ADJ_OFFSET                       0x00401054
+#define NV04_PGRAPH_DMA_A_OFFSET                           0x00401058
+#define NV04_PGRAPH_DMA_A_SIZE                             0x0040105C
+#define NV04_PGRAPH_DMA_A_Y_SIZE                           0x00401060
+#define NV04_PGRAPH_DMA_B_XLATE_INST                       0x00401080
+#define NV04_PGRAPH_DMA_B_CONTROL                          0x00401084
+#define NV04_PGRAPH_DMA_B_LIMIT                            0x00401088
+#define NV04_PGRAPH_DMA_B_TLB_PTE                          0x0040108C
+#define NV04_PGRAPH_DMA_B_TLB_TAG                          0x00401090
+#define NV04_PGRAPH_DMA_B_ADJ_OFFSET                       0x00401094
+#define NV04_PGRAPH_DMA_B_OFFSET                           0x00401098
+#define NV04_PGRAPH_DMA_B_SIZE                             0x0040109C
+#define NV04_PGRAPH_DMA_B_Y_SIZE                           0x004010A0
+#define NV40_PGRAPH_TILE1(i)                               (0x00406900 + (i*16))
+#define NV40_PGRAPH_TLIMIT1(i)                             (0x00406904 + (i*16))
+#define NV40_PGRAPH_TSIZE1(i)                              (0x00406908 + (i*16))
+#define NV40_PGRAPH_TSTATUS1(i)                            (0x0040690C + (i*16))
+
+
+/* It's a guess that this works on NV03. Confirmed on NV04, though */
+#define NV04_PFIFO_DELAY_0                                 0x00002040
+#define NV04_PFIFO_DMA_TIMESLICE                           0x00002044
+#define NV04_PFIFO_NEXT_CHANNEL                            0x00002050
+#define NV03_PFIFO_INTR_0                                  0x00002100
+#define NV03_PFIFO_INTR_EN_0                               0x00002140
+#    define NV_PFIFO_INTR_CACHE_ERROR                         (1<< 0)
+#    define NV_PFIFO_INTR_RUNOUT                              (1<< 4)
+#    define NV_PFIFO_INTR_RUNOUT_OVERFLOW                     (1<< 8)
+#    define NV_PFIFO_INTR_DMA_PUSHER                          (1<<12)
+#    define NV_PFIFO_INTR_DMA_PT                              (1<<16)
+#    define NV_PFIFO_INTR_SEMAPHORE                           (1<<20)
+#    define NV_PFIFO_INTR_ACQUIRE_TIMEOUT                     (1<<24)
+#define NV03_PFIFO_RAMHT                                   0x00002210
+#define NV03_PFIFO_RAMFC                                   0x00002214
+#define NV03_PFIFO_RAMRO                                   0x00002218
+#define NV40_PFIFO_RAMFC                                   0x00002220
+#define NV03_PFIFO_CACHES                                  0x00002500
+#define NV04_PFIFO_MODE                                    0x00002504
+#define NV04_PFIFO_DMA                                     0x00002508
+#define NV04_PFIFO_SIZE                                    0x0000250c
+#define NV50_PFIFO_CTX_TABLE(c)                        (0x2600+(c)*4)
+#define NV50_PFIFO_CTX_TABLE__SIZE                                128
+#define NV50_PFIFO_CTX_TABLE_CHANNEL_ENABLED                  (1<<31)
+#define NV50_PFIFO_CTX_TABLE_UNK30_BAD                        (1<<30)
+#define NV50_PFIFO_CTX_TABLE_INSTANCE_MASK_G80             0x0FFFFFFF
+#define NV50_PFIFO_CTX_TABLE_INSTANCE_MASK_G84             0x00FFFFFF
+#define NV03_PFIFO_CACHE0_PUSH0                            0x00003000
+#define NV03_PFIFO_CACHE0_PULL0                            0x00003040
+#define NV04_PFIFO_CACHE0_PULL0                            0x00003050
+#define NV04_PFIFO_CACHE0_PULL1                            0x00003054
+#define NV03_PFIFO_CACHE1_PUSH0                            0x00003200
+#define NV03_PFIFO_CACHE1_PUSH1                            0x00003204
+#define NV03_PFIFO_CACHE1_PUSH1_DMA                            (1<<8)
+#define NV40_PFIFO_CACHE1_PUSH1_DMA                           (1<<16)
+#define NV03_PFIFO_CACHE1_PUSH1_CHID_MASK                  0x0000000f
+#define NV10_PFIFO_CACHE1_PUSH1_CHID_MASK                  0x0000001f
+#define NV50_PFIFO_CACHE1_PUSH1_CHID_MASK                  0x0000007f
+#define NV03_PFIFO_CACHE1_PUT                              0x00003210
+#define NV04_PFIFO_CACHE1_DMA_PUSH                         0x00003220
+#define NV04_PFIFO_CACHE1_DMA_FETCH                        0x00003224
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_8_BYTES         0x00000000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_16_BYTES        0x00000008
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_24_BYTES        0x00000010
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_32_BYTES        0x00000018
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_40_BYTES        0x00000020
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_48_BYTES        0x00000028
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_56_BYTES        0x00000030
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_64_BYTES        0x00000038
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_72_BYTES        0x00000040
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_80_BYTES        0x00000048
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_88_BYTES        0x00000050
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_96_BYTES        0x00000058
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_104_BYTES       0x00000060
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_112_BYTES       0x00000068
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_120_BYTES       0x00000070
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_128_BYTES       0x00000078
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_136_BYTES       0x00000080
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_144_BYTES       0x00000088
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_152_BYTES       0x00000090
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_160_BYTES       0x00000098
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_168_BYTES       0x000000A0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_176_BYTES       0x000000A8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_184_BYTES       0x000000B0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_192_BYTES       0x000000B8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_200_BYTES       0x000000C0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_208_BYTES       0x000000C8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_216_BYTES       0x000000D0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_224_BYTES       0x000000D8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_232_BYTES       0x000000E0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_240_BYTES       0x000000E8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_248_BYTES       0x000000F0
+#    define NV_PFIFO_CACHE1_DMA_FETCH_TRIG_256_BYTES       0x000000F8
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE                 0x0000E000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_32_BYTES        0x00000000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_64_BYTES        0x00002000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_96_BYTES        0x00004000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES       0x00006000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_160_BYTES       0x00008000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_192_BYTES       0x0000A000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_224_BYTES       0x0000C000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_SIZE_256_BYTES       0x0000E000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS             0x001F0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_0           0x00000000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_1           0x00010000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_2           0x00020000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_3           0x00030000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_4           0x00040000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_5           0x00050000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_6           0x00060000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_7           0x00070000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_8           0x00080000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_9           0x00090000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_10          0x000A0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_11          0x000B0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_12          0x000C0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_13          0x000D0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_14          0x000E0000
+#    define NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_15          0x000F0000
+#    define NV_PFIFO_CACHE1_ENDIAN                         0x80000000
+#    define NV_PFIFO_CACHE1_LITTLE_ENDIAN                  0x7FFFFFFF
+#    define NV_PFIFO_CACHE1_BIG_ENDIAN                     0x80000000
+#define NV04_PFIFO_CACHE1_DMA_STATE                        0x00003228
+#define NV04_PFIFO_CACHE1_DMA_INSTANCE                     0x0000322c
+#define NV04_PFIFO_CACHE1_DMA_CTL                          0x00003230
+#define NV04_PFIFO_CACHE1_DMA_PUT                          0x00003240
+#define NV04_PFIFO_CACHE1_DMA_GET                          0x00003244
+#define NV10_PFIFO_CACHE1_REF_CNT                          0x00003248
+#define NV10_PFIFO_CACHE1_DMA_SUBROUTINE                   0x0000324C
+#define NV03_PFIFO_CACHE1_PULL0                            0x00003240
+#define NV04_PFIFO_CACHE1_PULL0                            0x00003250
+#define NV03_PFIFO_CACHE1_PULL1                            0x00003250
+#define NV04_PFIFO_CACHE1_PULL1                            0x00003254
+#define NV04_PFIFO_CACHE1_HASH                             0x00003258
+#define NV10_PFIFO_CACHE1_ACQUIRE_TIMEOUT                  0x00003260
+#define NV10_PFIFO_CACHE1_ACQUIRE_TIMESTAMP                0x00003264
+#define NV10_PFIFO_CACHE1_ACQUIRE_VALUE                    0x00003268
+#define NV10_PFIFO_CACHE1_SEMAPHORE                        0x0000326C
+#define NV03_PFIFO_CACHE1_GET                              0x00003270
+#define NV04_PFIFO_CACHE1_ENGINE                           0x00003280
+#define NV04_PFIFO_CACHE1_DMA_DCOUNT                       0x000032A0
+#define NV40_PFIFO_GRCTX_INSTANCE                          0x000032E0
+#define NV40_PFIFO_UNK32E4                                 0x000032E4
+#define NV04_PFIFO_CACHE1_METHOD(i)                (0x00003800+(i*8))
+#define NV04_PFIFO_CACHE1_DATA(i)                  (0x00003804+(i*8))
+#define NV40_PFIFO_CACHE1_METHOD(i)                (0x00090000+(i*8))
+#define NV40_PFIFO_CACHE1_DATA(i)                  (0x00090004+(i*8))
+
+#define NV_CRTC0_INTSTAT                                   0x00600100
+#define NV_CRTC0_INTEN                                     0x00600140
+#define NV_CRTC1_INTSTAT                                   0x00602100
+#define NV_CRTC1_INTEN                                     0x00602140
+#    define NV_CRTC_INTR_VBLANK                                (1<<0)
+
+/* This name is a partial guess. */
+#define NV50_DISPLAY_SUPERVISOR                     0x00610024
+
+#define NV50_PDISPLAY_BACKLIGHT				0x0061c084
+#	define NV50_PDISPLAY_BACKLIGHT_ENABLE		0x80000000
+
+#define NV04_PRAMIN						0x00700000
+
+/* Fifo commands. These are not regs, neither masks */
+#define NV03_FIFO_CMD_JUMP                                 0x20000000
+#define NV03_FIFO_CMD_JUMP_OFFSET_MASK                     0x1ffffffc
+#define NV03_FIFO_CMD_REWIND                               (NV03_FIFO_CMD_JUMP | (0 & NV03_FIFO_CMD_JUMP_OFFSET_MASK))
+
+/* RAMFC offsets */
+#define NV04_RAMFC_DMA_PUT                                       0x00
+#define NV04_RAMFC_DMA_GET                                       0x04
+#define NV04_RAMFC_DMA_INSTANCE                                  0x08
+#define NV04_RAMFC_DMA_STATE                                     0x0C
+#define NV04_RAMFC_DMA_FETCH                                     0x10
+#define NV04_RAMFC_ENGINE                                        0x14
+#define NV04_RAMFC_PULL1_ENGINE                                  0x18
+
+#define NV10_RAMFC_DMA_PUT                                       0x00
+#define NV10_RAMFC_DMA_GET                                       0x04
+#define NV10_RAMFC_REF_CNT                                       0x08
+#define NV10_RAMFC_DMA_INSTANCE                                  0x0C
+#define NV10_RAMFC_DMA_STATE                                     0x10
+#define NV10_RAMFC_DMA_FETCH                                     0x14
+#define NV10_RAMFC_ENGINE                                        0x18
+#define NV10_RAMFC_PULL1_ENGINE                                  0x1C
+#define NV10_RAMFC_ACQUIRE_VALUE                                 0x20
+#define NV10_RAMFC_ACQUIRE_TIMESTAMP                             0x24
+#define NV10_RAMFC_ACQUIRE_TIMEOUT                               0x28
+#define NV10_RAMFC_SEMAPHORE                                     0x2C
+#define NV10_RAMFC_DMA_SUBROUTINE                                0x30
+
+#define NV40_RAMFC_DMA_PUT                                       0x00
+#define NV40_RAMFC_DMA_GET                                       0x04
+#define NV40_RAMFC_REF_CNT                                       0x08
+#define NV40_RAMFC_DMA_INSTANCE                                  0x0C
+#define NV40_RAMFC_DMA_DCOUNT /* ? */                            0x10
+#define NV40_RAMFC_DMA_STATE                                     0x14
+#define NV40_RAMFC_DMA_FETCH                                     0x18
+#define NV40_RAMFC_ENGINE                                        0x1C
+#define NV40_RAMFC_PULL1_ENGINE                                  0x20
+#define NV40_RAMFC_ACQUIRE_VALUE                                 0x24
+#define NV40_RAMFC_ACQUIRE_TIMESTAMP                             0x28
+#define NV40_RAMFC_ACQUIRE_TIMEOUT                               0x2C
+#define NV40_RAMFC_SEMAPHORE                                     0x30
+#define NV40_RAMFC_DMA_SUBROUTINE                                0x34
+#define NV40_RAMFC_GRCTX_INSTANCE /* guess */                    0x38
+#define NV40_RAMFC_DMA_TIMESLICE                                 0x3C
+#define NV40_RAMFC_UNK_40                                        0x40
+#define NV40_RAMFC_UNK_44                                        0x44
+#define NV40_RAMFC_UNK_48                                        0x48
+#define NV40_RAMFC_UNK_4C                                        0x4C
+#define NV40_RAMFC_UNK_50                                        0x50
+
+/* This is a partial import from rules-ng, a few things may be duplicated.
+ * Eventually we should completely import everything from rules-ng.
+ * For the moment check rules-ng for docs.
+  */
+
+#define NV50_PMC                                            0x00000000
+#define NV50_PMC__LEN                                              0x1
+#define NV50_PMC__ESIZE                                         0x2000
+#    define NV50_PMC_BOOT_0                                 0x00000000
+#        define NV50_PMC_BOOT_0_REVISION                    0x000000ff
+#        define NV50_PMC_BOOT_0_REVISION__SHIFT                      0
+#        define NV50_PMC_BOOT_0_ARCH                        0x0ff00000
+#        define NV50_PMC_BOOT_0_ARCH__SHIFT                         20
+#    define NV50_PMC_INTR_0                                 0x00000100
+#        define NV50_PMC_INTR_0_PFIFO                           (1<<8)
+#        define NV50_PMC_INTR_0_PGRAPH                         (1<<12)
+#        define NV50_PMC_INTR_0_PTIMER                         (1<<20)
+#        define NV50_PMC_INTR_0_HOTPLUG                        (1<<21)
+#        define NV50_PMC_INTR_0_DISPLAY                        (1<<26)
+#    define NV50_PMC_INTR_EN_0                              0x00000140
+#        define NV50_PMC_INTR_EN_0_MASTER                       (1<<0)
+#            define NV50_PMC_INTR_EN_0_MASTER_DISABLED          (0<<0)
+#            define NV50_PMC_INTR_EN_0_MASTER_ENABLED           (1<<0)
+#    define NV50_PMC_ENABLE                                 0x00000200
+#        define NV50_PMC_ENABLE_PFIFO                           (1<<8)
+#        define NV50_PMC_ENABLE_PGRAPH                         (1<<12)
+
+#define NV50_PCONNECTOR                                     0x0000e000
+#define NV50_PCONNECTOR__LEN                                       0x1
+#define NV50_PCONNECTOR__ESIZE                                  0x1000
+#    define NV50_PCONNECTOR_HOTPLUG_INTR                    0x0000e050
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_PLUG_I2C0          (1<<0)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_PLUG_I2C1          (1<<1)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_PLUG_I2C2          (1<<2)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_PLUG_I2C3          (1<<3)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_UNPLUG_I2C0       (1<<16)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_UNPLUG_I2C1       (1<<17)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_UNPLUG_I2C2       (1<<18)
+#        define NV50_PCONNECTOR_HOTPLUG_INTR_UNPLUG_I2C3       (1<<19)
+#    define NV50_PCONNECTOR_HOTPLUG_CTRL                    0x0000e054
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_PLUG_I2C0          (1<<0)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_PLUG_I2C1          (1<<1)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_PLUG_I2C2          (1<<2)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_PLUG_I2C3          (1<<3)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_UNPLUG_I2C0       (1<<16)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_UNPLUG_I2C1       (1<<17)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_UNPLUG_I2C2       (1<<18)
+#        define NV50_PCONNECTOR_HOTPLUG_CTRL_UNPLUG_I2C3       (1<<19)
+#    define NV50_PCONNECTOR_HOTPLUG_STATE                   0x0000e104
+#        define NV50_PCONNECTOR_HOTPLUG_STATE_PIN_CONNECTED_I2C0 (1<<2)
+#        define NV50_PCONNECTOR_HOTPLUG_STATE_PIN_CONNECTED_I2C1 (1<<6)
+#        define NV50_PCONNECTOR_HOTPLUG_STATE_PIN_CONNECTED_I2C2 (1<<10)
+#        define NV50_PCONNECTOR_HOTPLUG_STATE_PIN_CONNECTED_I2C3 (1<<14)
+#    define NV50_PCONNECTOR_I2C_PORT_0                      0x0000e138
+#    define NV50_PCONNECTOR_I2C_PORT_1                      0x0000e150
+#    define NV50_PCONNECTOR_I2C_PORT_2                      0x0000e168
+#    define NV50_PCONNECTOR_I2C_PORT_3                      0x0000e180
+#    define NV50_PCONNECTOR_I2C_PORT_4                      0x0000e240
+#    define NV50_PCONNECTOR_I2C_PORT_5                      0x0000e258
+
+#define NV50_PBUS                                           0x00088000
+#define NV50_PBUS__LEN                                             0x1
+#define NV50_PBUS__ESIZE                                        0x1000
+#    define NV50_PBUS_PCI_ID                                0x00088000
+#        define NV50_PBUS_PCI_ID_VENDOR_ID                  0x0000ffff
+#        define NV50_PBUS_PCI_ID_VENDOR_ID__SHIFT                    0
+#        define NV50_PBUS_PCI_ID_DEVICE_ID                  0xffff0000
+#        define NV50_PBUS_PCI_ID_DEVICE_ID__SHIFT                   16
+
+#define NV50_PFB                                            0x00100000
+#define NV50_PFB__LEN                                              0x1
+#define NV50_PFB__ESIZE                                         0x1000
+
+#define NV50_PEXTDEV                                        0x00101000
+#define NV50_PEXTDEV__LEN                                          0x1
+#define NV50_PEXTDEV__ESIZE                                     0x1000
+
+#define NV50_PROM                                           0x00300000
+#define NV50_PROM__LEN                                             0x1
+#define NV50_PROM__ESIZE                                       0x10000
+
+#define NV50_PGRAPH                                         0x00400000
+#define NV50_PGRAPH__LEN                                           0x1
+#define NV50_PGRAPH__ESIZE                                     0x10000
+
+#define NV50_PDISPLAY                                       0x00610000
+#define NV50_PDISPLAY__LEN                                         0x1
+#define NV50_PDISPLAY__ESIZE                                   0x10000
+#    define NV50_PDISPLAY_SUPERVISOR                        0x00610024
+#        define NV50_PDISPLAY_SUPERVISOR_CRTCn              0x0000000c
+#        define NV50_PDISPLAY_SUPERVISOR_CRTCn__SHIFT                2
+#        define NV50_PDISPLAY_SUPERVISOR_CRTC0                  (1<<2)
+#        define NV50_PDISPLAY_SUPERVISOR_CRTC1                  (1<<3)
+#        define NV50_PDISPLAY_SUPERVISOR_CLK_MASK           0x00000070
+#        define NV50_PDISPLAY_SUPERVISOR_CLK_MASK__SHIFT             4
+#        define NV50_PDISPLAY_SUPERVISOR_CLK_UPDATE             (1<<5)
+#    define NV50_PDISPLAY_SUPERVISOR_INTR                   0x0061002c
+#        define NV50_PDISPLAY_SUPERVISOR_INTR_VBLANK_CRTC0      (1<<2)
+#        define NV50_PDISPLAY_SUPERVISOR_INTR_VBLANK_CRTC1      (1<<3)
+#        define NV50_PDISPLAY_SUPERVISOR_INTR_UNK1              (1<<4)
+#        define NV50_PDISPLAY_SUPERVISOR_INTR_CLK_UPDATE        (1<<5)
+#        define NV50_PDISPLAY_SUPERVISOR_INTR_UNK4              (1<<6)
+#    define NV50_PDISPLAY_UNK30_CTRL                        0x00610030
+#        define NV50_PDISPLAY_UNK30_CTRL_UPDATE_VCLK0           (1<<9)
+#        define NV50_PDISPLAY_UNK30_CTRL_UPDATE_VCLK1          (1<<10)
+#        define NV50_PDISPLAY_UNK30_CTRL_PENDING               (1<<31)
+#    define NV50_PDISPLAY_UNK50_CTRL                        0x00610050
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC0_ACTIVE           (1<<1)
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC0_ACTIVE_MASK  0x00000003
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC0_ACTIVE_MASK__SHIFT    0
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC1_ACTIVE           (1<<9)
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC1_ACTIVE_MASK  0x00000300
+#        define NV50_PDISPLAY_UNK50_CTRL_CRTC1_ACTIVE_MASK__SHIFT    8
+#    define NV50_PDISPLAY_UNK200_CTRL                       0x00610200
+#    define NV50_PDISPLAY_CURSOR                            0x00610270
+#    define NV50_PDISPLAY_CURSOR__LEN                              0x2
+#    define NV50_PDISPLAY_CURSOR__ESIZE                           0x10
+#        define NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(i) (0x00610270+(i)*0x10)
+#            define NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_ON        (1<<0)
+#            define NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_MASK 0x00030000
+#            define NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_MASK__SHIFT 16
+#            define NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_ACTIVE (1<<16)
+
+#    define NV50_PDISPLAY_CTRL_STATE                        0x00610300
+#        define NV50_PDISPLAY_CTRL_STATE_ENABLE                 (1<<0)
+#        define NV50_PDISPLAY_CTRL_STATE_PENDING               (1<<31)
+#    define NV50_PDISPLAY_CTRL_VAL                          0x00610304
+#    define NV50_PDISPLAY_UNK_380                           0x00610380
+#    define NV50_PDISPLAY_RAM_AMOUNT                        0x00610384
+#    define NV50_PDISPLAY_UNK_388                           0x00610388
+#    define NV50_PDISPLAY_UNK_38C                           0x0061038c
+#    define NV50_PDISPLAY_CRTC_VAL                          0x00610a00
+#    define NV50_PDISPLAY_CRTC_VAL__LEN                            0x2
+#            define NV50_PDISPLAY_CRTC_VAL_UNK_900(i,j) (0x00610a18+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_CLUT_MODE(i,j) (0x00610a24+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_INTERLACE(i,j) (0x00610a48+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SCALE_CTRL(i,j) (0x00610a50+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_CURSOR_CTRL(i,j) (0x00610a58+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_UNK_904(i,j) (0x00610ab8+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_DEPTH(i,j) (0x00610ac8+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_CLOCK(i,j) (0x00610ad0+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_COLOR_CTRL(i,j) (0x00610ae0+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SYNC_START_TO_BLANK_END(i,j) (0x00610ae8+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_MODE_UNK1(i,j) (0x00610af0+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_DISPLAY_TOTAL(i,j) (0x00610af8+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SYNC_DURATION(i,j) (0x00610b00+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_MODE_UNK2(i,j) (0x00610b08+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_UNK_828(i,j) (0x00610b10+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_FB_SIZE(i,j) (0x00610b18+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_FB_PITCH(i,j) (0x00610b20+(i)*0x540+(j)*0x4)
+#                define NV50_PDISPLAY_CRTC_VAL_FB_PITCH_LINEAR_FB (1<<20)
+#            define NV50_PDISPLAY_CRTC_VAL_FB_POS(i,j) (0x00610b28+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SCALE_CENTER_OFFSET(i,j) (0x00610b38+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_REAL_RES(i,j) (0x00610b40+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SCALE_RES1(i,j) (0x00610b48+(i)*0x540+(j)*0x4)
+#            define NV50_PDISPLAY_CRTC_VAL_SCALE_RES2(i,j) (0x00610b50+(i)*0x540+(j)*0x4)
+
+
+#            define NV50_PDISPLAY_DAC_VAL_MODE_CTRL(i,j) (0x00610b58+(i)*0x8+(j)*0x4)
+
+
+#            define NV50_PDISPLAY_SOR_VAL_MODE_CTRL(i,j) (0x00610b70+(i)*0x8+(j)*0x4)
+
+
+#            define NV50_PDISPLAY_DAC_VAL_MODE_CTRL2(i,j) (0x00610bdc+(i)*0x8+(j)*0x4)
+
+
+#    define NV50_PDISPLAY_CRTC_CLK                          0x00614000
+#    define NV50_PDISPLAY_CRTC_CLK__LEN                            0x2
+#        define NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1(i) (0x00614100+(i)*0x800)
+#            define NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1_CONNECTED 0x00000600
+#            define NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1_CONNECTED__SHIFT 9
+#        define NV50_PDISPLAY_CRTC_CLK_VPLL_A(i) (0x00614104+(i)*0x800)
+#        define NV50_PDISPLAY_CRTC_CLK_VPLL_B(i) (0x00614108+(i)*0x800)
+#        define NV50_PDISPLAY_CRTC_CLK_CLK_CTRL2(i) (0x00614200+(i)*0x800)
+
+#    define NV50_PDISPLAY_DAC_CLK                           0x00614000
+#    define NV50_PDISPLAY_DAC_CLK__LEN                             0x3
+#        define NV50_PDISPLAY_DAC_CLK_CLK_CTRL2(i) (0x00614280+(i)*0x800)
+
+#    define NV50_PDISPLAY_SOR_CLK                           0x00614000
+#    define NV50_PDISPLAY_SOR_CLK__LEN                             0x3
+#        define NV50_PDISPLAY_SOR_CLK_CLK_CTRL2(i) (0x00614300+(i)*0x800)
+
+#    define NV50_PDISPLAY_DAC_REGS                          0x0061a000
+#    define NV50_PDISPLAY_DAC_REGS__LEN                            0x3
+#    define NV50_PDISPLAY_DAC_REGS__ESIZE                        0x800
+#        define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(i) (0x0061a004+(i)*0x800)
+#            define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_HSYNC_OFF  (1<<0)
+#            define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_VSYNC_OFF  (1<<2)
+#            define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_BLANKED    (1<<4)
+#            define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_OFF        (1<<6)
+#            define NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING   (1<<31)
+#        define NV50_PDISPLAY_DAC_REGS_LOAD_CTRL(i) (0x0061a00c+(i)*0x800)
+#            define NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_ACTIVE    (1<<20)
+#            define NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_PRESENT 0x38000000
+#            define NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_PRESENT__SHIFT 29
+#            define NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_DONE      (1<<31)
+#        define NV50_PDISPLAY_DAC_REGS_CLK_CTRL1(i) (0x0061a010+(i)*0x800)
+#            define NV50_PDISPLAY_DAC_REGS_CLK_CTRL1_CONNECTED 0x00000600
+#            define NV50_PDISPLAY_DAC_REGS_CLK_CTRL1_CONNECTED__SHIFT 9
+
+#    define NV50_PDISPLAY_SOR_REGS                          0x0061c000
+#    define NV50_PDISPLAY_SOR_REGS__LEN                            0x3
+#    define NV50_PDISPLAY_SOR_REGS__ESIZE                        0x800
+#        define NV50_PDISPLAY_SOR_REGS_DPMS_CTRL(i) (0x0061c004+(i)*0x800)
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_ON         (1<<0)
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_PENDING   (1<<31)
+#        define NV50_PDISPLAY_SOR_REGS_CLK_CTRL1(i) (0x0061c008+(i)*0x800)
+#            define NV50_PDISPLAY_SOR_REGS_CLK_CTRL1_CONNECTED 0x00000600
+#            define NV50_PDISPLAY_SOR_REGS_CLK_CTRL1_CONNECTED__SHIFT 9
+#        define NV50_PDISPLAY_SOR_REGS_UNK_00C(i) (0x0061c00c+(i)*0x800)
+#        define NV50_PDISPLAY_SOR_REGS_UNK_010(i) (0x0061c010+(i)*0x800)
+#        define NV50_PDISPLAY_SOR_REGS_UNK_014(i) (0x0061c014+(i)*0x800)
+#        define NV50_PDISPLAY_SOR_REGS_UNK_018(i) (0x0061c018+(i)*0x800)
+#        define NV50_PDISPLAY_SOR_REGS_DPMS_STATE(i) (0x0061c030+(i)*0x800)
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_STATE_ACTIVE 0x00030000
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_STATE_ACTIVE__SHIFT 16
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_STATE_BLANKED  (1<<19)
+#            define NV50_PDISPLAY_SOR_REGS_DPMS_STATE_WAIT     (1<<28)
+
+
+#define NV50_UNK640000                                      0x00640000
+#define NV50_UNK640000__LEN                                        0x6
+#define NV50_UNK640000__ESIZE                                   0x1000
+#    define NV50_UNK640000_UNK_000(i)          (0x00640000+(i)*0x1000)
+
+#define NV50_HW_CURSOR                                      0x00647000
+#define NV50_HW_CURSOR__LEN                                        0x2
+#define NV50_HW_CURSOR__ESIZE                                   0x1000
+#    define NV50_HW_CURSOR_POS_CTRL(i)              (0x00647080+(i)*0x1000)
+#    define NV50_HW_CURSOR_POS(i)         (0x00647084+(i)*0x1000)
diff --git a/drivers/gpu/drm/nouveau/nouveau_sgdma.c b/drivers/gpu/drm/nouveau/nouveau_sgdma.c
new file mode 100644
index 0000000..08b2171
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_sgdma.c
@@ -0,0 +1,340 @@
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include <linux/pagemap.h>
+
+#define NV_CTXDMA_PAGE_SHIFT 12
+#define NV_CTXDMA_PAGE_SIZE  (1 << NV_CTXDMA_PAGE_SHIFT)
+#define NV_CTXDMA_PAGE_MASK  (NV_CTXDMA_PAGE_SIZE - 1)
+
+struct nouveau_sgdma_be {
+	struct drm_ttm_backend backend;
+	struct drm_device *dev;
+
+	struct page **pages;
+	unsigned nr_pages;
+
+	unsigned pte_start;
+	bool bound;
+};
+
+static int
+nouveau_sgdma_needs_ub_cache_adjust(struct drm_ttm_backend *be)
+{
+	return ((be->flags & DRM_BE_FLAG_BOUND_CACHED) ? 0 : 1);
+}
+
+static int
+nouveau_sgdma_populate(struct drm_ttm_backend *be, unsigned long num_pages,
+		       struct page **pages, struct page *dummy_read_page)
+{
+	struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)be;
+
+	NV_DEBUG(nvbe->dev, "num_pages = %ld\n", num_pages);
+
+	if (nvbe->pages)
+		return -EINVAL;
+
+	nvbe->pages = pages;
+	nvbe->nr_pages = num_pages;
+	return 0;
+}
+
+static void
+nouveau_sgdma_clear(struct drm_ttm_backend *be)
+{
+	struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)be;
+
+	NV_DEBUG(nvbe->dev, "\n");
+
+	if (nvbe && nvbe->pages) {
+		if (nvbe->bound)
+			be->func->unbind(be);
+		nvbe->pages = NULL;
+	}
+}
+
+static inline unsigned
+nouveau_sgdma_pte(struct drm_device *dev, uint64_t offset)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	unsigned pte = (offset >> NV_CTXDMA_PAGE_SHIFT);
+
+	if (dev_priv->card_type < NV_50)
+		return pte + 2;
+
+	return pte << 1;
+}
+
+static int
+nouveau_sgdma_bind(struct drm_ttm_backend *be, struct drm_bo_mem_reg *mem)
+{
+	struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)be;
+	struct drm_device *dev = nvbe->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = dev_priv->gart_info.sg_ctxdma;
+	unsigned i, j, pte, tile = 0;
+
+	NV_DEBUG(dev, "pg=0x%lx cached=%d\n", mem->mm_node->start,
+		 (mem->flags & DRM_BO_FLAG_CACHED) == 1);
+
+	if (mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_TILE &&
+	    mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_ZTILE)
+		tile = 0x2800;
+	else
+	if (mem->proposed_flags & DRM_NOUVEAU_BO_FLAG_TILE)
+		tile = 0x7000;
+
+	dev_priv->engine.instmem.prepare_access(nvbe->dev, true);
+	pte = nouveau_sgdma_pte(nvbe->dev, mem->mm_node->start << PAGE_SHIFT);
+	nvbe->pte_start = pte;
+	for (i = 0; i < nvbe->nr_pages; i++) {
+		dma_addr_t dma_offset = page_to_phys(nvbe->pages[i]);
+
+		for (j = 0; j < PAGE_SIZE / NV_CTXDMA_PAGE_SIZE; j++) {
+			if (dev_priv->card_type < NV_50)
+				INSTANCE_WR(gpuobj, pte++, dma_offset | 3);
+			else {
+				INSTANCE_WR(gpuobj, pte++, dma_offset | 0x21);
+				INSTANCE_WR(gpuobj, pte++, tile);
+			}
+
+			dma_offset += NV_CTXDMA_PAGE_SIZE;
+		}
+	}
+	dev_priv->engine.instmem.finish_access(nvbe->dev);
+
+	nvbe->bound = true;
+	return 0;
+}
+
+static int
+nouveau_sgdma_unbind(struct drm_ttm_backend *be)
+{
+	struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)be;
+	struct drm_device *dev = nvbe->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = dev_priv->gart_info.sg_ctxdma;
+	unsigned i, j, pte;
+
+	NV_DEBUG(dev, "\n");
+
+	if (!nvbe->bound)
+		return 0;
+
+	dev_priv->engine.instmem.prepare_access(nvbe->dev, true);
+	pte = nvbe->pte_start;
+	for (i = 0; i < nvbe->nr_pages; i++) {
+		dma_addr_t dma_offset = dev_priv->gart_info.sg_dummy_bus;
+
+		for (j = 0; j < PAGE_SIZE / NV_CTXDMA_PAGE_SIZE; j++) {
+			if (dev_priv->card_type < NV_50)
+				INSTANCE_WR(gpuobj, pte++, dma_offset | 3);
+			else {
+				INSTANCE_WR(gpuobj, pte++, dma_offset | 0x21);
+				INSTANCE_WR(gpuobj, pte++, 0x00000000);
+			}
+
+			dma_offset += NV_CTXDMA_PAGE_SIZE;
+		}
+	}
+	dev_priv->engine.instmem.finish_access(nvbe->dev);
+
+	nvbe->bound = false;
+	return 0;
+}
+
+static void
+nouveau_sgdma_destroy(struct drm_ttm_backend *be)
+{
+	struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)be;
+
+	if (be) {
+		NV_DEBUG(nvbe->dev, "\n");
+
+		if (nvbe) {
+			if (nvbe->pages)
+				be->func->clear(be);
+			drm_ctl_free(nvbe, sizeof(*nvbe), DRM_MEM_TTM);
+		}
+	}
+}
+
+static struct drm_ttm_backend_func nouveau_sgdma_backend = {
+	.needs_ub_cache_adjust	= nouveau_sgdma_needs_ub_cache_adjust,
+	.populate		= nouveau_sgdma_populate,
+	.clear			= nouveau_sgdma_clear,
+	.bind			= nouveau_sgdma_bind,
+	.unbind			= nouveau_sgdma_unbind,
+	.destroy		= nouveau_sgdma_destroy
+};
+
+struct drm_ttm_backend *
+nouveau_sgdma_init_ttm(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_sgdma_be *nvbe;
+
+	if (!dev_priv->gart_info.sg_ctxdma)
+		return NULL;
+
+	nvbe = drm_ctl_calloc(1, sizeof(*nvbe), DRM_MEM_TTM);
+	if (!nvbe)
+		return NULL;
+
+	nvbe->dev = dev;
+
+	nvbe->backend.func	= &nouveau_sgdma_backend;
+
+	return &nvbe->backend;
+}
+
+int
+nouveau_sgdma_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = NULL;
+	uint32_t aper_size, obj_size;
+	int i, ret;
+
+	if (dev_priv->card_type < NV_50) {
+		aper_size = (64 * 1024 * 1024);
+		obj_size  = (aper_size >> NV_CTXDMA_PAGE_SHIFT) * 4;
+		obj_size += 8; /* ctxdma header */
+	} else {
+		/* 1 entire VM page table */
+		aper_size = (512 * 1024 * 1024);
+		obj_size  = (aper_size >> NV_CTXDMA_PAGE_SHIFT) * 8;
+	}
+
+	if ((ret = nouveau_gpuobj_new(dev, NULL, obj_size, 16,
+				      NVOBJ_FLAG_ALLOW_NO_REFS |
+				      NVOBJ_FLAG_ZERO_ALLOC |
+				      NVOBJ_FLAG_ZERO_FREE, &gpuobj)))  {
+		NV_ERROR(dev, "Error creating sgdma object: %d\n", ret);
+		return ret;
+	}
+
+	dev_priv->gart_info.sg_dummy_page =
+		alloc_page(GFP_KERNEL|__GFP_DMA32);
+	set_bit(PG_locked, &dev_priv->gart_info.sg_dummy_page->flags);
+	dev_priv->gart_info.sg_dummy_bus =
+		pci_map_page(dev->pdev, dev_priv->gart_info.sg_dummy_page, 0,
+			     PAGE_SIZE, PCI_DMA_BIDIRECTIONAL);
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	if (dev_priv->card_type < NV_50) {
+		/* Maybe use NV_DMA_TARGET_AGP for PCIE? NVIDIA do this, and
+		 * confirmed to work on c51.  Perhaps means NV_DMA_TARGET_PCIE
+		 * on those cards? */
+		INSTANCE_WR(gpuobj, 0, NV_CLASS_DMA_IN_MEMORY |
+				       (1 << 12) /* PT present */ |
+				       (0 << 13) /* PT *not* linear */ |
+				       (NV_DMA_ACCESS_RW  << 14) |
+				       (NV_DMA_TARGET_PCI << 16));
+		INSTANCE_WR(gpuobj, 1, aper_size - 1);
+		for (i=2; i<2+(aper_size>>12); i++) {
+			INSTANCE_WR(gpuobj, i,
+				    dev_priv->gart_info.sg_dummy_bus | 3);
+		}
+	} else {
+		for (i=0; i<obj_size; i+=8) {
+			INSTANCE_WR(gpuobj, (i+0)/4,
+				    dev_priv->gart_info.sg_dummy_bus | 0x21);
+			INSTANCE_WR(gpuobj, (i+4)/4, 0);
+		}
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	dev_priv->gart_info.type      = NOUVEAU_GART_SGDMA;
+	dev_priv->gart_info.aper_base = 0;
+	dev_priv->gart_info.aper_size = aper_size;
+	dev_priv->gart_info.sg_ctxdma = gpuobj;
+	return 0;
+}
+
+void
+nouveau_sgdma_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->gart_info.sg_dummy_page) {
+		pci_unmap_page(dev->pdev, dev_priv->gart_info.sg_dummy_bus,
+			       NV_CTXDMA_PAGE_SIZE, PCI_DMA_BIDIRECTIONAL);
+		unlock_page(dev_priv->gart_info.sg_dummy_page);
+		__free_page(dev_priv->gart_info.sg_dummy_page);
+		dev_priv->gart_info.sg_dummy_page = NULL;
+		dev_priv->gart_info.sg_dummy_bus = 0;
+	}
+
+	nouveau_gpuobj_del(dev, &dev_priv->gart_info.sg_ctxdma);
+}
+
+int
+nouveau_sgdma_nottm_hack_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_ttm_backend *be;
+	struct drm_scatter_gather sgreq;
+	struct drm_mm_node mm_node;
+	struct drm_bo_mem_reg mem;
+	int ret;
+
+	dev_priv->gart_info.sg_be = nouveau_sgdma_init_ttm(dev);
+	if (!dev_priv->gart_info.sg_be)
+		return -ENOMEM;
+	be = dev_priv->gart_info.sg_be;
+
+	/* Hack the aperture size down to the amount of system memory
+	 * we're going to bind into it.
+	 */
+	if (dev_priv->gart_info.aper_size > 32*1024*1024)
+		dev_priv->gart_info.aper_size = 32*1024*1024;
+
+	sgreq.size = dev_priv->gart_info.aper_size;
+	if ((ret = drm_sg_alloc(dev, &sgreq))) {
+		NV_ERROR(dev, "drm_sg_alloc failed: %d\n", ret);
+		return ret;
+	}
+	dev_priv->gart_info.sg_handle = sgreq.handle;
+
+	if ((ret = be->func->populate(be, dev->sg->pages, dev->sg->pagelist, dev->bm.dummy_read_page))) {
+		NV_ERROR(dev, "failed populate: %d\n", ret);
+		return ret;
+	}
+
+	mm_node.start = 0;
+	mem.mm_node = &mm_node;
+	mem.proposed_flags = 0;
+
+	if ((ret = be->func->bind(be, &mem))) {
+		NV_ERROR(dev, "failed bind: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+void
+nouveau_sgdma_nottm_hack_takedown(struct drm_device *dev)
+{
+}
+
+int
+nouveau_sgdma_get_page(struct drm_device *dev, uint32_t offset, uint32_t *page)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *gpuobj = dev_priv->gart_info.sg_ctxdma;
+	struct nouveau_instmem_engine *instmem = &dev_priv->engine.instmem;
+	int pte;
+
+	pte = (offset >> NV_CTXDMA_PAGE_SHIFT);
+	if (dev_priv->card_type < NV_50) {
+		instmem->prepare_access(dev, false);
+		*page = INSTANCE_RD(gpuobj, (pte + 2)) & ~NV_CTXDMA_PAGE_MASK;
+		instmem->finish_access(dev);
+		return 0;
+	}
+
+	NV_ERROR(dev, "Unimplemented on NV50\n");
+	return -EINVAL;
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_state.c b/drivers/gpu/drm/nouveau/nouveau_state.c
new file mode 100644
index 0000000..3aee6d9
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_state.c
@@ -0,0 +1,1043 @@
+/*
+ * Copyright 2005 Stephane Marchesin
+ * Copyright 2008 Stuart Bennett
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include <linux/swab.h>
+
+#include "drmP.h"
+#include "drm.h"
+#include "drm_sarea.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+#include "nv50_display.h"
+
+static int nouveau_stub_init(struct drm_device *dev) { return 0; }
+static void nouveau_stub_takedown(struct drm_device *dev) {}
+
+extern int drm_gem_object_name(struct drm_device *, struct drm_gem_object *,
+			       uint64_t *);
+static int
+sfbhack_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t flags;
+	int ret, size;
+
+	if (dev_priv->sfb_gem || dev_priv->sfb)
+		return 0;
+
+	size = nouveau_mem_fb_amount(dev);
+	if (size > drm_get_resource_len(dev, 1))
+		size = drm_get_resource_len(dev, 1);
+	size >>= 1;
+
+	if (dev_priv->mm_enabled) {
+		flags = NOUVEAU_GEM_DOMAIN_VRAM;
+		if (dev_priv->card_type == NV_50)
+			flags |= NOUVEAU_GEM_DOMAIN_TILE;
+
+		ret = nouveau_gem_new(dev, dev_priv->channel, size, 0,
+				      flags, &dev_priv->sfb_gem);
+		if (ret)
+			return ret;
+
+		ret = nouveau_gem_pin(dev_priv->sfb_gem,
+				      NOUVEAU_GEM_DOMAIN_VRAM);
+		if (ret)
+			return ret;
+
+		ret = drm_gem_object_name(dev, dev_priv->sfb_gem,
+					  &dev_priv->sfbhack_handle);
+		mutex_lock(&dev->struct_mutex);
+		drm_gem_object_unreference(dev_priv->sfb_gem);
+		mutex_unlock(&dev->struct_mutex);
+		if (ret) {
+			dev_priv->sfb_gem = NULL;
+			return ret;
+		}
+		
+		dev_priv->sfbhack_size = dev_priv->sfb_gem->size;
+		return 0;
+	}
+
+	flags = NOUVEAU_MEM_FB | NOUVEAU_MEM_MAPPED;
+	if (dev_priv->card_type == NV_50)
+		flags |= NOUVEAU_MEM_TILE;
+
+	dev_priv->sfb = nouveau_mem_alloc(dev, 0, size, flags,
+					  (struct drm_file *)-2);
+	if (!dev_priv->sfb)
+		return -ENOMEM;
+
+	dev_priv->sfbhack_handle = ((u64)dev_priv->sfb->map_handle << 32 |
+				    dev_priv->sfb->start);
+	dev_priv->sfbhack_size = dev_priv->sfb->size;
+	return 0;
+}
+
+static void
+sfbhack_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (dev_priv->sfb_gem) {
+		mutex_lock(&dev->struct_mutex);
+		drm_gem_object_unreference(dev_priv->sfb_gem);
+		mutex_unlock(&dev->struct_mutex);
+		dev_priv->sfb_gem = NULL;
+	}
+
+	if (dev_priv->sfb) {
+		nouveau_mem_free(dev, dev_priv->sfb);
+		dev_priv->sfb = NULL;
+	}
+}
+
+static int nouveau_init_engine_ptrs(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+
+	switch (dev_priv->chipset & 0xf0) {
+	case 0x00:
+		engine->instmem.init	= nv04_instmem_init;
+		engine->instmem.takedown= nv04_instmem_takedown;
+		engine->instmem.populate	= nv04_instmem_populate;
+		engine->instmem.clear		= nv04_instmem_clear;
+		engine->instmem.bind		= nv04_instmem_bind;
+		engine->instmem.unbind		= nv04_instmem_unbind;
+		engine->instmem.prepare_access	= nv04_instmem_prepare_access;
+		engine->instmem.finish_access	= nv04_instmem_finish_access;
+		engine->mc.init		= nv04_mc_init;
+		engine->mc.takedown	= nv04_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nv04_fb_init;
+		engine->fb.takedown	= nv04_fb_takedown;
+		engine->graph.init	= nv04_graph_init;
+		engine->graph.takedown	= nv04_graph_takedown;
+		engine->graph.fifo_access	= nv04_graph_fifo_access;
+		engine->graph.create_context	= nv04_graph_create_context;
+		engine->graph.destroy_context	= nv04_graph_destroy_context;
+		engine->graph.load_context	= nv04_graph_load_context;
+		engine->graph.save_context	= nv04_graph_save_context;
+		engine->fifo.channels	= 16;
+		engine->fifo.init	= nouveau_fifo_init;
+		engine->fifo.takedown	= nouveau_stub_takedown;
+		engine->fifo.channel_id		= nv04_fifo_channel_id;
+		engine->fifo.create_context	= nv04_fifo_create_context;
+		engine->fifo.destroy_context	= nv04_fifo_destroy_context;
+		engine->fifo.load_context	= nv04_fifo_load_context;
+		engine->fifo.save_context	= nv04_fifo_save_context;
+		break;
+	case 0x10:
+		engine->instmem.init	= nv04_instmem_init;
+		engine->instmem.takedown= nv04_instmem_takedown;
+		engine->instmem.populate	= nv04_instmem_populate;
+		engine->instmem.clear		= nv04_instmem_clear;
+		engine->instmem.bind		= nv04_instmem_bind;
+		engine->instmem.unbind		= nv04_instmem_unbind;
+		engine->instmem.prepare_access	= nv04_instmem_prepare_access;
+		engine->instmem.finish_access	= nv04_instmem_finish_access;
+		engine->mc.init		= nv04_mc_init;
+		engine->mc.takedown	= nv04_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nv10_fb_init;
+		engine->fb.takedown	= nv10_fb_takedown;
+		engine->graph.init	= nv10_graph_init;
+		engine->graph.takedown	= nv10_graph_takedown;
+		engine->graph.create_context	= nv10_graph_create_context;
+		engine->graph.destroy_context	= nv10_graph_destroy_context;
+		engine->graph.fifo_access	= nv04_graph_fifo_access;
+		engine->graph.load_context	= nv10_graph_load_context;
+		engine->graph.save_context	= nv10_graph_save_context;
+		engine->fifo.channels	= 32;
+		engine->fifo.init	= nouveau_fifo_init;
+		engine->fifo.takedown	= nouveau_stub_takedown;
+		engine->fifo.channel_id		= nv10_fifo_channel_id;
+		engine->fifo.create_context	= nv10_fifo_create_context;
+		engine->fifo.destroy_context	= nv10_fifo_destroy_context;
+		engine->fifo.load_context	= nv10_fifo_load_context;
+		engine->fifo.save_context	= nv10_fifo_save_context;
+		break;
+	case 0x20:
+		engine->instmem.init	= nv04_instmem_init;
+		engine->instmem.takedown= nv04_instmem_takedown;
+		engine->instmem.populate	= nv04_instmem_populate;
+		engine->instmem.clear		= nv04_instmem_clear;
+		engine->instmem.bind		= nv04_instmem_bind;
+		engine->instmem.unbind		= nv04_instmem_unbind;
+		engine->instmem.prepare_access	= nv04_instmem_prepare_access;
+		engine->instmem.finish_access	= nv04_instmem_finish_access;
+		engine->mc.init		= nv04_mc_init;
+		engine->mc.takedown	= nv04_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nv10_fb_init;
+		engine->fb.takedown	= nv10_fb_takedown;
+		engine->graph.init	= nv20_graph_init;
+		engine->graph.takedown	= nv20_graph_takedown;
+		engine->graph.create_context	= nv20_graph_create_context;
+		engine->graph.destroy_context	= nv20_graph_destroy_context;
+		engine->graph.fifo_access	= nv04_graph_fifo_access;
+		engine->graph.load_context	= nv20_graph_load_context;
+		engine->graph.save_context	= nv20_graph_save_context;
+		engine->fifo.channels	= 32;
+		engine->fifo.init	= nouveau_fifo_init;
+		engine->fifo.takedown	= nouveau_stub_takedown;
+		engine->fifo.channel_id		= nv10_fifo_channel_id;
+		engine->fifo.create_context	= nv10_fifo_create_context;
+		engine->fifo.destroy_context	= nv10_fifo_destroy_context;
+		engine->fifo.load_context	= nv10_fifo_load_context;
+		engine->fifo.save_context	= nv10_fifo_save_context;
+		break;
+	case 0x30:
+		engine->instmem.init	= nv04_instmem_init;
+		engine->instmem.takedown= nv04_instmem_takedown;
+		engine->instmem.populate	= nv04_instmem_populate;
+		engine->instmem.clear		= nv04_instmem_clear;
+		engine->instmem.bind		= nv04_instmem_bind;
+		engine->instmem.unbind		= nv04_instmem_unbind;
+		engine->instmem.prepare_access	= nv04_instmem_prepare_access;
+		engine->instmem.finish_access	= nv04_instmem_finish_access;
+		engine->mc.init		= nv04_mc_init;
+		engine->mc.takedown	= nv04_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nv10_fb_init;
+		engine->fb.takedown	= nv10_fb_takedown;
+		engine->graph.init	= nv30_graph_init;
+		engine->graph.takedown	= nv20_graph_takedown;
+		engine->graph.fifo_access	= nv04_graph_fifo_access;
+		engine->graph.create_context	= nv20_graph_create_context;
+		engine->graph.destroy_context	= nv20_graph_destroy_context;
+		engine->graph.load_context	= nv20_graph_load_context;
+		engine->graph.save_context	= nv20_graph_save_context;
+		engine->fifo.channels	= 32;
+		engine->fifo.init	= nouveau_fifo_init;
+		engine->fifo.takedown	= nouveau_stub_takedown;
+		engine->fifo.channel_id		= nv10_fifo_channel_id;
+		engine->fifo.create_context	= nv10_fifo_create_context;
+		engine->fifo.destroy_context	= nv10_fifo_destroy_context;
+		engine->fifo.load_context	= nv10_fifo_load_context;
+		engine->fifo.save_context	= nv10_fifo_save_context;
+		break;
+	case 0x40:
+	case 0x60:
+		engine->instmem.init	= nv04_instmem_init;
+		engine->instmem.takedown= nv04_instmem_takedown;
+		engine->instmem.populate	= nv04_instmem_populate;
+		engine->instmem.clear		= nv04_instmem_clear;
+		engine->instmem.bind		= nv04_instmem_bind;
+		engine->instmem.unbind		= nv04_instmem_unbind;
+		engine->instmem.prepare_access	= nv04_instmem_prepare_access;
+		engine->instmem.finish_access	= nv04_instmem_finish_access;
+		engine->mc.init		= nv40_mc_init;
+		engine->mc.takedown	= nv40_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nv40_fb_init;
+		engine->fb.takedown	= nv40_fb_takedown;
+		engine->graph.init	= nv40_graph_init;
+		engine->graph.takedown	= nv40_graph_takedown;
+		engine->graph.fifo_access	= nv04_graph_fifo_access;
+		engine->graph.create_context	= nv40_graph_create_context;
+		engine->graph.destroy_context	= nv40_graph_destroy_context;
+		engine->graph.load_context	= nv40_graph_load_context;
+		engine->graph.save_context	= nv40_graph_save_context;
+		engine->fifo.channels	= 32;
+		engine->fifo.init	= nv40_fifo_init;
+		engine->fifo.takedown	= nouveau_stub_takedown;
+		engine->fifo.channel_id		= nv10_fifo_channel_id;
+		engine->fifo.create_context	= nv40_fifo_create_context;
+		engine->fifo.destroy_context	= nv40_fifo_destroy_context;
+		engine->fifo.load_context	= nv40_fifo_load_context;
+		engine->fifo.save_context	= nv40_fifo_save_context;
+		break;
+	case 0x50:
+	case 0x80: /* gotta love NVIDIA's consistency.. */
+	case 0x90:
+	case 0xA0:
+		engine->instmem.init	= nv50_instmem_init;
+		engine->instmem.takedown= nv50_instmem_takedown;
+		engine->instmem.populate	= nv50_instmem_populate;
+		engine->instmem.clear		= nv50_instmem_clear;
+		engine->instmem.bind		= nv50_instmem_bind;
+		engine->instmem.unbind		= nv50_instmem_unbind;
+		engine->instmem.prepare_access	= nv50_instmem_prepare_access;
+		engine->instmem.finish_access	= nv50_instmem_finish_access;
+		engine->mc.init		= nv50_mc_init;
+		engine->mc.takedown	= nv50_mc_takedown;
+		engine->timer.init	= nv04_timer_init;
+		engine->timer.read	= nv04_timer_read;
+		engine->timer.takedown	= nv04_timer_takedown;
+		engine->fb.init		= nouveau_stub_init;
+		engine->fb.takedown	= nouveau_stub_takedown;
+		engine->graph.init	= nv50_graph_init;
+		engine->graph.takedown	= nv50_graph_takedown;
+		engine->graph.fifo_access	= nv50_graph_fifo_access;
+		engine->graph.create_context	= nv50_graph_create_context;
+		engine->graph.destroy_context	= nv50_graph_destroy_context;
+		engine->graph.load_context	= nv50_graph_load_context;
+		engine->graph.save_context	= nv50_graph_save_context;
+		engine->fifo.channels	= 128;
+		engine->fifo.init	= nv50_fifo_init;
+		engine->fifo.takedown	= nv50_fifo_takedown;
+		engine->fifo.channel_id		= nv50_fifo_channel_id;
+		engine->fifo.create_context	= nv50_fifo_create_context;
+		engine->fifo.destroy_context	= nv50_fifo_destroy_context;
+		engine->fifo.load_context	= nv50_fifo_load_context;
+		engine->fifo.save_context	= nv50_fifo_save_context;
+		break;
+	default:
+		NV_ERROR(dev, "NV%02x unsupported\n", dev_priv->chipset);
+		return 1;
+	}
+
+	return 0;
+}
+
+int
+nouveau_card_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine;
+	int ret;
+
+	NV_DEBUG(dev, "prev state = %d\n", dev_priv->init_state);
+
+	if (dev_priv->init_state == NOUVEAU_CARD_INIT_DONE)
+		return 0;
+
+	if (drm_core_check_feature(dev, DRIVER_GEM))
+		dev_priv->mm_enabled = 1;
+	else
+		dev_priv->mm_enabled = 0;
+
+	/* Determine exact chipset we're running on */
+	if (dev_priv->card_type < NV_10)
+		dev_priv->chipset = dev_priv->card_type;
+	else
+		dev_priv->chipset =
+			(nv_rd32(NV03_PMC_BOOT_0) & 0x0ff00000) >> 20;
+
+	/* Initialise internal driver API hooks */
+	ret = nouveau_init_engine_ptrs(dev);
+	if (ret) return ret;
+	engine = &dev_priv->engine;
+	dev_priv->init_state = NOUVEAU_CARD_INIT_FAILED;
+
+	ret = nouveau_gpuobj_early_init(dev);
+	if (ret) return ret;
+
+	/* Initialise instance memory, must happen before mem_init so we
+	 * know exactly how much VRAM we're able to use for "normal"
+	 * purposes.
+	 */
+	ret = engine->instmem.init(dev);
+	if (ret) return ret;
+
+	/* Setup the memory manager */
+	if (dev_priv->mm_enabled) {
+		ret = nouveau_mem_init_ttm(dev);
+		if (ret) return ret;
+	} else {
+		ret = nouveau_mem_init(dev);
+		if (ret) return ret;
+	}
+
+	ret = nouveau_gpuobj_init(dev);
+	if (ret) return ret;
+
+	/* Parse BIOS tables / Run init tables? */
+
+	/* PMC */
+	ret = engine->mc.init(dev);
+	if (ret) return ret;
+
+	/* PTIMER */
+	ret = engine->timer.init(dev);
+	if (ret) return ret;
+
+	/* PFB */
+	ret = engine->fb.init(dev);
+	if (ret) return ret;
+
+	/* PGRAPH */
+	ret = engine->graph.init(dev);
+	if (ret) return ret;
+
+	/* PFIFO */
+	ret = engine->fifo.init(dev);
+	if (ret) return ret;
+
+	/* this call irq_preinstall, register irq handler and
+	 * call irq_postinstall
+	 */
+	ret = drm_irq_install(dev);
+	if (ret) return ret;
+
+	ret = drm_vblank_init(dev, 0);
+	if (ret) return ret;
+
+	/* what about PVIDEO/PCRTC/PRAMDAC etc? */
+
+	ret = nouveau_dma_channel_init(dev);
+	if (ret) return ret;
+
+	mutex_init(&dev_priv->submit_mutex);
+
+	if (drm_core_check_feature(dev, DRIVER_MODESET)) {
+		ret = nouveau_parse_bios(dev);
+		if (ret)
+			return ret;
+
+		if (dev_priv->card_type >= NV_50) {
+			ret = nv50_display_create(dev);
+			if (ret)
+				return ret;
+		}
+	}
+
+	ret = nouveau_backlight_init(dev);
+	if (ret)
+		NV_ERROR(dev, "Error %d registering backlight\n", ret);
+
+	dev_priv->init_state = NOUVEAU_CARD_INIT_DONE;
+
+	if (drm_core_check_feature(dev, DRIVER_MODESET))
+		drm_helper_initial_config(dev);
+
+	return 0;
+}
+
+static void nouveau_card_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+
+	NV_DEBUG(dev, "prev state = %d\n", dev_priv->init_state);
+
+	if (dev_priv->init_state != NOUVEAU_CARD_INIT_DOWN) {
+		nouveau_backlight_exit(dev);
+
+		nouveau_dma_channel_takedown(dev);
+
+		engine->fifo.takedown(dev);
+		engine->graph.takedown(dev);
+		engine->fb.takedown(dev);
+		engine->timer.takedown(dev);
+		engine->mc.takedown(dev);
+
+		if (dev_priv->mm_enabled) {
+			mutex_lock(&dev->struct_mutex);
+			drm_bo_clean_mm(dev, DRM_BO_MEM_TT, 1);
+			mutex_unlock(&dev->struct_mutex);
+		} else {
+			nouveau_sgdma_nottm_hack_takedown(dev);
+		}
+		nouveau_sgdma_takedown(dev);
+
+		nouveau_gpuobj_takedown(dev);
+		nouveau_mem_close(dev);
+		engine->instmem.takedown(dev);
+
+		if (drm_core_check_feature(dev, DRIVER_MODESET))
+			drm_irq_uninstall(dev);
+
+		nouveau_gpuobj_late_takedown(dev);
+
+		dev_priv->init_state = NOUVEAU_CARD_INIT_DOWN;
+	}
+}
+
+/* here a client dies, release the stuff that was allocated for its
+ * file_priv */
+void nouveau_preclose(struct drm_device *dev, struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	nouveau_fifo_cleanup(dev, file_priv);
+
+	if (!dev_priv->mm_enabled) {
+		nouveau_mem_release(file_priv, dev_priv->fb_heap);
+		nouveau_mem_release(file_priv, dev_priv->agp_heap);
+		nouveau_mem_release(file_priv, dev_priv->pci_heap);
+	}
+}
+
+/* first module load, setup the mmio/fb mapping */
+/* KMS: we need mmio at load time, not when the first drm client opens. */
+int nouveau_firstopen(struct drm_device *dev)
+{
+	return 0;
+}
+
+#define NV40_CHIPSET_MASK 0x00000baf
+#define NV44_CHIPSET_MASK 0x00005450
+
+int nouveau_load(struct drm_device *dev, unsigned long flags)
+{
+	struct drm_nouveau_private *dev_priv;
+#if defined(__powerpc__)
+	struct device_node *dn;
+#endif
+	uint32_t reg0;
+	uint8_t architecture = 0;
+	int ret;
+
+	dev_priv = drm_calloc(1, sizeof(*dev_priv), DRM_MEM_DRIVER);
+	if (!dev_priv)
+		return -ENOMEM;
+	dev->dev_private = dev_priv;
+
+	dev_priv->flags = flags & NOUVEAU_FLAGS;
+	dev_priv->init_state = NOUVEAU_CARD_INIT_DOWN;
+
+	NV_DEBUG(dev, "vendor: 0x%X device: 0x%X class: 0x%X\n",
+		 dev->pci_vendor, dev->pci_device, dev->pdev->class);
+
+	/* resource 0 is mmio regs */
+	/* resource 1 is linear FB */
+	/* resource 2 is RAMIN (mmio regs + 0x1000000) */
+	/* resource 6 is bios */
+
+	/* map the mmio regs */
+	ret = drm_addmap(dev, drm_get_resource_start(dev, 0),
+			 0x00800000, _DRM_REGISTERS, _DRM_READ_ONLY |
+			 _DRM_DRIVER, &dev_priv->mmio);
+	if (ret) {
+		NV_ERROR(dev, "Unable to initialize the mmio mapping (%d). "
+			      "Please report your setup to " DRIVER_EMAIL "\n",
+			 ret);
+		return -EINVAL;
+	}
+	NV_DEBUG(dev, "regs mapped ok at 0x%lx\n", (unsigned long)dev_priv->mmio->offset);
+
+#if defined(__powerpc__)
+	/* Put the card in BE mode if it's not */
+	if (nv_rd32(NV03_PMC_BOOT_1))
+		nv_wr32(NV03_PMC_BOOT_1,0x00000001);
+
+	DRM_MEMORYBARRIER();
+#endif
+
+	/* Time to determine the card architecture */
+	reg0 = nv_rd32(NV03_PMC_BOOT_0);
+
+	/* We're dealing with >=NV10 */
+	if ((reg0 & 0x0f000000) > 0 ) {
+		/* Bit 27-20 contain the architecture in hex */
+		architecture = (reg0 & 0xff00000) >> 20;
+	/* NV04 or NV05 */
+	} else if ((reg0 & 0xff00fff0) == 0x20004000) {
+		architecture = 0x04;
+	}
+
+	if (architecture >= 0x80) {
+		dev_priv->card_type = NV_50;
+	} else if (architecture >= 0x60) {
+		/* FIXME we need to figure out who's who for NV6x */
+		dev_priv->card_type = NV_44;
+	} else if (architecture >= 0x50) {
+		dev_priv->card_type = NV_50;
+	} else if (architecture >= 0x40) {
+		uint8_t subarch = architecture & 0xf;
+		/* Selection criteria borrowed from NV40EXA */
+		if (NV40_CHIPSET_MASK & (1 << subarch)) {
+			dev_priv->card_type = NV_40;
+		} else if (NV44_CHIPSET_MASK & (1 << subarch)) {
+			dev_priv->card_type = NV_44;
+		} else {
+			dev_priv->card_type = NV_UNKNOWN;
+		}
+	} else if (architecture >= 0x30) {
+		dev_priv->card_type = NV_30;
+	} else if (architecture >= 0x20) {
+		dev_priv->card_type = NV_20;
+	} else if (architecture >= 0x17) {
+		dev_priv->card_type = NV_17;
+	} else if (architecture >= 0x11) {
+		dev_priv->card_type = NV_11;
+	} else if (architecture >= 0x10) {
+		dev_priv->card_type = NV_10;
+	} else if (architecture >= 0x04) {
+		dev_priv->card_type = NV_04;
+	} else {
+		dev_priv->card_type = NV_UNKNOWN;
+	}
+
+	NV_INFO(dev, "Detected an NV%d generation card (0x%08x)\n", dev_priv->card_type,reg0);
+
+	if (dev_priv->card_type == NV_UNKNOWN) {
+		return -EINVAL;
+	}
+
+	/* map larger RAMIN aperture on NV40 cards */
+	dev_priv->ramin_map = dev_priv->ramin  = NULL;
+	if (dev_priv->card_type >= NV_40) {
+		int ramin_resource = 2;
+		if (drm_get_resource_len(dev, ramin_resource) == 0)
+			ramin_resource = 3;
+
+		ret = drm_addmap(dev,
+				 drm_get_resource_start(dev, ramin_resource),
+				 drm_get_resource_len(dev, ramin_resource),
+				 _DRM_REGISTERS, _DRM_READ_ONLY |
+				 _DRM_DRIVER, &dev_priv->ramin);
+		if (ret) {
+			NV_ERROR(dev, "Failed to init RAMIN mapping, "
+				      "limited instance memory available\n");
+			dev_priv->ramin = NULL;
+		}
+	}
+
+	/* On older cards (or if the above failed), create a map covering
+	 * the BAR0 PRAMIN aperture */
+	if (!dev_priv->ramin) {
+		ret = drm_addmap(dev,
+				 drm_get_resource_start(dev, 0) + NV_RAMIN,
+				 (1*1024*1024),
+				 _DRM_REGISTERS, _DRM_READ_ONLY | _DRM_DRIVER,
+				 &dev_priv->ramin);
+		if (ret) {
+			NV_ERROR(dev, "Failed to map BAR0 PRAMIN: %d\n", ret);
+			return ret;
+		}
+	}
+
+#if defined(__powerpc__)
+	/* if we have an OF card, copy vbios to RAMIN */
+	dn = pci_device_to_OF_node(dev->pdev);
+	if (dn)
+	{
+		int size, i;
+		const uint32_t *bios = of_get_property(dn, "NVDA,BMP", &size);
+		if (bios) {
+			for (i = 0; i < size; i+=4)
+				nv_out32(ramin, i, bios[i/4]);
+			NV_INFO(dev, "OF bios successfully copied (%d bytes)\n",size);
+		} else
+			NV_INFO(dev, "Unable to get the OF bios\n");
+	}
+	else
+		NV_INFO(dev, "Unable to get the OF node\n");
+#endif
+
+	/* For those who think they want to be funny. */
+	if (dev_priv->card_type < NV_50 &&
+	    drm_core_check_feature(dev, DRIVER_MODESET)) {
+		NV_ERROR(dev, "Kernel modesetting requested but not supported "
+			      "on this chipset.\n");
+		dev->driver->driver_features &= ~(DRIVER_MODESET|DRIVER_GEM);
+	}
+
+	/* Special flags */
+	if (dev->pci_device == 0x01a0) {
+		dev_priv->flags |= NV_NFORCE;
+	} else if (dev->pci_device == 0x01f0) {
+		dev_priv->flags |= NV_NFORCE2;
+	}
+
+	dev->dev_private = (void *)dev_priv;
+
+	/* For kernel modesetting, init card now and bring up fbcon */
+	if (drm_core_check_feature(dev, DRIVER_MODESET)) {
+		ret = nouveau_card_init(dev);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+void nouveau_close(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	/* In the case of an error dev_priv may not be be allocated yet */
+	if (dev_priv && dev_priv->card_type)
+		nouveau_card_takedown(dev);
+}
+
+/* KMS: we need mmio at load time, not when the first drm client opens. */
+void nouveau_lastclose(struct drm_device *dev)
+{
+	sfbhack_takedown(dev);
+
+	if (drm_core_check_feature(dev, DRIVER_MODESET))
+		return;
+
+	nouveau_close(dev);
+}
+
+int nouveau_unload(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (drm_core_check_feature(dev, DRIVER_MODESET)) {
+		nv50_display_destroy(dev);
+		nouveau_close(dev);
+	}
+
+	drm_rmmap(dev, dev_priv->mmio);
+	drm_rmmap(dev, dev_priv->ramin);
+
+	drm_free(dev_priv, sizeof(*dev_priv), DRM_MEM_DRIVER);
+	dev->dev_private = NULL;
+	return 0;
+}
+
+int
+nouveau_ioctl_card_init(struct drm_device *dev, void *data,
+			struct drm_file *file_priv)
+{
+	return nouveau_card_init(dev);
+}
+
+int nouveau_ioctl_getparam(struct drm_device *dev, void *data, struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_getparam *getparam = data;
+	int ret;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+
+	switch (getparam->param) {
+	case NOUVEAU_GETPARAM_CHIPSET_ID:
+		getparam->value = dev_priv->chipset;
+		break;
+	case NOUVEAU_GETPARAM_PCI_VENDOR:
+		getparam->value=dev->pci_vendor;
+		break;
+	case NOUVEAU_GETPARAM_PCI_DEVICE:
+		getparam->value=dev->pci_device;
+		break;
+	case NOUVEAU_GETPARAM_BUS_TYPE:
+		if (drm_device_is_agp(dev))
+			getparam->value=NV_AGP;
+		else if (drm_device_is_pcie(dev))
+			getparam->value=NV_PCIE;
+		else
+			getparam->value=NV_PCI;
+		break;
+	case NOUVEAU_GETPARAM_FB_PHYSICAL:
+		getparam->value=dev_priv->fb_phys;
+		break;
+	case NOUVEAU_GETPARAM_AGP_PHYSICAL:
+		getparam->value=dev_priv->gart_info.aper_base;
+		break;
+	case NOUVEAU_GETPARAM_PCI_PHYSICAL:
+		if ( dev -> sg )
+			getparam->value=(unsigned long)dev->sg->virtual;
+		else
+		     {
+		     NV_ERROR(dev, "Requested PCIGART address, "
+				   "while no PCIGART was created\n");
+		     return -EINVAL;
+		     }
+		break;
+	case NOUVEAU_GETPARAM_FB_SIZE:
+		getparam->value=dev_priv->fb_available_size;
+		break;
+	case NOUVEAU_GETPARAM_AGP_SIZE:
+		getparam->value=dev_priv->gart_info.aper_size;
+		break;
+	case NOUVEAU_GETPARAM_MM_ENABLED:
+		getparam->value = dev_priv->mm_enabled;
+		break;
+	case NOUVEAU_GETPARAM_VM_VRAM_BASE:
+		getparam->value = dev_priv->vm_vram_base;
+		break;
+	case 0xdeadcafe00000001: /* NOUVEAU_GETPARAM_SHAREDFB_HANDLE */
+		ret = sfbhack_init(dev);
+		if (ret)
+			return ret;
+
+		getparam->value = dev_priv->sfbhack_handle;
+		break;
+	case 0xdeadcafe00000002: /* NOUVEAU_GETPARAM_SHAREDFB_SIZE */
+		ret = sfbhack_init(dev);
+		if (ret)
+			return ret;
+
+		getparam->value = dev_priv->sfbhack_size;
+		break;
+	default:
+		NV_ERROR(dev, "unknown parameter %lld\n", getparam->param);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+int
+nouveau_ioctl_setparam(struct drm_device *dev, void *data,
+		       struct drm_file *file_priv)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_nouveau_setparam *setparam = data;
+
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+
+	switch (setparam->param) {
+	case NOUVEAU_SETPARAM_CMDBUF_LOCATION:
+		switch (setparam->value) {
+		case NOUVEAU_MEM_AGP:
+		case NOUVEAU_MEM_FB:
+		case NOUVEAU_MEM_PCI:
+		case NOUVEAU_MEM_AGP | NOUVEAU_MEM_PCI_ACCEPTABLE:
+			break;
+		default:
+			NV_ERROR(dev, "invalid CMDBUF_LOCATION value=%lld\n",
+				 setparam->value);
+			return -EINVAL;
+		}
+
+		dev_priv->config.cmdbuf.location = setparam->value;
+		break;
+	case NOUVEAU_SETPARAM_CMDBUF_SIZE:
+		dev_priv->config.cmdbuf.size = setparam->value;
+		break;
+	default:
+		NV_ERROR(dev, "unknown parameter %lld\n", setparam->param);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/* Wait until (value(reg) & mask) == val, up until timeout has hit */
+bool nouveau_wait_until(struct drm_device *dev, uint64_t timeout,
+			uint32_t reg, uint32_t mask, uint32_t val)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_timer_engine *ptimer = &dev_priv->engine.timer;
+	uint64_t start = ptimer->read(dev);
+
+	do {
+		if ((nv_rd32(reg) & mask) == val)
+			return true;
+	} while (ptimer->read(dev) - start < timeout);
+
+	return false;
+}
+
+/* Waits for PGRAPH to go completely idle */
+void nouveau_wait_for_idle(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv=dev->dev_private;
+
+	switch(dev_priv->card_type) {
+	case NV_50:
+		break;
+	default:
+		if (!nv_wait(NV04_PGRAPH_STATUS, 0xffffffff, 0x00000000)) {
+			NV_ERROR(dev, "timed out with status 0x%08x\n",
+				 nv_rd32(NV04_PGRAPH_STATUS));
+		}
+	}
+}
+
+static int nouveau_suspend(struct drm_device *dev)
+{
+	struct mem_block *p;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_suspend_resume *susres = &dev_priv->susres;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	int i;
+
+	drm_free(susres->ramin_copy, susres->ramin_size, DRM_MEM_DRIVER);
+	susres->ramin_size = 0;
+	list_for_each(p, dev_priv->ramin_heap)
+		if (p->file_priv && (p->start + p->size) > susres->ramin_size)
+			susres->ramin_size = p->start + p->size;
+	if (!(susres->ramin_copy = drm_alloc(susres->ramin_size, DRM_MEM_DRIVER))) {
+		NV_ERROR(dev, "Couldn't alloc RAMIN backing for suspend\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < engine->fifo.channels; i++) {
+		uint64_t t_start = engine->timer.read(dev);
+
+		if (dev_priv->fifos[i] == NULL)
+			continue;
+
+		/* Give the channel a chance to idle, wait 2s (hopefully) */
+		while (!nouveau_channel_idle(dev_priv->fifos[i]))
+			if (engine->timer.read(dev) - t_start > 2000000000ULL) {
+				NV_ERROR(dev, "Failed to idle channel %d before"
+					  "suspend.", dev_priv->fifos[i]->id);
+				return -EBUSY;
+			}
+	}
+	nouveau_wait_for_idle(dev);
+
+	nv_wr32(NV04_PGRAPH_FIFO, 0);
+	/* disable the fifo caches */
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) & ~1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000000);
+
+	susres->fifo_mode = nv_rd32(NV04_PFIFO_MODE);
+
+	if (dev_priv->card_type >= NV_10) {
+		susres->graph_state = nv_rd32(NV10_PGRAPH_STATE);
+		susres->graph_ctx_control = nv_rd32(NV10_PGRAPH_CTX_CONTROL);
+	} else {
+		susres->graph_state = nv_rd32(NV04_PGRAPH_STATE);
+		susres->graph_ctx_control = nv_rd32(NV04_PGRAPH_CTX_CONTROL);
+	}
+
+	engine->fifo.save_context(dev_priv->fifos[engine->fifo.channel_id(dev)]);
+	engine->graph.save_context(dev_priv->fifos[engine->fifo.channel_id(dev)]);
+	nouveau_wait_for_idle(dev);
+
+	engine->instmem.prepare_access(dev, false);
+	for (i = 0; i < susres->ramin_size / 4; i++)
+		susres->ramin_copy[i] = nv_ri32(i << 2);
+	engine->instmem.finish_access(dev);
+
+	/* reenable the fifo caches */
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) | 1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000001);
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000001);
+	nv_wr32(NV04_PGRAPH_FIFO, 1);
+
+	return 0;
+}
+
+static int nouveau_resume(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_suspend_resume *susres = &dev_priv->susres;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	int i;
+
+	if (!susres->ramin_copy)
+		return -EINVAL;
+
+	NV_DEBUG(dev, "Doing resume\n");
+
+	if (dev_priv->gart_info.type == NOUVEAU_GART_AGP) {
+		struct drm_agp_info info;
+		struct drm_agp_mode mode;
+
+		/* agp bridge drivers don't re-enable agp on resume. lame. */
+		if ((i = drm_agp_info(dev, &info))) {
+			NV_ERROR(dev, "Unable to get AGP info: %d\n", i);
+			return i;
+		}
+		mode.mode = info.mode;
+		if ((i = drm_agp_enable(dev, mode))) {
+			NV_ERROR(dev, "Unable to enable AGP: %d\n", i);
+			return i;
+		}
+	}
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	for (i = 0; i < susres->ramin_size / 4; i++)
+		nv_wi32(i << 2, susres->ramin_copy[i]);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	engine->mc.init(dev);
+	engine->timer.init(dev);
+	engine->fb.init(dev);
+	engine->graph.init(dev);
+	engine->fifo.init(dev);
+
+	nv_wr32(NV04_PGRAPH_FIFO, 0);
+	/* disable the fifo caches */
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) & ~1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000000);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000000);
+
+	/* PMC power cycling PFIFO in init clobbers some of the stuff stored in
+	 * PRAMIN (such as NV04_PFIFO_CACHE1_DMA_INSTANCE). this is unhelpful
+	 */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	for (i = 0; i < susres->ramin_size / 4; i++)
+		nv_wi32(i << 2, susres->ramin_copy[i]);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	engine->fifo.load_context(dev_priv->fifos[0]);
+	nv_wr32(NV04_PFIFO_MODE, susres->fifo_mode);
+
+	engine->graph.load_context(dev_priv->fifos[0]);
+	nouveau_wait_for_idle(dev);
+
+	if (dev_priv->card_type >= NV_10) {
+		nv_wr32(NV10_PGRAPH_STATE, susres->graph_state);
+		nv_wr32(NV10_PGRAPH_CTX_CONTROL, susres->graph_ctx_control);
+	} else {
+		nv_wr32(NV04_PGRAPH_STATE, susres->graph_state);
+		nv_wr32(NV04_PGRAPH_CTX_CONTROL, susres->graph_ctx_control);
+	}
+
+	/* reenable the fifo caches */
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUSH,
+		 nv_rd32(NV04_PFIFO_CACHE1_DMA_PUSH) | 1);
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH0, 0x00000001);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x00000001);
+	nv_wr32(NV03_PFIFO_CACHES, 0x00000001);
+	nv_wr32(NV04_PGRAPH_FIFO, 0x1);
+
+	if (dev->irq_enabled)
+		nouveau_irq_postinstall(dev);
+
+	drm_free(susres->ramin_copy, susres->ramin_size, DRM_MEM_DRIVER);
+	susres->ramin_copy = NULL;
+	susres->ramin_size = 0;
+
+	return 0;
+}
+
+int nouveau_ioctl_suspend(struct drm_device *dev, void *data,
+				 struct drm_file *file_priv)
+{
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+
+	return nouveau_suspend(dev);
+}
+
+int nouveau_ioctl_resume(struct drm_device *dev, void *data,
+				struct drm_file *file_priv)
+{
+	NOUVEAU_CHECK_INITIALISED_WITH_RETURN;
+
+	return nouveau_resume(dev);
+}
diff --git a/drivers/gpu/drm/nouveau/nouveau_swmthd.c b/drivers/gpu/drm/nouveau/nouveau_swmthd.c
new file mode 100644
index 0000000..fcb05fa
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_swmthd.c
@@ -0,0 +1,190 @@
+/*
+ * Copyright (C) 2007 Arthur Huillet.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/*
+ * Authors:
+ *   Arthur Huillet <arthur.huillet AT free DOT fr>
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_reg.h"
+
+/*TODO: add a "card_type" attribute*/
+typedef struct{
+	uint32_t oclass; /* object class for this software method */
+	uint32_t mthd; /* method number */
+	void (*method_code)(struct drm_device *dev, uint32_t oclass, uint32_t mthd); /* pointer to the function that does the work */
+ } nouveau_software_method_t;
+
+
+ /* This function handles the NV04 setcontext software methods.
+One function for all because they are very similar.*/
+static void nouveau_NV04_setcontext_sw_method(struct drm_device *dev, uint32_t oclass, uint32_t mthd) {
+	uint32_t inst_loc = nv_rd32(NV04_PGRAPH_CTX_SWITCH4) & 0xFFFF;
+	uint32_t value_to_set = 0, bit_to_set = 0;
+
+	switch ( oclass ) {
+		case 0x4a:
+			switch ( mthd ) {
+				case 0x188 :
+				case 0x18c :
+					bit_to_set = 0;
+					break;
+				case 0x198 :
+					bit_to_set = 1 << 24; /*PATCH_STATUS_VALID*/
+					break;
+				case 0x2fc :
+					bit_to_set = nv_rd32(NV04_PGRAPH_TRAPPED_DATA) << 15; /*PATCH_CONFIG = NV04_PGRAPH_TRAPPED_DATA*/
+					break;
+				default : ;
+				};
+			break;
+		case 0x5c:
+			switch ( mthd ) {
+				case 0x184:
+					bit_to_set = 1 << 13; /*USER_CLIP_ENABLE*/
+					break;
+				case 0x188:
+				case 0x18c:
+					bit_to_set = 0;
+					break;
+				case 0x198:
+					bit_to_set = 1 << 24; /*PATCH_STATUS_VALID*/
+					break;
+				case 0x2fc :
+					bit_to_set = nv_rd32(NV04_PGRAPH_TRAPPED_DATA) << 15; /*PATCH_CONFIG = NV04_PGRAPH_TRAPPED_DATA*/
+					break;
+			};
+			break;
+		case 0x5f:
+			switch ( mthd ) {
+				case 0x184 :
+					bit_to_set = 1 << 12; /*CHROMA_KEY_ENABLE*/
+					break;
+				case 0x188 :
+					bit_to_set = 1 << 13; /*USER_CLIP_ENABLE*/
+					break;
+				case 0x18c :
+				case 0x190 :
+					bit_to_set = 0;
+					break;
+				case 0x19c :
+					bit_to_set = 1 << 24; /*PATCH_STATUS_VALID*/
+					break;
+				case 0x2fc :
+					bit_to_set = nv_rd32(NV04_PGRAPH_TRAPPED_DATA) << 15; /*PATCH_CONFIG = NV04_PGRAPH_TRAPPED_DATA*/
+					break;
+			};
+			break;
+		case 0x61:
+			switch ( mthd ) {
+				case 0x188 :
+					bit_to_set = 1 << 13; /*USER_CLIP_ENABLE*/
+					break;
+				case 0x18c :
+				case 0x190 :
+					bit_to_set = 0;
+					break;
+				case 0x19c :
+					bit_to_set = 1 << 24; /*PATCH_STATUS_VALID*/
+					break;
+				case 0x2fc :
+					bit_to_set = nv_rd32(NV04_PGRAPH_TRAPPED_DATA) << 15; /*PATCH_CONFIG = NV04_PGRAPH_TRAPPED_DATA*/
+					break;
+			};
+			break;
+		case 0x77:
+			switch ( mthd ) {
+				case 0x198 :
+					bit_to_set = 1 << 24; /*PATCH_STATUS_VALID*/
+					break;
+				case 0x304 :
+					bit_to_set = nv_rd32(NV04_PGRAPH_TRAPPED_DATA) << 15; //PATCH_CONFIG
+					break;
+			};
+			break;
+		default :;
+		};
+
+	value_to_set = (nv_rd32(0x00700000 | inst_loc << 4))| bit_to_set;
+
+	/*RAMIN*/
+	nouveau_wait_for_idle(dev);
+	nv_wr32(0x00700000 | inst_loc << 4, value_to_set);
+
+	/*NV_DEBUG(dev, "CTX_SWITCH1 value is %#x\n", nv_rd32(NV04_PGRAPH_CTX_SWITCH1));*/
+	nv_wr32(NV04_PGRAPH_CTX_SWITCH1, value_to_set);
+
+	/*NV_DEBUG(dev, "CTX_CACHE1 + xxx value is %#x\n", nv_rd32(NV04_PGRAPH_CTX_CACHE1 + (((nv_rd32(NV04_PGRAPH_TRAPPED_ADDR) >> 13) & 0x7) << 2)));*/
+	nv_wr32(NV04_PGRAPH_CTX_CACHE1 + (((nv_rd32(NV04_PGRAPH_TRAPPED_ADDR) >> 13) & 0x7) << 2), value_to_set);
+}
+
+ nouveau_software_method_t nouveau_sw_methods[] = {
+	/*NV04 context software methods*/
+	{ 0x4a, 0x188, nouveau_NV04_setcontext_sw_method },
+	{ 0x4a, 0x18c, nouveau_NV04_setcontext_sw_method },
+	{ 0x4a, 0x198, nouveau_NV04_setcontext_sw_method },
+	{ 0x4a, 0x2fc, nouveau_NV04_setcontext_sw_method },
+	{ 0x5c, 0x184, nouveau_NV04_setcontext_sw_method },
+	{ 0x5c, 0x188, nouveau_NV04_setcontext_sw_method },
+	{ 0x5c, 0x18c, nouveau_NV04_setcontext_sw_method },
+	{ 0x5c, 0x198, nouveau_NV04_setcontext_sw_method },
+	{ 0x5c, 0x2fc, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x184, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x188, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x18c, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x190, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x19c, nouveau_NV04_setcontext_sw_method },
+	{ 0x5f, 0x2fc, nouveau_NV04_setcontext_sw_method },
+	{ 0x61, 0x188, nouveau_NV04_setcontext_sw_method },
+	{ 0x61, 0x18c, nouveau_NV04_setcontext_sw_method },
+	{ 0x61, 0x190, nouveau_NV04_setcontext_sw_method },
+	{ 0x61, 0x19c, nouveau_NV04_setcontext_sw_method },
+	{ 0x61, 0x2fc, nouveau_NV04_setcontext_sw_method },
+	{ 0x77, 0x198, nouveau_NV04_setcontext_sw_method },
+	{ 0x77, 0x304, nouveau_NV04_setcontext_sw_method },
+	/*terminator*/
+	{ 0x0, 0x0, NULL, },
+ };
+
+ int nouveau_sw_method_execute(struct drm_device *dev, uint32_t oclass, uint32_t method) {
+	int i = 0;
+	while ( nouveau_sw_methods[ i ] . method_code != NULL )
+		{
+		if ( nouveau_sw_methods[ i ] . oclass == oclass && nouveau_sw_methods[ i ] . mthd == method )
+			{
+			nouveau_sw_methods[ i ] . method_code(dev, oclass, method);
+			return 0;
+			}
+		i ++;
+		}
+
+	 return 1;
+ }
diff --git a/drivers/gpu/drm/nouveau/nouveau_swmthd.h b/drivers/gpu/drm/nouveau/nouveau_swmthd.h
new file mode 100644
index 0000000..5b9409f
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nouveau_swmthd.h
@@ -0,0 +1,33 @@
+/*
+ * Copyright (C) 2007 Arthur Huillet.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/*
+ * Authors:
+ *   Arthur Huillet <arthur.huillet AT free DOT fr>
+ */
+
+int nouveau_sw_method_execute(struct drm_device *dev, uint32_t oclass, uint32_t method); /* execute the given software method, returns 0 on success */
diff --git a/drivers/gpu/drm/nouveau/nv04_fb.c b/drivers/gpu/drm/nouveau/nv04_fb.c
new file mode 100644
index 0000000..cfa04fe
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_fb.c
@@ -0,0 +1,21 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv04_fb_init(struct drm_device *dev)
+{
+	/* This is what the DDX did for NV_ARCH_04, but a mmio-trace shows
+	 * nvidia reading PFB_CFG_0, then writing back its original value.
+	 * (which was 0x701114 in this case)
+	 */
+
+	nv_wr32(NV04_PFB_CFG0, 0x1114);
+	return 0;
+}
+
+void
+nv04_fb_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv04_fifo.c b/drivers/gpu/drm/nouveau/nv04_fifo.c
new file mode 100644
index 0000000..4adaec0
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_fifo.c
@@ -0,0 +1,144 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+#define RAMFC_WR(offset,val) INSTANCE_WR(chan->ramfc->gpuobj, \
+					 NV04_RAMFC_##offset/4, (val))
+#define RAMFC_RD(offset)     INSTANCE_RD(chan->ramfc->gpuobj, \
+					 NV04_RAMFC_##offset/4)
+#define NV04_RAMFC(c) (dev_priv->ramfc_offset + ((c) * NV04_RAMFC__SIZE))
+#define NV04_RAMFC__SIZE 32
+
+int
+nv04_fifo_channel_id(struct drm_device *dev)
+{
+	return (nv_rd32(NV03_PFIFO_CACHE1_PUSH1) &
+			NV03_PFIFO_CACHE1_PUSH1_CHID_MASK);
+}
+
+int
+nv04_fifo_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	if ((ret = nouveau_gpuobj_new_fake(dev, NV04_RAMFC(chan->id), ~0,
+						NV04_RAMFC__SIZE,
+						NVOBJ_FLAG_ZERO_ALLOC |
+						NVOBJ_FLAG_ZERO_FREE,
+						NULL, &chan->ramfc)))
+		return ret;
+
+	/* Setup initial state */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	RAMFC_WR(DMA_PUT, chan->pushbuf_base);
+	RAMFC_WR(DMA_GET, chan->pushbuf_base);
+	RAMFC_WR(DMA_INSTANCE, chan->pushbuf->instance >> 4);
+	RAMFC_WR(DMA_FETCH, (NV_PFIFO_CACHE1_DMA_FETCH_TRIG_128_BYTES |
+			     NV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES |
+			     NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_8 |
+#ifdef __BIG_ENDIAN
+			     NV_PFIFO_CACHE1_BIG_ENDIAN |
+#endif
+			     0));
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* enable the fifo dma operation */
+	nv_wr32(NV04_PFIFO_MODE,nv_rd32(NV04_PFIFO_MODE) | (1<<chan->id));
+	return 0;
+}
+
+void
+nv04_fifo_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+
+	nv_wr32(NV04_PFIFO_MODE, nv_rd32(NV04_PFIFO_MODE)&~(1<<chan->id));
+
+	nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+}
+
+int
+nv04_fifo_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	dev_priv->engine.instmem.prepare_access(dev, false);
+
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH1,
+		 NV03_PFIFO_CACHE1_PUSH1_DMA | chan->id);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_GET, RAMFC_RD(DMA_GET));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUT, RAMFC_RD(DMA_PUT));
+
+	tmp = RAMFC_RD(DMA_INSTANCE);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_INSTANCE, tmp & 0xFFFF);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_DCOUNT, tmp >> 16);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_STATE, RAMFC_RD(DMA_STATE));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_FETCH, RAMFC_RD(DMA_FETCH));
+	nv_wr32(NV04_PFIFO_CACHE1_ENGINE, RAMFC_RD(ENGINE));
+	nv_wr32(NV04_PFIFO_CACHE1_PULL1, RAMFC_RD(PULL1_ENGINE));
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* Reset NV04_PFIFO_CACHE1_DMA_CTL_AT_INFO to INVALID */
+	tmp = nv_rd32(NV04_PFIFO_CACHE1_DMA_CTL) & ~(1<<31);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_CTL, tmp);
+
+	return 0;
+}
+
+int
+nv04_fifo_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+
+	RAMFC_WR(DMA_PUT, nv_rd32(NV04_PFIFO_CACHE1_DMA_PUT));
+	RAMFC_WR(DMA_GET, nv_rd32(NV04_PFIFO_CACHE1_DMA_GET));
+
+	tmp  = nv_rd32(NV04_PFIFO_CACHE1_DMA_DCOUNT) << 16;
+	tmp |= nv_rd32(NV04_PFIFO_CACHE1_DMA_INSTANCE);
+	RAMFC_WR(DMA_INSTANCE, tmp);
+
+	RAMFC_WR(DMA_STATE, nv_rd32(NV04_PFIFO_CACHE1_DMA_STATE));
+	RAMFC_WR(DMA_FETCH, nv_rd32(NV04_PFIFO_CACHE1_DMA_FETCH));
+	RAMFC_WR(ENGINE, nv_rd32(NV04_PFIFO_CACHE1_ENGINE));
+	RAMFC_WR(PULL1_ENGINE, nv_rd32(NV04_PFIFO_CACHE1_PULL1));
+
+	dev_priv->engine.instmem.finish_access(dev);
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv04_graph.c b/drivers/gpu/drm/nouveau/nv04_graph.c
new file mode 100644
index 0000000..c0033ba
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_graph.c
@@ -0,0 +1,521 @@
+/*
+ * Copyright 2007 Stephane Marchesin
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drm.h"
+#include "nouveau_drv.h"
+
+static uint32_t nv04_graph_ctx_regs [] = {
+	NV04_PGRAPH_CTX_SWITCH1,
+	NV04_PGRAPH_CTX_SWITCH2,
+	NV04_PGRAPH_CTX_SWITCH3,
+	NV04_PGRAPH_CTX_SWITCH4,
+	NV04_PGRAPH_CTX_CACHE1,
+	NV04_PGRAPH_CTX_CACHE2,
+	NV04_PGRAPH_CTX_CACHE3,
+	NV04_PGRAPH_CTX_CACHE4,
+	0x00400184,
+	0x004001a4,
+	0x004001c4,
+	0x004001e4,
+	0x00400188,
+	0x004001a8,
+	0x004001c8,
+	0x004001e8,
+	0x0040018c,
+	0x004001ac,
+	0x004001cc,
+	0x004001ec,
+	0x00400190,
+	0x004001b0,
+	0x004001d0,
+	0x004001f0,
+	0x00400194,
+	0x004001b4,
+	0x004001d4,
+	0x004001f4,
+	0x00400198,
+	0x004001b8,
+	0x004001d8,
+	0x004001f8,
+	0x0040019c,
+	0x004001bc,
+	0x004001dc,
+	0x004001fc,
+	0x00400174,
+	NV04_PGRAPH_DMA_START_0,
+	NV04_PGRAPH_DMA_START_1,
+	NV04_PGRAPH_DMA_LENGTH,
+	NV04_PGRAPH_DMA_MISC,
+	NV04_PGRAPH_DMA_PITCH,
+	NV04_PGRAPH_BOFFSET0,
+	NV04_PGRAPH_BBASE0,
+	NV04_PGRAPH_BLIMIT0,
+	NV04_PGRAPH_BOFFSET1,
+	NV04_PGRAPH_BBASE1,
+	NV04_PGRAPH_BLIMIT1,
+	NV04_PGRAPH_BOFFSET2,
+	NV04_PGRAPH_BBASE2,
+	NV04_PGRAPH_BLIMIT2,
+	NV04_PGRAPH_BOFFSET3,
+	NV04_PGRAPH_BBASE3,
+	NV04_PGRAPH_BLIMIT3,
+	NV04_PGRAPH_BOFFSET4,
+	NV04_PGRAPH_BBASE4,
+	NV04_PGRAPH_BLIMIT4,
+	NV04_PGRAPH_BOFFSET5,
+	NV04_PGRAPH_BBASE5,
+	NV04_PGRAPH_BLIMIT5,
+	NV04_PGRAPH_BPITCH0,
+	NV04_PGRAPH_BPITCH1,
+	NV04_PGRAPH_BPITCH2,
+	NV04_PGRAPH_BPITCH3,
+	NV04_PGRAPH_BPITCH4,
+	NV04_PGRAPH_SURFACE,
+	NV04_PGRAPH_STATE,
+	NV04_PGRAPH_BSWIZZLE2,
+	NV04_PGRAPH_BSWIZZLE5,
+	NV04_PGRAPH_BPIXEL,
+	NV04_PGRAPH_NOTIFY,
+	NV04_PGRAPH_PATT_COLOR0,
+	NV04_PGRAPH_PATT_COLOR1,
+	NV04_PGRAPH_PATT_COLORRAM+0x00,
+	NV04_PGRAPH_PATT_COLORRAM+0x01,
+	NV04_PGRAPH_PATT_COLORRAM+0x02,
+	NV04_PGRAPH_PATT_COLORRAM+0x03,
+	NV04_PGRAPH_PATT_COLORRAM+0x04,
+	NV04_PGRAPH_PATT_COLORRAM+0x05,
+	NV04_PGRAPH_PATT_COLORRAM+0x06,
+	NV04_PGRAPH_PATT_COLORRAM+0x07,
+	NV04_PGRAPH_PATT_COLORRAM+0x08,
+	NV04_PGRAPH_PATT_COLORRAM+0x09,
+	NV04_PGRAPH_PATT_COLORRAM+0x0A,
+	NV04_PGRAPH_PATT_COLORRAM+0x0B,
+	NV04_PGRAPH_PATT_COLORRAM+0x0C,
+	NV04_PGRAPH_PATT_COLORRAM+0x0D,
+	NV04_PGRAPH_PATT_COLORRAM+0x0E,
+	NV04_PGRAPH_PATT_COLORRAM+0x0F,
+	NV04_PGRAPH_PATT_COLORRAM+0x10,
+	NV04_PGRAPH_PATT_COLORRAM+0x11,
+	NV04_PGRAPH_PATT_COLORRAM+0x12,
+	NV04_PGRAPH_PATT_COLORRAM+0x13,
+	NV04_PGRAPH_PATT_COLORRAM+0x14,
+	NV04_PGRAPH_PATT_COLORRAM+0x15,
+	NV04_PGRAPH_PATT_COLORRAM+0x16,
+	NV04_PGRAPH_PATT_COLORRAM+0x17,
+	NV04_PGRAPH_PATT_COLORRAM+0x18,
+	NV04_PGRAPH_PATT_COLORRAM+0x19,
+	NV04_PGRAPH_PATT_COLORRAM+0x1A,
+	NV04_PGRAPH_PATT_COLORRAM+0x1B,
+	NV04_PGRAPH_PATT_COLORRAM+0x1C,
+	NV04_PGRAPH_PATT_COLORRAM+0x1D,
+	NV04_PGRAPH_PATT_COLORRAM+0x1E,
+	NV04_PGRAPH_PATT_COLORRAM+0x1F,
+	NV04_PGRAPH_PATT_COLORRAM+0x20,
+	NV04_PGRAPH_PATT_COLORRAM+0x21,
+	NV04_PGRAPH_PATT_COLORRAM+0x22,
+	NV04_PGRAPH_PATT_COLORRAM+0x23,
+	NV04_PGRAPH_PATT_COLORRAM+0x24,
+	NV04_PGRAPH_PATT_COLORRAM+0x25,
+	NV04_PGRAPH_PATT_COLORRAM+0x26,
+	NV04_PGRAPH_PATT_COLORRAM+0x27,
+	NV04_PGRAPH_PATT_COLORRAM+0x28,
+	NV04_PGRAPH_PATT_COLORRAM+0x29,
+	NV04_PGRAPH_PATT_COLORRAM+0x2A,
+	NV04_PGRAPH_PATT_COLORRAM+0x2B,
+	NV04_PGRAPH_PATT_COLORRAM+0x2C,
+	NV04_PGRAPH_PATT_COLORRAM+0x2D,
+	NV04_PGRAPH_PATT_COLORRAM+0x2E,
+	NV04_PGRAPH_PATT_COLORRAM+0x2F,
+	NV04_PGRAPH_PATT_COLORRAM+0x30,
+	NV04_PGRAPH_PATT_COLORRAM+0x31,
+	NV04_PGRAPH_PATT_COLORRAM+0x32,
+	NV04_PGRAPH_PATT_COLORRAM+0x33,
+	NV04_PGRAPH_PATT_COLORRAM+0x34,
+	NV04_PGRAPH_PATT_COLORRAM+0x35,
+	NV04_PGRAPH_PATT_COLORRAM+0x36,
+	NV04_PGRAPH_PATT_COLORRAM+0x37,
+	NV04_PGRAPH_PATT_COLORRAM+0x38,
+	NV04_PGRAPH_PATT_COLORRAM+0x39,
+	NV04_PGRAPH_PATT_COLORRAM+0x3A,
+	NV04_PGRAPH_PATT_COLORRAM+0x3B,
+	NV04_PGRAPH_PATT_COLORRAM+0x3C,
+	NV04_PGRAPH_PATT_COLORRAM+0x3D,
+	NV04_PGRAPH_PATT_COLORRAM+0x3E,
+	NV04_PGRAPH_PATT_COLORRAM+0x3F,
+	NV04_PGRAPH_PATTERN,
+	0x0040080c,
+	NV04_PGRAPH_PATTERN_SHAPE,
+	0x00400600,
+	NV04_PGRAPH_ROP3,
+	NV04_PGRAPH_CHROMA,
+	NV04_PGRAPH_BETA_AND,
+	NV04_PGRAPH_BETA_PREMULT,
+	NV04_PGRAPH_CONTROL0,
+	NV04_PGRAPH_CONTROL1,
+	NV04_PGRAPH_CONTROL2,
+	NV04_PGRAPH_BLEND,
+	NV04_PGRAPH_STORED_FMT,
+	NV04_PGRAPH_SOURCE_COLOR,
+	0x00400560,
+	0x00400568,
+	0x00400564,
+	0x0040056c,
+	0x00400400,
+	0x00400480,
+	0x00400404,
+	0x00400484,
+	0x00400408,
+	0x00400488,
+	0x0040040c,
+	0x0040048c,
+	0x00400410,
+	0x00400490,
+	0x00400414,
+	0x00400494,
+	0x00400418,
+	0x00400498,
+	0x0040041c,
+	0x0040049c,
+	0x00400420,
+	0x004004a0,
+	0x00400424,
+	0x004004a4,
+	0x00400428,
+	0x004004a8,
+	0x0040042c,
+	0x004004ac,
+	0x00400430,
+	0x004004b0,
+	0x00400434,
+	0x004004b4,
+	0x00400438,
+	0x004004b8,
+	0x0040043c,
+	0x004004bc,
+	0x00400440,
+	0x004004c0,
+	0x00400444,
+	0x004004c4,
+	0x00400448,
+	0x004004c8,
+	0x0040044c,
+	0x004004cc,
+	0x00400450,
+	0x004004d0,
+	0x00400454,
+	0x004004d4,
+	0x00400458,
+	0x004004d8,
+	0x0040045c,
+	0x004004dc,
+	0x00400460,
+	0x004004e0,
+	0x00400464,
+	0x004004e4,
+	0x00400468,
+	0x004004e8,
+	0x0040046c,
+	0x004004ec,
+	0x00400470,
+	0x004004f0,
+	0x00400474,
+	0x004004f4,
+	0x00400478,
+	0x004004f8,
+	0x0040047c,
+	0x004004fc,
+	0x0040053c,
+	0x00400544,
+	0x00400540,
+	0x00400548,
+	0x00400560,
+	0x00400568,
+	0x00400564,
+	0x0040056c,
+	0x00400534,
+	0x00400538,
+	0x00400514,
+	0x00400518,
+	0x0040051c,
+	0x00400520,
+	0x00400524,
+	0x00400528,
+	0x0040052c,
+	0x00400530,
+	0x00400d00,
+	0x00400d40,
+	0x00400d80,
+	0x00400d04,
+	0x00400d44,
+	0x00400d84,
+	0x00400d08,
+	0x00400d48,
+	0x00400d88,
+	0x00400d0c,
+	0x00400d4c,
+	0x00400d8c,
+	0x00400d10,
+	0x00400d50,
+	0x00400d90,
+	0x00400d14,
+	0x00400d54,
+	0x00400d94,
+	0x00400d18,
+	0x00400d58,
+	0x00400d98,
+	0x00400d1c,
+	0x00400d5c,
+	0x00400d9c,
+	0x00400d20,
+	0x00400d60,
+	0x00400da0,
+	0x00400d24,
+	0x00400d64,
+	0x00400da4,
+	0x00400d28,
+	0x00400d68,
+	0x00400da8,
+	0x00400d2c,
+	0x00400d6c,
+	0x00400dac,
+	0x00400d30,
+	0x00400d70,
+	0x00400db0,
+	0x00400d34,
+	0x00400d74,
+	0x00400db4,
+	0x00400d38,
+	0x00400d78,
+	0x00400db8,
+	0x00400d3c,
+	0x00400d7c,
+	0x00400dbc,
+	0x00400590,
+	0x00400594,
+	0x00400598,
+	0x0040059c,
+	0x004005a8,
+	0x004005ac,
+	0x004005b0,
+	0x004005b4,
+	0x004005c0,
+	0x004005c4,
+	0x004005c8,
+	0x004005cc,
+	0x004005d0,
+	0x004005d4,
+	0x004005d8,
+	0x004005dc,
+	0x004005e0,
+	NV04_PGRAPH_PASSTHRU_0,
+	NV04_PGRAPH_PASSTHRU_1,
+	NV04_PGRAPH_PASSTHRU_2,
+	NV04_PGRAPH_DVD_COLORFMT,
+	NV04_PGRAPH_SCALED_FORMAT,
+	NV04_PGRAPH_MISC24_0,
+	NV04_PGRAPH_MISC24_1,
+	NV04_PGRAPH_MISC24_2,
+	0x00400500,
+	0x00400504,
+	NV04_PGRAPH_VALID1,
+	NV04_PGRAPH_VALID2
+
+
+};
+
+struct graph_state {
+	int nv04[sizeof(nv04_graph_ctx_regs)/sizeof(nv04_graph_ctx_regs[0])];
+};
+
+void nouveau_nv04_context_switch(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	struct nouveau_channel *next, *last;
+	int chid;
+
+	if (!dev) {
+		NV_DEBUG(dev, "Invalid drm_device\n");
+		return;
+	}
+	dev_priv = dev->dev_private;
+	if (!dev_priv) {
+		NV_DEBUG(dev, "Invalid drm_nouveau_private\n");
+		return;
+	}
+	if (!dev_priv->fifos) {
+		NV_DEBUG(dev, "Invalid drm_nouveau_private->fifos\n");
+		return;
+	}
+
+	chid = engine->fifo.channel_id(dev);
+	next = dev_priv->fifos[chid];
+
+	if (!next) {
+		NV_DEBUG(dev, "Invalid next channel\n");
+		return;
+	}
+
+	chid = (nv_rd32(NV04_PGRAPH_CTX_USER) >> 24) & (engine->fifo.channels - 1);
+	last = dev_priv->fifos[chid];
+
+	if (!last) {
+		NV_DEBUG(dev, "WARNING: Invalid last channel, switch to %x\n",
+			 next->id);
+	} else {
+		NV_INFO(dev, "NV: PGRAPH context switch interrupt channel %x -> %x\n",
+			last->id, next->id);
+	}
+
+/*	nv_wr32(NV03_PFIFO_CACHES, 0x0);
+	nv_wr32(NV04_PFIFO_CACHE0_PULL0, 0x0);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x0);*/
+	nv_wr32(NV04_PGRAPH_FIFO,0x0);
+
+	if (last)
+		nv04_graph_save_context(last);
+
+	nouveau_wait_for_idle(dev);
+
+	nv_wr32(NV04_PGRAPH_CTX_CONTROL, 0x10000000);
+	nv_wr32(NV04_PGRAPH_CTX_USER, (nv_rd32(NV04_PGRAPH_CTX_USER) & 0xffffff) | (0x0f << 24));
+
+	nouveau_wait_for_idle(dev);
+
+	nv04_graph_load_context(next);
+
+	nv_wr32(NV04_PGRAPH_CTX_CONTROL, 0x10010100);
+	nv_wr32(NV04_PGRAPH_CTX_USER, next->id << 24);
+	nv_wr32(NV04_PGRAPH_FFINTFC_ST2, nv_rd32(NV04_PGRAPH_FFINTFC_ST2)&0x000FFFFF);
+
+/*	nv_wr32(NV04_PGRAPH_FIFO,0x0);
+	nv_wr32(NV04_PFIFO_CACHE0_PULL0, 0x0);
+	nv_wr32(NV04_PFIFO_CACHE1_PULL0, 0x1);
+	nv_wr32(NV03_PFIFO_CACHES, 0x1);*/
+	nv_wr32(NV04_PGRAPH_FIFO,0x1);
+}
+
+int nv04_graph_create_context(struct nouveau_channel *chan) {
+	struct graph_state* pgraph_ctx;
+	NV_DEBUG(chan-> dev, "nv04_graph_context_create %d\n", chan->id);
+
+	chan->pgraph_ctx = pgraph_ctx = drm_calloc(1, sizeof(*pgraph_ctx),
+					      DRM_MEM_DRIVER);
+
+	if (pgraph_ctx == NULL)
+		return -ENOMEM;
+
+	//dev_priv->fifos[channel].pgraph_ctx_user = channel << 24;
+	pgraph_ctx->nv04[0] = 0x0001ffff;
+	/* is it really needed ??? */
+	//dev_priv->fifos[channel].pgraph_ctx[1] = nv_rd32(NV_PGRAPH_DEBUG_4);
+	//dev_priv->fifos[channel].pgraph_ctx[2] = nv_rd32(0x004006b0);
+
+	return 0;
+}
+
+void nv04_graph_destroy_context(struct nouveau_channel *chan)
+{
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+
+	drm_free(pgraph_ctx, sizeof(*pgraph_ctx), DRM_MEM_DRIVER);
+	chan->pgraph_ctx = NULL;
+}
+
+int nv04_graph_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	int i;
+
+	for (i = 0; i < sizeof(nv04_graph_ctx_regs)/sizeof(nv04_graph_ctx_regs[0]); i++)
+		nv_wr32(nv04_graph_ctx_regs[i], pgraph_ctx->nv04[i]);
+
+	return 0;
+}
+
+int nv04_graph_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	int i;
+
+	for (i = 0; i < sizeof(nv04_graph_ctx_regs)/sizeof(nv04_graph_ctx_regs[0]); i++)
+		pgraph_ctx->nv04[i] = nv_rd32(nv04_graph_ctx_regs[i]);
+
+	return 0;
+}
+
+int nv04_graph_init(struct drm_device *dev) {
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PGRAPH);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PGRAPH);
+
+	/* Enable PGRAPH interrupts */
+	nv_wr32(NV03_PGRAPH_INTR, 0xFFFFFFFF);
+	nv_wr32(NV03_PGRAPH_INTR_EN, 0xFFFFFFFF);
+
+	nv_wr32(NV04_PGRAPH_VALID1, 0);
+	nv_wr32(NV04_PGRAPH_VALID2, 0);
+	/*nv_wr32(NV04_PGRAPH_DEBUG_0, 0x000001FF);
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x001FFFFF);*/
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x1231c000);
+	/*1231C000 blob, 001 haiku*/
+	//*V_WRITE(NV04_PGRAPH_DEBUG_1, 0xf2d91100);*/
+	nv_wr32(NV04_PGRAPH_DEBUG_1, 0x72111100);
+	/*0x72111100 blob , 01 haiku*/
+	/*nv_wr32(NV04_PGRAPH_DEBUG_2, 0x11d5f870);*/
+	nv_wr32(NV04_PGRAPH_DEBUG_2, 0x11d5f071);
+	/*haiku same*/
+
+	/*nv_wr32(NV04_PGRAPH_DEBUG_3, 0xfad4ff31);*/
+	nv_wr32(NV04_PGRAPH_DEBUG_3, 0xf0d4ff31);
+	/*haiku and blob 10d4*/
+
+	nv_wr32(NV04_PGRAPH_STATE        , 0xFFFFFFFF);
+	nv_wr32(NV04_PGRAPH_CTX_CONTROL  , 0x10010100);
+
+	/* These don't belong here, they're part of a per-channel context */
+	nv_wr32(NV04_PGRAPH_PATTERN_SHAPE, 0x00000000);
+	nv_wr32(NV04_PGRAPH_BETA_AND     , 0xFFFFFFFF);
+
+	return 0;
+}
+
+void nv04_graph_takedown(struct drm_device *dev)
+{
+}
+
+void
+nv04_graph_fifo_access(struct drm_device *dev, bool enabled)
+{
+	if (enabled)
+		nv_wr32(NV04_PGRAPH_FIFO, nv_rd32(NV04_PGRAPH_FIFO) | 1);
+	else
+		nv_wr32(NV04_PGRAPH_FIFO, nv_rd32(NV04_PGRAPH_FIFO) & ~1);
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv04_instmem.c b/drivers/gpu/drm/nouveau/nv04_instmem.c
new file mode 100644
index 0000000..5994869
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_instmem.c
@@ -0,0 +1,190 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+static void
+nv04_instmem_determine_amount(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int i;
+
+	/* Figure out how much instance memory we need */
+	if (dev_priv->card_type >= NV_40) {
+		/* We'll want more instance memory than this on some NV4x cards.
+		 * There's a 16MB aperture to play with that maps onto the end
+		 * of vram.  For now, only reserve a small piece until we know
+		 * more about what each chipset requires.
+		 */
+		switch (dev_priv->chipset & 0xf0) {
+		case 0x40:
+		case 0x47:
+		case 0x49:
+		case 0x4b:
+			dev_priv->ramin_rsvd_vram = (2*1024* 1024);
+			break;
+		default:
+			dev_priv->ramin_rsvd_vram = (1*1024* 1024);
+			break;
+		}
+	} else {
+		/*XXX: what *are* the limits on <NV40 cards?
+		 */
+		dev_priv->ramin_rsvd_vram = (512*1024);
+	}
+	NV_DEBUG(dev, "RAMIN size: %dKiB\n", dev_priv->ramin_rsvd_vram>>10);
+
+	/* Clear all of it, except the BIOS image that's in the first 64KiB */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	for (i=(64*1024); i<dev_priv->ramin_rsvd_vram; i+=4)
+		nv_wi32(i, 0x00000000);
+	dev_priv->engine.instmem.finish_access(dev);
+}
+
+static void
+nv04_instmem_configure_fixed_tables(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+
+	/* FIFO hash table (RAMHT)
+	 *   use 4k hash table at RAMIN+0x10000
+	 *   TODO: extend the hash table
+	 */
+	dev_priv->ramht_offset = 0x10000;
+	dev_priv->ramht_bits   = 9;
+	dev_priv->ramht_size   = (1 << dev_priv->ramht_bits); /* nr entries */
+	dev_priv->ramht_size  *= 8; /* 2 32-bit values per entry in RAMHT */
+	NV_DEBUG(dev, "RAMHT offset=0x%x, size=%d\n", dev_priv->ramht_offset,
+						      dev_priv->ramht_size);
+
+	/* FIFO runout table (RAMRO) - 512k at 0x11200 */
+	dev_priv->ramro_offset = 0x11200;
+	dev_priv->ramro_size   = 512;
+	NV_DEBUG(dev, "RAMRO offset=0x%x, size=%d\n", dev_priv->ramro_offset,
+						      dev_priv->ramro_size);
+
+	/* FIFO context table (RAMFC)
+	 *   NV40  : Not sure exactly how to position RAMFC on some cards,
+	 *           0x30002 seems to position it at RAMIN+0x20000 on these
+	 *           cards.  RAMFC is 4kb (32 fifos, 128byte entries).
+	 *   Others: Position RAMFC at RAMIN+0x11400
+	 */
+	switch(dev_priv->card_type)
+	{
+		case NV_40:
+		case NV_44:
+			dev_priv->ramfc_offset = 0x20000;
+			dev_priv->ramfc_size   = engine->fifo.channels *
+						 nouveau_fifo_ctx_size(dev);
+			break;
+		case NV_30:
+		case NV_20:
+		case NV_17:
+		case NV_11:
+		case NV_10:
+		case NV_04:
+		default:
+			dev_priv->ramfc_offset = 0x11400;
+			dev_priv->ramfc_size   = engine->fifo.channels *
+						 nouveau_fifo_ctx_size(dev);
+			break;
+	}
+	NV_DEBUG(dev, "RAMFC offset=0x%x, size=%d\n", dev_priv->ramfc_offset,
+						      dev_priv->ramfc_size);
+}
+
+int nv04_instmem_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t offset;
+	int ret = 0;
+
+	nv04_instmem_determine_amount(dev);
+	nv04_instmem_configure_fixed_tables(dev);
+
+	/* Create a heap to manage RAMIN allocations, we don't allocate
+	 * the space that was reserved for RAMHT/FC/RO.
+	 */
+	offset = dev_priv->ramfc_offset + dev_priv->ramfc_size;
+
+	/* On my NV4E, there's *something* clobbering the 16KiB just after
+	 * where we setup these fixed tables.  No idea what it is just yet,
+	 * so reserve this space on all NV4X cards for now.
+	 */
+	if (dev_priv->card_type >= NV_40)
+		offset += 16*1024;
+
+	ret = nouveau_mem_init_heap(&dev_priv->ramin_heap,
+				    offset, dev_priv->ramin_rsvd_vram - offset);
+	if (ret) {
+		dev_priv->ramin_heap = NULL;
+		NV_ERROR(dev, "Failed to init RAMIN heap\n");
+	}
+
+	return ret;
+}
+
+void
+nv04_instmem_takedown(struct drm_device *dev)
+{
+}
+
+int
+nv04_instmem_populate(struct drm_device *dev, struct nouveau_gpuobj *gpuobj, uint32_t *sz)
+{
+	if (gpuobj->im_backing)
+		return -EINVAL;
+
+	return 0;
+}
+
+void
+nv04_instmem_clear(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (gpuobj && gpuobj->im_backing) {
+		if (gpuobj->im_bound)
+			dev_priv->engine.instmem.unbind(dev, gpuobj);
+		gpuobj->im_backing = NULL;
+	}
+}
+
+int
+nv04_instmem_bind(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	if (!gpuobj->im_pramin || gpuobj->im_bound)
+		return -EINVAL;
+
+	gpuobj->im_bound = 1;
+	return 0;
+}
+
+int
+nv04_instmem_unbind(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	if (gpuobj->im_bound == 0)
+		return -EINVAL;
+
+	gpuobj->im_bound = 0;
+	return 0;
+}
+
+void
+nv04_instmem_prepare_access(struct drm_device *dev, bool write)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	BUG_ON(dev_priv->ramin_map != NULL);
+	dev_priv->ramin_map = dev_priv->ramin;
+}
+
+void
+nv04_instmem_finish_access(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	BUG_ON(dev_priv->ramin_map == NULL);
+	dev_priv->ramin_map = NULL;
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv04_mc.c b/drivers/gpu/drm/nouveau/nv04_mc.c
new file mode 100644
index 0000000..963c484
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_mc.c
@@ -0,0 +1,20 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv04_mc_init(struct drm_device *dev)
+{
+	/* Power up everything, resetting each individual unit will
+	 * be done later if needed.
+	 */
+
+	nv_wr32(NV03_PMC_ENABLE, 0xFFFFFFFF);
+	return 0;
+}
+
+void
+nv04_mc_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv04_timer.c b/drivers/gpu/drm/nouveau/nv04_timer.c
new file mode 100644
index 0000000..d7466cb
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv04_timer.c
@@ -0,0 +1,50 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv04_timer_init(struct drm_device *dev)
+{
+	nv_wr32(NV04_PTIMER_INTR_EN_0, 0x00000000);
+	nv_wr32(NV04_PTIMER_INTR_0, 0xFFFFFFFF);
+
+	/* Just use the pre-existing values when possible for now; these regs
+	 * are not written in nv (driver writer missed a /4 on the address), and
+	 * writing 8 and 3 to the correct regs breaks the timings on the LVDS
+	 * hardware sequencing microcode.
+	 * A correct solution (involving calculations with the GPU PLL) can
+	 * be done when kernel modesetting lands
+	 */
+	if (!nv_rd32(NV04_PTIMER_NUMERATOR) || !nv_rd32(NV04_PTIMER_DENOMINATOR)) {
+		nv_wr32(NV04_PTIMER_NUMERATOR, 0x00000008);
+		nv_wr32(NV04_PTIMER_DENOMINATOR, 0x00000003);
+	}
+
+	return 0;
+}
+
+uint64_t
+nv04_timer_read(struct drm_device *dev)
+{
+	uint32_t low;
+	/* From kmmio dumps on nv28 this looks like how the blob does this.
+	 * It reads the high dword twice, before and after.
+	 * The only explanation seems to be that the 64-bit timer counter
+	 * advances between high and low dword reads and may corrupt the
+	 * result. Not confirmed.
+	 */
+	uint32_t high2 = nv_rd32(NV04_PTIMER_TIME_1);
+	uint32_t high1;
+	do {
+		high1 = high2;
+		low = nv_rd32(NV04_PTIMER_TIME_0);
+		high2 = nv_rd32(NV04_PTIMER_TIME_1);
+	} while(high1 != high2);
+	return (((uint64_t)high2) << 32) | (uint64_t)low;
+}
+
+void
+nv04_timer_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv10_fb.c b/drivers/gpu/drm/nouveau/nv10_fb.c
new file mode 100644
index 0000000..2a9ca65
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv10_fb.c
@@ -0,0 +1,24 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv10_fb_init(struct drm_device *dev)
+{
+	uint32_t fb_bar_size;
+	int i;
+
+	fb_bar_size = drm_get_resource_len(dev, 0) - 1;
+	for (i=0; i<NV10_PFB_TILE__SIZE; i++) {
+		nv_wr32(NV10_PFB_TILE(i), 0);
+		nv_wr32(NV10_PFB_TLIMIT(i), fb_bar_size);
+	}
+
+	return 0;
+}
+
+void
+nv10_fb_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv10_fifo.c b/drivers/gpu/drm/nouveau/nv10_fifo.c
new file mode 100644
index 0000000..62c1c11
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv10_fifo.c
@@ -0,0 +1,175 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+
+#define RAMFC_WR(offset,val) INSTANCE_WR(chan->ramfc->gpuobj, \
+					 NV10_RAMFC_##offset/4, (val))
+#define RAMFC_RD(offset)     INSTANCE_RD(chan->ramfc->gpuobj, \
+					 NV10_RAMFC_##offset/4)
+#define NV10_RAMFC(c) (dev_priv->ramfc_offset + ((c) * NV10_RAMFC__SIZE))
+#define NV10_RAMFC__SIZE ((dev_priv->chipset) >= 0x17 ? 64 : 32)
+
+int
+nv10_fifo_channel_id(struct drm_device *dev)
+{
+	return (nv_rd32(NV03_PFIFO_CACHE1_PUSH1) &
+			NV10_PFIFO_CACHE1_PUSH1_CHID_MASK);
+}
+
+int
+nv10_fifo_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	if ((ret = nouveau_gpuobj_new_fake(dev, NV10_RAMFC(chan->id), ~0,
+						NV10_RAMFC__SIZE,
+						NVOBJ_FLAG_ZERO_ALLOC |
+						NVOBJ_FLAG_ZERO_FREE,
+						NULL, &chan->ramfc)))
+		return ret;
+
+	/* Fill entries that are seen filled in dumps of nvidia driver just
+	 * after channel's is put into DMA mode
+	 */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	RAMFC_WR(DMA_PUT       , chan->pushbuf_base);
+	RAMFC_WR(DMA_GET       , chan->pushbuf_base);
+	RAMFC_WR(DMA_INSTANCE  , chan->pushbuf->instance >> 4);
+	RAMFC_WR(DMA_FETCH     , NV_PFIFO_CACHE1_DMA_FETCH_TRIG_128_BYTES |
+				 NV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES |
+				 NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_8 |
+#ifdef __BIG_ENDIAN
+				 NV_PFIFO_CACHE1_BIG_ENDIAN |
+#endif
+				 0);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* enable the fifo dma operation */
+	nv_wr32(NV04_PFIFO_MODE,nv_rd32(NV04_PFIFO_MODE)|(1<<chan->id));
+	return 0;
+}
+
+void
+nv10_fifo_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+
+	nv_wr32(NV04_PFIFO_MODE, nv_rd32(NV04_PFIFO_MODE)&~(1<<chan->id));
+
+	nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+}
+
+int
+nv10_fifo_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH1,
+		 NV03_PFIFO_CACHE1_PUSH1_DMA | chan->id);
+
+	dev_priv->engine.instmem.prepare_access(dev, false);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_GET          , RAMFC_RD(DMA_GET));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUT          , RAMFC_RD(DMA_PUT));
+	nv_wr32(NV10_PFIFO_CACHE1_REF_CNT          , RAMFC_RD(REF_CNT));
+
+	tmp = RAMFC_RD(DMA_INSTANCE);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_INSTANCE     , tmp & 0xFFFF);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_DCOUNT       , tmp >> 16);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_STATE        , RAMFC_RD(DMA_STATE));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_FETCH        , RAMFC_RD(DMA_FETCH));
+	nv_wr32(NV04_PFIFO_CACHE1_ENGINE           , RAMFC_RD(ENGINE));
+	nv_wr32(NV04_PFIFO_CACHE1_PULL1            , RAMFC_RD(PULL1_ENGINE));
+
+	if (dev_priv->chipset >= 0x17) {
+		nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_VALUE,
+			 RAMFC_RD(ACQUIRE_VALUE));
+		nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_TIMESTAMP,
+			 RAMFC_RD(ACQUIRE_TIMESTAMP));
+		nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_TIMEOUT,
+			 RAMFC_RD(ACQUIRE_TIMEOUT));
+		nv_wr32(NV10_PFIFO_CACHE1_SEMAPHORE,
+			 RAMFC_RD(SEMAPHORE));
+		nv_wr32(NV10_PFIFO_CACHE1_DMA_SUBROUTINE,
+			 RAMFC_RD(DMA_SUBROUTINE));
+	}
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* Reset NV04_PFIFO_CACHE1_DMA_CTL_AT_INFO to INVALID */
+	tmp = nv_rd32(NV04_PFIFO_CACHE1_DMA_CTL) & ~(1<<31);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_CTL, tmp);
+
+	return 0;
+}
+
+int
+nv10_fifo_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+
+	RAMFC_WR(DMA_PUT          , nv_rd32(NV04_PFIFO_CACHE1_DMA_PUT));
+	RAMFC_WR(DMA_GET          , nv_rd32(NV04_PFIFO_CACHE1_DMA_GET));
+	RAMFC_WR(REF_CNT          , nv_rd32(NV10_PFIFO_CACHE1_REF_CNT));
+
+	tmp  = nv_rd32(NV04_PFIFO_CACHE1_DMA_INSTANCE) & 0xFFFF;
+	tmp |= (nv_rd32(NV04_PFIFO_CACHE1_DMA_DCOUNT) << 16);
+	RAMFC_WR(DMA_INSTANCE     , tmp);
+
+	RAMFC_WR(DMA_STATE        , nv_rd32(NV04_PFIFO_CACHE1_DMA_STATE));
+	RAMFC_WR(DMA_FETCH	  , nv_rd32(NV04_PFIFO_CACHE1_DMA_FETCH));
+	RAMFC_WR(ENGINE           , nv_rd32(NV04_PFIFO_CACHE1_ENGINE));
+	RAMFC_WR(PULL1_ENGINE     , nv_rd32(NV04_PFIFO_CACHE1_PULL1));
+
+	if (dev_priv->chipset >= 0x17) {
+		RAMFC_WR(ACQUIRE_VALUE,
+			 nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_VALUE));
+		RAMFC_WR(ACQUIRE_TIMESTAMP,
+			 nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_TIMESTAMP));
+		RAMFC_WR(ACQUIRE_TIMEOUT,
+			 nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_TIMEOUT));
+		RAMFC_WR(SEMAPHORE,
+			 nv_rd32(NV10_PFIFO_CACHE1_SEMAPHORE));
+		RAMFC_WR(DMA_SUBROUTINE,
+			 nv_rd32(NV04_PFIFO_CACHE1_DMA_GET));
+	}
+
+	dev_priv->engine.instmem.finish_access(dev);
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv10_graph.c b/drivers/gpu/drm/nouveau/nv10_graph.c
new file mode 100644
index 0000000..2c11b8d
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv10_graph.c
@@ -0,0 +1,912 @@
+/*
+ * Copyright 2007 Matthieu CASTET <castet.matthieu@free.fr>
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drm.h"
+#include "nouveau_drv.h"
+
+#define NV10_FIFO_NUMBER 32
+
+struct pipe_state {
+	uint32_t pipe_0x0000[0x040/4];
+	uint32_t pipe_0x0040[0x010/4];
+	uint32_t pipe_0x0200[0x0c0/4];
+	uint32_t pipe_0x4400[0x080/4];
+	uint32_t pipe_0x6400[0x3b0/4];
+	uint32_t pipe_0x6800[0x2f0/4];
+	uint32_t pipe_0x6c00[0x030/4];
+	uint32_t pipe_0x7000[0x130/4];
+	uint32_t pipe_0x7400[0x0c0/4];
+	uint32_t pipe_0x7800[0x0c0/4];
+};
+
+static int nv10_graph_ctx_regs [] = {
+NV10_PGRAPH_CTX_SWITCH1,
+NV10_PGRAPH_CTX_SWITCH2,
+NV10_PGRAPH_CTX_SWITCH3,
+NV10_PGRAPH_CTX_SWITCH4,
+NV10_PGRAPH_CTX_SWITCH5,
+NV10_PGRAPH_CTX_CACHE1,	/* 8 values from 0x400160 to 0x40017c */
+NV10_PGRAPH_CTX_CACHE2,	/* 8 values from 0x400180 to 0x40019c */
+NV10_PGRAPH_CTX_CACHE3,	/* 8 values from 0x4001a0 to 0x4001bc */
+NV10_PGRAPH_CTX_CACHE4,	/* 8 values from 0x4001c0 to 0x4001dc */
+NV10_PGRAPH_CTX_CACHE5,	/* 8 values from 0x4001e0 to 0x4001fc */
+0x00400164,
+0x00400184,
+0x004001a4,
+0x004001c4,
+0x004001e4,
+0x00400168,
+0x00400188,
+0x004001a8,
+0x004001c8,
+0x004001e8,
+0x0040016c,
+0x0040018c,
+0x004001ac,
+0x004001cc,
+0x004001ec,
+0x00400170,
+0x00400190,
+0x004001b0,
+0x004001d0,
+0x004001f0,
+0x00400174,
+0x00400194,
+0x004001b4,
+0x004001d4,
+0x004001f4,
+0x00400178,
+0x00400198,
+0x004001b8,
+0x004001d8,
+0x004001f8,
+0x0040017c,
+0x0040019c,
+0x004001bc,
+0x004001dc,
+0x004001fc,
+NV10_PGRAPH_CTX_USER,
+NV04_PGRAPH_DMA_START_0,
+NV04_PGRAPH_DMA_START_1,
+NV04_PGRAPH_DMA_LENGTH,
+NV04_PGRAPH_DMA_MISC,
+NV10_PGRAPH_DMA_PITCH,
+NV04_PGRAPH_BOFFSET0,
+NV04_PGRAPH_BBASE0,
+NV04_PGRAPH_BLIMIT0,
+NV04_PGRAPH_BOFFSET1,
+NV04_PGRAPH_BBASE1,
+NV04_PGRAPH_BLIMIT1,
+NV04_PGRAPH_BOFFSET2,
+NV04_PGRAPH_BBASE2,
+NV04_PGRAPH_BLIMIT2,
+NV04_PGRAPH_BOFFSET3,
+NV04_PGRAPH_BBASE3,
+NV04_PGRAPH_BLIMIT3,
+NV04_PGRAPH_BOFFSET4,
+NV04_PGRAPH_BBASE4,
+NV04_PGRAPH_BLIMIT4,
+NV04_PGRAPH_BOFFSET5,
+NV04_PGRAPH_BBASE5,
+NV04_PGRAPH_BLIMIT5,
+NV04_PGRAPH_BPITCH0,
+NV04_PGRAPH_BPITCH1,
+NV04_PGRAPH_BPITCH2,
+NV04_PGRAPH_BPITCH3,
+NV04_PGRAPH_BPITCH4,
+NV10_PGRAPH_SURFACE,
+NV10_PGRAPH_STATE,
+NV04_PGRAPH_BSWIZZLE2,
+NV04_PGRAPH_BSWIZZLE5,
+NV04_PGRAPH_BPIXEL,
+NV10_PGRAPH_NOTIFY,
+NV04_PGRAPH_PATT_COLOR0,
+NV04_PGRAPH_PATT_COLOR1,
+NV04_PGRAPH_PATT_COLORRAM, /* 64 values from 0x400900 to 0x4009fc */
+0x00400904,
+0x00400908,
+0x0040090c,
+0x00400910,
+0x00400914,
+0x00400918,
+0x0040091c,
+0x00400920,
+0x00400924,
+0x00400928,
+0x0040092c,
+0x00400930,
+0x00400934,
+0x00400938,
+0x0040093c,
+0x00400940,
+0x00400944,
+0x00400948,
+0x0040094c,
+0x00400950,
+0x00400954,
+0x00400958,
+0x0040095c,
+0x00400960,
+0x00400964,
+0x00400968,
+0x0040096c,
+0x00400970,
+0x00400974,
+0x00400978,
+0x0040097c,
+0x00400980,
+0x00400984,
+0x00400988,
+0x0040098c,
+0x00400990,
+0x00400994,
+0x00400998,
+0x0040099c,
+0x004009a0,
+0x004009a4,
+0x004009a8,
+0x004009ac,
+0x004009b0,
+0x004009b4,
+0x004009b8,
+0x004009bc,
+0x004009c0,
+0x004009c4,
+0x004009c8,
+0x004009cc,
+0x004009d0,
+0x004009d4,
+0x004009d8,
+0x004009dc,
+0x004009e0,
+0x004009e4,
+0x004009e8,
+0x004009ec,
+0x004009f0,
+0x004009f4,
+0x004009f8,
+0x004009fc,
+NV04_PGRAPH_PATTERN,	/* 2 values from 0x400808 to 0x40080c */
+0x0040080c,
+NV04_PGRAPH_PATTERN_SHAPE,
+NV03_PGRAPH_MONO_COLOR0,
+NV04_PGRAPH_ROP3,
+NV04_PGRAPH_CHROMA,
+NV04_PGRAPH_BETA_AND,
+NV04_PGRAPH_BETA_PREMULT,
+0x00400e70,
+0x00400e74,
+0x00400e78,
+0x00400e7c,
+0x00400e80,
+0x00400e84,
+0x00400e88,
+0x00400e8c,
+0x00400ea0,
+0x00400ea4,
+0x00400ea8,
+0x00400e90,
+0x00400e94,
+0x00400e98,
+0x00400e9c,
+NV10_PGRAPH_WINDOWCLIP_HORIZONTAL, /* 8 values from 0x400f00 to 0x400f1c */
+NV10_PGRAPH_WINDOWCLIP_VERTICAL,   /* 8 values from 0x400f20 to 0x400f3c */
+0x00400f04,
+0x00400f24,
+0x00400f08,
+0x00400f28,
+0x00400f0c,
+0x00400f2c,
+0x00400f10,
+0x00400f30,
+0x00400f14,
+0x00400f34,
+0x00400f18,
+0x00400f38,
+0x00400f1c,
+0x00400f3c,
+NV10_PGRAPH_XFMODE0,
+NV10_PGRAPH_XFMODE1,
+NV10_PGRAPH_GLOBALSTATE0,
+NV10_PGRAPH_GLOBALSTATE1,
+NV04_PGRAPH_STORED_FMT,
+NV04_PGRAPH_SOURCE_COLOR,
+NV03_PGRAPH_ABS_X_RAM,	/* 32 values from 0x400400 to 0x40047c */
+NV03_PGRAPH_ABS_Y_RAM,	/* 32 values from 0x400480 to 0x4004fc */
+0x00400404,
+0x00400484,
+0x00400408,
+0x00400488,
+0x0040040c,
+0x0040048c,
+0x00400410,
+0x00400490,
+0x00400414,
+0x00400494,
+0x00400418,
+0x00400498,
+0x0040041c,
+0x0040049c,
+0x00400420,
+0x004004a0,
+0x00400424,
+0x004004a4,
+0x00400428,
+0x004004a8,
+0x0040042c,
+0x004004ac,
+0x00400430,
+0x004004b0,
+0x00400434,
+0x004004b4,
+0x00400438,
+0x004004b8,
+0x0040043c,
+0x004004bc,
+0x00400440,
+0x004004c0,
+0x00400444,
+0x004004c4,
+0x00400448,
+0x004004c8,
+0x0040044c,
+0x004004cc,
+0x00400450,
+0x004004d0,
+0x00400454,
+0x004004d4,
+0x00400458,
+0x004004d8,
+0x0040045c,
+0x004004dc,
+0x00400460,
+0x004004e0,
+0x00400464,
+0x004004e4,
+0x00400468,
+0x004004e8,
+0x0040046c,
+0x004004ec,
+0x00400470,
+0x004004f0,
+0x00400474,
+0x004004f4,
+0x00400478,
+0x004004f8,
+0x0040047c,
+0x004004fc,
+NV03_PGRAPH_ABS_UCLIP_XMIN,
+NV03_PGRAPH_ABS_UCLIP_XMAX,
+NV03_PGRAPH_ABS_UCLIP_YMIN,
+NV03_PGRAPH_ABS_UCLIP_YMAX,
+0x00400550,
+0x00400558,
+0x00400554,
+0x0040055c,
+NV03_PGRAPH_ABS_UCLIPA_XMIN,
+NV03_PGRAPH_ABS_UCLIPA_XMAX,
+NV03_PGRAPH_ABS_UCLIPA_YMIN,
+NV03_PGRAPH_ABS_UCLIPA_YMAX,
+NV03_PGRAPH_ABS_ICLIP_XMAX,
+NV03_PGRAPH_ABS_ICLIP_YMAX,
+NV03_PGRAPH_XY_LOGIC_MISC0,
+NV03_PGRAPH_XY_LOGIC_MISC1,
+NV03_PGRAPH_XY_LOGIC_MISC2,
+NV03_PGRAPH_XY_LOGIC_MISC3,
+NV03_PGRAPH_CLIPX_0,
+NV03_PGRAPH_CLIPX_1,
+NV03_PGRAPH_CLIPY_0,
+NV03_PGRAPH_CLIPY_1,
+NV10_PGRAPH_COMBINER0_IN_ALPHA,
+NV10_PGRAPH_COMBINER1_IN_ALPHA,
+NV10_PGRAPH_COMBINER0_IN_RGB,
+NV10_PGRAPH_COMBINER1_IN_RGB,
+NV10_PGRAPH_COMBINER_COLOR0,
+NV10_PGRAPH_COMBINER_COLOR1,
+NV10_PGRAPH_COMBINER0_OUT_ALPHA,
+NV10_PGRAPH_COMBINER1_OUT_ALPHA,
+NV10_PGRAPH_COMBINER0_OUT_RGB,
+NV10_PGRAPH_COMBINER1_OUT_RGB,
+NV10_PGRAPH_COMBINER_FINAL0,
+NV10_PGRAPH_COMBINER_FINAL1,
+0x00400e00,
+0x00400e04,
+0x00400e08,
+0x00400e0c,
+0x00400e10,
+0x00400e14,
+0x00400e18,
+0x00400e1c,
+0x00400e20,
+0x00400e24,
+0x00400e28,
+0x00400e2c,
+0x00400e30,
+0x00400e34,
+0x00400e38,
+0x00400e3c,
+NV04_PGRAPH_PASSTHRU_0,
+NV04_PGRAPH_PASSTHRU_1,
+NV04_PGRAPH_PASSTHRU_2,
+NV10_PGRAPH_DIMX_TEXTURE,
+NV10_PGRAPH_WDIMX_TEXTURE,
+NV10_PGRAPH_DVD_COLORFMT,
+NV10_PGRAPH_SCALED_FORMAT,
+NV04_PGRAPH_MISC24_0,
+NV04_PGRAPH_MISC24_1,
+NV04_PGRAPH_MISC24_2,
+NV03_PGRAPH_X_MISC,
+NV03_PGRAPH_Y_MISC,
+NV04_PGRAPH_VALID1,
+NV04_PGRAPH_VALID2,
+};
+
+static int nv17_graph_ctx_regs [] = {
+NV10_PGRAPH_DEBUG_4,
+0x004006b0,
+0x00400eac,
+0x00400eb0,
+0x00400eb4,
+0x00400eb8,
+0x00400ebc,
+0x00400ec0,
+0x00400ec4,
+0x00400ec8,
+0x00400ecc,
+0x00400ed0,
+0x00400ed4,
+0x00400ed8,
+0x00400edc,
+0x00400ee0,
+0x00400a00,
+0x00400a04,
+};
+
+struct graph_state {
+	int nv10[sizeof(nv10_graph_ctx_regs)/sizeof(nv10_graph_ctx_regs[0])];
+	int nv17[sizeof(nv17_graph_ctx_regs)/sizeof(nv17_graph_ctx_regs[0])];
+	struct pipe_state pipe_state;
+};
+
+static void nv10_graph_save_pipe(struct nouveau_channel *chan) {
+	struct drm_device *dev = chan->dev;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	struct pipe_state *fifo_pipe_state = &pgraph_ctx->pipe_state;
+	int i;
+#define PIPE_SAVE(addr) \
+	do { \
+		nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, addr); \
+		for (i=0; i < sizeof(fifo_pipe_state->pipe_##addr)/sizeof(fifo_pipe_state->pipe_##addr[0]); i++) \
+			fifo_pipe_state->pipe_##addr[i] = nv_rd32(NV10_PGRAPH_PIPE_DATA); \
+	} while (0)
+
+	PIPE_SAVE(0x4400);
+	PIPE_SAVE(0x0200);
+	PIPE_SAVE(0x6400);
+	PIPE_SAVE(0x6800);
+	PIPE_SAVE(0x6c00);
+	PIPE_SAVE(0x7000);
+	PIPE_SAVE(0x7400);
+	PIPE_SAVE(0x7800);
+	PIPE_SAVE(0x0040);
+	PIPE_SAVE(0x0000);
+
+#undef PIPE_SAVE
+}
+
+static void nv10_graph_load_pipe(struct nouveau_channel *chan) {
+	struct drm_device *dev = chan->dev;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	struct pipe_state *fifo_pipe_state = &pgraph_ctx->pipe_state;
+	int i;
+	uint32_t xfmode0, xfmode1;
+#define PIPE_RESTORE(addr) \
+	do { \
+		nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, addr); \
+		for (i=0; i < sizeof(fifo_pipe_state->pipe_##addr)/sizeof(fifo_pipe_state->pipe_##addr[0]); i++) \
+			nv_wr32(NV10_PGRAPH_PIPE_DATA, fifo_pipe_state->pipe_##addr[i]); \
+	} while (0)
+
+
+	nouveau_wait_for_idle(dev);
+	/* XXX check haiku comments */
+	xfmode0 = nv_rd32(NV10_PGRAPH_XFMODE0);
+	xfmode1 = nv_rd32(NV10_PGRAPH_XFMODE1);
+	nv_wr32(NV10_PGRAPH_XFMODE0, 0x10000000);
+	nv_wr32(NV10_PGRAPH_XFMODE1, 0x00000000);
+	nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, 0x000064c0);
+	for (i = 0; i < 4; i++)
+		nv_wr32(NV10_PGRAPH_PIPE_DATA, 0x3f800000);
+	for (i = 0; i < 4; i++)
+		nv_wr32(NV10_PGRAPH_PIPE_DATA, 0x00000000);
+
+	nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, 0x00006ab0);
+	for (i = 0; i < 3; i++)
+		nv_wr32(NV10_PGRAPH_PIPE_DATA, 0x3f800000);
+
+	nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, 0x00006a80);
+	for (i = 0; i < 3; i++)
+		nv_wr32(NV10_PGRAPH_PIPE_DATA, 0x00000000);
+
+	nv_wr32(NV10_PGRAPH_PIPE_ADDRESS, 0x00000040);
+	nv_wr32(NV10_PGRAPH_PIPE_DATA, 0x00000008);
+
+
+	PIPE_RESTORE(0x0200);
+	nouveau_wait_for_idle(dev);
+
+	/* restore XFMODE */
+	nv_wr32(NV10_PGRAPH_XFMODE0, xfmode0);
+	nv_wr32(NV10_PGRAPH_XFMODE1, xfmode1);
+	PIPE_RESTORE(0x6400);
+	PIPE_RESTORE(0x6800);
+	PIPE_RESTORE(0x6c00);
+	PIPE_RESTORE(0x7000);
+	PIPE_RESTORE(0x7400);
+	PIPE_RESTORE(0x7800);
+	PIPE_RESTORE(0x4400);
+	PIPE_RESTORE(0x0000);
+	PIPE_RESTORE(0x0040);
+	nouveau_wait_for_idle(dev);
+
+#undef PIPE_RESTORE
+}
+
+static void nv10_graph_create_pipe(struct nouveau_channel *chan) {
+	struct drm_device *dev = chan->dev;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	struct pipe_state *fifo_pipe_state = &pgraph_ctx->pipe_state;
+	uint32_t *fifo_pipe_state_addr;
+	int i;
+#define PIPE_INIT(addr) \
+	do { \
+		fifo_pipe_state_addr = fifo_pipe_state->pipe_##addr; \
+	} while (0)
+#define PIPE_INIT_END(addr) \
+	do { \
+		if (fifo_pipe_state_addr != \
+				sizeof(fifo_pipe_state->pipe_##addr)/sizeof(fifo_pipe_state->pipe_##addr[0]) + fifo_pipe_state->pipe_##addr) \
+			NV_ERROR(dev, "incomplete pipe init for 0x%x :  %p/%p\n", addr, fifo_pipe_state_addr, \
+					sizeof(fifo_pipe_state->pipe_##addr)/sizeof(fifo_pipe_state->pipe_##addr[0]) + fifo_pipe_state->pipe_##addr); \
+	} while (0)
+#define NV_WRITE_PIPE_INIT(value) *(fifo_pipe_state_addr++) = value
+
+	PIPE_INIT(0x0200);
+	for (i = 0; i < 48; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x0200);
+
+	PIPE_INIT(0x6400);
+	for (i = 0; i < 211; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x40000000);
+	NV_WRITE_PIPE_INIT(0x40000000);
+	NV_WRITE_PIPE_INIT(0x40000000);
+	NV_WRITE_PIPE_INIT(0x40000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f000000);
+	NV_WRITE_PIPE_INIT(0x3f000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	PIPE_INIT_END(0x6400);
+
+	PIPE_INIT(0x6800);
+	for (i = 0; i < 162; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x3f800000);
+	for (i = 0; i < 25; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x6800);
+
+	PIPE_INIT(0x6c00);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0xbf800000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x6c00);
+
+	PIPE_INIT(0x7000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x00000000);
+	NV_WRITE_PIPE_INIT(0x7149f2ca);
+	for (i = 0; i < 35; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x7000);
+
+	PIPE_INIT(0x7400);
+	for (i = 0; i < 48; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x7400);
+
+	PIPE_INIT(0x7800);
+	for (i = 0; i < 48; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x7800);
+
+	PIPE_INIT(0x4400);
+	for (i = 0; i < 32; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x4400);
+
+	PIPE_INIT(0x0000);
+	for (i = 0; i < 16; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x0000);
+
+	PIPE_INIT(0x0040);
+	for (i = 0; i < 4; i++)
+		NV_WRITE_PIPE_INIT(0x00000000);
+	PIPE_INIT_END(0x0040);
+
+#undef PIPE_INIT
+#undef PIPE_INIT_END
+#undef NV_WRITE_PIPE_INIT
+}
+
+static int nv10_graph_ctx_regs_find_offset(struct drm_device *dev, int reg)
+{
+	int i;
+	for (i = 0; i < sizeof(nv10_graph_ctx_regs)/sizeof(nv10_graph_ctx_regs[0]); i++) {
+		if (nv10_graph_ctx_regs[i] == reg)
+			return i;
+	}
+	NV_ERROR(dev, "unknow offset nv10_ctx_regs %d\n", reg);
+	return -1;
+}
+
+static int nv17_graph_ctx_regs_find_offset(struct drm_device *dev, int reg)
+{
+	int i;
+	for (i = 0; i < sizeof(nv17_graph_ctx_regs)/sizeof(nv17_graph_ctx_regs[0]); i++) {
+		if (nv17_graph_ctx_regs[i] == reg)
+			return i;
+	}
+	NV_ERROR(dev, "unknow offset nv17_ctx_regs %d\n", reg);
+	return -1;
+}
+
+int nv10_graph_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	int i;
+
+	for (i = 0; i < sizeof(nv10_graph_ctx_regs)/sizeof(nv10_graph_ctx_regs[0]); i++)
+		nv_wr32(nv10_graph_ctx_regs[i], pgraph_ctx->nv10[i]);
+	if (dev_priv->chipset>=0x17) {
+		for (i = 0; i < sizeof(nv17_graph_ctx_regs)/sizeof(nv17_graph_ctx_regs[0]); i++)
+			nv_wr32(nv17_graph_ctx_regs[i], pgraph_ctx->nv17[i]);
+	}
+
+	nv10_graph_load_pipe(chan);
+
+	return 0;
+}
+
+int nv10_graph_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	int i;
+
+	for (i = 0; i < sizeof(nv10_graph_ctx_regs)/sizeof(nv10_graph_ctx_regs[0]); i++)
+		pgraph_ctx->nv10[i] = nv_rd32(nv10_graph_ctx_regs[i]);
+	if (dev_priv->chipset>=0x17) {
+		for (i = 0; i < sizeof(nv17_graph_ctx_regs)/sizeof(nv17_graph_ctx_regs[0]); i++)
+			pgraph_ctx->nv17[i] = nv_rd32(nv17_graph_ctx_regs[i]);
+	}
+
+	nv10_graph_save_pipe(chan);
+
+	return 0;
+}
+
+void nouveau_nv10_context_switch(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv;
+	struct nouveau_engine *engine;
+	struct nouveau_channel *next, *last;
+	int chid;
+
+	if (!dev) {
+		NV_DEBUG(dev, "Invalid drm_device\n");
+		return;
+	}
+	dev_priv = dev->dev_private;
+	if (!dev_priv) {
+		NV_DEBUG(dev, "Invalid drm_nouveau_private\n");
+		return;
+	}
+	if (!dev_priv->fifos) {
+		NV_DEBUG(dev, "Invalid drm_nouveau_private->fifos\n");
+		return;
+	}
+	engine = &dev_priv->engine;
+
+	chid = (nv_rd32(NV04_PGRAPH_TRAPPED_ADDR) >> 20) &
+		(engine->fifo.channels - 1);
+	next = dev_priv->fifos[chid];
+
+	if (!next) {
+		NV_ERROR(dev, "Invalid next channel\n");
+		return;
+	}
+
+	chid = (nv_rd32(NV10_PGRAPH_CTX_USER) >> 24) & 
+		(engine->fifo.channels - 1);
+	last = dev_priv->fifos[chid];
+
+	if (!last) {
+		NV_INFO(dev, "WARNING: Invalid last channel, switch to %x\n",
+			next->id);
+	} else {
+		NV_DEBUG(dev, "NV: PGRAPH context switch interrupt channel %x -> %x\n",
+		         last->id, next->id);
+	}
+
+	nv_wr32(NV04_PGRAPH_FIFO,0x0);
+	if (last) {
+		nouveau_wait_for_idle(dev);
+		nv10_graph_save_context(last);
+	}
+
+	nouveau_wait_for_idle(dev);
+
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10000000);
+
+	nouveau_wait_for_idle(dev);
+
+	nv10_graph_load_context(next);
+
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10010100);
+	nv_wr32(NV10_PGRAPH_FFINTFC_ST2, nv_rd32(NV10_PGRAPH_FFINTFC_ST2)&0xCFFFFFFF);
+	nv_wr32(NV04_PGRAPH_FIFO,0x1);
+}
+
+#define NV_WRITE_CTX(reg, val) do { \
+	int offset = nv10_graph_ctx_regs_find_offset(dev, reg); \
+	if (offset > 0) \
+		pgraph_ctx->nv10[offset] = val; \
+	} while (0)
+
+#define NV17_WRITE_CTX(reg, val) do { \
+	int offset = nv17_graph_ctx_regs_find_offset(dev, reg); \
+	if (offset > 0) \
+		pgraph_ctx->nv17[offset] = val; \
+	} while (0)
+
+int nv10_graph_create_context(struct nouveau_channel *chan) {
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct graph_state* pgraph_ctx;
+
+	NV_DEBUG(dev, "nv10_graph_context_create %d\n", chan->id);
+
+	chan->pgraph_ctx = pgraph_ctx = drm_calloc(1, sizeof(*pgraph_ctx),
+					      DRM_MEM_DRIVER);
+
+	if (pgraph_ctx == NULL)
+		return -ENOMEM;
+
+	/* mmio trace suggest that should be done in ddx with methods/objects */
+#if 0
+	uint32_t tmp, vramsz;
+	/* per channel init from ddx */
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) & 0x0007ff00;
+	/*XXX the original ddx code, does this in 2 steps :
+	 * tmp = nv_rd32(NV10_PGRAPH_SURFACE) & 0x0007ff00;
+	 * nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+	 * tmp = nv_rd32(NV10_PGRAPH_SURFACE) | 0x00020100;
+	 * nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+	 */
+	tmp |= 0x00020100;
+	NV_WRITE_CTX(NV10_PGRAPH_SURFACE, tmp);
+
+	vramsz = drm_get_resource_len(dev, 0) - 1;
+	NV_WRITE_CTX(NV04_PGRAPH_BOFFSET0, 0);
+	NV_WRITE_CTX(NV04_PGRAPH_BOFFSET1, 0);
+	NV_WRITE_CTX(NV04_PGRAPH_BLIMIT0 , vramsz);
+	NV_WRITE_CTX(NV04_PGRAPH_BLIMIT1 , vramsz);
+
+	NV_WRITE_CTX(NV04_PGRAPH_PATTERN_SHAPE, 0x00000000);
+	NV_WRITE_CTX(NV04_PGRAPH_BETA_AND     , 0xFFFFFFFF);
+
+	NV_WRITE_CTX(NV03_PGRAPH_ABS_UCLIP_XMIN, 0);
+	NV_WRITE_CTX(NV03_PGRAPH_ABS_UCLIP_YMIN, 0);
+	NV_WRITE_CTX(NV03_PGRAPH_ABS_UCLIP_XMAX, 0x7fff);
+	NV_WRITE_CTX(NV03_PGRAPH_ABS_UCLIP_YMAX, 0x7fff);
+#endif
+
+	NV_WRITE_CTX(0x00400e88, 0x08000000);
+	NV_WRITE_CTX(0x00400e9c, 0x4b7fffff);
+	NV_WRITE_CTX(NV03_PGRAPH_XY_LOGIC_MISC0, 0x0001ffff);
+	NV_WRITE_CTX(0x00400e10, 0x00001000);
+	NV_WRITE_CTX(0x00400e14, 0x00001000);
+	NV_WRITE_CTX(0x00400e30, 0x00080008);
+	NV_WRITE_CTX(0x00400e34, 0x00080008);
+	if (dev_priv->chipset>=0x17) {
+		/* is it really needed ??? */
+		NV17_WRITE_CTX(NV10_PGRAPH_DEBUG_4, nv_rd32(NV10_PGRAPH_DEBUG_4));
+		NV17_WRITE_CTX(0x004006b0, nv_rd32(0x004006b0));
+		NV17_WRITE_CTX(0x00400eac, 0x0fff0000);
+		NV17_WRITE_CTX(0x00400eb0, 0x0fff0000);
+		NV17_WRITE_CTX(0x00400ec0, 0x00000080);
+		NV17_WRITE_CTX(0x00400ed0, 0x00000080);
+	}
+	NV_WRITE_CTX(NV10_PGRAPH_CTX_USER, chan->id << 24);
+
+	nv10_graph_create_pipe(chan);
+	return 0;
+}
+
+void nv10_graph_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_engine *engine = &dev_priv->engine;
+	struct graph_state* pgraph_ctx = chan->pgraph_ctx;
+	int chid;
+
+	drm_free(pgraph_ctx, sizeof(*pgraph_ctx), DRM_MEM_DRIVER);
+	chan->pgraph_ctx = NULL;
+
+	chid = (nv_rd32(NV10_PGRAPH_CTX_USER) >> 24) & (engine->fifo.channels - 1);
+
+	/* This code seems to corrupt the 3D pipe, but blob seems to do similar things ????
+	 */
+#if 0
+	/* does this avoid a potential context switch while we are written graph
+	 * reg, or we should mask graph interrupt ???
+	 */
+	nv_wr32(NV04_PGRAPH_FIFO,0x0);
+	if (chid == chan->id) {
+		NV_INFO(dev, "cleanning a channel with graph in current context\n");
+		nouveau_wait_for_idle(dev);
+		NV_INFO(dev, "reseting current graph context\n");
+		/* can't be call here because of dynamic mem alloc */
+		//nv10_graph_create_context(chan);
+		nv10_graph_load_context(chan);
+	}
+	nv_wr32(NV04_PGRAPH_FIFO, 0x1);
+#else
+	if (chid == chan->id) {
+		NV_INFO(dev, "cleanning a channel with graph in current context\n");
+	}
+#endif
+}
+
+int nv10_graph_init(struct drm_device *dev) {
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int i;
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PGRAPH);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PGRAPH);
+
+	nv_wr32(NV03_PGRAPH_INTR   , 0xFFFFFFFF);
+	nv_wr32(NV03_PGRAPH_INTR_EN, 0xFFFFFFFF);
+
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0xFFFFFFFF);
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x00000000);
+	nv_wr32(NV04_PGRAPH_DEBUG_1, 0x00118700);
+	//nv_wr32(NV04_PGRAPH_DEBUG_2, 0x24E00810); /* 0x25f92ad9 */
+	nv_wr32(NV04_PGRAPH_DEBUG_2, 0x25f92ad9);
+	nv_wr32(NV04_PGRAPH_DEBUG_3, 0x55DE0830 |
+				      (1<<29) |
+				      (1<<31));
+	if (dev_priv->chipset>=0x17) {
+		nv_wr32(NV10_PGRAPH_DEBUG_4, 0x1f000000);
+		nv_wr32(0x004006b0, 0x40000020);
+	}
+	else
+		nv_wr32(NV10_PGRAPH_DEBUG_4, 0x00000000);
+
+	/* copy tile info from PFB */
+	for (i=0; i<NV10_PFB_TILE__SIZE; i++) {
+		nv_wr32(NV10_PGRAPH_TILE(i), nv_rd32(NV10_PFB_TILE(i)));
+		nv_wr32(NV10_PGRAPH_TLIMIT(i), nv_rd32(NV10_PFB_TLIMIT(i)));
+		nv_wr32(NV10_PGRAPH_TSIZE(i), nv_rd32(NV10_PFB_TSIZE(i)));
+		nv_wr32(NV10_PGRAPH_TSTATUS(i), nv_rd32(NV10_PFB_TSTATUS(i)));
+	}
+
+	nv_wr32(NV10_PGRAPH_CTX_SWITCH1, 0x00000000);
+	nv_wr32(NV10_PGRAPH_CTX_SWITCH2, 0x00000000);
+	nv_wr32(NV10_PGRAPH_CTX_SWITCH3, 0x00000000);
+	nv_wr32(NV10_PGRAPH_CTX_SWITCH4, 0x00000000);
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10010100);
+	nv_wr32(NV10_PGRAPH_STATE      , 0xFFFFFFFF);
+
+	return 0;
+}
+
+void nv10_graph_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv20_graph.c b/drivers/gpu/drm/nouveau/nv20_graph.c
new file mode 100644
index 0000000..8d20b9e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv20_graph.c
@@ -0,0 +1,907 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+/*
+ * NV20
+ * -----
+ * There are 3 families :
+ * NV20 is 0x10de:0x020*
+ * NV25/28 is 0x10de:0x025* / 0x10de:0x028*
+ * NV2A is 0x10de:0x02A0
+ *
+ * NV30
+ * -----
+ * There are 3 families :
+ * NV30/31 is 0x10de:0x030* / 0x10de:0x031*
+ * NV34 is 0x10de:0x032*
+ * NV35/36 is 0x10de:0x033* / 0x10de:0x034*
+ *
+ * Not seen in the wild, no dumps (probably NV35) :
+ * NV37 is 0x10de:0x00fc, 0x10de:0x00fd
+ * NV38 is 0x10de:0x0333, 0x10de:0x00fe
+ *
+ */
+
+#define NV20_GRCTX_SIZE (3580*4)
+#define NV25_GRCTX_SIZE (3529*4)
+#define NV2A_GRCTX_SIZE (3500*4)
+
+#define NV30_31_GRCTX_SIZE (24392)
+#define NV34_GRCTX_SIZE    (18140)
+#define NV35_36_GRCTX_SIZE (22396)
+
+static void nv20_graph_context_init(struct drm_device *dev,
+                                    struct nouveau_gpuobj *ctx)
+{
+	int i;
+/*
+write32 #1 block at +0x00740adc NV_PRAMIN+0x40adc of 3369 (0xd29) elements:
++0x00740adc: ffff0000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740afc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b1c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b3c: 00000000 0fff0000 0fff0000 00000000 00000000 00000000 00000000 00000000
++0x00740b5c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b7c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b9c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740bbc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740bdc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740bfc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+
++0x00740c1c: 00000101 00000000 00000000 00000000 00000000 00000111 00000000 00000000
++0x00740c3c: 00000000 00000000 00000000 44400000 00000000 00000000 00000000 00000000
++0x00740c5c: 00000000 00000000 00000000 00000000 00000000 00000000 00030303 00030303
++0x00740c7c: 00030303 00030303 00000000 00000000 00000000 00000000 00080000 00080000
++0x00740c9c: 00080000 00080000 00000000 00000000 01012000 01012000 01012000 01012000
++0x00740cbc: 000105b8 000105b8 000105b8 000105b8 00080008 00080008 00080008 00080008
++0x00740cdc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740cfc: 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000
++0x00740d1c: 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000
++0x00740d3c: 00000000 00000000 4b7fffff 00000000 00000000 00000000 00000000 00000000
+
++0x00740d5c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740d7c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740d9c: 00000001 00000000 00004000 00000000 00000000 00000001 00000000 00040000
++0x00740dbc: 00010000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740ddc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+...
+*/
+	INSTANCE_WR(ctx, (0x33c/4)+0, 0xffff0000);
+	INSTANCE_WR(ctx, (0x33c/4)+25, 0x0fff0000);
+	INSTANCE_WR(ctx, (0x33c/4)+26, 0x0fff0000);
+	INSTANCE_WR(ctx, (0x33c/4)+80, 0x00000101);
+	INSTANCE_WR(ctx, (0x33c/4)+85, 0x00000111);
+	INSTANCE_WR(ctx, (0x33c/4)+91, 0x44400000);
+	for (i = 0; i < 4; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+102+i, 0x00030303);
+	for (i = 0; i < 4; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+110+i, 0x00080000);
+	for (i = 0; i < 4; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+116+i, 0x01012000);
+	for (i = 0; i < 4; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+120+i, 0x000105b8);
+	for (i = 0; i < 4; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+124+i, 0x00080008);
+	for (i = 0; i < 16; ++i)
+		INSTANCE_WR(ctx, (0x33c/4)+136+i, 0x07ff0000);
+	INSTANCE_WR(ctx, (0x33c/4)+154, 0x4b7fffff);
+	INSTANCE_WR(ctx, (0x33c/4)+176, 0x00000001);
+	INSTANCE_WR(ctx, (0x33c/4)+178, 0x00004000);
+	INSTANCE_WR(ctx, (0x33c/4)+181, 0x00000001);
+	INSTANCE_WR(ctx, (0x33c/4)+183, 0x00040000);
+	INSTANCE_WR(ctx, (0x33c/4)+184, 0x00010000);
+
+/*
+...
++0x0074239c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x007423bc: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x007423dc: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x007423fc: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
+...
++0x00742bdc: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742bfc: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742c1c: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742c3c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+...
+*/
+	for (i = 0; i < 0x880; i += 0x10) {
+		INSTANCE_WR(ctx, ((0x1c1c + i)/4)+0, 0x10700ff9);
+		INSTANCE_WR(ctx, ((0x1c1c + i)/4)+1, 0x0436086c);
+		INSTANCE_WR(ctx, ((0x1c1c + i)/4)+2, 0x000c001b);
+	}
+
+/*
+write32 #1 block at +0x00742fbc NV_PRAMIN+0x42fbc of 4 (0x4) elements:
++0x00742fbc: 3f800000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x281c/4), 0x3f800000);
+
+/*
+write32 #1 block at +0x00742ffc NV_PRAMIN+0x42ffc of 12 (0xc) elements:
++0x00742ffc: 40000000 3f800000 3f000000 00000000 40000000 3f800000 00000000 bf800000
++0x0074301c: 00000000 bf800000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x285c/4)+0, 0x40000000);
+	INSTANCE_WR(ctx, (0x285c/4)+1, 0x3f800000);
+	INSTANCE_WR(ctx, (0x285c/4)+2, 0x3f000000);
+	INSTANCE_WR(ctx, (0x285c/4)+4, 0x40000000);
+	INSTANCE_WR(ctx, (0x285c/4)+5, 0x3f800000);
+	INSTANCE_WR(ctx, (0x285c/4)+7, 0xbf800000);
+	INSTANCE_WR(ctx, (0x285c/4)+9, 0xbf800000);
+
+/*
+write32 #1 block at +0x00742fcc NV_PRAMIN+0x42fcc of 4 (0x4) elements:
++0x00742fcc: 00000000 3f800000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x282c/4)+1, 0x3f800000);
+
+/*
+write32 #1 block at +0x0074302c NV_PRAMIN+0x4302c of 4 (0x4) elements:
++0x0074302c: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x00743c9c NV_PRAMIN+0x43c9c of 4 (0x4) elements:
++0x00743c9c: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x00743c3c NV_PRAMIN+0x43c3c of 8 (0x8) elements:
++0x00743c3c: 00000000 00000000 000fe000 00000000 00000000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x349c/4)+2, 0x000fe000);
+
+/*
+write32 #1 block at +0x00743c6c NV_PRAMIN+0x43c6c of 4 (0x4) elements:
++0x00743c6c: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x00743ccc NV_PRAMIN+0x43ccc of 4 (0x4) elements:
++0x00743ccc: 00000000 000003f8 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x352c/4)+1, 0x000003f8);
+
+/* write32 #1 NV_PRAMIN+0x43ce0 <- 0x002fe000 */
+	INSTANCE_WR(ctx, 0x3540/4, 0x002fe000);
+
+/*
+write32 #1 block at +0x00743cfc NV_PRAMIN+0x43cfc of 8 (0x8) elements:
++0x00743cfc: 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c
+*/
+	for (i = 0; i < 8; ++i)
+		INSTANCE_WR(ctx, (0x355c/4)+i, 0x001c527c);
+}
+
+static void nv2a_graph_context_init(struct drm_device *dev,
+                                    struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x33c/4, 0xffff0000);
+	for(i = 0x3a0; i< 0x3a8; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x47c/4, 0x00000101);
+	INSTANCE_WR(ctx, 0x490/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x4a8/4, 0x44400000);
+	for(i = 0x4d4; i< 0x4e4; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00030303);
+	for(i = 0x4f4; i< 0x504; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080000);
+	for(i = 0x50c; i< 0x51c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for(i = 0x51c; i< 0x52c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x000105b8);
+	for(i = 0x52c; i< 0x53c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for(i = 0x55c; i< 0x59c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x5a4/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x5fc/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x604/4, 0x00004000);
+	INSTANCE_WR(ctx, 0x610/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x618/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x61c/4, 0x00010000);
+
+	for (i=0x1a9c; i <= 0x22fc/4; i += 32) {
+		INSTANCE_WR(ctx, i/4    , 0x10700ff9);
+		INSTANCE_WR(ctx, i/4 + 1, 0x0436086c);
+		INSTANCE_WR(ctx, i/4 + 2, 0x000c001b);
+	}
+
+	INSTANCE_WR(ctx, 0x269c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x26b0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x26dc/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x26e0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x26e4/4, 0x3f000000);
+	INSTANCE_WR(ctx, 0x26ec/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x26f0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x26f8/4, 0xbf800000);
+	INSTANCE_WR(ctx, 0x2700/4, 0xbf800000);
+	INSTANCE_WR(ctx, 0x3024/4, 0x000fe000);
+	INSTANCE_WR(ctx, 0x30a0/4, 0x000003f8);
+	INSTANCE_WR(ctx, 0x33fc/4, 0x002fe000);
+	for(i = 0x341c; i< 0x343c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x001c527c);
+}
+
+static void nv25_graph_context_init(struct drm_device *dev,
+                                    struct nouveau_gpuobj *ctx)
+{
+	int i;
+/*
+write32 #1 block at +0x00740a7c NV_PRAMIN.GRCTX0+0x35c of 173 (0xad) elements:
++0x00740a7c: ffff0000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740a9c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740abc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740adc: 00000000 0fff0000 0fff0000 00000000 00000000 00000000 00000000 00000000
++0x00740afc: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b1c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b3c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b5c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+
++0x00740b7c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740b9c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740bbc: 00000101 00000000 00000000 00000000 00000000 00000111 00000000 00000000
++0x00740bdc: 00000000 00000000 00000000 00000080 ffff0000 00000001 00000000 00000000
++0x00740bfc: 00000000 00000000 44400000 00000000 00000000 00000000 00000000 00000000
++0x00740c1c: 4b800000 00000000 00000000 00000000 00000000 00030303 00030303 00030303
++0x00740c3c: 00030303 00000000 00000000 00000000 00000000 00080000 00080000 00080000
++0x00740c5c: 00080000 00000000 00000000 01012000 01012000 01012000 01012000 000105b8
+
++0x00740c7c: 000105b8 000105b8 000105b8 00080008 00080008 00080008 00080008 00000000
++0x00740c9c: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 07ff0000
++0x00740cbc: 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000
++0x00740cdc: 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 07ff0000 00000000
++0x00740cfc: 00000000 4b7fffff 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740d1c: 00000000 00000000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x35c/4)+0, 0xffff0000);
+	INSTANCE_WR(ctx, (0x35c/4)+25, 0x0fff0000);
+	INSTANCE_WR(ctx, (0x35c/4)+26, 0x0fff0000);
+	INSTANCE_WR(ctx, (0x35c/4)+80, 0x00000101);
+	INSTANCE_WR(ctx, (0x35c/4)+85, 0x00000111);
+	INSTANCE_WR(ctx, (0x35c/4)+91, 0x00000080);
+	INSTANCE_WR(ctx, (0x35c/4)+92, 0xffff0000);
+	INSTANCE_WR(ctx, (0x35c/4)+93, 0x00000001);
+	INSTANCE_WR(ctx, (0x35c/4)+98, 0x44400000);
+	INSTANCE_WR(ctx, (0x35c/4)+104, 0x4b800000);
+	INSTANCE_WR(ctx, (0x35c/4)+109, 0x00030303);
+	INSTANCE_WR(ctx, (0x35c/4)+110, 0x00030303);
+	INSTANCE_WR(ctx, (0x35c/4)+111, 0x00030303);
+	INSTANCE_WR(ctx, (0x35c/4)+112, 0x00030303);
+	INSTANCE_WR(ctx, (0x35c/4)+117, 0x00080000);
+	INSTANCE_WR(ctx, (0x35c/4)+118, 0x00080000);
+	INSTANCE_WR(ctx, (0x35c/4)+119, 0x00080000);
+	INSTANCE_WR(ctx, (0x35c/4)+120, 0x00080000);
+	INSTANCE_WR(ctx, (0x35c/4)+123, 0x01012000);
+	INSTANCE_WR(ctx, (0x35c/4)+124, 0x01012000);
+	INSTANCE_WR(ctx, (0x35c/4)+125, 0x01012000);
+	INSTANCE_WR(ctx, (0x35c/4)+126, 0x01012000);
+	INSTANCE_WR(ctx, (0x35c/4)+127, 0x000105b8);
+	INSTANCE_WR(ctx, (0x35c/4)+128, 0x000105b8);
+	INSTANCE_WR(ctx, (0x35c/4)+129, 0x000105b8);
+	INSTANCE_WR(ctx, (0x35c/4)+130, 0x000105b8);
+	INSTANCE_WR(ctx, (0x35c/4)+131, 0x00080008);
+	INSTANCE_WR(ctx, (0x35c/4)+132, 0x00080008);
+	INSTANCE_WR(ctx, (0x35c/4)+133, 0x00080008);
+	INSTANCE_WR(ctx, (0x35c/4)+134, 0x00080008);
+	for (i=0; i<16; ++i)
+		INSTANCE_WR(ctx, (0x35c/4)+143+i, 0x07ff0000);
+	INSTANCE_WR(ctx, (0x35c/4)+161, 0x4b7fffff);
+
+/*
+write32 #1 block at +0x00740d34 NV_PRAMIN.GRCTX0+0x614 of 3136 (0xc40) elements:
++0x00740d34: 00000000 00000000 00000000 00000080 30201000 70605040 b0a09080 f0e0d0c0
++0x00740d54: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00740d74: 00000000 00000000 00000000 00000000 00000001 00000000 00004000 00000000
++0x00740d94: 00000000 00000001 00000000 00040000 00010000 00000000 00000000 00000000
++0x00740db4: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+...
++0x00742214: 00000000 00000000 00000000 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742234: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742254: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742274: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
+...
++0x00742a34: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742a54: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742a74: 10700ff9 0436086c 000c001b 00000000 10700ff9 0436086c 000c001b 00000000
++0x00742a94: 10700ff9 0436086c 000c001b 00000000 00000000 00000000 00000000 00000000
++0x00742ab4: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
++0x00742ad4: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x614/4)+3, 0x00000080);
+	INSTANCE_WR(ctx, (0x614/4)+4, 0x30201000);
+	INSTANCE_WR(ctx, (0x614/4)+5, 0x70605040);
+	INSTANCE_WR(ctx, (0x614/4)+6, 0xb0a09080);
+	INSTANCE_WR(ctx, (0x614/4)+7, 0xf0e0d0c0);
+	INSTANCE_WR(ctx, (0x614/4)+20, 0x00000001);
+	INSTANCE_WR(ctx, (0x614/4)+22, 0x00004000);
+	INSTANCE_WR(ctx, (0x614/4)+25, 0x00000001);
+	INSTANCE_WR(ctx, (0x614/4)+27, 0x00040000);
+	INSTANCE_WR(ctx, (0x614/4)+28, 0x00010000);
+	for (i=0; i < 0x880/4; i+=4) {
+		INSTANCE_WR(ctx, (0x1b04/4)+i+0, 0x10700ff9);
+		INSTANCE_WR(ctx, (0x1b04/4)+i+1, 0x0436086c);
+		INSTANCE_WR(ctx, (0x1b04/4)+i+2, 0x000c001b);
+	}
+
+/*
+write32 #1 block at +0x00742e24 NV_PRAMIN.GRCTX0+0x2704 of 4 (0x4) elements:
++0x00742e24: 3f800000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x2704/4), 0x3f800000);
+
+/*
+write32 #1 block at +0x00742e64 NV_PRAMIN.GRCTX0+0x2744 of 12 (0xc) elements:
++0x00742e64: 40000000 3f800000 3f000000 00000000 40000000 3f800000 00000000 bf800000
++0x00742e84: 00000000 bf800000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x2744/4)+0, 0x40000000);
+	INSTANCE_WR(ctx, (0x2744/4)+1, 0x3f800000);
+	INSTANCE_WR(ctx, (0x2744/4)+2, 0x3f000000);
+	INSTANCE_WR(ctx, (0x2744/4)+4, 0x40000000);
+	INSTANCE_WR(ctx, (0x2744/4)+5, 0x3f800000);
+	INSTANCE_WR(ctx, (0x2744/4)+7, 0xbf800000);
+	INSTANCE_WR(ctx, (0x2744/4)+9, 0xbf800000);
+
+/*
+write32 #1 block at +0x00742e34 NV_PRAMIN.GRCTX0+0x2714 of 4 (0x4) elements:
++0x00742e34: 00000000 3f800000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x2714/4)+1, 0x3f800000);
+
+/*
+write32 #1 block at +0x00742e94 NV_PRAMIN.GRCTX0+0x2774 of 4 (0x4) elements:
++0x00742e94: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x00743804 NV_PRAMIN.GRCTX0+0x30e4 of 4 (0x4) elements:
++0x00743804: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x007437a4 NV_PRAMIN.GRCTX0+0x3084 of 8 (0x8) elements:
++0x007437a4: 00000000 00000000 000fe000 00000000 00000000 00000000 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x3084/4)+2, 0x000fe000);
+
+/*
+write32 #1 block at +0x007437d4 NV_PRAMIN.GRCTX0+0x30b4 of 4 (0x4) elements:
++0x007437d4: 00000000 00000000 00000000 00000000
+write32 #1 block at +0x00743824 NV_PRAMIN.GRCTX0+0x3104 of 4 (0x4) elements:
++0x00743824: 00000000 000003f8 00000000 00000000
+*/
+	INSTANCE_WR(ctx, (0x3104/4)+1, 0x000003f8);
+
+/* write32 #1 NV_PRAMIN.GRCTX0+0x3468 <- 0x002fe000 */
+	INSTANCE_WR(ctx, 0x3468/4, 0x002fe000);
+
+/*
+write32 #1 block at +0x00743ba4 NV_PRAMIN.GRCTX0+0x3484 of 8 (0x8) elements:
++0x00743ba4: 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c 001c527c
+*/
+	for (i=0; i<8; ++i)
+		INSTANCE_WR(ctx, (0x3484/4)+i, 0x001c527c);
+}
+
+static void nv30_31_graph_context_init(struct drm_device *dev,
+                                       struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x410/4, 0x00000101);
+	INSTANCE_WR(ctx, 0x424/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x428/4, 0x00000060);
+	INSTANCE_WR(ctx, 0x444/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x448/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x44c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x460/4, 0x44400000);
+	INSTANCE_WR(ctx, 0x48c/4, 0xffff0000);
+	for(i = 0x4e0; i< 0x4e8; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x4ec/4, 0x00011100);
+	for(i = 0x508; i< 0x548; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x550/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x58c/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x590/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x594/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x598/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x59c/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x5b0/4, 0xb0000000);
+	for(i = 0x600; i< 0x640; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00010588);
+	for(i = 0x640; i< 0x680; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00030303);
+	for(i = 0x6c0; i< 0x700; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0008aae4);
+	for(i = 0x700; i< 0x740; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for(i = 0x740; i< 0x780; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x85c/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x860/4, 0x00010000);
+	for(i = 0x864; i< 0x874; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00040004);
+	for(i = 0x1f18; i<= 0x3088 ; i+= 16) {
+		INSTANCE_WR(ctx, i/4 + 0, 0x10700ff9);
+		INSTANCE_WR(ctx, i/4 + 1, 0x0436086c);
+		INSTANCE_WR(ctx, i/4 + 2, 0x000c001b);
+	}
+	for(i = 0x30b8; i< 0x30c8; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x344c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3808/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x381c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3848/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x384c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3850/4, 0x3f000000);
+	INSTANCE_WR(ctx, 0x3858/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x385c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3864/4, 0xbf800000);
+	INSTANCE_WR(ctx, 0x386c/4, 0xbf800000);
+}
+
+static void nv34_graph_context_init(struct drm_device *dev,
+                                    struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x40c/4, 0x01000101);
+	INSTANCE_WR(ctx, 0x420/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x424/4, 0x00000060);
+	INSTANCE_WR(ctx, 0x440/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x444/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x448/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x45c/4, 0x44400000);
+	INSTANCE_WR(ctx, 0x480/4, 0xffff0000);
+	for(i = 0x4d4; i< 0x4dc; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x4e0/4, 0x00011100);
+	for(i = 0x4fc; i< 0x53c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x544/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x57c/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x580/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x584/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x588/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x58c/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x5a0/4, 0xb0000000);
+	for(i = 0x5f0; i< 0x630; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00010588);
+	for(i = 0x630; i< 0x670; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00030303);
+	for(i = 0x6b0; i< 0x6f0; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0008aae4);
+	for(i = 0x6f0; i< 0x730; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for(i = 0x730; i< 0x770; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x850/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x854/4, 0x00010000);
+	for(i = 0x858; i< 0x868; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00040004);
+	for(i = 0x15ac; i<= 0x271c ; i+= 16) {
+		INSTANCE_WR(ctx, i/4 + 0, 0x10700ff9);
+		INSTANCE_WR(ctx, i/4 + 1, 0x0436086c);
+		INSTANCE_WR(ctx, i/4 + 2, 0x000c001b);
+	}
+	for(i = 0x274c; i< 0x275c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x2ae0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x2e9c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x2eb0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x2edc/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x2ee0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x2ee4/4, 0x3f000000);
+	INSTANCE_WR(ctx, 0x2eec/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x2ef0/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x2ef8/4, 0xbf800000);
+	INSTANCE_WR(ctx, 0x2f00/4, 0xbf800000);
+}
+
+static void nv35_36_graph_context_init(struct drm_device *dev,
+                                       struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x40c/4, 0x00000101);
+	INSTANCE_WR(ctx, 0x420/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x424/4, 0x00000060);
+	INSTANCE_WR(ctx, 0x440/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x444/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x448/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x45c/4, 0x44400000);
+	INSTANCE_WR(ctx, 0x488/4, 0xffff0000);
+	for(i = 0x4dc; i< 0x4e4; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x4e8/4, 0x00011100);
+	for(i = 0x504; i< 0x544; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x54c/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x588/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x58c/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x590/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x594/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x598/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x5ac/4, 0xb0000000);
+	for(i = 0x604; i< 0x644; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00010588);
+	for(i = 0x644; i< 0x684; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00030303);
+	for(i = 0x6c4; i< 0x704; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0008aae4);
+	for(i = 0x704; i< 0x744; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for(i = 0x744; i< 0x784; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x860/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x864/4, 0x00010000);
+	for(i = 0x868; i< 0x878; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00040004);
+	for(i = 0x1f1c; i<= 0x308c ; i+= 16) {
+		INSTANCE_WR(ctx, i/4 + 0, 0x10700ff9);
+		INSTANCE_WR(ctx, i/4 + 1, 0x0436086c);
+		INSTANCE_WR(ctx, i/4 + 2, 0x000c001b);
+	}
+	for(i = 0x30bc; i< 0x30cc; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x3450/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x380c/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3820/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x384c/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x3850/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3854/4, 0x3f000000);
+	INSTANCE_WR(ctx, 0x385c/4, 0x40000000);
+	INSTANCE_WR(ctx, 0x3860/4, 0x3f800000);
+	INSTANCE_WR(ctx, 0x3868/4, 0xbf800000);
+	INSTANCE_WR(ctx, 0x3870/4, 0xbf800000);
+}
+
+int nv20_graph_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	void (*ctx_init)(struct drm_device *, struct nouveau_gpuobj *);
+	unsigned int ctx_size;
+	unsigned int idoffs = 0x28/4;
+	int ret;
+
+	switch (dev_priv->chipset) {
+	case 0x20:
+		ctx_size = NV20_GRCTX_SIZE;
+		ctx_init = nv20_graph_context_init;
+		idoffs = 0;
+		break;
+	case 0x25:
+	case 0x28:
+		ctx_size = NV25_GRCTX_SIZE;
+		ctx_init = nv25_graph_context_init;
+		break;
+	case 0x2a:
+		ctx_size = NV2A_GRCTX_SIZE;
+		ctx_init = nv2a_graph_context_init;
+		idoffs = 0;
+		break;
+	case 0x30:
+	case 0x31:
+		ctx_size = NV30_31_GRCTX_SIZE;
+		ctx_init = nv30_31_graph_context_init;
+		break;
+	case 0x34:
+		ctx_size = NV34_GRCTX_SIZE;
+		ctx_init = nv34_graph_context_init;
+		break;
+	case 0x35:
+	case 0x36:
+		ctx_size = NV35_36_GRCTX_SIZE;
+		ctx_init = nv35_36_graph_context_init;
+		break;
+	default:
+		ctx_size = 0;
+		ctx_init = nv35_36_graph_context_init;
+		NV_ERROR(dev, "Please contact the devs if you want your NV%x"
+			      " card to work\n", dev_priv->chipset);
+		return -ENOSYS;
+		break;
+	}
+
+	if ((ret = nouveau_gpuobj_new_ref(dev, chan, NULL, 0, ctx_size, 16,
+					  NVOBJ_FLAG_ZERO_ALLOC,
+					  &chan->ramin_grctx)))
+		return ret;
+
+	/* Initialise default context values */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	ctx_init(dev, chan->ramin_grctx->gpuobj);
+
+	/* nv20: INSTANCE_WR(chan->ramin_grctx->gpuobj, 10, chan->id<<24); */
+	INSTANCE_WR(chan->ramin_grctx->gpuobj, idoffs, (chan->id<<24)|0x1);
+	                                                     /* CTX_USER */
+
+	INSTANCE_WR(dev_priv->ctx_table->gpuobj, chan->id,
+			chan->ramin_grctx->instance >> 4);
+
+	dev_priv->engine.instmem.finish_access(dev);
+	return 0;
+}
+
+void nv20_graph_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (chan->ramin_grctx)
+		nouveau_gpuobj_ref_del(dev, &chan->ramin_grctx);
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	INSTANCE_WR(dev_priv->ctx_table->gpuobj, chan->id, 0);
+	dev_priv->engine.instmem.finish_access(dev);
+}
+
+int nv20_graph_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst;
+
+	if (!chan->ramin_grctx)
+		return -EINVAL;
+	inst = chan->ramin_grctx->instance >> 4;
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_XFER,
+		 NV20_PGRAPH_CHANNEL_CTX_XFER_LOAD);
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10010100);
+
+	nouveau_wait_for_idle(dev);
+	return 0;
+}
+
+int nv20_graph_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst;
+
+	if (!chan->ramin_grctx)
+		return -EINVAL;
+	inst = chan->ramin_grctx->instance >> 4;
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_XFER,
+		 NV20_PGRAPH_CHANNEL_CTX_XFER_SAVE);
+
+	nouveau_wait_for_idle(dev);
+	return 0;
+}
+
+static void nv20_graph_rdi(struct drm_device *dev) {
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int i, writecount = 32;
+	uint32_t rdi_index = 0x2c80000;
+
+	if (dev_priv->chipset == 0x20) {
+		rdi_index = 0x3d0000;
+		writecount = 15;
+	}
+
+	nv_wr32(NV10_PGRAPH_RDI_INDEX, rdi_index);
+	for (i = 0; i < writecount; i++)
+		nv_wr32(NV10_PGRAPH_RDI_DATA, 0);
+
+	nouveau_wait_for_idle(dev);
+}
+
+int nv20_graph_init(struct drm_device *dev) {
+	struct drm_nouveau_private *dev_priv =
+		(struct drm_nouveau_private *)dev->dev_private;
+	uint32_t tmp, vramsz;
+	int ret, i;
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PGRAPH);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PGRAPH);
+
+	if (!dev_priv->ctx_table) {
+		/* Create Context Pointer Table */
+		dev_priv->ctx_table_size = 32 * 4;
+		if ((ret = nouveau_gpuobj_new_ref(dev, NULL, NULL, 0,
+						  dev_priv->ctx_table_size, 16,
+						  NVOBJ_FLAG_ZERO_ALLOC,
+						  &dev_priv->ctx_table)))
+			return ret;
+	}
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_TABLE,
+		 dev_priv->ctx_table->instance >> 4);
+
+	nv20_graph_rdi(dev);
+
+	nv_wr32(NV03_PGRAPH_INTR   , 0xFFFFFFFF);
+	nv_wr32(NV03_PGRAPH_INTR_EN, 0xFFFFFFFF);
+
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0xFFFFFFFF);
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x00000000);
+	nv_wr32(NV04_PGRAPH_DEBUG_1, 0x00118700);
+	nv_wr32(NV04_PGRAPH_DEBUG_3, 0xF3CE0475); /* 0x4 = auto ctx switch */
+	nv_wr32(NV10_PGRAPH_DEBUG_4, 0x00000000);
+	nv_wr32(0x40009C           , 0x00000040);
+
+	if (dev_priv->chipset >= 0x25) {
+		nv_wr32(0x400890, 0x00080000);
+		nv_wr32(0x400610, 0x304B1FB6);
+		nv_wr32(0x400B80, 0x18B82880);
+		nv_wr32(0x400B84, 0x44000000);
+		nv_wr32(0x400098, 0x40000080);
+		nv_wr32(0x400B88, 0x000000ff);
+	} else {
+		nv_wr32(0x400880, 0x00080000); /* 0x0008c7df */
+		nv_wr32(0x400094, 0x00000005);
+		nv_wr32(0x400B80, 0x45CAA208); /* 0x45eae20e */
+		nv_wr32(0x400B84, 0x24000000);
+		nv_wr32(0x400098, 0x00000040);
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00E00038);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00000030);
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00E10038);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00000030);
+	}
+
+	/* copy tile info from PFB */
+	for (i = 0; i < NV10_PFB_TILE__SIZE; i++) {
+		nv_wr32(0x00400904 + i*0x10, nv_rd32(NV10_PFB_TLIMIT(i)));
+			/* which is NV40_PGRAPH_TLIMIT0(i) ?? */
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0030+i*4);
+		nv_wr32(NV10_PGRAPH_RDI_DATA, nv_rd32(NV10_PFB_TLIMIT(i)));
+		nv_wr32(0x00400908 + i*0x10, nv_rd32(NV10_PFB_TSIZE(i)));
+			/* which is NV40_PGRAPH_TSIZE0(i) ?? */
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0050+i*4);
+		nv_wr32(NV10_PGRAPH_RDI_DATA, nv_rd32(NV10_PFB_TSIZE(i)));
+		nv_wr32(0x00400900 + i*0x10, nv_rd32(NV10_PFB_TILE(i)));
+			/* which is NV40_PGRAPH_TILE0(i) ?? */
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0010+i*4);
+		nv_wr32(NV10_PGRAPH_RDI_DATA, nv_rd32(NV10_PFB_TILE(i)));
+	}
+	for (i = 0; i < 8; i++) {
+		nv_wr32(0x400980+i*4, nv_rd32(0x100300+i*4));
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0090+i*4);
+		nv_wr32(NV10_PGRAPH_RDI_DATA, nv_rd32(0x100300+i*4));
+	}
+	nv_wr32(0x4009a0, nv_rd32(0x100324));
+	nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA000C);
+	nv_wr32(NV10_PGRAPH_RDI_DATA, nv_rd32(0x100324));
+
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10000100);
+	nv_wr32(NV10_PGRAPH_STATE      , 0xFFFFFFFF);
+
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) & 0x0007ff00;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) | 0x00020100;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+
+	/* begin RAM config */
+	vramsz = drm_get_resource_len(dev, 0) - 1;
+	nv_wr32(0x4009A4, nv_rd32(NV04_PFB_CFG0));
+	nv_wr32(0x4009A8, nv_rd32(NV04_PFB_CFG1));
+	nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0000);
+	nv_wr32(NV10_PGRAPH_RDI_DATA , nv_rd32(NV04_PFB_CFG0));
+	nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0004);
+	nv_wr32(NV10_PGRAPH_RDI_DATA , nv_rd32(NV04_PFB_CFG1));
+	nv_wr32(0x400820, 0);
+	nv_wr32(0x400824, 0);
+	nv_wr32(0x400864, vramsz-1);
+	nv_wr32(0x400868, vramsz-1);
+
+	/* interesting.. the below overwrites some of the tile setup above.. */
+	nv_wr32(0x400B20, 0x00000000);
+	nv_wr32(0x400B04, 0xFFFFFFFF);
+
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMAX, 0x7fff);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMAX, 0x7fff);
+
+	return 0;
+}
+
+void nv20_graph_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	nouveau_gpuobj_ref_del(dev, &dev_priv->ctx_table);
+}
+
+int nv30_graph_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+//	uint32_t vramsz, tmp;
+	int ret, i;
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PGRAPH);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PGRAPH);
+
+	if (!dev_priv->ctx_table) {
+		/* Create Context Pointer Table */
+		dev_priv->ctx_table_size = 32 * 4;
+		if ((ret = nouveau_gpuobj_new_ref(dev, NULL, NULL, 0,
+						  dev_priv->ctx_table_size, 16,
+						  NVOBJ_FLAG_ZERO_ALLOC,
+						  &dev_priv->ctx_table)))
+			return ret;
+	}
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_TABLE,
+			dev_priv->ctx_table->instance >> 4);
+
+	nv_wr32(NV03_PGRAPH_INTR   , 0xFFFFFFFF);
+	nv_wr32(NV03_PGRAPH_INTR_EN, 0xFFFFFFFF);
+
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0xFFFFFFFF);
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x00000000);
+	nv_wr32(NV04_PGRAPH_DEBUG_1, 0x401287c0);
+	nv_wr32(0x400890, 0x01b463ff);
+	nv_wr32(NV04_PGRAPH_DEBUG_3, 0xf2de0475);
+	nv_wr32(NV10_PGRAPH_DEBUG_4, 0x00008000);
+	nv_wr32(NV04_PGRAPH_LIMIT_VIOL_PIX, 0xf04bdff6);
+	nv_wr32(0x400B80, 0x1003d888);
+	nv_wr32(0x400B84, 0x0c000000);
+	nv_wr32(0x400098, 0x00000000);
+	nv_wr32(0x40009C, 0x0005ad00);
+	nv_wr32(0x400B88, 0x62ff00ff); // suspiciously like PGRAPH_DEBUG_2
+	nv_wr32(0x4000a0, 0x00000000);
+	nv_wr32(0x4000a4, 0x00000008);
+	nv_wr32(0x4008a8, 0xb784a400);
+	nv_wr32(0x400ba0, 0x002f8685);
+	nv_wr32(0x400ba4, 0x00231f3f);
+	nv_wr32(0x4008a4, 0x40000020);
+
+	if (dev_priv->chipset == 0x34) {
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0004);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00200201);
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0008);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00000008);
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00EA0000);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00000032);
+		nv_wr32(NV10_PGRAPH_RDI_INDEX, 0x00E00004);
+		nv_wr32(NV10_PGRAPH_RDI_DATA , 0x00000002);
+	}
+
+	nv_wr32(0x4000c0, 0x00000016);
+
+	/* copy tile info from PFB */
+	for (i = 0; i < NV10_PFB_TILE__SIZE; i++) {
+		nv_wr32(0x00400904 + i*0x10, nv_rd32(NV10_PFB_TLIMIT(i)));
+			/* which is NV40_PGRAPH_TLIMIT0(i) ?? */
+		nv_wr32(0x00400908 + i*0x10, nv_rd32(NV10_PFB_TSIZE(i)));
+			/* which is NV40_PGRAPH_TSIZE0(i) ?? */
+		nv_wr32(0x00400900 + i*0x10, nv_rd32(NV10_PFB_TILE(i)));
+			/* which is NV40_PGRAPH_TILE0(i) ?? */
+	}
+
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10000100);
+	nv_wr32(NV10_PGRAPH_STATE      , 0xFFFFFFFF);
+	nv_wr32(0x0040075c             , 0x00000001);
+
+	/* begin RAM config */
+//	vramsz = drm_get_resource_len(dev, 0) - 1;
+	nv_wr32(0x4009A4, nv_rd32(NV04_PFB_CFG0));
+	nv_wr32(0x4009A8, nv_rd32(NV04_PFB_CFG1));
+	if (dev_priv->chipset != 0x34) {
+		nv_wr32(0x400750, 0x00EA0000);
+		nv_wr32(0x400754, nv_rd32(NV04_PFB_CFG0));
+		nv_wr32(0x400750, 0x00EA0004);
+		nv_wr32(0x400754, nv_rd32(NV04_PFB_CFG1));
+	}
+
+#if 0
+	nv_wr32(0x400820, 0);
+	nv_wr32(0x400824, 0);
+	nv_wr32(0x400864, vramsz-1);
+	nv_wr32(0x400868, vramsz-1);
+
+	nv_wr32(0x400B20, 0x00000000);
+	nv_wr32(0x400B04, 0xFFFFFFFF);
+
+	/* per-context state, doesn't belong here */
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) & 0x0007ff00;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) | 0x00020100;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMAX, 0x7fff);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMAX, 0x7fff);
+#endif
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv40_fb.c b/drivers/gpu/drm/nouveau/nv40_fb.c
new file mode 100644
index 0000000..530bbee
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv40_fb.c
@@ -0,0 +1,62 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv40_fb_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t fb_bar_size, tmp;
+	int num_tiles;
+	int i;
+
+	/* This is strictly a NV4x register (don't know about NV5x). */
+	/* The blob sets these to all kinds of values, and they mess up our setup. */
+	/* I got value 0x52802 instead. For some cards the blob even sets it back to 0x1. */
+	/* Note: the blob doesn't read this value, so i'm pretty sure this is safe for all cards. */
+	/* Any idea what this is? */
+	nv_wr32(NV40_PFB_UNK_800, 0x1);
+
+	switch (dev_priv->chipset) {
+	case 0x40:
+	case 0x45:
+		tmp = nv_rd32(NV10_PFB_CLOSE_PAGE2);
+		nv_wr32(NV10_PFB_CLOSE_PAGE2, tmp & ~(1<<15));
+		num_tiles = NV10_PFB_TILE__SIZE;
+		break;
+	case 0x46: /* G72 */
+	case 0x47: /* G70 */
+	case 0x49: /* G71 */
+	case 0x4b: /* G73 */
+	case 0x4c: /* C51 (G7X version) */
+		num_tiles = NV40_PFB_TILE__SIZE_1;
+		break;
+	default:
+		num_tiles = NV40_PFB_TILE__SIZE_0;
+		break;
+	}
+
+	fb_bar_size = drm_get_resource_len(dev, 0) - 1;
+	switch (dev_priv->chipset) {
+	case 0x40:
+		for (i=0; i<num_tiles; i++) {
+			nv_wr32(NV10_PFB_TILE(i), 0);
+			nv_wr32(NV10_PFB_TLIMIT(i), fb_bar_size);
+		}
+		break;
+	default:
+		for (i=0; i<num_tiles; i++) {
+			nv_wr32(NV40_PFB_TILE(i), 0);
+			nv_wr32(NV40_PFB_TLIMIT(i), fb_bar_size);
+		}
+		break;
+	}
+
+	return 0;
+}
+
+void
+nv40_fb_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv40_fifo.c b/drivers/gpu/drm/nouveau/nv40_fifo.c
new file mode 100644
index 0000000..2f44daa
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv40_fifo.c
@@ -0,0 +1,216 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+
+#define RAMFC_WR(offset,val) INSTANCE_WR(chan->ramfc->gpuobj, \
+					 NV40_RAMFC_##offset/4, (val))
+#define RAMFC_RD(offset)     INSTANCE_RD(chan->ramfc->gpuobj, \
+					 NV40_RAMFC_##offset/4)
+#define NV40_RAMFC(c) (dev_priv->ramfc_offset + ((c)*NV40_RAMFC__SIZE))
+#define NV40_RAMFC__SIZE 128
+
+int
+nv40_fifo_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	int ret;
+
+	if ((ret = nouveau_gpuobj_new_fake(dev, NV40_RAMFC(chan->id), ~0,
+						NV40_RAMFC__SIZE,
+						NVOBJ_FLAG_ZERO_ALLOC |
+						NVOBJ_FLAG_ZERO_FREE,
+						NULL, &chan->ramfc)))
+		return ret;
+
+	/* Fill entries that are seen filled in dumps of nvidia driver just
+	 * after channel's is put into DMA mode
+	 */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	RAMFC_WR(DMA_PUT       , chan->pushbuf_base);
+	RAMFC_WR(DMA_GET       , chan->pushbuf_base);
+	RAMFC_WR(DMA_INSTANCE  , chan->pushbuf->instance >> 4);
+	RAMFC_WR(DMA_FETCH     , NV_PFIFO_CACHE1_DMA_FETCH_TRIG_128_BYTES |
+				 NV_PFIFO_CACHE1_DMA_FETCH_SIZE_128_BYTES |
+				 NV_PFIFO_CACHE1_DMA_FETCH_MAX_REQS_8 |
+#ifdef __BIG_ENDIAN
+				 NV_PFIFO_CACHE1_BIG_ENDIAN |
+#endif
+				 0x30000000 /* no idea.. */);
+	RAMFC_WR(DMA_SUBROUTINE, 0);
+	RAMFC_WR(GRCTX_INSTANCE, chan->ramin_grctx->instance >> 4);
+	RAMFC_WR(DMA_TIMESLICE , 0x0001FFFF);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* enable the fifo dma operation */
+	nv_wr32(NV04_PFIFO_MODE,nv_rd32(NV04_PFIFO_MODE)|(1<<chan->id));
+	return 0;
+}
+
+void
+nv40_fifo_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+
+	nv_wr32(NV04_PFIFO_MODE, nv_rd32(NV04_PFIFO_MODE)&~(1<<chan->id));
+
+	if (chan->ramfc)
+		nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+}
+
+int
+nv40_fifo_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp, tmp2;
+
+	dev_priv->engine.instmem.prepare_access(dev, false);
+
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_GET          , RAMFC_RD(DMA_GET));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_PUT          , RAMFC_RD(DMA_PUT));
+	nv_wr32(NV10_PFIFO_CACHE1_REF_CNT          , RAMFC_RD(REF_CNT));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_INSTANCE     , RAMFC_RD(DMA_INSTANCE));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_DCOUNT       , RAMFC_RD(DMA_DCOUNT));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_STATE        , RAMFC_RD(DMA_STATE));
+
+	/* No idea what 0x2058 is.. */
+	tmp   = RAMFC_RD(DMA_FETCH);
+	tmp2  = nv_rd32(0x2058) & 0xFFF;
+	tmp2 |= (tmp & 0x30000000);
+	nv_wr32(0x2058, tmp2);
+	tmp  &= ~0x30000000;
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_FETCH        , tmp);
+
+	nv_wr32(NV04_PFIFO_CACHE1_ENGINE           , RAMFC_RD(ENGINE));
+	nv_wr32(NV04_PFIFO_CACHE1_PULL1            , RAMFC_RD(PULL1_ENGINE));
+	nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_VALUE    , RAMFC_RD(ACQUIRE_VALUE));
+	nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_TIMESTAMP, RAMFC_RD(ACQUIRE_TIMESTAMP));
+	nv_wr32(NV10_PFIFO_CACHE1_ACQUIRE_TIMEOUT  , RAMFC_RD(ACQUIRE_TIMEOUT));
+	nv_wr32(NV10_PFIFO_CACHE1_SEMAPHORE        , RAMFC_RD(SEMAPHORE));
+	nv_wr32(NV10_PFIFO_CACHE1_DMA_SUBROUTINE   , RAMFC_RD(DMA_SUBROUTINE));
+	nv_wr32(NV40_PFIFO_GRCTX_INSTANCE          , RAMFC_RD(GRCTX_INSTANCE));
+	nv_wr32(0x32e4, RAMFC_RD(UNK_40));
+	/* NVIDIA does this next line twice... */
+	nv_wr32(0x32e8, RAMFC_RD(UNK_44));
+	nv_wr32(0x2088, RAMFC_RD(UNK_4C));
+	nv_wr32(0x3300, RAMFC_RD(UNK_50));
+
+	/* not sure what part is PUT, and which is GET.. never seen a non-zero
+	 * value appear in a mmio-trace yet..
+	 */
+#if 0
+	tmp = nv_rd32(UNK_84);
+	nv_wr32(NV_PFIFO_CACHE1_GET, tmp ???);
+	nv_wr32(NV_PFIFO_CACHE1_PUT, tmp ???);
+#endif
+
+	/* Don't clobber the TIMEOUT_ENABLED flag when restoring from RAMFC */
+	tmp  = nv_rd32(NV04_PFIFO_DMA_TIMESLICE) & ~0x1FFFF;
+	tmp |= RAMFC_RD(DMA_TIMESLICE) & 0x1FFFF;
+	nv_wr32(NV04_PFIFO_DMA_TIMESLICE, tmp);
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	/* Set channel active, and in DMA mode */
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH1,
+		 NV03_PFIFO_CACHE1_PUSH1_DMA | chan->id);
+
+	/* Reset DMA_CTL_AT_INFO to INVALID */
+	tmp = nv_rd32(NV04_PFIFO_CACHE1_DMA_CTL) & ~(1<<31);
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_CTL, tmp);
+
+	return 0;
+}
+
+int
+nv40_fifo_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+
+	RAMFC_WR(DMA_PUT          , nv_rd32(NV04_PFIFO_CACHE1_DMA_PUT));
+	RAMFC_WR(DMA_GET          , nv_rd32(NV04_PFIFO_CACHE1_DMA_GET));
+	RAMFC_WR(REF_CNT          , nv_rd32(NV10_PFIFO_CACHE1_REF_CNT));
+	RAMFC_WR(DMA_INSTANCE     , nv_rd32(NV04_PFIFO_CACHE1_DMA_INSTANCE));
+	RAMFC_WR(DMA_DCOUNT       , nv_rd32(NV04_PFIFO_CACHE1_DMA_DCOUNT));
+	RAMFC_WR(DMA_STATE        , nv_rd32(NV04_PFIFO_CACHE1_DMA_STATE));
+
+	tmp  = nv_rd32(NV04_PFIFO_CACHE1_DMA_FETCH);
+	tmp |= nv_rd32(0x2058) & 0x30000000;
+	RAMFC_WR(DMA_FETCH	  , tmp);
+
+	RAMFC_WR(ENGINE           , nv_rd32(NV04_PFIFO_CACHE1_ENGINE));
+	RAMFC_WR(PULL1_ENGINE     , nv_rd32(NV04_PFIFO_CACHE1_PULL1));
+	RAMFC_WR(ACQUIRE_VALUE    , nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_VALUE));
+	tmp = nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_TIMESTAMP);
+	RAMFC_WR(ACQUIRE_TIMESTAMP, tmp);
+	RAMFC_WR(ACQUIRE_TIMEOUT  , nv_rd32(NV10_PFIFO_CACHE1_ACQUIRE_TIMEOUT));
+	RAMFC_WR(SEMAPHORE        , nv_rd32(NV10_PFIFO_CACHE1_SEMAPHORE));
+
+	/* NVIDIA read 0x3228 first, then write DMA_GET here.. maybe something
+	 * more involved depending on the value of 0x3228?
+	 */
+	RAMFC_WR(DMA_SUBROUTINE   , nv_rd32(NV04_PFIFO_CACHE1_DMA_GET));
+
+	RAMFC_WR(GRCTX_INSTANCE   , nv_rd32(NV40_PFIFO_GRCTX_INSTANCE));
+
+	/* No idea what the below is for exactly, ripped from a mmio-trace */
+	RAMFC_WR(UNK_40           , nv_rd32(NV40_PFIFO_UNK32E4));
+
+	/* NVIDIA do this next line twice.. bug? */
+	RAMFC_WR(UNK_44           , nv_rd32(0x32e8));
+	RAMFC_WR(UNK_4C           , nv_rd32(0x2088));
+	RAMFC_WR(UNK_50           , nv_rd32(0x3300));
+
+#if 0 /* no real idea which is PUT/GET in UNK_48.. */
+	tmp  = nv_rd32(NV04_PFIFO_CACHE1_GET);
+	tmp |= (nv_rd32(NV04_PFIFO_CACHE1_PUT) << 16);
+	RAMFC_WR(UNK_48           , tmp);
+#endif
+
+	dev_priv->engine.instmem.finish_access(dev);
+	return 0;
+}
+
+int
+nv40_fifo_init(struct drm_device *dev)
+{
+	int ret;
+
+	if ((ret = nouveau_fifo_init(dev)))
+		return ret;
+
+	nv_wr32(NV04_PFIFO_DMA_TIMESLICE, 0x2101ffff);
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv40_graph.c b/drivers/gpu/drm/nouveau/nv40_graph.c
new file mode 100644
index 0000000..ba56db8
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv40_graph.c
@@ -0,0 +1,1842 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+/*TODO: deciper what each offset in the context represents. The below
+ *      contexts are taken from dumps just after the 3D object is
+ *      created.
+ */
+static void
+nv40_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	/* Always has the "instance address" of itself at offset 0 */
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	/* unknown */
+	INSTANCE_WR(ctx, 0x00024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x0016c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00170/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00174/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00180/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00184/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00188/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0018c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0019c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001a0/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001b0/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001c0/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0039c/4, 0x00000010);
+	INSTANCE_WR(ctx, 0x00480/4, 0x00000100);
+	INSTANCE_WR(ctx, 0x00494/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00498/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x004b4/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x004b8/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x004bc/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x004d0/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x004ec/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x004fc/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00504/4, 0x00011100);
+	for (i=0x00520; i<=0x0055c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00568/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x00594/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x00598/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x0059c/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x005a0/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x005b4/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x005cc/4, 0x00000004);
+	INSTANCE_WR(ctx, 0x005d8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0060c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00610/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00614/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00618/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00628/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0062c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00630/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00640/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x0067c/4, 0x00ffff00);
+	/* 0x680-0x6BC - NV30_TCL_PRIMITIVE_3D_TX_ADDRESS_UNIT(0-15) */
+	/* 0x6C0-0x6FC - NV30_TCL_PRIMITIVE_3D_TX_FORMAT_UNIT(0-15) */
+	for (i=0x006C0; i<=0x006fc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	/* 0x700-0x73C - NV30_TCL_PRIMITIVE_3D_TX_WRAP_UNIT(0-15) */
+	for (i=0x00700; i<=0x0073c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	/* 0x740-0x77C - NV30_TCL_PRIMITIVE_3D_TX_ENABLE_UNIT(0-15) */
+	/* 0x780-0x7BC - NV30_TCL_PRIMITIVE_3D_TX_SWIZZLE_UNIT(0-15) */
+	for (i=0x00780; i<=0x007bc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	/* 0x7C0-0x7FC - NV30_TCL_PRIMITIVE_3D_TX_FILTER_UNIT(0-15) */
+	for (i=0x007c0; i<=0x007fc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	/* 0x800-0x83C - NV30_TCL_PRIMITIVE_3D_TX_XY_DIM_UNIT(0-15) */
+	for (i=0x00800; i<=0x0083c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	/* 0x840-0x87C - NV30_TCL_PRIMITIVE_3D_TX_UNK07_UNIT(0-15) */
+	/* 0x880-0x8BC - NV30_TCL_PRIMITIVE_3D_TX_DEPTH_UNIT(0-15) */
+	for (i=0x00880; i<=0x008bc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	/* unknown */
+	for (i=0x00910; i<=0x0091c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x00920; i<=0x0092c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x00940; i<=0x0094c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x00960; i<=0x0096c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x00980/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x009b4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x009c0/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x009c4/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x009c8/4, 0x60103f00);
+	INSTANCE_WR(ctx, 0x009d4/4, 0x00020000);
+	INSTANCE_WR(ctx, 0x00a08/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x00aac/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00af0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00af8/4, 0x80800001);
+	INSTANCE_WR(ctx, 0x00bcc/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00bf8/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00bfc/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c00/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c04/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c08/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c0c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c44/4, 0x00000001);
+	for (i=0x03008; i<=0x03080; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x05288; i<=0x08570; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x08628; i<=0x08e18; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x0bd28; i<=0x0f010; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0f0c8; i<=0x0f8b8; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x127c8; i<=0x15ab0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x15b68; i<=0x16358; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x19268; i<=0x1c550; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x1c608; i<=0x1cdf8; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x1fd08; i<=0x22ff0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x230a8; i<=0x23898; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x267a8; i<=0x29a90; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x29b48; i<=0x2a338; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv41_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00000024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0000011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00000120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00000128/4, 0x02008821);
+	for (i = 0x00000178; i <= 0x00000180; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00000188/4, 0x00000040);
+	for (i = 0x00000194; i <= 0x000001b0; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x000001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00000340/4, 0x00040000);
+	for (i = 0x00000350; i <= 0x0000035c; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00000388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0000039c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x000003cc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x000003d0/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x000003ec/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x000003f0/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x000003f4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000408/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00000418/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00000424/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00000428/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00000430/4, 0x00011100);
+	for (i = 0x0000044c; i <= 0x00000488; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00000494/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x000004bc/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x000004c0/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x000004c4/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x000004c8/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x000004dc/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x000004f8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0000052c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00000530/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00000534/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00000538/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00000548/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0000054c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00000550/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000560/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x00000598/4, 0x00ffff00);
+	for (i = 0x000005dc; i <= 0x00000618; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i = 0x0000061c; i <= 0x00000658; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i = 0x0000069c; i <= 0x000006d8; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i = 0x000006dc; i <= 0x00000718; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i = 0x0000071c; i <= 0x00000758; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i = 0x0000079c; i <= 0x000007d8; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i = 0x0000082c; i <= 0x00000838; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i = 0x0000083c; i <= 0x00000848; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i = 0x0000085c; i <= 0x00000868; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i = 0x0000087c; i <= 0x00000888; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x0000089c/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x000008d0/4, 0x00000021);
+	INSTANCE_WR(ctx, 0x000008d4/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x000008e0/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x000008e4/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x000008e8/4, 0x20103f00);
+	INSTANCE_WR(ctx, 0x000008f4/4, 0x00020000);
+	INSTANCE_WR(ctx, 0x0000092c/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x000009b8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x000009fc/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00000a04/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00000a08/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00000aac/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00000ab8/4, 0x0000ffff);
+	for (i = 0x00000ad4; i <= 0x00000ae4; i += 4)
+		INSTANCE_WR(ctx, i/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00000ae8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000b20/4, 0x00000001);
+	for (i = 0x00002ee8; i <= 0x00002f60; i += 8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i = 0x00005168; i <= 0x00007358; i += 24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i = 0x00007368; i <= 0x00007758; i += 16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i = 0x0000a068; i <= 0x0000c258; i += 24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i = 0x0000c268; i <= 0x0000c658; i += 16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i = 0x0000ef68; i <= 0x00011158; i += 24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i = 0x00011168; i <= 0x00011558; i += 16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i = 0x00013e68; i <= 0x00016058; i += 24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i = 0x00016068; i <= 0x00016458; i += 16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+};
+
+static void
+nv43_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00178/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00180/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00188/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00194/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00198/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0019c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001a0/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001a4/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001a8/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001ac/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001b0/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0039c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x003cc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003d0/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x003ec/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x003f0/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00408/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00418/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00424/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00428/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00430/4, 0x00011100);
+	for (i=0x0044c; i<=0x00488; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00494/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x004bc/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x004c0/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x004c4/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x004c8/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x004dc/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0052c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00530/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00534/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00538/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00548/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0054c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00550/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00560/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x00598/4, 0x00ffff00);
+	for (i=0x005dc; i<=0x00618; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x0061c; i<=0x00658; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x0069c; i<=0x006d8; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x006dc; i<=0x00718; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x0071c; i<=0x00758; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x0079c; i<=0x007d8; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x0082c; i<=0x00838; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x0083c; i<=0x00848; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x0085c; i<=0x00868; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x0087c; i<=0x00888; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x0089c/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x008d0/4, 0x00000021);
+	INSTANCE_WR(ctx, 0x008d4/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x008e0/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x008e4/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x008e8/4, 0x0c103f00);
+	INSTANCE_WR(ctx, 0x008f4/4, 0x00020000);
+	INSTANCE_WR(ctx, 0x0092c/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x009b8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x009fc/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00a04/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00a08/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00a8c/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00a98/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00ab4/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00ab8/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00abc/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00ac0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00af8/4, 0x00000001);
+	for (i=0x02ec0; i<=0x02f38; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x04c80; i<=0x06e70; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x06e80; i<=0x07270; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x096c0; i<=0x0b8b0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0b8c0; i<=0x0bcb0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x0e100; i<=0x102f0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x10300; i<=0x106f0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+};
+
+static void
+nv46_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00040/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00044/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0004c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00138/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x0013c/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00144/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00174/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00178/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00180/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00184/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00188/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0018c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00190/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00194/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00198/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0019c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001a4/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001ec/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x0036c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00370/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00374/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00378/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003a4/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x003b8/4, 0x00003010);
+	INSTANCE_WR(ctx, 0x003dc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003e0/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003e4/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003e8/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003ec/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003f0/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003f8/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003fc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00400/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00404/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00408/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0040c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00410/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00414/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00418/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004b0/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004b4/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x004d0/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x004d4/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x004d8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x004ec/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x004fc/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00500/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00504/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00508/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0050c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00510/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00514/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00518/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0051c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00520/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00524/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00528/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0052c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00530/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00534/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00538/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0053c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00550/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00554/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x0055c/4, 0x00011100);
+	for (i=0x00578; i<0x005b4; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c0/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x005e8/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x005ec/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x005f0/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x005f4/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x00608/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x00624/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00658/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x0065c/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00660/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00664/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00674/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00678/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x0067c/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0068c/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x006c8/4, 0x00ffff00);
+	for (i=0x0070c; i<=0x00748; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x0074c; i<=0x00788; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x007cc; i<=0x00808; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x0080c; i<=0x00848; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x0084c; i<=0x00888; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x008cc; i<=0x00908; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x0095c; i<=0x00968; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x0096c; i<=0x00978; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x0098c; i<=0x00998; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x009ac; i<=0x009b8; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x009cc/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x00a00/4, 0x00000421);
+	INSTANCE_WR(ctx, 0x00a04/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x00a08/4, 0x00011001);
+	INSTANCE_WR(ctx, 0x00a14/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x00a18/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x00a1c/4, 0x0c103f00);
+	INSTANCE_WR(ctx, 0x00a28/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00a60/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x00aec/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00b30/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00b38/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00b3c/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00bc0/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00bcc/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00be8/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00bec/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00bf0/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00bf4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00c2c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00c30/4, 0x08e00001);
+	INSTANCE_WR(ctx, 0x00c34/4, 0x000e3000);
+	for (i=0x017f8; i<=0x01870; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x035b8; i<=0x057a8; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x057b8; i<=0x05ba8; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x07f38; i<=0x0a128; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0a138; i<=0x0a528; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x0c8b8; i<=0x0eaa8; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0eab8; i<=0x0eea8; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+/* This may only work on 7800 AGP cards, will include a warning */
+static void
+nv47_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00000024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0000011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00000120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00000128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00000178/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0000017c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00000180/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00000188/4, 0x00000040);
+	for (i=0x00000194; i<=0x000001b0; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x000001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00000340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00000350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00000354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00000358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0000035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00000388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0000039c/4, 0x00001010);
+	for (i=0x000003c0; i<=0x000003fc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00000454/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00000458/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x00000474/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x00000478/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x0000047c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000490/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x000004a0/4, 0xffff0000);
+	for (i=0x000004a4; i<=0x000004e0; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x000004f4/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x000004f8/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00000500/4, 0x00011100);
+	for (i=0x0000051c; i<=0x00000558; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00000564/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x0000058c/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x00000590/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x00000594/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x00000598/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x000005ac/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x000005c8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x000005fc/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00000600/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00000604/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00000608/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00000618/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0000061c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00000620/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00000630/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x0000066c/4, 0x00ffff00);
+	for (i=0x000006b0; i<=0x000006ec; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x000006f0; i<=0x0000072c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x00000770; i<=0x000007ac; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x000007b0; i<=0x000007ec; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x000007f0; i<=0x0000082c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x00000870; i<=0x000008ac; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	INSTANCE_WR(ctx, 0x00000900/4, 0x0001bc80);
+	INSTANCE_WR(ctx, 0x00000904/4, 0x0001bc80);
+	INSTANCE_WR(ctx, 0x00000908/4, 0x0001bc80);
+	INSTANCE_WR(ctx, 0x0000090c/4, 0x0001bc80);
+	INSTANCE_WR(ctx, 0x00000910/4, 0x00000202);
+	INSTANCE_WR(ctx, 0x00000914/4, 0x00000202);
+	INSTANCE_WR(ctx, 0x00000918/4, 0x00000202);
+	INSTANCE_WR(ctx, 0x0000091c/4, 0x00000202);
+	for (i=0x00000930; i<=0x0000095c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x00000970/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x000009a4/4, 0x00000021);
+	INSTANCE_WR(ctx, 0x000009a8/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x000009b4/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x000009b8/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x000009bc/4, 0x40103f00);
+	INSTANCE_WR(ctx, 0x000009c8/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00000a00/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x00000a8c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000ad0/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00000adc/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00000ae0/4, 0x00888001);
+	for (i=0x00000b10; i<=0x00000b8c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00000bb4/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00000bc0/4, 0x0000ffff);
+	for (i=0x00000bdc; i<=0x00000bf8; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00000bfc/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000c34/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00000c38/4, 0x08e00001);
+	INSTANCE_WR(ctx, 0x00000c3c/4, 0x000e3000);
+	for (i=0x00003000; i<=0x00003078; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x00004dc0; i<=0x00006fb0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x00006fc0; i<=0x000073b0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x00009800; i<=0x0000b9f0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0000ba00; i<=0x00010430; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x00010440; i<=0x00010830; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x00012c80; i<=0x00014e70; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x00014e80; i<=0x00015270; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x000176c0; i<=0x000198b0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x000198c0; i<=0x00019cb0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x0001c100; i<=0x0001e2f0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0001e300; i<=0x0001e6f0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv49_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00004/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00008/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x0000c/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00010/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00014/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00018/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x0001c/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00020/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x000c4/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x000c8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x000d0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x001bc/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x001c0/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x001c8/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00218/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0021c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00220/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00228/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00234/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00238/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0023c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00240/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00244/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00248/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0024c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00250/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00270/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x003e0/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x003f0/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003f8/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003fc/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00428/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0043c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x00460/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00464/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00468/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0046c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00470/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00474/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00478/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0047c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00480/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00484/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00488/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0048c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00490/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00494/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00498/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0049c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004f4/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x00514/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x00518/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x0051c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00530/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00540/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00544/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00548/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0054c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00550/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00554/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00558/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0055c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00560/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00564/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00568/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0056c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00570/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00574/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00578/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0057c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00580/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00594/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00598/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x005a0/4, 0x00011100);
+	INSTANCE_WR(ctx, 0x005bc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005cc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005dc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005ec/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00604/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x0062c/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x00630/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x00634/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x00638/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x0064c/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x00668/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0069c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x006a0/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x006a4/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x006a8/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x006b8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x006bc/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x006c0/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x006d0/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x0070c/4, 0x00ffff00);
+	for (i=0x00750; i<=0x0078c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x00790; i<=0x007cc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x00810; i<=0x0084c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x00850; i<=0x0088c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x00890; i<=0x008cc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x00910; i<=0x0094c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x009a0; i<=0x009ac; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x009b0; i<=0x009bc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x009d0; i<=0x009dc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x009f0; i<=0x009fc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x00a10/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x00a44/4, 0x00000421);
+	INSTANCE_WR(ctx, 0x00a48/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x00a54/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x00a58/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x00a5c/4, 0x20103f00);
+	INSTANCE_WR(ctx, 0x00a68/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00aa0/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x00b2c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00b70/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00b7c/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00b80/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00bb0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bb4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bb8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bbc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bcc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bdc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bec/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bfc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c00/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c04/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c08/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c0c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c10/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c14/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c18/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c1c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c20/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c24/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c28/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c2c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c54/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00c60/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00c7c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c80/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c84/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c88/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c8c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c90/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c94/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c98/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c9c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00cd4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00cd8/4, 0x08e00001);
+	INSTANCE_WR(ctx, 0x00cdc/4, 0x000e3000);
+	for(i=0x030a0; i<=0x03118; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x098a0; i<=0x0ba90; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x0baa0; i<=0x0be90; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x0e2e0; i<=0x0fff0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x10008; i<=0x104d0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x104e0; i<=0x108d0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x12d20; i<=0x14f10; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x14f20; i<=0x15310; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x17760; i<=0x19950; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x19960; i<=0x19d50; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x1c1a0; i<=0x1e390; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x1e3a0; i<=0x1e790; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x20be0; i<=0x22dd0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x22de0; i<=0x231d0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv4a_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00158/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0015c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00160/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00164/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00168/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0016c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00170/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00174/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00178/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00180/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00188/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0039c/4, 0x00003010);
+	INSTANCE_WR(ctx, 0x003cc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003d0/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x003ec/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x003f0/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00408/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00418/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00424/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00428/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00430/4, 0x00011100);
+	for (i=0x0044c; i<=0x00488; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00494/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x004bc/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x004c0/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x004c4/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x004c8/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x004dc/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0052c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00530/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00534/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00538/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00548/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0054c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00550/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0055c/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x00594/4, 0x00ffff00);
+	for (i=0x005d8; i<=0x00614; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x00618; i<=0x00654; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x00698; i<=0x006d4; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x006d8; i<=0x00714; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x00718; i<=0x00754; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x00798; i<=0x007d4; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x00828; i<=0x00834; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x00838; i<=0x00844; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x00858; i<=0x00864; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x00878; i<=0x00884; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x00898/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x008cc/4, 0x00000021);
+	INSTANCE_WR(ctx, 0x008d0/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x008d4/4, 0x00011001);
+	INSTANCE_WR(ctx, 0x008e0/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x008e4/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x008e8/4, 0x0c103f00);
+	INSTANCE_WR(ctx, 0x008f4/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x0092c/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x009b8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x009fc/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00a04/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00a08/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00a8c/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00a98/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00ab4/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00ab8/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00abc/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00ac0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00af8/4, 0x00000001);
+	for (i=0x016c0; i<=0x01738; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x03840; i<=0x05670; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x05680; i<=0x05a70; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x07e00; i<=0x09ff0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0a000; i<=0x0a3f0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x0c780; i<=0x0e970; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x0e980; i<=0x0ed70; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv4b_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00004/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00008/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x0000c/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00010/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00014/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00018/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x0001c/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x00020/4, 0x0000c040);
+	INSTANCE_WR(ctx, 0x000c4/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x000c8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x000d0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x001bc/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x001c0/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x001c8/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00218/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0021c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00220/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00228/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00234/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00238/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0023c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00240/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00244/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00248/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x0024c/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00250/4, 0x80000000);
+	INSTANCE_WR(ctx, 0x00270/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x003e0/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x003f0/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003f8/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x003fc/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00428/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0043c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x00460/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00464/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00468/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0046c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00470/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00474/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00478/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0047c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00480/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00484/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00488/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0048c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00490/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00494/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x00498/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x0049c/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004f4/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x00514/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x00518/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x0051c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00530/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00540/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00544/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00548/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0054c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00550/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00554/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00558/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0055c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00560/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00564/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00568/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0056c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00570/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00574/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00578/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x0057c/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00580/4, 0x88888888);
+	INSTANCE_WR(ctx, 0x00594/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00598/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x005a0/4, 0x00011100);
+	INSTANCE_WR(ctx, 0x005bc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005c8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005cc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005d8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005dc/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005e8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005ec/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f0/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f4/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x005f8/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00604/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x0062c/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x00630/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x00634/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x00638/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x0064c/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x00668/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0069c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x006a0/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x006a4/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x006a8/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x006b8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x006bc/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x006c0/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x006d0/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x0070c/4, 0x00ffff00);
+	for (i=0x00750; i<=0x0078c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x00790; i<=0x007cc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x00810; i<=0x0084c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x00850; i<=0x0088c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x00890; i<=0x008cc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x00910; i<=0x0094c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x009a0; i<=0x009ac; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x009b0; i<=0x009bc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x009d0; i<=0x009dc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x009f0; i<=0x009fc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x00a10/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x00a44/4, 0x00000421);
+	INSTANCE_WR(ctx, 0x00a48/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x00a54/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x00a58/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x00a5c/4, 0x20103f00);
+	INSTANCE_WR(ctx, 0x00a68/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00aa0/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x00b2c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00b70/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00b7c/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00b80/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00bb0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bb4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bb8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bbc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bc8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bcc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bd8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bdc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00be8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bec/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf0/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf4/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bf8/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00bfc/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c00/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c04/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c08/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c0c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c10/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c14/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c18/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c1c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c20/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c24/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c28/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c2c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00c54/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00c60/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00c7c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c80/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c84/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c88/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c8c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c90/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c94/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c98/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00c9c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00cd4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00cd8/4, 0x08e00001);
+	INSTANCE_WR(ctx, 0x00cdc/4, 0x000e3000);
+	for(i=0x030a0; i<=0x03118; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x098a0; i<=0x0ba90; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x0baa0; i<=0x0be90; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x0e2e0; i<=0x0fff0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x10008; i<=0x104d0; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x104e0; i<=0x108d0; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x12d20; i<=0x14f10; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x14f20; i<=0x15310; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for(i=0x17760; i<=0x19950; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for(i=0x19960; i<=0x19d50; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv4c_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00158/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0015c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00160/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00164/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00168/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0016c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00170/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00174/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00178/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00180/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00188/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0039c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x003d0/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003d4/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x003f0/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x003f4/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x003f8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0040c/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x0041c/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00428/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x0042c/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00434/4, 0x00011100);
+	for (i=0x00450; i<0x0048c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00498/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x004c0/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x004c4/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x004c8/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x004cc/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x004e0/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x004fc/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00530/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00534/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00538/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x0053c/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x0054c/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x00550/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00554/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00564/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x0059c/4, 0x00ffff00);
+	for (i=0x005e0; i<=0x0061c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x00620; i<=0x0065c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x006a0; i<=0x006dc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x006e0; i<=0x0071c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x00720; i<=0x0075c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x007a0; i<=0x007dc; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x00830; i<=0x0083c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x00840; i<=0x0084c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x00860; i<=0x0086c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x00880; i<=0x0088c; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x008a0/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x008d4/4, 0x00000020);
+	INSTANCE_WR(ctx, 0x008d8/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x008dc/4, 0x00011001);
+	INSTANCE_WR(ctx, 0x008e8/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x008ec/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x008f0/4, 0x0c103f00);
+	INSTANCE_WR(ctx, 0x008fc/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00934/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x009c0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00a04/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00a0c/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00a10/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00a74/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00a80/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00a9c/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00aa0/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00ad8/4, 0x00000001);
+	for (i=0x016a0; i<0x01718; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x03460; i<0x05650; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x05660; i<0x05a50; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+static void
+nv4e_graph_context_init(struct drm_device *dev, struct nouveau_gpuobj *ctx)
+{
+	int i;
+
+	INSTANCE_WR(ctx, 0x00000/4, ctx->im_pramin->start);
+	INSTANCE_WR(ctx, 0x00024/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00028/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00030/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0011c/4, 0x20010001);
+	INSTANCE_WR(ctx, 0x00120/4, 0x0f73ef00);
+	INSTANCE_WR(ctx, 0x00128/4, 0x02008821);
+	INSTANCE_WR(ctx, 0x00158/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0015c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00160/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00164/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00168/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x0016c/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00170/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00174/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00178/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x0017c/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00180/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x00188/4, 0x00000040);
+	INSTANCE_WR(ctx, 0x001d0/4, 0x0b0b0b0c);
+	INSTANCE_WR(ctx, 0x00340/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x00350/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00354/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00358/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x0035c/4, 0x55555555);
+	INSTANCE_WR(ctx, 0x00388/4, 0x00000008);
+	INSTANCE_WR(ctx, 0x0039c/4, 0x00001010);
+	INSTANCE_WR(ctx, 0x003cc/4, 0x00000111);
+	INSTANCE_WR(ctx, 0x003d0/4, 0x00080060);
+	INSTANCE_WR(ctx, 0x003ec/4, 0x00000080);
+	INSTANCE_WR(ctx, 0x003f0/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x003f4/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00408/4, 0x46400000);
+	INSTANCE_WR(ctx, 0x00418/4, 0xffff0000);
+	INSTANCE_WR(ctx, 0x00424/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00428/4, 0x0fff0000);
+	INSTANCE_WR(ctx, 0x00430/4, 0x00011100);
+	for (i=0x0044c; i<=0x00488; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x07ff0000);
+	INSTANCE_WR(ctx, 0x00494/4, 0x4b7fffff);
+	INSTANCE_WR(ctx, 0x004bc/4, 0x30201000);
+	INSTANCE_WR(ctx, 0x004c0/4, 0x70605040);
+	INSTANCE_WR(ctx, 0x004c4/4, 0xb8a89888);
+	INSTANCE_WR(ctx, 0x004c8/4, 0xf8e8d8c8);
+	INSTANCE_WR(ctx, 0x004dc/4, 0x40100000);
+	INSTANCE_WR(ctx, 0x004f8/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0052c/4, 0x435185d6);
+	INSTANCE_WR(ctx, 0x00530/4, 0x2155b699);
+	INSTANCE_WR(ctx, 0x00534/4, 0xfedcba98);
+	INSTANCE_WR(ctx, 0x00538/4, 0x00000098);
+	INSTANCE_WR(ctx, 0x00548/4, 0xffffffff);
+	INSTANCE_WR(ctx, 0x0054c/4, 0x00ff7000);
+	INSTANCE_WR(ctx, 0x00550/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x0055c/4, 0x00ff0000);
+	INSTANCE_WR(ctx, 0x00594/4, 0x00ffff00);
+	for (i=0x005d8; i<=0x00614; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00018488);
+	for (i=0x00618; i<=0x00654; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00028202);
+	for (i=0x00698; i<=0x006d4; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0000aae4);
+	for (i=0x006d8; i<=0x00714; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x01012000);
+	for (i=0x00718; i<=0x00754; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	for (i=0x00798; i<=0x007d4; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00100008);
+	for (i=0x00828; i<=0x00834; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x0001bc80);
+	for (i=0x00838; i<=0x00844; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000202);
+	for (i=0x00858; i<=0x00864; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00000008);
+	for (i=0x00878; i<=0x00884; i+=4)
+		INSTANCE_WR(ctx, i/4, 0x00080008);
+	INSTANCE_WR(ctx, 0x00898/4, 0x00000002);
+	INSTANCE_WR(ctx, 0x008cc/4, 0x00000020);
+	INSTANCE_WR(ctx, 0x008d0/4, 0x030c30c3);
+	INSTANCE_WR(ctx, 0x008d4/4, 0x00011001);
+	INSTANCE_WR(ctx, 0x008e0/4, 0x3e020200);
+	INSTANCE_WR(ctx, 0x008e4/4, 0x00ffffff);
+	INSTANCE_WR(ctx, 0x008e8/4, 0x0c103f00);
+	INSTANCE_WR(ctx, 0x008f4/4, 0x00040000);
+	INSTANCE_WR(ctx, 0x0092c/4, 0x00008100);
+	INSTANCE_WR(ctx, 0x009b8/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x009fc/4, 0x00001001);
+	INSTANCE_WR(ctx, 0x00a04/4, 0x00000003);
+	INSTANCE_WR(ctx, 0x00a08/4, 0x00888001);
+	INSTANCE_WR(ctx, 0x00a6c/4, 0x00000005);
+	INSTANCE_WR(ctx, 0x00a78/4, 0x0000ffff);
+	INSTANCE_WR(ctx, 0x00a94/4, 0x00005555);
+	INSTANCE_WR(ctx, 0x00a98/4, 0x00000001);
+	INSTANCE_WR(ctx, 0x00aa4/4, 0x00000001);
+	for (i=0x01668; i<=0x016e0; i+=8)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+	for (i=0x03428; i<=0x05618; i+=24)
+		INSTANCE_WR(ctx, i/4, 0x00000001);
+	for (i=0x05628; i<=0x05a18; i+=16)
+		INSTANCE_WR(ctx, i/4, 0x3f800000);
+}
+
+int
+nv40_graph_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	void (*ctx_init)(struct drm_device *, struct nouveau_gpuobj *);
+	int ret;
+
+	/* These functions populate the graphics context with a whole heap
+	 * of default state.  All these functions are very similar, with
+	 * a minimal amount of chipset-specific changes.  However, as we're
+	 * currently dependant on the context programs used by the NVIDIA
+	 * binary driver these functions must match the layout expected by
+	 * them.  Hopefully at some point this will all change.
+	 */
+	switch (dev_priv->chipset) {
+	case 0x40:
+		ctx_init = nv40_graph_context_init;
+		break;
+	case 0x41:
+	case 0x42:
+		ctx_init = nv41_graph_context_init;
+		break;
+	case 0x43:
+		ctx_init = nv43_graph_context_init;
+		break;
+	case 0x46:
+		ctx_init = nv46_graph_context_init;
+		break;
+	case 0x47:
+		ctx_init = nv47_graph_context_init;
+		break;
+	case 0x49:
+		ctx_init = nv49_graph_context_init;
+		break;
+	case 0x44:
+	case 0x4a:
+		ctx_init = nv4a_graph_context_init;
+		break;
+	case 0x4b:
+		ctx_init = nv4b_graph_context_init;
+		break;
+	case 0x4c:
+	case 0x67:
+		ctx_init = nv4c_graph_context_init;
+		break;
+	case 0x4e:
+		ctx_init = nv4e_graph_context_init;
+		break;
+	default:
+		ctx_init = nv40_graph_context_init;
+		break;
+	}
+
+	/* Allocate a 175KiB block of PRAMIN to store the context.  This
+	 * is massive overkill for a lot of chipsets, but it should be safe
+	 * until we're able to implement this properly (will happen at more
+	 * or less the same time we're able to write our own context programs.
+	 */
+	if ((ret = nouveau_gpuobj_new_ref(dev, chan, NULL, 0, 175*1024, 16,
+					  NVOBJ_FLAG_ZERO_ALLOC,
+					  &chan->ramin_grctx)))
+		return ret;
+
+	/* Initialise default context values */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	ctx_init(dev, chan->ramin_grctx->gpuobj);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	return 0;
+}
+
+void
+nv40_graph_destroy_context(struct nouveau_channel *chan)
+{
+	nouveau_gpuobj_ref_del(chan->dev, &chan->ramin_grctx);
+}
+
+static int
+nv40_graph_transfer_context(struct drm_device *dev, uint32_t inst, int save)
+{
+	uint32_t old_cp, tv = 1000, tmp;
+	int i;
+
+	old_cp = nv_rd32(NV20_PGRAPH_CHANNEL_CTX_POINTER);
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+
+	tmp  = nv_rd32(NV40_PGRAPH_CTXCTL_0310);
+	tmp |= save ? NV40_PGRAPH_CTXCTL_0310_XFER_SAVE :
+		      NV40_PGRAPH_CTXCTL_0310_XFER_LOAD;
+	nv_wr32(NV40_PGRAPH_CTXCTL_0310, tmp);
+
+	tmp  = nv_rd32(NV40_PGRAPH_CTXCTL_0304);
+	tmp |= NV40_PGRAPH_CTXCTL_0304_XFER_CTX;
+	nv_wr32(NV40_PGRAPH_CTXCTL_0304, tmp);
+
+	nouveau_wait_for_idle(dev);
+
+	for (i = 0; i < tv; i++) {
+		if (nv_rd32(NV40_PGRAPH_CTXCTL_030C) == 0)
+			break;
+	}
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, old_cp);
+
+	if (i == tv) {
+		uint32_t ucstat = nv_rd32(NV40_PGRAPH_CTXCTL_UCODE_STAT);
+		NV_ERROR(dev, "Failed: Instance=0x%08x Save=%d\n", inst, save);
+		NV_ERROR(dev, "IP: 0x%02x, Opcode: 0x%08x\n",
+			 ucstat >> NV40_PGRAPH_CTXCTL_UCODE_STAT_IP_SHIFT,
+			 ucstat  & NV40_PGRAPH_CTXCTL_UCODE_STAT_OP_MASK);
+		NV_ERROR(dev, "0x40030C = 0x%08x\n",
+			 nv_rd32(NV40_PGRAPH_CTXCTL_030C));
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+/* Save current context (from PGRAPH) into the channel's context */
+int
+nv40_graph_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst;
+
+	if (!chan->ramin_grctx)
+		return -EINVAL;
+	inst = chan->ramin_grctx->instance >> 4;
+
+	return nv40_graph_transfer_context(dev, inst, 1);
+}
+
+/* Restore the context for a specific channel into PGRAPH */
+int
+nv40_graph_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst;
+	int ret;
+
+	if (!chan->ramin_grctx)
+		return -EINVAL;
+	inst = chan->ramin_grctx->instance >> 4;
+
+	ret = nv40_graph_transfer_context(dev, inst, 0);
+	if (ret)
+		return ret;
+
+	/* 0x40032C, no idea of it's exact function.  Could simply be a
+	 * record of the currently active PGRAPH context.  It's currently
+	 * unknown as to what bit 24 does.  The nv ddx has it set, so we will
+	 * set it here too.
+	 */
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+	nv_wr32(NV40_PGRAPH_CTXCTL_CUR,
+		 (inst & NV40_PGRAPH_CTXCTL_CUR_INST_MASK) |
+		  NV40_PGRAPH_CTXCTL_CUR_LOADED);
+	/* 0x32E0 records the instance address of the active FIFO's PGRAPH
+	 * context.  If at any time this doesn't match 0x40032C, you will
+	 * recieve PGRAPH_INTR_CONTEXT_SWITCH
+	 */
+	nv_wr32(NV40_PFIFO_GRCTX_INSTANCE, inst);
+	return 0;
+}
+
+/*(DEBLOBBED)*/
+
+/*
+ * G70		0x47
+ * G71		0x49
+ * NV45		0x48
+ * G72[M]	0x46
+ * G73		0x4b
+ * C51_G7X	0x4c
+ * C51		0x4e
+ */
+int
+nv40_graph_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv =
+		(struct drm_nouveau_private *)dev->dev_private;
+	uint32_t *ctx_prog;
+	uint32_t vramsz, tmp;
+	int i, j;
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) &
+			~NV_PMC_ENABLE_PGRAPH);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |
+			 NV_PMC_ENABLE_PGRAPH);
+
+	switch (dev_priv->chipset) {
+		/*(DEBLOBBED)*/
+	default:
+		NV_ERROR(dev, "Context program for 0x%02x unavailable\n",
+			 dev_priv->chipset);
+		return -EINVAL;
+	}
+
+	/* Load the context program onto the card */
+	NV_DEBUG(dev, "Loading context program\n");
+
+	i = 0;
+	nv_wr32(NV40_PGRAPH_CTXCTL_UCODE_INDEX, 0);
+	while (ctx_prog[i] != ~0) {
+		nv_wr32(NV40_PGRAPH_CTXCTL_UCODE_DATA, ctx_prog[i]);
+		i++;
+	}
+
+	/* No context present currently */
+	nv_wr32(NV40_PGRAPH_CTXCTL_CUR, 0x00000000);
+
+	nv_wr32(NV03_PGRAPH_INTR   , 0xFFFFFFFF);
+	nv_wr32(NV40_PGRAPH_INTR_EN, 0xFFFFFFFF);
+
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0xFFFFFFFF);
+	nv_wr32(NV04_PGRAPH_DEBUG_0, 0x00000000);
+	nv_wr32(NV04_PGRAPH_DEBUG_1, 0x401287c0);
+	nv_wr32(NV04_PGRAPH_DEBUG_3, 0xe0de8055);
+	nv_wr32(NV10_PGRAPH_DEBUG_4, 0x00008000);
+	nv_wr32(NV04_PGRAPH_LIMIT_VIOL_PIX, 0x00be3c5f);
+
+	nv_wr32(NV10_PGRAPH_CTX_CONTROL, 0x10010100);
+	nv_wr32(NV10_PGRAPH_STATE      , 0xFFFFFFFF);
+
+	j = nv_rd32(0x1540) & 0xff;
+	if (j) {
+		for (i=0; !(j&1); j>>=1, i++);
+		nv_wr32(0x405000, i);
+	}
+
+	if (dev_priv->chipset == 0x40) {
+		nv_wr32(0x4009b0, 0x83280fff);
+		nv_wr32(0x4009b4, 0x000000a0);
+	} else {
+		nv_wr32(0x400820, 0x83280eff);
+		nv_wr32(0x400824, 0x000000a0);
+	}
+
+	switch (dev_priv->chipset) {
+	case 0x40:
+	case 0x45:
+		nv_wr32(0x4009b8, 0x0078e366);
+		nv_wr32(0x4009bc, 0x0000014c);
+		break;
+	case 0x41:
+	case 0x42: /* pciid also 0x00Cx */
+//	case 0x0120: //XXX (pciid)
+		nv_wr32(0x400828, 0x007596ff);
+		nv_wr32(0x40082c, 0x00000108);
+		break;
+	case 0x43:
+		nv_wr32(0x400828, 0x0072cb77);
+		nv_wr32(0x40082c, 0x00000108);
+		break;
+	case 0x44:
+	case 0x46: /* G72 */
+	case 0x4a:
+	case 0x4c: /* G7x-based C51 */
+	case 0x4e:
+		nv_wr32(0x400860, 0);
+		nv_wr32(0x400864, 0);
+		break;
+	case 0x47: /* G70 */
+	case 0x49: /* G71 */
+	case 0x4b: /* G73 */
+		nv_wr32(0x400828, 0x07830610);
+		nv_wr32(0x40082c, 0x0000016A);
+		break;
+	default:
+		break;
+	}
+
+	nv_wr32(0x400b38, 0x2ffff800);
+	nv_wr32(0x400b3c, 0x00006000);
+
+	/* copy tile info from PFB */
+	switch (dev_priv->chipset) {
+	case 0x40: /* vanilla NV40 */
+		for (i=0; i<NV10_PFB_TILE__SIZE; i++) {
+			tmp = nv_rd32(NV10_PFB_TILE(i));
+			nv_wr32(NV40_PGRAPH_TILE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TILE1(i), tmp);
+			tmp = nv_rd32(NV10_PFB_TLIMIT(i));
+			nv_wr32(NV40_PGRAPH_TLIMIT0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TLIMIT1(i), tmp);
+			tmp = nv_rd32(NV10_PFB_TSIZE(i));
+			nv_wr32(NV40_PGRAPH_TSIZE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSIZE1(i), tmp);
+			tmp = nv_rd32(NV10_PFB_TSTATUS(i));
+			nv_wr32(NV40_PGRAPH_TSTATUS0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSTATUS1(i), tmp);
+		}
+		break;
+	case 0x44:
+	case 0x4a:
+	case 0x4e: /* NV44-based cores don't have 0x406900? */
+		for (i=0; i<NV40_PFB_TILE__SIZE_0; i++) {
+			tmp = nv_rd32(NV40_PFB_TILE(i));
+			nv_wr32(NV40_PGRAPH_TILE0(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TLIMIT(i));
+			nv_wr32(NV40_PGRAPH_TLIMIT0(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSIZE(i));
+			nv_wr32(NV40_PGRAPH_TSIZE0(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSTATUS(i));
+			nv_wr32(NV40_PGRAPH_TSTATUS0(i), tmp);
+		}
+		break;
+	case 0x46:
+	case 0x47:
+	case 0x49:
+	case 0x4b: /* G7X-based cores */
+		for (i=0; i<NV40_PFB_TILE__SIZE_1; i++) {
+			tmp = nv_rd32(NV40_PFB_TILE(i));
+			nv_wr32(NV47_PGRAPH_TILE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TILE1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TLIMIT(i));
+			nv_wr32(NV47_PGRAPH_TLIMIT0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TLIMIT1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSIZE(i));
+			nv_wr32(NV47_PGRAPH_TSIZE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSIZE1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSTATUS(i));
+			nv_wr32(NV47_PGRAPH_TSTATUS0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSTATUS1(i), tmp);
+		}
+		break;
+	default: /* everything else */
+		for (i=0; i<NV40_PFB_TILE__SIZE_0; i++) {
+			tmp = nv_rd32(NV40_PFB_TILE(i));
+			nv_wr32(NV40_PGRAPH_TILE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TILE1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TLIMIT(i));
+			nv_wr32(NV40_PGRAPH_TLIMIT0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TLIMIT1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSIZE(i));
+			nv_wr32(NV40_PGRAPH_TSIZE0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSIZE1(i), tmp);
+			tmp = nv_rd32(NV40_PFB_TSTATUS(i));
+			nv_wr32(NV40_PGRAPH_TSTATUS0(i), tmp);
+			nv_wr32(NV40_PGRAPH_TSTATUS1(i), tmp);
+		}
+		break;
+	}
+
+	/* begin RAM config */
+	vramsz = drm_get_resource_len(dev, 0) - 1;
+	switch (dev_priv->chipset) {
+	case 0x40:
+		nv_wr32(0x4009A4, nv_rd32(NV04_PFB_CFG0));
+		nv_wr32(0x4009A8, nv_rd32(NV04_PFB_CFG1));
+		nv_wr32(0x4069A4, nv_rd32(NV04_PFB_CFG0));
+		nv_wr32(0x4069A8, nv_rd32(NV04_PFB_CFG1));
+		nv_wr32(0x400820, 0);
+		nv_wr32(0x400824, 0);
+		nv_wr32(0x400864, vramsz);
+		nv_wr32(0x400868, vramsz);
+		break;
+	default:
+		switch (dev_priv->chipset) {
+		case 0x46:
+		case 0x47:
+		case 0x49:
+		case 0x4b:
+			nv_wr32(0x400DF0, nv_rd32(NV04_PFB_CFG0));
+			nv_wr32(0x400DF4, nv_rd32(NV04_PFB_CFG1));
+			break;
+		default:
+			nv_wr32(0x4009F0, nv_rd32(NV04_PFB_CFG0));
+			nv_wr32(0x4009F4, nv_rd32(NV04_PFB_CFG1));
+			break;
+		}
+		nv_wr32(0x4069F0, nv_rd32(NV04_PFB_CFG0));
+		nv_wr32(0x4069F4, nv_rd32(NV04_PFB_CFG1));
+		nv_wr32(0x400840, 0);
+		nv_wr32(0x400844, 0);
+		nv_wr32(0x4008A0, vramsz);
+		nv_wr32(0x4008A4, vramsz);
+		break;
+	}
+
+	/* per-context state, doesn't belong here */
+	nv_wr32(0x400B20, 0x00000000);
+	nv_wr32(0x400B04, 0xFFFFFFFF);
+
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) & 0x0007ff00;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+	tmp = nv_rd32(NV10_PGRAPH_SURFACE) | 0x00020100;
+	nv_wr32(NV10_PGRAPH_SURFACE, tmp);
+
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMIN, 0);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_XMAX, 0x7fff);
+	nv_wr32(NV03_PGRAPH_ABS_UCLIP_YMAX, 0x7fff);
+
+	return 0;
+}
+
+void nv40_graph_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv40_mc.c b/drivers/gpu/drm/nouveau/nv40_mc.c
new file mode 100644
index 0000000..87c6213
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv40_mc.c
@@ -0,0 +1,38 @@
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_drm.h"
+
+int
+nv40_mc_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t tmp;
+
+	/* Power up everything, resetting each individual unit will
+	 * be done later if needed.
+	 */
+	nv_wr32(NV03_PMC_ENABLE, 0xFFFFFFFF);
+
+	switch (dev_priv->chipset) {
+	case 0x44:
+	case 0x46: /* G72 */
+	case 0x4e:
+	case 0x4c: /* C51_G7X */
+		tmp = nv_rd32(NV40_PFB_020C);
+		nv_wr32(NV40_PMC_1700, tmp);
+		nv_wr32(NV40_PMC_1704, 0);
+		nv_wr32(NV40_PMC_1708, 0);
+		nv_wr32(NV40_PMC_170C, tmp);
+		break;
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+void
+nv40_mc_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_connector.c b/drivers/gpu/drm/nouveau/nv50_connector.c
new file mode 100644
index 0000000..8074cb8
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_connector.c
@@ -0,0 +1,498 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_edid.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_reg.h"
+#include "nouveau_drv.h"
+#include "nouveau_encoder.h"
+#include "nouveau_crtc.h"
+#include "nouveau_connector.h"
+#include "nv50_display.h"
+#include "nv50_display_commands.h"
+
+static struct nouveau_encoder *
+nv50_connector_to_encoder(struct nouveau_connector *connector, bool digital)
+{
+	struct drm_device *dev = connector->base.dev;
+	struct nouveau_encoder *encoder;
+	struct drm_mode_object *obj;
+	int i, id;
+
+	for (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {
+		id = connector->base.encoder_ids[i];
+		if (!id)
+			break;
+
+		obj = drm_mode_object_find(dev, id, DRM_MODE_OBJECT_ENCODER);
+		if (!obj)
+			continue;
+		encoder = to_nouveau_encoder(obj_to_encoder(obj));
+
+		if (digital) {
+			switch (encoder->dcb->type) {
+			case OUTPUT_TMDS:
+			case OUTPUT_LVDS:
+				return encoder;
+			default:
+				break;
+			}
+		} else {
+			switch (encoder->dcb->type) {
+			case OUTPUT_ANALOG:
+				return encoder;
+			default:
+				break;
+			}
+		}
+	}
+
+	return NULL;
+}
+
+static void nv50_connector_destroy(struct drm_connector *drm_connector)
+{
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+	struct drm_device *dev = connector->base.dev;
+
+	NV_DEBUG(dev, "\n");
+
+	if (!connector)
+		return;
+
+	nouveau_i2c_del(&connector->i2c_chan);
+
+	drm_sysfs_connector_remove(drm_connector);
+	drm_connector_cleanup(drm_connector);
+	kfree(drm_connector);
+}
+
+static void
+nv50_connector_set_digital(struct nouveau_connector *connector, bool digital)
+{
+	struct drm_device *dev = connector->base.dev;
+
+	if (connector->base.connector_type == DRM_MODE_CONNECTOR_DVII) {
+		struct drm_property *prop =
+			dev->mode_config.dvi_i_subconnector_property;
+		uint64_t val;
+
+		if (digital)
+			val = DRM_MODE_SUBCONNECTOR_DVID;
+		else
+			val = DRM_MODE_SUBCONNECTOR_DVIA;
+
+		drm_connector_property_set_value(&connector->base, prop, val);
+	}
+
+	connector->digital = digital;
+}
+
+void nv50_connector_detect_all(struct drm_device *dev)
+{
+	struct drm_connector *drm_connector = NULL;
+
+	list_for_each_entry(drm_connector, &dev->mode_config.connector_list, head) {
+		drm_connector->funcs->detect(drm_connector);
+	}
+}
+
+static enum drm_connector_status
+nv50_connector_detect(struct drm_connector *drm_connector)
+{
+	struct drm_device *dev = drm_connector->dev;
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+	struct nouveau_encoder *encoder = NULL;
+	struct drm_encoder_helper_funcs *helper = NULL;
+
+	if (drm_connector->connector_type == DRM_MODE_CONNECTOR_LVDS) {
+		if (!connector->native_mode && !nouveau_i2c_detect(connector)) {
+			NV_ERROR(dev, "No native mode for LVDS.\n");
+			return connector_status_disconnected;
+		}
+
+		nv50_connector_set_digital(connector, true);
+		return connector_status_connected;
+	}
+
+	encoder = connector->to_encoder(connector, false);
+	if (encoder)
+		helper = encoder->base.helper_private;
+
+	if (helper && helper->detect(&encoder->base, &connector->base) ==
+			connector_status_connected) {
+		nv50_connector_set_digital(connector, false);
+		return connector_status_connected;
+	}
+
+	if (nouveau_i2c_detect(connector)) {
+		nv50_connector_set_digital(connector, true);
+		return connector_status_connected;
+	}
+
+	return connector_status_disconnected;
+}
+
+static int nv50_connector_set_property(struct drm_connector *drm_connector,
+				       struct drm_property *property,
+				       uint64_t value)
+{
+	struct drm_device *dev = drm_connector->dev;
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+	int rval;
+
+	/* DPMS */
+	if (property == dev->mode_config.dpms_property) {
+		if (value > 3)
+			return -EINVAL;
+
+		drm_helper_set_connector_dpms(drm_connector, value);
+	}
+
+	/* Scaling mode */
+	if (property == dev->mode_config.scaling_mode_property) {
+		struct nouveau_crtc *crtc = NULL;
+		bool modeset = false;
+
+		switch (value) {
+		case DRM_MODE_SCALE_NON_GPU:
+		case DRM_MODE_SCALE_FULLSCREEN:
+		case DRM_MODE_SCALE_NO_SCALE:
+		case DRM_MODE_SCALE_ASPECT:
+			break;
+		default:
+			return -EINVAL;
+		}
+
+		/* LVDS always needs gpu scaling */
+		if (connector->base.connector_type == DRM_MODE_CONNECTOR_LVDS &&
+		    value == DRM_MODE_SCALE_NON_GPU)
+			return -EINVAL;
+
+		/* Changing between GPU and panel scaling requires a full
+		 * modeset
+		 */
+		if ((connector->scaling_mode == DRM_MODE_SCALE_NON_GPU) ||
+		    (value == DRM_MODE_SCALE_NON_GPU))
+			modeset = true;
+		connector->scaling_mode = value;
+
+		if (drm_connector->encoder && drm_connector->encoder->crtc)
+			crtc = to_nouveau_crtc(drm_connector->encoder->crtc);
+
+		if (!crtc)
+			return 0;
+
+		if (modeset) {
+			rval = drm_crtc_helper_set_mode(&crtc->base,
+							&crtc->base.mode,
+							crtc->base.x,
+							crtc->base.y, NULL);
+			if (rval)
+				return rval;
+		} else {
+			rval = crtc->set_scale(crtc, value, true);
+			if (rval)
+				return rval;
+		}
+
+		return 0;
+	}
+
+	/* Dithering */
+	if (property == dev->mode_config.dithering_mode_property) {
+		struct nouveau_crtc *crtc = NULL;
+
+		if (value == DRM_MODE_DITHERING_ON)
+			connector->use_dithering = true;
+		else
+			connector->use_dithering = false;
+
+		if (drm_connector->encoder && drm_connector->encoder->crtc)
+			crtc = to_nouveau_crtc(drm_connector->encoder->crtc);
+
+		if (!crtc)
+			return 0;
+
+		/* update hw state */
+		crtc->use_dithering = connector->use_dithering;
+		rval = crtc->set_dither(crtc, true);
+		if (rval)
+			return rval;
+
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static struct drm_display_mode *
+nv50_connector_native_mode(struct nouveau_connector *connector)
+{
+	struct drm_device *dev = connector->base.dev;
+	struct drm_display_mode *mode;
+
+	if (!connector->digital)
+		return NULL;
+
+	list_for_each_entry(mode, &connector->base.probed_modes, head) {
+		if (mode->type & DRM_MODE_TYPE_PREFERRED)
+			return drm_mode_duplicate(dev, mode);
+	}
+
+	return NULL;
+}
+
+static int nv50_connector_get_modes(struct drm_connector *drm_connector)
+{
+	struct drm_device *dev = drm_connector->dev;
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+	struct edid *edid = NULL;
+	int ret = 0;
+
+	/* If we're not LVDS, destroy the previous native mode, the attached
+	 * monitor could have changed.
+	 */
+	if (drm_connector->connector_type != DRM_MODE_CONNECTOR_LVDS &&
+	    connector->native_mode) {
+		drm_mode_destroy(dev, connector->native_mode);
+		connector->native_mode = NULL;
+	}
+
+	if (connector->i2c_chan)
+		edid = drm_get_edid(drm_connector, &connector->i2c_chan->adapter);
+	drm_mode_connector_update_edid_property(drm_connector, edid);
+
+	if (edid) {
+		ret = drm_add_edid_modes(drm_connector, edid);
+		kfree(edid);
+	}
+
+	/* Find the native mode if this is a digital panel, if we didn't
+	 * find any modes through DDC previously add the native mode to
+	 * the list of modes.
+	 */
+	if (!connector->native_mode)
+		connector->native_mode = nv50_connector_native_mode(connector);
+	if (ret == 0 && connector->native_mode) {
+		struct drm_display_mode *mode;
+
+		mode = drm_mode_duplicate(dev, connector->native_mode);
+		drm_mode_probed_add(drm_connector, mode);
+		ret = 1;
+	}
+
+	return ret;
+}
+
+static int nv50_connector_mode_valid(struct drm_connector *drm_connector,
+				     struct drm_display_mode *mode)
+{
+	struct drm_device *dev = drm_connector->dev;
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+	struct nouveau_encoder *encoder =
+		connector->to_encoder(connector, connector->digital);
+	unsigned min_clock, max_clock;
+
+	/* This really should not happen, but it appears it might do
+	 * somehow, debug!
+	 */
+	if (!encoder) {
+		int i;
+
+		NV_ERROR(dev, "no encoder for connector: %s %d\n",
+			 drm_get_connector_name(drm_connector),
+			 connector->digital);
+		for (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {
+			struct drm_mode_object *obj;
+			if (!drm_connector->encoder_ids[i])
+				break;
+
+			obj = drm_mode_object_find(dev, drm_connector->encoder_ids[i], DRM_MODE_OBJECT_ENCODER);
+			if (!obj)
+				continue;
+			encoder = to_nouveau_encoder(obj_to_encoder(obj));
+			NV_ERROR(dev, " %d: %d\n", i, encoder->dcb->type);
+		}
+
+		return MODE_BAD;
+	}
+
+	min_clock = 25000;
+
+	switch (encoder->base.encoder_type) {
+	case DRM_MODE_ENCODER_LVDS:
+		if (!connector->native_mode) {
+			NV_ERROR(dev, "AIIII no native mode\n");
+			return MODE_PANEL;
+		}
+
+		if (mode->hdisplay > connector->native_mode->hdisplay ||
+		    mode->vdisplay > connector->native_mode->vdisplay)
+			return MODE_PANEL;
+
+		max_clock = 400000;
+		break;
+	case DRM_MODE_ENCODER_TMDS:
+		if (!encoder->dual_link)
+			max_clock = 165000;
+		else
+			max_clock = 330000;
+		break;
+	default:
+		max_clock = 400000;
+		break;
+	}
+
+	if (mode->clock < min_clock)
+		return MODE_CLOCK_LOW;
+
+	if (mode->clock > max_clock)
+		return MODE_CLOCK_HIGH;
+
+	return MODE_OK;
+}
+
+static struct drm_encoder *
+nv50_connector_best_encoder(struct drm_connector *drm_connector)
+{
+	struct nouveau_connector *connector = to_nouveau_connector(drm_connector);
+
+	return &connector->to_encoder(connector, connector->digital)->base;
+}
+
+static const struct drm_connector_helper_funcs nv50_connector_helper_funcs = {
+	.get_modes = nv50_connector_get_modes,
+	.mode_valid = nv50_connector_mode_valid,
+	.best_encoder = nv50_connector_best_encoder,
+};
+
+static const struct drm_connector_funcs nv50_connector_funcs = {
+	.save = NULL,
+	.restore = NULL,
+	.detect = nv50_connector_detect,
+	.destroy = nv50_connector_destroy,
+	.fill_modes = drm_helper_probe_single_connector_modes,
+	.set_property = nv50_connector_set_property
+};
+
+int nv50_connector_create(struct drm_device *dev, int i2c_index, int type)
+{
+	struct nouveau_connector *connector = NULL;
+	struct drm_encoder *drm_encoder;
+	struct drm_display_mode native;
+
+	NV_DEBUG(dev, "\n");
+
+	connector = kzalloc(sizeof(*connector), GFP_KERNEL);
+	if (!connector)
+		return -ENOMEM;
+
+	switch (type) {
+	case DRM_MODE_CONNECTOR_VGA:
+		NV_INFO(dev, "Detected a VGA connector\n");
+		break;
+	case DRM_MODE_CONNECTOR_DVID:
+		NV_INFO(dev, "Detected a DVI-D connector\n");
+		break;
+	case DRM_MODE_CONNECTOR_DVII:
+		NV_INFO(dev, "Detected a DVI-I connector\n");
+		break;
+	case DRM_MODE_CONNECTOR_LVDS:
+		NV_INFO(dev, "Detected a LVDS connector\n");
+
+		if (nouveau_bios_fp_mode(dev, &native))
+			connector->native_mode = drm_mode_duplicate(dev, &native);
+		break;
+	case DRM_MODE_CONNECTOR_SVIDEO:
+		NV_INFO(dev, "Detected a TV connector\n");
+		break;
+	default:
+		NV_ERROR(dev, "Unknown connector, this is not good.\n");
+		break;
+	}
+
+	/* some reasonable defaults */
+	switch (type) {
+	case DRM_MODE_CONNECTOR_DVII:
+	case DRM_MODE_CONNECTOR_DVID:
+	case DRM_MODE_CONNECTOR_LVDS:
+		connector->scaling_mode = DRM_MODE_SCALE_FULLSCREEN;
+		break;
+	default:
+		connector->scaling_mode = DRM_MODE_SCALE_NON_GPU;
+		break;
+	}
+
+	if (type == DRM_MODE_CONNECTOR_LVDS)
+		connector->use_dithering = true;
+	else
+		connector->use_dithering = false;
+
+	if (i2c_index < 0xf)
+		nouveau_i2c_new(dev, "conn", i2c_index, &connector->i2c_chan);
+
+	/* set function pointers */
+	connector->to_encoder = nv50_connector_to_encoder;
+
+	/* It should be allowed sometimes, but let's be safe for the moment. */
+	connector->base.interlace_allowed = false;
+	connector->base.doublescan_allowed = false;
+
+	drm_connector_init(dev, &connector->base, &nv50_connector_funcs, type);
+	drm_connector_helper_add(&connector->base, &nv50_connector_helper_funcs);
+
+	/* Init DVI-I specific properties */
+	if (type == DRM_MODE_CONNECTOR_DVII) {
+		drm_mode_create_dvi_i_properties(dev);
+		drm_connector_attach_property(&connector->base, dev->mode_config.dvi_i_subconnector_property, 0);
+		drm_connector_attach_property(&connector->base, dev->mode_config.dvi_i_select_subconnector_property, 0);
+	}
+
+	/* If supported in the future, it will have to use the scalers
+	 * internally and not expose them.
+	 */
+	if (type != DRM_MODE_CONNECTOR_SVIDEO) {
+		drm_connector_attach_property(&connector->base, dev->mode_config.scaling_mode_property, connector->scaling_mode);
+	}
+
+	drm_connector_attach_property(&connector->base, dev->mode_config.dithering_mode_property, connector->use_dithering ? DRM_MODE_DITHERING_ON : DRM_MODE_DITHERING_OFF);
+
+	/* attach encoders */
+	list_for_each_entry(drm_encoder, &dev->mode_config.encoder_list, head) {
+		struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+
+		if (encoder->dcb->i2c_index != i2c_index)
+			continue;
+
+		drm_mode_connector_attach_encoder(&connector->base, drm_encoder);
+	}
+
+	drm_sysfs_connector_add(&connector->base);
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_crtc.c b/drivers/gpu/drm/nouveau/nv50_crtc.c
new file mode 100644
index 0000000..8790d4c
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_crtc.c
@@ -0,0 +1,807 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_mode.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_reg.h"
+#include "nouveau_drv.h"
+#include "nouveau_encoder.h"
+#include "nouveau_crtc.h"
+#include "nouveau_fb.h"
+#include "nouveau_fbcon.h"
+#include "nouveau_connector.h"
+#include "nv50_display.h"
+
+#define NV50_LUT_INDEX(val, w) ((val << (8 - w)) | (val >> ((w << 1) - 8)))
+static int
+nv50_crtc_lut_load(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+	uint32_t index = 0, i;
+	void __iomem *lut = crtc->lut.mem->kmap.virtual;
+
+	NV_DEBUG(dev, "\n");
+
+	/* 16 bits, red, green, blue, unused, total of 64 bits per index */
+	/* 10 bits lut, with 14 bits values. */
+	switch (crtc->lut.depth) {
+	case 15:
+		/* R5G5B5 */
+		for (i = 0; i < 32; i++) {
+			index = NV50_LUT_INDEX(i, 5);
+			writew(crtc->lut.r[i] >> 2, lut + 8*index + 0);
+			writew(crtc->lut.g[i] >> 2, lut + 8*index + 2);
+			writew(crtc->lut.b[i] >> 2, lut + 8*index + 4);
+		}
+		break;
+	case 16:
+		/* R5G6B5 */
+		for (i = 0; i < 32; i++) {
+			index = NV50_LUT_INDEX(i, 5);
+			writew(crtc->lut.r[i] >> 2, lut + 8*index + 0);
+			writew(crtc->lut.b[i] >> 2, lut + 8*index + 4);
+		}
+
+		/* Green has an extra bit. */
+		for (i = 0; i < 64; i++) {
+			index = NV50_LUT_INDEX(i, 6);
+			writew(crtc->lut.g[i] >> 2, lut + 8*index + 2);
+		}
+		break;
+	default:
+		/* R8G8B8 */
+		for (i = 0; i < 256; i++) {
+			writew(crtc->lut.r[i] >> 2, lut + 8*i + 0);
+			writew(crtc->lut.g[i] >> 2, lut + 8*i + 2);
+			writew(crtc->lut.b[i] >> 2, lut + 8*i + 4);
+		}
+		break;
+	}
+
+	return 0;
+}
+
+int
+nv50_crtc_blank(struct nouveau_crtc *crtc, bool blanked)
+{
+	struct drm_device *dev = crtc->base.dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t offset = crtc->index * 0x400;
+
+	NV_DEBUG(dev, "index %d\n", crtc->index);
+	NV_DEBUG(dev, "%s\n", blanked ? "blanked" : "unblanked");
+
+	if (blanked) {
+		crtc->cursor.hide(crtc, false);
+
+		OUT_MODE(NV50_CRTC0_CLUT_MODE + offset,
+			 NV50_CRTC0_CLUT_MODE_BLANK);
+		OUT_MODE(NV50_CRTC0_CLUT_OFFSET + offset, 0);
+		if (dev_priv->chipset != 0x50)
+			OUT_MODE(NV84_CRTC0_CLUT_DMA + offset,
+				 NV84_CRTC0_CLUT_DMA_DISABLE);
+
+		OUT_MODE(NV50_CRTC0_BLANK_CTRL + offset,
+			 NV50_CRTC0_BLANK_CTRL_BLANK);
+	} else {
+		crtc->cursor.set_offset(crtc, crtc->cursor.offset);
+		if (crtc->cursor.visible)
+			crtc->cursor.show(crtc, false);
+		else
+			crtc->cursor.hide(crtc, false);
+
+		OUT_MODE(NV50_CRTC0_CLUT_MODE + offset, crtc->lut.depth == 8 ?
+			 NV50_CRTC0_CLUT_MODE_OFF : NV50_CRTC0_CLUT_MODE_ON);
+		OUT_MODE(NV50_CRTC0_CLUT_OFFSET + offset,
+			 crtc->lut.mem->start >> 8);
+		if (dev_priv->chipset != 0x50)
+			OUT_MODE(NV84_CRTC0_CLUT_DMA + offset,
+				 NV84_CRTC0_CLUT_DMA_LOCAL);
+
+		OUT_MODE(NV50_CRTC0_FB_OFFSET + offset, crtc->fb.offset >> 8);
+		OUT_MODE(0x864 + offset, 0);
+		OUT_MODE(NV50_CRTC0_BLANK_CTRL + offset,
+			 NV50_CRTC0_BLANK_CTRL_UNBLANK);
+	}
+
+	return 0;
+}
+
+static int nv50_crtc_set_dither(struct nouveau_crtc *crtc, bool update)
+{
+	struct drm_device *dev = crtc->base.dev;
+	uint32_t offset = crtc->index * 0x400;
+
+	NV_DEBUG(dev, "\n");
+
+	OUT_MODE(NV50_CRTC0_DITHERING_CTRL + offset, crtc->use_dithering ?
+		 NV50_CRTC0_DITHERING_CTRL_ON : NV50_CRTC0_DITHERING_CTRL_OFF);
+
+	if (update)
+		OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+	return 0;
+}
+
+static struct nouveau_encoder *
+nouveau_crtc_encoder_get(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+	struct drm_encoder *drm_encoder;
+
+	list_for_each_entry(drm_encoder, &dev->mode_config.encoder_list, head) {
+		if (drm_encoder->crtc == &crtc->base)
+			return to_nouveau_encoder(drm_encoder);
+	}
+
+	return NULL;
+}
+
+static struct nouveau_connector *
+nouveau_crtc_connector_get(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+	struct drm_connector *drm_connector;
+	struct nouveau_encoder *encoder;
+
+	encoder = nouveau_crtc_encoder_get(crtc);
+	if (!encoder)
+		return NULL;
+
+	list_for_each_entry(drm_connector, &dev->mode_config.connector_list, head) {
+		if (drm_connector->encoder == &encoder->base)
+			return to_nouveau_connector(drm_connector);
+	}
+
+	return NULL;
+}
+
+static int
+nv50_crtc_set_scale(struct nouveau_crtc *crtc, int scaling_mode, bool update)
+{
+	struct nouveau_connector *connector = nouveau_crtc_connector_get(crtc);
+	struct drm_device *dev = crtc->base.dev;
+	struct drm_display_mode *native_mode = NULL;
+	struct drm_display_mode *mode = &crtc->base.mode;
+	uint32_t offset = crtc->index * 0x400;
+	uint32_t outX, outY, horiz, vert;
+
+	NV_DEBUG(dev, "\n");
+
+	if (!connector->digital)
+		scaling_mode = DRM_MODE_SCALE_NON_GPU;
+
+	switch (scaling_mode) {
+	case DRM_MODE_SCALE_NO_SCALE:
+	case DRM_MODE_SCALE_NON_GPU:
+		break;
+	default:
+		if (!connector || !connector->native_mode) {
+			NV_ERROR(dev, "No native mode, forcing panel scaling\n");
+			scaling_mode = DRM_MODE_SCALE_NON_GPU;
+		} else {
+			native_mode = connector->native_mode;
+		}
+		break;
+	}
+
+	switch (scaling_mode) {
+	case DRM_MODE_SCALE_ASPECT:
+		horiz = (native_mode->hdisplay << 19) / mode->hdisplay;
+		vert = (native_mode->vdisplay << 19) / mode->vdisplay;
+
+		if (vert > horiz) {
+			outX = (mode->hdisplay * horiz) >> 19;
+			outY = (mode->vdisplay * horiz) >> 19;
+		} else {
+			outX = (mode->hdisplay * vert) >> 19;
+			outY = (mode->vdisplay * vert) >> 19;
+		}
+		break;
+	case DRM_MODE_SCALE_FULLSCREEN:
+		outX = native_mode->hdisplay;
+		outY = native_mode->vdisplay;
+		break;
+	case DRM_MODE_SCALE_NO_SCALE:
+	case DRM_MODE_SCALE_NON_GPU:
+	default:
+		outX = mode->hdisplay;
+		outY = mode->vdisplay;
+		break;
+	}
+
+	/* Got a better name for SCALER_ACTIVE? */
+	/* One day i've got to really figure out why this is needed. */
+	if ((mode->flags & DRM_MODE_FLAG_DBLSCAN) ||
+	    (mode->flags & DRM_MODE_FLAG_INTERLACE) ||
+	    mode->hdisplay != outX || mode->vdisplay != outY) {
+		OUT_MODE(NV50_CRTC0_SCALE_CTRL + offset,
+			 NV50_CRTC0_SCALE_CTRL_SCALER_ACTIVE);
+	} else {
+		OUT_MODE(NV50_CRTC0_SCALE_CTRL + offset,
+			 NV50_CRTC0_SCALE_CTRL_SCALER_INACTIVE);
+	}
+
+	OUT_MODE(NV50_CRTC0_SCALE_RES1 + offset, outY << 16 | outX);
+	OUT_MODE(NV50_CRTC0_SCALE_RES2 + offset, outY << 16 | outX);
+
+	if (update)
+		OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+
+	return 0;
+}
+
+static int
+nv50_crtc_calc_clock(struct nouveau_crtc *crtc, struct drm_display_mode *mode,
+		     uint32_t *bestN1, uint32_t *bestN2, uint32_t *bestM1,
+		     uint32_t *bestM2, uint32_t *bestlog2P)
+{
+	struct drm_device *dev = crtc->base.dev;
+	struct pll_lims limits;
+	int clk = mode->clock, vco2, crystal;
+	int minvco1, minvco2, minU1, maxU1, minU2, maxU2, minM1, maxM1;
+	int maxvco1, maxvco2, minN1, maxN1, minM2, maxM2, minN2, maxN2;
+	bool fixedgain2;
+	int M1, N1, M2, N2, log2P;
+	int clkP, calcclk1, calcclk2, calcclkout;
+	int delta, bestdelta = INT_MAX;
+	int bestclk = 0;
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	/* These are in the g80 bios tables, at least in mine. */
+	ret = get_pll_limits(crtc->base.dev,
+			     NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1(crtc->index),
+			     &limits);
+	if (ret)
+		return ret;
+
+	minvco1 = limits.vco1.minfreq, maxvco1 = limits.vco1.maxfreq;
+	minvco2 = limits.vco2.minfreq, maxvco2 = limits.vco2.maxfreq;
+	minU1 = limits.vco1.min_inputfreq, minU2 = limits.vco2.min_inputfreq;
+	maxU1 = limits.vco1.max_inputfreq, maxU2 = limits.vco2.max_inputfreq;
+	minM1 = limits.vco1.min_m, maxM1 = limits.vco1.max_m;
+	minN1 = limits.vco1.min_n, maxN1 = limits.vco1.max_n;
+	minM2 = limits.vco2.min_m, maxM2 = limits.vco2.max_m;
+	minN2 = limits.vco2.min_n, maxN2 = limits.vco2.max_n;
+	crystal = limits.refclk;
+	fixedgain2 = (minM2 == maxM2 && minN2 == maxN2);
+
+	vco2 = (maxvco2 - maxvco2/200) / 2;
+	/* log2P is maximum of 6 */
+	for (log2P = 0; clk && log2P < 6 && clk <= (vco2 >> log2P); log2P++);
+	clkP = clk << log2P;
+
+	if (maxvco2 < clk + clk/200)	/* +0.5% */
+		maxvco2 = clk + clk/200;
+
+	for (M1 = minM1; M1 <= maxM1; M1++) {
+		if (crystal/M1 < minU1)
+			return bestclk;
+		if (crystal/M1 > maxU1)
+			continue;
+
+		for (N1 = minN1; N1 <= maxN1; N1++) {
+			calcclk1 = crystal * N1 / M1;
+			if (calcclk1 < minvco1)
+				continue;
+			if (calcclk1 > maxvco1)
+				break;
+
+			for (M2 = minM2; M2 <= maxM2; M2++) {
+				if (calcclk1/M2 < minU2)
+					break;
+				if (calcclk1/M2 > maxU2)
+					continue;
+
+				/* add calcclk1/2 to round better */
+				N2 = (clkP * M2 + calcclk1/2) / calcclk1;
+				if (N2 < minN2)
+					continue;
+				if (N2 > maxN2)
+					break;
+
+				if (!fixedgain2) {
+					calcclk2 = calcclk1 * N2 / M2;
+					if (calcclk2 < minvco2)
+						break;
+					if (calcclk2 > maxvco2)
+						continue;
+				} else
+					calcclk2 = calcclk1;
+
+				calcclkout = calcclk2 >> log2P;
+				delta = abs(calcclkout - clk);
+				/* we do an exhaustive search rather than
+				 * terminating on an optimality condition...
+				 */
+				if (delta < bestdelta) {
+					bestdelta = delta;
+					bestclk = calcclkout;
+					*bestN1 = N1;
+					*bestN2 = N2;
+					*bestM1 = M1;
+					*bestM2 = M2;
+					*bestlog2P = log2P;
+					if (delta == 0)	/* except this one */
+						return bestclk;
+				}
+			}
+		}
+	}
+
+	return bestclk;
+}
+
+static int
+nv50_crtc_set_clock(struct nouveau_crtc *crtc, struct drm_display_mode *mode)
+{
+	struct drm_device *dev = crtc->base.dev;
+	uint32_t pll_reg = NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1(crtc->index);
+	uint32_t N1 = 0, N2 = 0, M1 = 0, M2 = 0, log2P = 0;
+	uint32_t reg1 = nv_rd32(pll_reg + 4);
+	uint32_t reg2 = nv_rd32(pll_reg + 8);
+
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(pll_reg, NV50_PDISPLAY_CRTC_CLK_CLK_CTRL1_CONNECTED | 0x10000011);
+
+	/* The other bits are typically empty, but let's be on the safe side. */
+	reg1 &= 0xff00ff00;
+	reg2 &= 0x8000ff00;
+
+	if (!nv50_crtc_calc_clock(crtc, mode, &N1, &N2, &M1, &M2, &log2P))
+		return -EINVAL;
+
+	NV_DEBUG(dev, "N1 %d N2 %d M1 %d M2 %d log2P %d\n", N1, N2, M1, M2, log2P);
+
+	reg1 |= (M1 << 16) | N1;
+	reg2 |= (log2P << 28) | (M2 << 16) | N2;
+
+	nv_wr32(pll_reg + 4, reg1);
+	nv_wr32(pll_reg + 8, reg2);
+
+	return 0;
+}
+
+static int nv50_crtc_set_clock_mode(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+
+	NV_DEBUG(dev, "\n");
+
+	/* This acknowledges a clock request. */
+	nv_wr32(NV50_PDISPLAY_CRTC_CLK_CLK_CTRL2(crtc->index), 0);
+
+	return 0;
+}
+
+static void nv50_crtc_destroy(struct drm_crtc *drm_crtc)
+{
+	struct drm_device *dev = drm_crtc->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+	NV_DEBUG(dev, "\n");
+
+	if (!crtc)
+		return;
+
+	drm_crtc_cleanup(&crtc->base);
+
+	nv50_cursor_fini(crtc);
+
+	if (crtc->lut.mem)
+		nouveau_mem_free(dev, crtc->lut.mem);
+	kfree(crtc->mode);
+	kfree(crtc);
+}
+
+static int nv50_crtc_cursor_set(struct drm_crtc *drm_crtc,
+				struct drm_file *file_priv,
+				uint32_t buffer_handle,
+				uint32_t width, uint32_t height)
+{
+	struct drm_device *dev = drm_crtc->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+	struct drm_gem_object *gem = NULL;
+	int ret = 0;
+
+	if (width != 64 || height != 64)
+		return -EINVAL;
+
+	if (crtc->cursor.gem) {
+		nouveau_gem_unpin(crtc->cursor.gem);
+
+		mutex_lock(&dev->struct_mutex);
+		drm_gem_object_unreference(crtc->cursor.gem);
+		mutex_unlock(&dev->struct_mutex);
+		crtc->cursor.gem = NULL;
+	}
+
+	if (buffer_handle) {
+		struct drm_nouveau_private *dev_priv = dev->dev_private;
+		struct nouveau_gem_object *ngem;
+
+		gem = drm_gem_object_lookup(dev, file_priv, buffer_handle);
+		if (!gem)
+			return -EINVAL;
+		ngem = gem->driver_private;
+
+		ret = nouveau_gem_pin(gem, NOUVEAU_GEM_DOMAIN_VRAM);
+		if (ret) {
+			mutex_lock(&dev->struct_mutex);
+			drm_gem_object_unreference(gem);
+			mutex_unlock(&dev->struct_mutex);
+			return ret;
+		}
+
+		crtc->cursor.offset = ngem->bo->offset -
+				      dev_priv->vm_vram_base;
+		crtc->cursor.set_offset(crtc, crtc->cursor.offset);
+		crtc->cursor.show(crtc, true);
+		crtc->cursor.gem = gem;
+	} else {
+		crtc->cursor.hide(crtc, true);
+	}
+
+	return ret;
+}
+
+static int
+nv50_crtc_cursor_move(struct drm_crtc *drm_crtc, int x, int y)
+{
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+	crtc->cursor.set_pos(crtc, x, y);
+	return 0;
+}
+
+void
+nv50_crtc_gamma_set(struct drm_crtc *drm_crtc, u16 *r, u16 *g, u16 *b,
+		    uint32_t size)
+{
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+	int i;
+
+	if (size != 256)
+		return;
+
+	for (i = 0; i < 256; i++) {
+		crtc->lut.r[i] = r[i];
+		crtc->lut.g[i] = g[i];
+		crtc->lut.b[i] = b[i];
+	}
+
+	/* We need to know the depth before we upload, but it's possible to
+	 * get called before a framebuffer is bound.  If this is the case,
+	 * mark the lut values as dirty by setting depth==0, and it'll be
+	 * uploaded on the first mode_set_base()
+	 */
+	if (!crtc->base.fb) {
+		crtc->lut.depth = 0;
+		return;
+	}
+
+	nv50_crtc_lut_load(crtc);
+}
+
+static int
+nv50_crtc_helper_set_config(struct drm_mode_set *set)
+{
+	struct drm_nouveau_private *dev_priv = set->crtc->dev->dev_private;
+	int ret;
+
+	dev_priv->in_modeset = true;
+	ret = drm_crtc_helper_set_config(set);
+	dev_priv->in_modeset = false;
+	return ret;
+}
+
+static const struct drm_crtc_funcs nv50_crtc_funcs = {
+	.save = NULL,
+	.restore = NULL,
+	.cursor_set = nv50_crtc_cursor_set,
+	.cursor_move = nv50_crtc_cursor_move,
+	.gamma_set = nv50_crtc_gamma_set,
+	.set_config = nv50_crtc_helper_set_config,
+	.destroy = nv50_crtc_destroy,
+};
+
+static void nv50_crtc_dpms(struct drm_crtc *drm_crtc, int mode)
+{
+	struct drm_nouveau_private *dev_priv = drm_crtc->dev->dev_private;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+	if (dev_priv->in_modeset)
+		nv50_crtc_blank(crtc, true);
+}
+
+static void nv50_crtc_prepare(struct drm_crtc *drm_crtc)
+{
+}
+
+static void nv50_crtc_commit(struct drm_crtc *drm_crtc)
+{
+	struct drm_device *dev = drm_crtc->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+	nv50_crtc_blank(crtc, false);
+
+	OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+}
+
+static bool nv50_crtc_mode_fixup(struct drm_crtc *drm_crtc,
+				 struct drm_display_mode *mode,
+				 struct drm_display_mode *adjusted_mode)
+{
+	return true;
+}
+
+static int
+nv50_crtc_do_mode_set_base(struct drm_crtc *drm_crtc, int x, int y,
+			   struct drm_framebuffer *old_fb, bool update)
+{
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+	struct drm_device *dev = crtc->base.dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct drm_framebuffer *drm_fb = crtc->base.fb;
+	struct nouveau_framebuffer *fb = to_nouveau_framebuffer(drm_fb);
+	struct nouveau_gem_object *ngem = nouveau_gem_object(fb->gem);
+	uint32_t offset = crtc->index * 0x400;
+	int ret;
+
+	ret = nouveau_gem_pin(fb->gem, NOUVEAU_GEM_DOMAIN_VRAM);
+	if (ret)
+		return ret;
+
+	if (old_fb) {
+		struct nouveau_framebuffer *fb = to_nouveau_framebuffer(old_fb);
+		nouveau_gem_unpin(fb->gem);
+	}
+
+	crtc->fb.offset = ngem->bo->offset - dev_priv->vm_vram_base;
+
+	OUT_MODE(NV50_CRTC0_FB_OFFSET + offset, crtc->fb.offset >> 8);
+	OUT_MODE(0x864 + offset, 0);
+
+	OUT_MODE(NV50_CRTC0_FB_SIZE + offset,
+		 drm_fb->height << 16 | drm_fb->width);
+
+	/* I suspect this flag indicates a linear fb. */
+	OUT_MODE(NV50_CRTC0_FB_PITCH + offset, drm_fb->pitch | 0x100000);
+
+	switch (drm_fb->depth) {
+	case 8:
+		OUT_MODE(NV50_CRTC0_DEPTH + offset, NV50_CRTC0_DEPTH_8BPP); 
+		break;
+	case 15:
+		OUT_MODE(NV50_CRTC0_DEPTH + offset, NV50_CRTC0_DEPTH_15BPP);
+		break;
+	case 16:
+		OUT_MODE(NV50_CRTC0_DEPTH + offset, NV50_CRTC0_DEPTH_16BPP);
+		break;
+	case 24:
+		OUT_MODE(NV50_CRTC0_DEPTH + offset, NV50_CRTC0_DEPTH_24BPP); 
+		break;
+	}
+
+	OUT_MODE(NV50_CRTC0_COLOR_CTRL + offset,
+		 NV50_CRTC_COLOR_CTRL_MODE_COLOR);
+	OUT_MODE(NV50_CRTC0_FB_POS + offset, (y << 16) | x);
+
+	if (crtc->lut.depth != fb->base.depth) {
+		crtc->lut.depth = fb->base.depth;
+		nv50_crtc_lut_load(crtc);
+	}
+
+	if (update)
+		OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+
+	return 0;
+}
+
+static int
+nv50_crtc_mode_set(struct drm_crtc *drm_crtc, struct drm_display_mode *mode,
+		   struct drm_display_mode *adjusted_mode, int x, int y,
+		   struct drm_framebuffer *old_fb)
+{
+	struct drm_device *dev = drm_crtc->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+	struct drm_encoder *drm_encoder;
+	struct nouveau_encoder *encoder;
+	struct nouveau_connector *connector = NULL;
+	uint32_t hsync_dur,  vsync_dur, hsync_start_to_end, vsync_start_to_end;
+	uint32_t hunk1, vunk1, vunk2a, vunk2b;
+	uint32_t offset = crtc->index * 0x400;
+
+	/* Find the connector attached to this CRTC */
+	list_for_each_entry(drm_encoder, &dev->mode_config.encoder_list, head) {
+		struct drm_connector *drm_connector;
+
+		encoder = to_nouveau_encoder(drm_encoder);
+		if (drm_encoder->crtc != &crtc->base)
+			continue;
+
+		list_for_each_entry(drm_connector, &dev->mode_config.connector_list, head) {
+			connector = to_nouveau_connector(drm_connector);
+			if (drm_connector->encoder != drm_encoder)
+				continue;
+
+			break;
+		}
+
+		break; /* no use in finding more than one mode */
+	}
+
+	*crtc->mode = *adjusted_mode;
+	crtc->use_dithering = connector->use_dithering;
+
+	NV_DEBUG(dev, "index %d\n", crtc->index);
+
+	hsync_dur = adjusted_mode->hsync_end - adjusted_mode->hsync_start;
+	vsync_dur = adjusted_mode->vsync_end - adjusted_mode->vsync_start;
+	hsync_start_to_end = adjusted_mode->htotal - adjusted_mode->hsync_start;
+	vsync_start_to_end = adjusted_mode->vtotal - adjusted_mode->vsync_start;
+	/* I can't give this a proper name, anyone else can? */
+	hunk1 = adjusted_mode->htotal -
+		adjusted_mode->hsync_start + adjusted_mode->hdisplay;
+	vunk1 = adjusted_mode->vtotal -
+		adjusted_mode->vsync_start + adjusted_mode->vdisplay;
+	/* Another strange value, this time only for interlaced adjusted_modes. */
+	vunk2a = 2 * adjusted_mode->vtotal -
+		 adjusted_mode->vsync_start + adjusted_mode->vdisplay;
+	vunk2b = adjusted_mode->vtotal -
+		 adjusted_mode->vsync_start + adjusted_mode->vtotal;
+
+	if (adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		vsync_dur /= 2;
+		vsync_start_to_end  /= 2;
+		vunk1 /= 2;
+		vunk2a /= 2;
+		vunk2b /= 2;
+		/* magic */
+		if (adjusted_mode->flags & DRM_MODE_FLAG_DBLSCAN) {
+			vsync_start_to_end -= 1;
+			vunk1 -= 1;
+			vunk2a -= 1;
+			vunk2b -= 1;
+		}
+	}
+
+	OUT_MODE(NV50_CRTC0_CLOCK + offset, adjusted_mode->clock | 0x800000);
+	OUT_MODE(NV50_CRTC0_INTERLACE + offset,
+		 (adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE) ? 2 : 0);
+	OUT_MODE(NV50_CRTC0_DISPLAY_START + offset, 0);
+	OUT_MODE(NV50_CRTC0_UNK82C + offset, 0);
+	OUT_MODE(NV50_CRTC0_DISPLAY_TOTAL + offset,
+		 adjusted_mode->vtotal << 16 | adjusted_mode->htotal);
+	OUT_MODE(NV50_CRTC0_SYNC_DURATION + offset,
+		 (vsync_dur - 1) << 16 | (hsync_dur - 1));
+	OUT_MODE(NV50_CRTC0_SYNC_START_TO_BLANK_END + offset,
+		 (vsync_start_to_end - 1) << 16 | (hsync_start_to_end - 1));
+	OUT_MODE(NV50_CRTC0_MODE_UNK1 + offset,
+		 (vunk1 - 1) << 16 | (hunk1 - 1));
+	if (adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		OUT_MODE(NV50_CRTC0_MODE_UNK2 + offset,
+			 (vunk2b - 1) << 16 | (vunk2a - 1));
+	}
+
+	crtc->set_dither(crtc, false);
+
+	/* This is the actual resolution of the mode. */
+	OUT_MODE(NV50_CRTC0_REAL_RES + offset,
+		 (crtc->base.mode.vdisplay << 16) | crtc->base.mode.hdisplay);
+	OUT_MODE(NV50_CRTC0_SCALE_CENTER_OFFSET + offset,
+		 NV50_CRTC_SCALE_CENTER_OFFSET_VAL(0,0));
+
+	crtc->set_scale(crtc, connector->scaling_mode, false);
+	return nv50_crtc_do_mode_set_base(drm_crtc, x, y, old_fb, false);
+}
+
+static int
+nv50_crtc_mode_set_base(struct drm_crtc *drm_crtc, int x, int y,
+			struct drm_framebuffer *old_fb)
+{
+	return nv50_crtc_do_mode_set_base(drm_crtc, x, y, old_fb, true);
+}
+
+static const struct drm_crtc_helper_funcs nv50_crtc_helper_funcs = {
+	.dpms = nv50_crtc_dpms,
+	.prepare = nv50_crtc_prepare,
+	.commit = nv50_crtc_commit,
+	.mode_fixup = nv50_crtc_mode_fixup,
+	.mode_set = nv50_crtc_mode_set,
+	.mode_set_base = nv50_crtc_mode_set_base,
+};
+
+int nv50_crtc_create(struct drm_device *dev, int index)
+{
+	struct nouveau_crtc *crtc = NULL;
+	int ret, i;
+
+	NV_DEBUG(dev, "\n");
+
+	crtc = kzalloc(sizeof(*crtc) +
+		       NOUVEAUFB_CONN_LIMIT * sizeof(struct drm_connector *),
+		       GFP_KERNEL);
+	if (!crtc)
+		return -ENOMEM;
+
+	crtc->mode = kzalloc(sizeof(*crtc->mode), GFP_KERNEL);
+	if (!crtc->mode) {
+		kfree(crtc);
+		return -ENOMEM;
+	}
+
+	/* Default CLUT parameters, will be activated on the hw upon
+	 * first mode set.
+	 */
+	for (i = 0; i < 256; i++) {
+		crtc->lut.r[i] = i << 8;
+		crtc->lut.g[i] = i << 8;
+		crtc->lut.b[i] = i << 8;
+	}
+	crtc->lut.depth = 0;
+
+	crtc->lut.mem = nouveau_mem_alloc(dev, 0x100, 4096, NOUVEAU_MEM_FB |
+					  NOUVEAU_MEM_NOVM | NOUVEAU_MEM_MAPPED,
+					  (struct drm_file *)-2);
+	if (crtc->lut.mem) {
+		ret = drm_bo_kmap(crtc->lut.mem->bo, 0,
+				  crtc->lut.mem->bo->mem.num_pages,
+				  &crtc->lut.mem->kmap);
+		if (ret) {
+			nouveau_mem_free(dev, crtc->lut.mem);
+			crtc->lut.mem = NULL;
+		}
+	}
+
+	if (!crtc->lut.mem) {
+		kfree(crtc->mode);
+		kfree(crtc);
+		return -ENOMEM;
+	}
+
+	crtc->index = index;
+
+	/* set function pointers */
+	crtc->set_dither = nv50_crtc_set_dither;
+	crtc->set_scale = nv50_crtc_set_scale;
+	crtc->set_clock = nv50_crtc_set_clock;
+	crtc->set_clock_mode = nv50_crtc_set_clock_mode;
+
+	crtc->mode_set.crtc = &crtc->base;
+	crtc->mode_set.connectors = (struct drm_connector **)(crtc + 1);
+	crtc->mode_set.num_connectors = 0;
+
+	drm_crtc_init(dev, &crtc->base, &nv50_crtc_funcs);
+	drm_crtc_helper_add(&crtc->base, &nv50_crtc_helper_funcs);
+	drm_mode_crtc_set_gamma_size(&crtc->base, 256);
+
+	nv50_cursor_init(crtc);
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_cursor.c b/drivers/gpu/drm/nouveau/nv50_cursor.c
new file mode 100644
index 0000000..763cffe
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_cursor.c
@@ -0,0 +1,144 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_mode.h"
+#include "nouveau_reg.h"
+#include "nouveau_drv.h"
+#include "nouveau_crtc.h"
+#include "nv50_display.h"
+
+static void
+nv50_cursor_show(struct nouveau_crtc *crtc, bool update)
+{
+	struct drm_nouveau_private *dev_priv = crtc->base.dev->dev_private;
+	struct drm_device *dev = crtc->base.dev;
+	uint32_t offset = crtc->index * 0x400;
+
+	NV_DEBUG(dev, "\n");
+
+	if (dev_priv->chipset != 0x50)
+		OUT_MODE(NV84_CRTC0_CURSOR_DMA + offset,
+			 NV84_CRTC0_CURSOR_DMA_LOCAL);
+	OUT_MODE(NV50_CRTC0_CURSOR_CTRL + offset, NV50_CRTC0_CURSOR_CTRL_SHOW);
+			 
+	if (update) {
+		OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+		crtc->cursor.visible = true;
+	}
+}
+
+static void
+nv50_cursor_hide(struct nouveau_crtc *crtc, bool update)
+{
+	struct drm_nouveau_private *dev_priv = crtc->base.dev->dev_private;
+	struct drm_device *dev = crtc->base.dev;
+	uint32_t offset = crtc->index * 0x400;
+
+	NV_DEBUG(dev, "\n");
+
+	OUT_MODE(NV50_CRTC0_CURSOR_CTRL + offset, NV50_CRTC0_CURSOR_CTRL_HIDE);
+	if (dev_priv->chipset != 0x50)
+		OUT_MODE(NV84_CRTC0_CURSOR_DMA + offset,
+			 NV84_CRTC0_CURSOR_DMA_DISABLE);
+
+	if (update) {
+		OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+		crtc->cursor.visible = false;
+	}
+}
+
+static void
+nv50_cursor_set_pos(struct nouveau_crtc *crtc, int x, int y)
+{
+	struct drm_device *dev = crtc->base.dev;
+
+	nv_wr32(NV50_HW_CURSOR_POS(crtc->index),
+		((y & 0xFFFF) << 16) | (x & 0xFFFF));
+	/* Needed to make the cursor move. */
+	nv_wr32(NV50_HW_CURSOR_POS_CTRL(crtc->index), 0);
+}
+
+static void
+nv50_cursor_set_offset(struct nouveau_crtc *crtc, uint32_t offset)
+{
+	struct drm_device *dev = crtc->base.dev;
+
+	NV_DEBUG(dev, "\n");
+
+	OUT_MODE(NV50_CRTC0_CURSOR_OFFSET + crtc->index * 0x0400, offset >> 8);
+}
+
+int
+nv50_cursor_init(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+	int idx = crtc->index;
+
+	nv_wr32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx), 0x2000);
+	if (!nv_wait(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx),
+		     NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_MASK, 0)) {
+		NV_ERROR(dev, "timeout: CURSOR_CTRL2_STATUS == 0\n");
+		NV_ERROR(dev, "CURSOR_CTRL2 = 0x%08x\n",
+			 nv_rd32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx)));
+		return -EBUSY;
+	}
+
+	nv_wr32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(crtc->index),
+		NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_ON);
+	if (!nv_wait(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx),
+		     NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_ACTIVE,
+		     NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_ACTIVE)) {
+		NV_ERROR(dev, "timeout: CURSOR_CTRL2_STATUS_ACTIVE(%d)\n", idx);
+		NV_ERROR(dev, "CURSOR_CTRL2(%d) = 0x%08x\n", idx,
+			 nv_rd32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx)));
+		return -EBUSY;
+	}
+
+	crtc->cursor.set_offset = nv50_cursor_set_offset;
+	crtc->cursor.set_pos = nv50_cursor_set_pos;
+	crtc->cursor.hide = nv50_cursor_hide;
+	crtc->cursor.show = nv50_cursor_show;
+	return 0;
+}
+
+void
+nv50_cursor_fini(struct nouveau_crtc *crtc)
+{
+	struct drm_device *dev = crtc->base.dev;
+	int idx = crtc->index;
+
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx), 0);
+	if (!nv_wait(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx),
+		     NV50_PDISPLAY_CURSOR_CURSOR_CTRL2_STATUS_MASK, 0)) {
+		NV_ERROR(dev, "timeout: CURSOR_CTRL2_STATUS == 0\n");
+		NV_ERROR(dev, "CURSOR_CTRL2 = 0x%08x\n",
+			 nv_rd32(NV50_PDISPLAY_CURSOR_CURSOR_CTRL2(idx)));
+	}
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv50_dac.c b/drivers/gpu/drm/nouveau/nv50_dac.c
new file mode 100644
index 0000000..ecd16d2
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_dac.c
@@ -0,0 +1,280 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_reg.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+#include "nouveau_encoder.h"
+#include "nouveau_crtc.h"
+#include "nv50_display.h"
+#include "nv50_display_commands.h"
+
+static void
+nv50_dac_disconnect(struct nouveau_encoder *encoder)
+{
+	struct drm_device *dev = encoder->base.dev;
+	uint32_t offset = encoder->or * 0x80;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	OUT_MODE(NV50_DAC0_MODE_CTRL + offset, NV50_DAC_MODE_CTRL_OFF);
+}
+
+static int
+nv50_dac_set_clock_mode(struct nouveau_encoder *encoder,
+			struct drm_display_mode *mode)
+{
+	struct drm_device *dev = encoder->base.dev;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	nv_wr32(NV50_PDISPLAY_DAC_CLK_CLK_CTRL2(encoder->or),  0);
+	return 0;
+}
+
+static enum drm_connector_status
+nv50_dac_detect(struct drm_encoder *drm_encoder,
+		struct drm_connector *drm_connector)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	struct drm_device *dev = encoder->base.dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	enum drm_connector_status status = connector_status_disconnected;
+	uint32_t dpms_state, load_pattern, load_state;
+	int or = encoder->or;
+
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_CLK_CTRL1(or), 0x00000001);
+	dpms_state = nv_rd32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or));
+
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or),
+		0x00150000 | NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING);
+	if (!nv_wait(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or),
+		     NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING, 0)) {
+		NV_ERROR(dev, "timeout: DAC_DPMS_CTRL_PENDING(%d) == 0\n", or);
+		NV_ERROR(dev, "DAC_DPMS_CTRL(%d) = 0x%08x\n", or,
+			  nv_rd32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or)));
+		return status;
+	}
+
+	/* Use bios provided value if possible. */
+	if (dev_priv->vbios->dactestval) {
+		load_pattern = dev_priv->vbios->dactestval;
+		NV_DEBUG(dev, "Using bios provided load_pattern of %d\n",
+			  load_pattern);
+	} else {
+		load_pattern = 340;
+		NV_DEBUG(dev, "Using default load_pattern of %d\n",
+			 load_pattern);
+	}
+
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_LOAD_CTRL(or),
+		NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_ACTIVE | load_pattern);
+	mdelay(45); /* give it some time to process */
+	load_state = nv_rd32(NV50_PDISPLAY_DAC_REGS_LOAD_CTRL(or));
+
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_LOAD_CTRL(or), 0);
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or), dpms_state);
+
+	if ((load_state & NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_PRESENT) ==
+			  NV50_PDISPLAY_DAC_REGS_LOAD_CTRL_PRESENT)
+		status = connector_status_connected;
+
+	if (status == connector_status_connected)
+		NV_DEBUG(dev, "Load was detected on output with or %d\n", or);
+	else
+		NV_DEBUG(dev, "Load was not detected on output with or %d\n", or);
+
+	return status;
+}
+
+static void nv50_dac_dpms(struct drm_encoder *drm_encoder, int mode)
+{
+	struct drm_device *dev = drm_encoder->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	uint32_t val;
+	int or = encoder->or;
+
+	NV_DEBUG(dev, "or %d\n", or);
+
+	if (dev_priv->in_modeset) {
+		nv50_dac_disconnect(encoder);
+		return;
+	}
+
+	/* wait for it to be done */
+	if (!nv_wait(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or),
+		     NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING, 0)) {
+		NV_ERROR(dev, "timeout: DAC_DPMS_CTRL_PENDING(%d) == 0\n", or);
+		NV_ERROR(dev, "DAC_DPMS_CTRL(%d) = 0x%08x\n", or,
+			  nv_rd32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or)));
+		return;
+	}
+
+	val = nv_rd32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or)) & ~0x7F;
+
+	if (mode != DRM_MODE_DPMS_ON)
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_BLANKED;
+
+	switch (mode) {
+	case DRM_MODE_DPMS_STANDBY:
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_HSYNC_OFF;
+		break;
+	case DRM_MODE_DPMS_SUSPEND:
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_VSYNC_OFF;
+		break;
+	case DRM_MODE_DPMS_OFF:
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_OFF;
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_HSYNC_OFF;
+		val |= NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_VSYNC_OFF;
+		break;
+	default:
+		break;
+	}
+
+	nv_wr32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(or),
+		val | NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING);
+}
+
+static void nv50_dac_save(struct drm_encoder *drm_encoder)
+{
+	NV_ERROR(drm_encoder->dev, "!!\n");
+}
+
+static void nv50_dac_restore(struct drm_encoder *drm_encoder)
+{
+	NV_ERROR(drm_encoder->dev, "!!\n");
+}
+
+static bool nv50_dac_mode_fixup(struct drm_encoder *drm_encoder,
+				struct drm_display_mode *mode,
+				struct drm_display_mode *adjusted_mode)
+{
+	return true;
+}
+
+static void nv50_dac_prepare(struct drm_encoder *drm_encoder)
+{
+}
+
+static void nv50_dac_commit(struct drm_encoder *drm_encoder)
+{
+}
+
+static void nv50_dac_mode_set(struct drm_encoder *drm_encoder,
+			      struct drm_display_mode *mode,
+			      struct drm_display_mode *adjusted_mode)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	struct drm_device *dev = drm_encoder->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_encoder->crtc);
+	uint32_t offset = encoder->or * 0x80;
+	uint32_t mode_ctl = NV50_DAC_MODE_CTRL_OFF;
+	uint32_t mode_ctl2 = 0;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	if (crtc->index == 1)
+		mode_ctl |= NV50_DAC_MODE_CTRL_CRTC1;
+	else
+		mode_ctl |= NV50_DAC_MODE_CTRL_CRTC0;
+
+	/* Lacking a working tv-out, this is not a 100% sure. */
+	if (encoder->base.encoder_type == DRM_MODE_ENCODER_DAC) {
+		mode_ctl |= 0x40;
+	} else
+	if (encoder->base.encoder_type == DRM_MODE_ENCODER_TVDAC) {
+		mode_ctl |= 0x100;
+	}
+
+	if (adjusted_mode->flags & DRM_MODE_FLAG_NHSYNC)
+		mode_ctl2 |= NV50_DAC_MODE_CTRL2_NHSYNC;
+
+	if (adjusted_mode->flags & DRM_MODE_FLAG_NVSYNC)
+		mode_ctl2 |= NV50_DAC_MODE_CTRL2_NVSYNC;
+
+	OUT_MODE(NV50_DAC0_MODE_CTRL + offset, mode_ctl);
+	OUT_MODE(NV50_DAC0_MODE_CTRL2 + offset, mode_ctl2);
+}
+
+static const struct drm_encoder_helper_funcs nv50_dac_helper_funcs = {
+	.dpms = nv50_dac_dpms,
+	.save = nv50_dac_save,
+	.restore = nv50_dac_restore,
+	.mode_fixup = nv50_dac_mode_fixup,
+	.prepare = nv50_dac_prepare,
+	.commit = nv50_dac_commit,
+	.mode_set = nv50_dac_mode_set,
+	.detect = nv50_dac_detect
+};
+
+static void nv50_dac_destroy(struct drm_encoder *drm_encoder)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+
+	NV_DEBUG(drm_encoder->dev, "\n");
+
+	if (!drm_encoder)
+		return;
+
+	drm_encoder_cleanup(&encoder->base);
+
+	kfree(encoder);
+}
+
+static const struct drm_encoder_funcs nv50_dac_encoder_funcs = {
+	.destroy = nv50_dac_destroy,
+};
+
+int nv50_dac_create(struct drm_device *dev, struct dcb_entry *entry)
+{
+	struct nouveau_encoder *encoder = NULL;
+
+	NV_DEBUG(dev, "\n");
+	NV_INFO(dev, "Detected a DAC output\n");
+
+	encoder = kzalloc(sizeof(*encoder), GFP_KERNEL);
+	if (!encoder)
+		return -ENOMEM;
+
+	encoder->dcb = entry;
+	encoder->or = ffs(entry->or) - 1;
+
+	/* Set function pointers. */
+	encoder->set_clock_mode = nv50_dac_set_clock_mode;
+
+	drm_encoder_init(dev, &encoder->base, &nv50_dac_encoder_funcs,
+			 DRM_MODE_ENCODER_DAC);
+	drm_encoder_helper_add(&encoder->base, &nv50_dac_helper_funcs);
+
+	/* I've never seen possible crtc's restricted. */
+	encoder->base.possible_crtcs = 3;
+	encoder->base.possible_clones = 0;
+	return 0;
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv50_display.c b/drivers/gpu/drm/nouveau/nv50_display.c
new file mode 100644
index 0000000..fd253c5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_display.c
@@ -0,0 +1,421 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "nv50_display.h"
+#include "nouveau_crtc.h"
+#include "nouveau_encoder.h"
+#include "nouveau_connector.h"
+#include "nouveau_fb.h"
+#include "drm_crtc_helper.h"
+
+static int nv50_display_pre_init(struct drm_device *dev)
+{
+	uint32_t ram_amount;
+	int i;
+
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(0x00610184, nv_rd32(0x00614004));
+	/*
+	 * I think the 0x006101XX range is some kind of main control area that enables things.
+	 */
+	/* CRTC? */
+	nv_wr32(0x00610190 + 0 * 0x10, nv_rd32(0x00616100 + 0 * 0x800));
+	nv_wr32(0x00610190 + 1 * 0x10, nv_rd32(0x00616100 + 1 * 0x800));
+	nv_wr32(0x00610194 + 0 * 0x10, nv_rd32(0x00616104 + 0 * 0x800));
+	nv_wr32(0x00610194 + 1 * 0x10, nv_rd32(0x00616104 + 1 * 0x800));
+	nv_wr32(0x00610198 + 0 * 0x10, nv_rd32(0x00616108 + 0 * 0x800));
+	nv_wr32(0x00610198 + 1 * 0x10, nv_rd32(0x00616108 + 1 * 0x800));
+	nv_wr32(0x0061019c + 0 * 0x10, nv_rd32(0x0061610c + 0 * 0x800));
+	nv_wr32(0x0061019c + 1 * 0x10, nv_rd32(0x0061610c + 1 * 0x800));
+	/* DAC */
+	nv_wr32(0x006101d0 + 0 * 0x4, nv_rd32(0x0061a000 + 0 * 0x800));
+	nv_wr32(0x006101d0 + 1 * 0x4, nv_rd32(0x0061a000 + 1 * 0x800));
+	nv_wr32(0x006101d0 + 2 * 0x4, nv_rd32(0x0061a000 + 2 * 0x800));
+	/* SOR */
+	nv_wr32(0x006101e0 + 0 * 0x4, nv_rd32(0x0061c000 + 0 * 0x800));
+	nv_wr32(0x006101e0 + 1 * 0x4, nv_rd32(0x0061c000 + 1 * 0x800));
+	nv_wr32(0x006101e0 + 2 * 0x4, nv_rd32(0x0061c000 + 2 * 0x800));
+	/* Something not yet in use, tv-out maybe. */
+	nv_wr32(0x006101f0 + 0 * 0x4, nv_rd32(0x0061e000 + 0 * 0x800));
+	nv_wr32(0x006101f0 + 1 * 0x4, nv_rd32(0x0061e000 + 1 * 0x800));
+	nv_wr32(0x006101f0 + 2 * 0x4, nv_rd32(0x0061e000 + 2 * 0x800));
+
+	for (i = 0; i < 3; i++) {
+		nv_wr32(NV50_PDISPLAY_DAC_REGS_DPMS_CTRL(i), 0x00550000 |
+			NV50_PDISPLAY_DAC_REGS_DPMS_CTRL_PENDING);
+		nv_wr32(NV50_PDISPLAY_DAC_REGS_CLK_CTRL1(i), 0x00000001);
+	}
+
+	/* This used to be in crtc unblank, but seems out of place there. */
+	nv_wr32(NV50_PDISPLAY_UNK_380, 0);
+	/* RAM is clamped to 256 MiB. */
+	ram_amount = nouveau_mem_fb_amount(dev);
+	NV_DEBUG(dev, "ram_amount %d\n", ram_amount);
+	if (ram_amount > 256*1024*1024)
+		ram_amount = 256*1024*1024;
+	nv_wr32(NV50_PDISPLAY_RAM_AMOUNT, ram_amount - 1);
+	nv_wr32(NV50_PDISPLAY_UNK_388, 0x150000);
+	nv_wr32(NV50_PDISPLAY_UNK_38C, 0);
+
+	return 0;
+}
+
+static int
+nv50_display_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_timer_engine *ptimer = &dev_priv->engine.timer;
+	uint64_t start;
+	uint32_t val;
+
+	NV_DEBUG(dev, "\n");
+
+	/* The precise purpose is unknown, i suspect it has something to do
+	 * with text mode.
+	 */
+	if (nv_rd32(NV50_PDISPLAY_SUPERVISOR) & 0x100) {
+		nv_wr32(NV50_PDISPLAY_SUPERVISOR, 0x100);
+		nv_wr32(0x006194e8, nv_rd32(0x006194e8) & ~1);
+		if (!nv_wait(0x006194e8, 2, 0)) {
+			NV_ERROR(dev, "timeout: (0x6194e8 & 2) != 0\n");
+			NV_ERROR(dev, "0x6194e8 = 0x%08x\n", nv_rd32(0x6194e8));
+			return -EBUSY;
+		}
+	}
+
+	/* taken from nv bug #12637, attempts to un-wedge the hw if it's
+	 * stuck in some unspecified state
+	 */
+	start = ptimer->read(dev);
+	nv_wr32(NV50_PDISPLAY_UNK200_CTRL, 0x2b00);
+	while ((val = nv_rd32(NV50_PDISPLAY_UNK200_CTRL)) & 0x1e0000) {
+		if ((val & 0x9f0000) == 0x20000)
+			nv_wr32(NV50_PDISPLAY_UNK200_CTRL, val | 0x800000);
+
+		if ((val & 0x3f0000) == 0x30000)
+			nv_wr32(NV50_PDISPLAY_UNK200_CTRL, val | 0x200000);
+
+		if (ptimer->read(dev) - start > 1000000000ULL) {
+			NV_ERROR(dev, "timeout: (0x610200 & 0x1e0000) != 0\n");
+			NV_ERROR(dev, "0x610200 = 0x%08x\n", val);
+			return -EBUSY;
+		}
+	}
+
+	nv_wr32(NV50_PDISPLAY_CTRL_STATE, NV50_PDISPLAY_CTRL_STATE_ENABLE);
+	nv_wr32(NV50_PDISPLAY_UNK200_CTRL, 0x1000b03);
+	if (!nv_wait(NV50_PDISPLAY_UNK200_CTRL, 0x40000000, 0x40000000)) {
+		NV_ERROR(dev, "timeout: (0x610200 & 0x40000000) == 0x40000000\n");
+		NV_ERROR(dev, "0x610200 = 0x%08x\n",
+			  nv_rd32(NV50_PDISPLAY_UNK200_CTRL));
+		return -EBUSY;
+	}
+
+	/* For the moment this is just a wrapper, which should be replaced with a real fifo at some point. */
+	OUT_MODE(NV50_UNK84, 0);
+	OUT_MODE(NV50_UNK88, 0);
+	OUT_MODE(NV50_CRTC0_BLANK_CTRL, NV50_CRTC0_BLANK_CTRL_BLANK);
+	OUT_MODE(NV50_CRTC0_UNK800, 0);
+	OUT_MODE(NV50_CRTC0_DISPLAY_START, 0);
+	OUT_MODE(NV50_CRTC0_UNK82C, 0);
+
+	/* enable clock change interrupts. */
+//	nv_wr32(NV50_PDISPLAY_SUPERVISOR_INTR, nv_rd32(NV50_PDISPLAY_SUPERVISOR_INTR) | 0x70);
+
+	/* enable hotplug interrupts */
+	nv_wr32(NV50_PCONNECTOR_HOTPLUG_CTRL, 0x7FFF7FFF);
+//	nv_wr32(NV50_PCONNECTOR_HOTPLUG_INTR, 0x7FFF7FFF);
+
+
+	return 0;
+}
+
+static int nv50_display_disable(struct drm_device *dev)
+{
+	struct drm_crtc *drm_crtc;
+	int i;
+
+	NV_DEBUG(dev, "\n");
+
+	list_for_each_entry(drm_crtc, &dev->mode_config.crtc_list, head) {
+		struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+		nv50_crtc_blank(crtc, true);
+	}
+
+	OUT_MODE(NV50_UPDATE_DISPLAY, 0);
+
+	/* Almost like ack'ing a vblank interrupt, maybe in the spirit of cleaning up? */
+	list_for_each_entry(drm_crtc, &dev->mode_config.crtc_list, head) {
+		struct nouveau_crtc *crtc = to_nouveau_crtc(drm_crtc);
+
+		if (crtc->base.enabled) {
+			uint32_t mask;
+
+			if (crtc->index == 1)
+				mask = NV50_PDISPLAY_SUPERVISOR_CRTC1;
+			else
+				mask = NV50_PDISPLAY_SUPERVISOR_CRTC0;
+
+			nv_wr32(NV50_PDISPLAY_SUPERVISOR, mask);
+			if (!nv_wait(NV50_PDISPLAY_SUPERVISOR, mask, mask)) {
+				NV_ERROR(dev, "timeout: (0x610024 & 0x%08x) == "
+					  "0x%08x\n", mask, mask);
+				NV_ERROR(dev, "0x610024 = 0x%08x\n",
+					  nv_rd32(0x610024));
+			}
+		}
+	}
+
+	nv_wr32(NV50_PDISPLAY_UNK200_CTRL, 0);
+	nv_wr32(NV50_PDISPLAY_CTRL_STATE, 0);
+	if (!nv_wait(NV50_PDISPLAY_UNK200_CTRL, 0x1e0000, 0)) {
+		NV_ERROR(dev, "timeout: (0x610200 & 0x1e0000) == 0\n");
+		NV_ERROR(dev, "0x610200 = 0x%08x\n",
+			  nv_rd32(NV50_PDISPLAY_UNK200_CTRL));
+	}
+
+	for (i = 0; i < NV50_PDISPLAY_SOR_REGS__LEN; i++) {
+		if (!nv_wait(NV50_PDISPLAY_SOR_REGS_DPMS_STATE(i),
+			     NV50_PDISPLAY_SOR_REGS_DPMS_STATE_WAIT, 0)) {
+			NV_ERROR(dev, "timeout: SOR_DPMS_STATE_WAIT(%d) == 0\n", i);
+			NV_ERROR(dev, "SOR_DPMS_STATE(%d) = 0x%08x\n", i,
+				  nv_rd32(NV50_PDISPLAY_SOR_REGS_DPMS_STATE(i)));
+		}
+	}
+
+	/* disable clock change interrupts. */
+	nv_wr32(NV50_PDISPLAY_SUPERVISOR_INTR,
+		nv_rd32(NV50_PDISPLAY_SUPERVISOR_INTR) & ~0x70);
+
+	/* disable hotplug interrupts */
+	nv_wr32(NV50_PCONNECTOR_HOTPLUG_INTR, 0);
+
+	return 0;
+}
+
+int nv50_display_create(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct parsed_dcb *dcb = dev_priv->vbios->dcb;
+	uint32_t connector[16] = {};
+	int ret, i;
+
+	NV_DEBUG(dev, "\n");
+
+	/* init basic kernel modesetting */
+	drm_mode_config_init(dev);
+
+	/* Initialise some optional connector properties. */
+	drm_mode_create_scaling_mode_property(dev);
+	drm_mode_create_dithering_property(dev);
+
+	dev->mode_config.min_width = 0;
+	dev->mode_config.min_height = 0;
+
+	dev->mode_config.funcs = (void *)&nouveau_mode_config_funcs;
+
+	dev->mode_config.max_width = 8192;
+	dev->mode_config.max_height = 8192;
+
+	dev->mode_config.fb_base = dev_priv->fb_phys;
+
+	ret = nv50_display_pre_init(dev);
+	if (ret)
+		return ret;
+
+	/* Create CRTC objects */
+	for (i = 0; i < 2; i++)
+		nv50_crtc_create(dev, i);
+
+	/* We setup the encoders from the BIOS table */
+	for (i = 0 ; i < dcb->entries; i++) {
+		struct dcb_entry *entry = &dcb->entry[i];
+
+		switch (entry->type) {
+		case OUTPUT_TMDS:
+		case OUTPUT_LVDS:
+			nv50_sor_create(dev, entry);
+			break;
+		case OUTPUT_ANALOG:
+			nv50_dac_create(dev, entry);
+			break;
+		default:
+			NV_WARN(dev, "DCB encoder %d unknown\n", entry->type);
+			continue;
+		}
+
+		connector[entry->i2c_index] |= (1 << entry->type);
+	}
+
+	/* Look at which encoders are attached to each i2c bus to
+	 * determine which connectors are present.
+	 */
+	for (i = 0 ; i < dcb->entries; i++) {
+		struct dcb_entry *entry = &dcb->entry[i];
+		uint16_t encoders;
+		int type;
+
+		encoders = connector[entry->i2c_index];
+		connector[entry->i2c_index] = 0;
+
+		/* already done? */
+		if (!encoders)
+			continue;
+
+		if (encoders & (1 << OUTPUT_TMDS)) {
+			if (encoders & (1 << OUTPUT_ANALOG))
+				type = DRM_MODE_CONNECTOR_DVII;
+			else
+				type = DRM_MODE_CONNECTOR_DVID;
+		} else
+		if (encoders & (1 << OUTPUT_ANALOG)) {
+			type = DRM_MODE_CONNECTOR_VGA;
+		} else
+		if (encoders & (1 << OUTPUT_LVDS)) {
+			type = DRM_MODE_CONNECTOR_LVDS;
+		} else
+			type = DRM_MODE_CONNECTOR_Unknown;
+
+		if (type == DRM_MODE_CONNECTOR_Unknown)
+			continue;
+
+		nv50_connector_create(dev, entry->i2c_index, type);
+	}
+
+	ret = nv50_display_init(dev);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int nv50_display_destroy(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv50_display_disable(dev);
+
+	drm_mode_config_cleanup(dev);
+
+	return 0;
+}
+
+/* This can be replaced with a real fifo in the future. */
+static void nv50_display_vclk_update(struct drm_device *dev)
+{
+	struct drm_encoder *drm_encoder;
+	struct drm_crtc *drm_crtc;
+	struct nouveau_encoder *encoder = NULL;
+	struct nouveau_crtc *crtc = NULL;
+	int crtc_index;
+	uint32_t unk30 = nv_rd32(NV50_PDISPLAY_UNK30_CTRL);
+
+	for (crtc_index = 0; crtc_index < 2; crtc_index++) {
+		bool clock_change = false;
+		bool clock_ack = false;
+
+		if (crtc_index == 0 && (unk30 & NV50_PDISPLAY_UNK30_CTRL_UPDATE_VCLK0))
+			clock_change = true;
+
+		if (crtc_index == 1 && (unk30 & NV50_PDISPLAY_UNK30_CTRL_UPDATE_VCLK1))
+			clock_change = true;
+
+		if (clock_change)
+			clock_ack = true;
+
+#if 0
+		if (dev_priv->last_crtc == crtc_index)
+#endif
+			clock_ack = true;
+
+		list_for_each_entry(drm_crtc, &dev->mode_config.crtc_list, head) {
+			crtc = to_nouveau_crtc(drm_crtc);
+			if (crtc->index == crtc_index)
+				break;
+		}
+
+		if (clock_change)
+			crtc->set_clock(crtc, crtc->mode);
+
+		NV_DEBUG(dev, "index %d clock_change %d clock_ack %d\n", crtc_index, clock_change, clock_ack);
+
+		if (!clock_ack)
+			continue;
+
+		crtc->set_clock_mode(crtc);
+
+		list_for_each_entry(drm_encoder, &dev->mode_config.encoder_list, head) {
+			encoder = to_nouveau_encoder(drm_encoder);
+
+			if (!drm_encoder->crtc)
+				continue;
+
+			if (drm_encoder->crtc == drm_crtc)
+				encoder->set_clock_mode(encoder, crtc->mode);
+		}
+	}
+}
+
+void nv50_display_command(struct drm_device *dev, uint32_t mthd, uint32_t val)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_timer_engine *ptimer = &dev_priv->engine.timer;
+	uint64_t start;
+
+	NV_DEBUG(dev, "mthd 0x%03X val 0x%08X\n", mthd, val);
+
+	nv_wr32(NV50_PDISPLAY_CTRL_VAL, val);
+	nv_wr32(NV50_PDISPLAY_CTRL_STATE, NV50_PDISPLAY_CTRL_STATE_PENDING |
+					   NV50_PDISPLAY_CTRL_STATE_ENABLE |
+					   0x10000 | mthd);
+
+	start = ptimer->read(dev);
+	while (nv_rd32(NV50_PDISPLAY_CTRL_STATE) & NV50_PDISPLAY_CTRL_STATE_PENDING) {
+		const uint32_t super = nv_rd32(NV50_PDISPLAY_SUPERVISOR);
+		uint32_t state;
+
+		state   = (super & NV50_PDISPLAY_SUPERVISOR_CLK_MASK);
+		state >>= NV50_PDISPLAY_SUPERVISOR_CLK_MASK__SHIFT;
+		if (state) {
+			if (state == 2)
+				nv50_display_vclk_update(dev);
+
+			nv_wr32(NV50_PDISPLAY_SUPERVISOR,
+				(super & NV50_PDISPLAY_SUPERVISOR_CLK_MASK));
+			nv_wr32(NV50_PDISPLAY_UNK30_CTRL,
+				NV50_PDISPLAY_UNK30_CTRL_PENDING);
+		}
+
+		if (ptimer->read(dev) - start > 1000000000ULL) {
+			NV_ERROR(dev, "timeout: 0x610300 = 0x%08x\n",
+				  nv_rd32(NV50_PDISPLAY_CTRL_STATE));
+			break;
+		}
+	}
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv50_display.h b/drivers/gpu/drm/nouveau/nv50_display.h
new file mode 100644
index 0000000..8cd7fe6
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_display.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#ifndef __NV50_DISPLAY_H__
+#define __NV50_DISPLAY_H__
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+#include "nouveau_reg.h"
+#include "nouveau_crtc.h"
+#include "nv50_display_commands.h"
+
+void nv50_display_command(struct drm_device *dev, uint32_t mthd, uint32_t val);
+int nv50_display_create(struct drm_device *dev);
+int nv50_display_destroy(struct drm_device *dev);
+int nv50_crtc_blank(struct nouveau_crtc *, bool blank);
+
+#endif /* __NV50_DISPLAY_H__ */
diff --git a/drivers/gpu/drm/nouveau/nv50_display_commands.h b/drivers/gpu/drm/nouveau/nv50_display_commands.h
new file mode 100644
index 0000000..4fd10c9
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_display_commands.h
@@ -0,0 +1,195 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+/* copied from ddx definitions, until rules-ng can handle this */
+
+#define NV50_UPDATE_DISPLAY		0x80
+#define NV50_UNK84				0x84
+#define NV50_UNK88				0x88
+
+#define NV50_DAC0_MODE_CTRL		0x400
+	#define NV50_DAC_MODE_CTRL_OFF			(0 << 0)
+	#define NV50_DAC_MODE_CTRL_CRTC0			(1 << 0)
+	#define NV50_DAC_MODE_CTRL_CRTC1			(1 << 1)
+#define NV50_DAC1_MODE_CTRL		0x480
+#define NV50_DAC2_MODE_CTRL		0x500
+
+#define NV50_DAC0_MODE_CTRL2		0x404
+	#define NV50_DAC_MODE_CTRL2_NHSYNC			(1 << 0)
+	#define NV50_DAC_MODE_CTRL2_NVSYNC			(2 << 0)
+#define NV50_DAC1_MODE_CTRL2		0x484
+#define NV50_DAC2_MODE_CTRL2		0x504
+
+#define NV50_SOR0_MODE_CTRL		0x600
+	#define NV50_SOR_MODE_CTRL_OFF			(0 << 0)
+	#define NV50_SOR_MODE_CTRL_CRTC0			(1 << 0)
+	#define NV50_SOR_MODE_CTRL_CRTC1			(1 << 1)
+	#define NV50_SOR_MODE_CTRL_LVDS			(0 << 8)
+	#define NV50_SOR_MODE_CTRL_TMDS			(1 << 8)
+	#define NV50_SOR_MODE_CTRL_TMDS_DUAL_LINK	(4 << 8)
+	#define NV50_SOR_MODE_CTRL_NHSYNC			(1 << 12)
+	#define NV50_SOR_MODE_CTRL_NVSYNC			(2 << 12)
+#define NV50_SOR1_MODE_CTRL		0x640
+
+#define NV50_CRTC0_UNK800			0x800
+#define NV50_CRTC0_CLOCK			0x804
+#define NV50_CRTC0_INTERLACE		0x808
+
+/* 0x810 is a reasonable guess, nothing more. */
+#define NV50_CRTC0_DISPLAY_START				0x810
+#define NV50_CRTC0_DISPLAY_TOTAL				0x814
+#define NV50_CRTC0_SYNC_DURATION				0x818
+#define NV50_CRTC0_SYNC_START_TO_BLANK_END		0x81C
+#define NV50_CRTC0_MODE_UNK1					0x820
+#define NV50_CRTC0_MODE_UNK2					0x824
+
+#define NV50_CRTC0_UNK82C						0x82C
+
+/* You can't have a palette in 8 bit mode (=OFF) */
+#define NV50_CRTC0_CLUT_MODE		0x840
+	#define NV50_CRTC0_CLUT_MODE_BLANK		0x00000000
+	#define NV50_CRTC0_CLUT_MODE_OFF		0x80000000
+	#define NV50_CRTC0_CLUT_MODE_ON		0xC0000000
+#define NV50_CRTC0_CLUT_OFFSET		0x844
+
+#define NV84_CRTC0_CLUT_DMA		0x85C
+	#define NV84_CRTC0_CLUT_DMA_DISABLE	0x0
+	#define NV84_CRTC0_CLUT_DMA_LOCAL	0x1
+
+#define NV50_CRTC0_FB_OFFSET		0x860
+
+#define NV50_CRTC0_FB_SIZE			0x868
+#define NV50_CRTC0_FB_PITCH		0x86C
+
+#define NV50_CRTC0_DEPTH			0x870
+	#define NV50_CRTC0_DEPTH_8BPP		0x1E00
+	#define NV50_CRTC0_DEPTH_15BPP	0xE900
+	#define NV50_CRTC0_DEPTH_16BPP	0xE800
+	#define NV50_CRTC0_DEPTH_24BPP	0xCF00
+
+/* I'm openminded to better interpretations. */
+/* This is an educated guess. */
+/* NV50 has RAMDAC and TMDS offchip, so it's unlikely to be that. */
+#define NV50_CRTC0_BLANK_CTRL		0x874
+	#define NV50_CRTC0_BLANK_CTRL_BLANK	0x0
+	#define NV50_CRTC0_BLANK_CTRL_UNBLANK	0x1
+
+#define NV50_CRTC0_CURSOR_CTRL	0x880
+	#define NV50_CRTC0_CURSOR_CTRL_SHOW	0x85000000
+	#define NV50_CRTC0_CURSOR_CTRL_HIDE	0x05000000
+
+#define NV50_CRTC0_CURSOR_OFFSET	0x884
+
+/* Anyone know what part of the chip is triggered here precisely? */
+#define NV84_CRTC0_CURSOR_DMA		0x89C
+	#define NV84_CRTC0_CURSOR_DMA_DISABLE	0x0
+	#define NV84_CRTC0_CURSOR_DMA_LOCAL	0x1
+
+#define NV50_CRTC0_DITHERING_CTRL	0x8A0
+	#define NV50_CRTC0_DITHERING_CTRL_ON	0x11
+	#define NV50_CRTC0_DITHERING_CTRL_OFF	0x0
+
+#define NV50_CRTC0_SCALE_CTRL		0x8A4
+	#define	NV50_CRTC0_SCALE_CTRL_SCALER_INACTIVE	(0 << 0)
+	/* It doesn't seem to be needed, hence i wonder what it does precisely. */
+	#define	NV50_CRTC0_SCALE_CTRL_SCALER_ACTIVE	(9 << 0)
+#define NV50_CRTC0_COLOR_CTRL		0x8A8
+	#define NV50_CRTC_COLOR_CTRL_MODE_COLOR		(4 << 16)
+
+#define NV50_CRTC0_FB_POS			0x8C0
+#define NV50_CRTC0_REAL_RES		0x8C8
+
+/* Added a macro, because the signed stuff can cause you problems very quickly. */
+#define NV50_CRTC0_SCALE_CENTER_OFFSET		0x8D4
+	#define NV50_CRTC_SCALE_CENTER_OFFSET_VAL(x, y) ((((unsigned)y << 16) & 0xFFFF0000) | (((unsigned)x) & 0x0000FFFF))
+/* Both of these are needed, otherwise nothing happens. */
+#define NV50_CRTC0_SCALE_RES1		0x8D8
+#define NV50_CRTC0_SCALE_RES2		0x8DC
+
+#define NV50_CRTC1_UNK800			0xC00
+#define NV50_CRTC1_CLOCK			0xC04
+#define NV50_CRTC1_INTERLACE		0xC08
+
+/* 0xC10 is a reasonable guess, nothing more. */
+#define NV50_CRTC1_DISPLAY_START				0xC10
+#define NV50_CRTC1_DISPLAY_TOTAL				0xC14
+#define NV50_CRTC1_SYNC_DURATION				0xC18
+#define NV50_CRTC1_SYNC_START_TO_BLANK_END		0xC1C
+#define NV50_CRTC1_MODE_UNK1					0xC20
+#define NV50_CRTC1_MODE_UNK2					0xC24
+
+#define NV50_CRTC1_CLUT_MODE		0xC40
+	#define NV50_CRTC1_CLUT_MODE_BLANK		0x00000000
+	#define NV50_CRTC1_CLUT_MODE_OFF		0x80000000
+	#define NV50_CRTC1_CLUT_MODE_ON		0xC0000000
+#define NV50_CRTC1_CLUT_OFFSET		0xC44
+
+/* Anyone know what part of the chip is triggered here precisely? */
+#define NV84_CRTC1_BLANK_UNK1		0xC5C
+	#define NV84_CRTC1_BLANK_UNK1_BLANK	0x0
+	#define NV84_CRTC1_BLANK_UNK1_UNBLANK	0x1
+
+#define NV50_CRTC1_FB_OFFSET		0xC60
+
+#define NV50_CRTC1_FB_SIZE			0xC68
+#define NV50_CRTC1_FB_PITCH		0xC6C
+
+#define NV50_CRTC1_DEPTH			0xC70
+	#define NV50_CRTC1_DEPTH_8BPP		0x1E00
+	#define NV50_CRTC1_DEPTH_15BPP	0xE900
+	#define NV50_CRTC1_DEPTH_16BPP	0xE800
+	#define NV50_CRTC1_DEPTH_24BPP	0xCF00
+
+/* I'm openminded to better interpretations. */
+#define NV50_CRTC1_BLANK_CTRL		0xC74
+	#define NV50_CRTC1_BLANK_CTRL_BLANK	0x0
+	#define NV50_CRTC1_BLANK_CTRL_UNBLANK	0x1
+
+#define NV50_CRTC1_CURSOR_CTRL		0xC80
+	#define NV50_CRTC1_CURSOR_CTRL_SHOW	0x85000000
+	#define NV50_CRTC1_CURSOR_CTRL_HIDE	0x05000000
+
+#define NV50_CRTC1_CURSOR_OFFSET	0xC84
+
+/* Anyone know what part of the chip is triggered here precisely? */
+#define NV84_CRTC1_BLANK_UNK2		0xC9C
+	#define NV84_CRTC1_BLANK_UNK2_BLANK	0x0
+	#define NV84_CRTC1_BLANK_UNK2_UNBLANK	0x1
+
+#define NV50_CRTC1_DITHERING_CTRL	0xCA0
+	#define NV50_CRTC1_DITHERING_CTRL_ON	0x11
+	#define NV50_CRTC1_DITHERING_CTRL_OFF	0x0
+
+#define NV50_CRTC1_SCALE_CTRL		0xCA4
+#define NV50_CRTC1_COLOR_CTRL		0xCA8
+
+#define NV50_CRTC1_FB_POS			0xCC0
+#define NV50_CRTC1_REAL_RES		0xCC8
+
+#define NV50_CRTC1_SCALE_CENTER_OFFSET		0xCD4
+/* Both of these are needed, otherwise nothing happens. */
+#define NV50_CRTC1_SCALE_RES1		0xCD8
+#define NV50_CRTC1_SCALE_RES2		0xCDC
diff --git a/drivers/gpu/drm/nouveau/nv50_fbcon.c b/drivers/gpu/drm/nouveau/nv50_fbcon.c
new file mode 100644
index 0000000..9ca1c1e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_fbcon.c
@@ -0,0 +1,222 @@
+#include "drmP.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+#include "nouveau_fbcon.h"
+
+static int
+nv50_fbcon_sync(struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan = dev_priv->channel;
+	int ret, i;
+
+	if (!chan->accel_done ||
+	    info->state != FBINFO_STATE_RUNNING ||
+	    info->flags & FBINFO_HWACCEL_DISABLED)
+		return 0;
+
+	if (RING_SPACE(chan, 4)) {
+		NV_ERROR(dev, "GPU lockup - switching to software fbcon\n");
+		info->flags |= FBINFO_HWACCEL_DISABLED;
+		return 0;
+	}
+
+	BEGIN_RING(chan, 0, 0x0104, 1);
+	OUT_RING  (chan, 0);
+	BEGIN_RING(chan, 0, 0x0100, 1);
+	OUT_RING  (chan, 0);
+	chan->m2mf_ntfy_map[3] = 0xffffffff;
+	FIRE_RING (chan);
+
+	ret = -EBUSY;
+	for (i = 0; i < 100000; i++) {
+		if (chan->m2mf_ntfy_map[3] == 0) {
+			ret = 0;
+			break;
+		}
+		DRM_UDELAY(1);
+	}
+
+	if (ret) {
+		NV_ERROR(dev, "GPU lockup - switching to software fbcon\n");
+		info->flags |= FBINFO_HWACCEL_DISABLED;
+		return 0;
+	}
+
+	chan->accel_done = false;
+	return 0;
+}
+
+static void
+nv50_fbcon_fillrect(struct fb_info *info, const struct fb_fillrect *rect)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan = dev_priv->channel;
+
+	if (info->state != FBINFO_STATE_RUNNING)
+		return;
+
+	if (info->flags & FBINFO_HWACCEL_DISABLED) {
+		cfb_fillrect(info, rect);
+		return;
+	}
+
+	if (RING_SPACE(chan, 9)) {
+		NV_ERROR(dev, "GPU lockup - switching to software fbcon\n");
+
+		info->flags |= FBINFO_HWACCEL_DISABLED;
+		cfb_fillrect(info, rect);
+		return;
+	}
+
+	BEGIN_RING(chan, NvSub2D, 0x02ac, 1);
+	OUT_RING  (chan, rect->rop == ROP_COPY ? 3 : 1);
+	BEGIN_RING(chan, NvSub2D, 0x0588, 1);
+	OUT_RING  (chan, rect->color);
+	BEGIN_RING(chan, NvSub2D, 0x0600, 4);
+	OUT_RING  (chan, rect->dx);
+	OUT_RING  (chan, rect->dy);
+	OUT_RING  (chan, rect->dx + rect->width);
+	OUT_RING  (chan, rect->dy + rect->height);
+	FIRE_RING (chan);
+}
+
+static void
+nv50_fbcon_copyarea(struct fb_info *info, const struct fb_copyarea *region)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan = dev_priv->channel;
+
+	if (info->state != FBINFO_STATE_RUNNING)
+		return;
+
+	if (info->flags & FBINFO_HWACCEL_DISABLED) {
+		cfb_copyarea(info, region);
+		return;
+	}
+
+	if (RING_SPACE(chan, 17)) {
+		NV_ERROR(dev, "GPU lockup - switching to software fbcon\n");
+
+		info->flags |= FBINFO_HWACCEL_DISABLED;
+		cfb_copyarea(info, region);
+		return;
+	}
+
+	BEGIN_RING(chan, NvSub2D, 0x02ac, 1);
+	OUT_RING  (chan, 3);
+	BEGIN_RING(chan, NvSub2D, 0x0110, 1);
+	OUT_RING  (chan, 0);
+	BEGIN_RING(chan, NvSub2D, 0x08b0, 12);
+	OUT_RING  (chan, region->dx);
+	OUT_RING  (chan, region->dy);
+	OUT_RING  (chan, region->width);
+	OUT_RING  (chan, region->height);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, 1);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, 1);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, region->sx);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, region->sy);
+	FIRE_RING (chan);
+}
+
+static void
+nv50_fbcon_imageblit(struct fb_info *info, const struct fb_image *image)
+{
+	if (info->state != FBINFO_STATE_RUNNING)
+		return;
+
+	if (info->flags & FBINFO_HWACCEL_DISABLED) {
+		cfb_imageblit(info, image);
+		return;
+	}
+
+	cfb_imageblit(info, image);
+}
+
+int
+nv50_fbcon_accel_init(struct fb_info *info)
+{
+	struct nouveau_fbcon_par *par = info->par;
+	struct drm_device *dev = par->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan = dev_priv->channel;
+	struct nouveau_gpuobj *eng2d = NULL;
+	int ret, format;
+
+	switch (info->var.bits_per_pixel) {
+	case 16:
+		format = 0xe8;
+		break;
+	default:
+		format = 0xe6;
+		break;
+	}
+
+	ret = nouveau_gpuobj_gr_new(dev_priv->channel, 0x502d, &eng2d);
+	if (ret)
+		return ret;
+
+	ret = nouveau_gpuobj_ref_add(dev, dev_priv->channel, Nv2D, eng2d, NULL);
+	if (ret)
+		return ret;
+
+	ret = RING_SPACE(chan, 34);
+	if (ret) {
+		NV_ERROR(dev, "GPU lockup - switching to software fbcon\n");
+		return ret;
+	}
+
+	BEGIN_RING(chan, NvSub2D, 0x0000, 1);
+	OUT_RING  (chan, Nv2D);
+	BEGIN_RING(chan, NvSub2D, 0x0180, 4);
+	OUT_RING  (chan, NvNotify0);
+	OUT_RING  (chan, chan->vram_handle);
+	OUT_RING  (chan, chan->vram_handle);
+	OUT_RING  (chan, chan->vram_handle);
+	BEGIN_RING(chan, NvSub2D, 0x0290, 1);
+	OUT_RING  (chan, 0);
+	BEGIN_RING(chan, NvSub2D, 0x0888, 1);
+	OUT_RING  (chan, 1);
+	BEGIN_RING(chan, NvSub2D, 0x02a0, 1);
+	OUT_RING  (chan, 0x55);
+	BEGIN_RING(chan, NvSub2D, 0x0580, 2);
+	OUT_RING  (chan, 4);
+	OUT_RING  (chan, format);
+	BEGIN_RING(chan, NvSub2D, 0x0200, 2);
+	OUT_RING  (chan, format);
+	OUT_RING  (chan, 1);
+	BEGIN_RING(chan, NvSub2D, 0x0214, 5);
+	OUT_RING  (chan, info->fix.line_length);
+	OUT_RING  (chan, info->var.xres_virtual);
+	OUT_RING  (chan, info->var.yres_virtual);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, info->fix.smem_start - dev_priv->fb_phys +
+			 dev_priv->vm_vram_base);
+	BEGIN_RING(chan, NvSub2D, 0x0230, 2);
+	OUT_RING  (chan, format);
+	OUT_RING  (chan, 1);
+	BEGIN_RING(chan, NvSub2D, 0x0244, 5);
+	OUT_RING  (chan, info->fix.line_length);
+	OUT_RING  (chan, info->var.xres_virtual);
+	OUT_RING  (chan, info->var.yres_virtual);
+	OUT_RING  (chan, 0);
+	OUT_RING  (chan, info->fix.smem_start - dev_priv->fb_phys +
+			 dev_priv->vm_vram_base);
+
+	info->fbops->fb_fillrect = nv50_fbcon_fillrect;
+	info->fbops->fb_copyarea = nv50_fbcon_copyarea;
+	info->fbops->fb_imageblit = nv50_fbcon_imageblit;
+	info->fbops->fb_sync = nv50_fbcon_sync;
+	return 0;
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv50_fifo.c b/drivers/gpu/drm/nouveau/nv50_fifo.c
new file mode 100644
index 0000000..fbbc235
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_fifo.c
@@ -0,0 +1,343 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+struct nv50_fifo_priv {
+	struct nouveau_gpuobj_ref *thingo[2];
+	int cur_thingo;
+};
+
+#define IS_G80 ((dev_priv->chipset & 0xf0) == 0x50)
+
+static void
+nv50_fifo_init_thingo(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_fifo_priv *priv = dev_priv->engine.fifo.priv;
+	struct nouveau_gpuobj_ref *cur;
+	int i, nr;
+
+	NV_DEBUG(dev, "\n");
+
+	cur = priv->thingo[priv->cur_thingo];
+	priv->cur_thingo = !priv->cur_thingo;
+
+	/* We never schedule channel 0 or 127 */
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	for (i = 1, nr = 0; i < 127; i++) {
+		if (dev_priv->fifos[i]) {
+			INSTANCE_WR(cur->gpuobj, nr++, i);
+		}
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	nv_wr32(0x32f4, cur->instance >> 12);
+	nv_wr32(0x32ec, nr);
+	nv_wr32(0x2500, 0x101);
+}
+
+static int
+nv50_fifo_channel_enable(struct drm_device *dev, int channel, int nt)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan = dev_priv->fifos[channel];
+	uint32_t inst;
+
+	NV_DEBUG(dev, "ch%d\n", channel);
+
+	if (!chan->ramfc)
+		return -EINVAL;
+
+	if (IS_G80) inst = chan->ramfc->instance >> 12;
+	else        inst = chan->ramfc->instance >> 8;
+	nv_wr32(NV50_PFIFO_CTX_TABLE(channel),
+		 inst | NV50_PFIFO_CTX_TABLE_CHANNEL_ENABLED);
+
+	if (!nt) nv50_fifo_init_thingo(dev);
+	return 0;
+}
+
+static void
+nv50_fifo_channel_disable(struct drm_device *dev, int channel, int nt)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t inst;
+
+	NV_DEBUG(dev, "ch%d, nt=%d\n", channel, nt);
+
+	if (IS_G80) inst = NV50_PFIFO_CTX_TABLE_INSTANCE_MASK_G80;
+	else        inst = NV50_PFIFO_CTX_TABLE_INSTANCE_MASK_G84;
+	nv_wr32(NV50_PFIFO_CTX_TABLE(channel), inst);
+
+	if (!nt) nv50_fifo_init_thingo(dev);
+}
+
+static void
+nv50_fifo_init_reset(struct drm_device *dev)
+{
+	uint32_t pmc_e = NV_PMC_ENABLE_PFIFO;
+
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) & ~pmc_e);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |  pmc_e);
+}
+
+static void
+nv50_fifo_init_intr(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV03_PFIFO_INTR_0, 0xFFFFFFFF);
+	nv_wr32(NV03_PFIFO_INTR_EN_0, 0xFFFFFFFF);
+}
+
+static void
+nv50_fifo_init_context_table(struct drm_device *dev)
+{
+	int i;
+
+	NV_DEBUG(dev, "\n");
+
+	for (i = 0; i < NV50_PFIFO_CTX_TABLE__SIZE; i++)
+		nv50_fifo_channel_disable(dev, i, 1);
+	nv50_fifo_init_thingo(dev);
+}
+
+static void
+nv50_fifo_init_regs__nv(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(0x250c, 0x6f3cfc34);
+}
+
+static void
+nv50_fifo_init_regs(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(0x2500, 0);
+	nv_wr32(0x3250, 0);
+	nv_wr32(0x3220, 0);
+	nv_wr32(0x3204, 0);
+	nv_wr32(0x3210, 0);
+	nv_wr32(0x3270, 0);
+
+	/* Enable dummy channels setup by nv50_instmem.c */
+	nv50_fifo_channel_enable(dev, 0, 1);
+	nv50_fifo_channel_enable(dev, 127, 1);
+}
+
+int
+nv50_fifo_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_fifo_priv *priv;
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	priv = drm_calloc(1, sizeof(*priv), DRM_MEM_DRIVER);
+	if (!priv)
+		return -ENOMEM;
+	dev_priv->engine.fifo.priv = priv;
+
+	nv50_fifo_init_reset(dev);
+	nv50_fifo_init_intr(dev);
+
+	ret = nouveau_gpuobj_new_ref(dev, NULL, NULL, 0, 128*4, 0x1000,
+				     NVOBJ_FLAG_ZERO_ALLOC, &priv->thingo[0]);
+	if (ret) {
+		NV_ERROR(dev, "error creating thingo0: %d\n", ret);
+		return ret;
+	}
+
+	ret = nouveau_gpuobj_new_ref(dev, NULL, NULL, 0, 128*4, 0x1000,
+				     NVOBJ_FLAG_ZERO_ALLOC, &priv->thingo[1]);
+	if (ret) {
+		NV_ERROR(dev, "error creating thingo1: %d\n", ret);
+		return ret;
+	}
+
+	nv50_fifo_init_context_table(dev);
+	nv50_fifo_init_regs__nv(dev);
+	nv50_fifo_init_regs(dev);
+
+	return 0;
+}
+
+void
+nv50_fifo_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_fifo_priv *priv = dev_priv->engine.fifo.priv;
+
+	NV_DEBUG(dev, "\n");
+
+	if (!priv)
+		return;
+
+	nouveau_gpuobj_ref_del(dev, &priv->thingo[0]);
+	nouveau_gpuobj_ref_del(dev, &priv->thingo[1]);
+
+	dev_priv->engine.fifo.priv = NULL;
+	drm_free(priv, sizeof(*priv), DRM_MEM_DRIVER);
+}
+
+int
+nv50_fifo_channel_id(struct drm_device *dev)
+{
+	return (nv_rd32(NV03_PFIFO_CACHE1_PUSH1) &
+			NV50_PFIFO_CACHE1_PUSH1_CHID_MASK);
+}
+
+int
+nv50_fifo_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *ramfc = NULL;
+	int ret;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	if (IS_G80) {
+		uint32_t ramfc_offset = chan->ramin->gpuobj->im_pramin->start;
+		uint32_t vram_offset = chan->ramin->gpuobj->im_backing->start;
+		ret = nouveau_gpuobj_new_fake(dev, ramfc_offset, vram_offset,
+					      0x100, NVOBJ_FLAG_ZERO_ALLOC |
+					      NVOBJ_FLAG_ZERO_FREE, &ramfc,
+					      &chan->ramfc);
+		if (ret)
+			return ret;
+	} else {
+		ret = nouveau_gpuobj_new_ref(dev, chan, NULL, 0, 0x100, 256,
+					     NVOBJ_FLAG_ZERO_ALLOC |
+					     NVOBJ_FLAG_ZERO_FREE,
+					     &chan->ramfc);
+		if (ret)
+			return ret;
+		ramfc = chan->ramfc->gpuobj;
+	}
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+
+	INSTANCE_WR(ramfc, 0x08/4, chan->pushbuf_base);
+	INSTANCE_WR(ramfc, 0x10/4, chan->pushbuf_base);
+	INSTANCE_WR(ramfc, 0x48/4, chan->pushbuf->instance >> 4);
+	INSTANCE_WR(ramfc, 0x80/4, (0xc << 24) | (chan->ramht->instance >> 4));
+	INSTANCE_WR(ramfc, 0x3c/4, 0x000f0078); /* fetch? */
+	INSTANCE_WR(ramfc, 0x44/4, 0x2101ffff);
+	INSTANCE_WR(ramfc, 0x60/4, 0x7fffffff);
+	INSTANCE_WR(ramfc, 0x40/4, 0x00000000);
+	INSTANCE_WR(ramfc, 0x50/4, 0x2039b2e0);
+	INSTANCE_WR(ramfc, 0x54/4, 0x000f0000);
+	INSTANCE_WR(ramfc, 0x7c/4, 0x30000001);
+	INSTANCE_WR(ramfc, 0x78/4, 0x00000000);
+	INSTANCE_WR(ramfc, 0x4c/4, chan->pushbuf_mem->size - 1);
+
+	if (!IS_G80) {
+		INSTANCE_WR(chan->ramin->gpuobj, 0, chan->id);
+		INSTANCE_WR(chan->ramin->gpuobj, 1, chan->ramfc->instance >> 8);
+
+		INSTANCE_WR(ramfc, 0x88/4, 0x3d520); /* some vram addy >> 10 */
+		INSTANCE_WR(ramfc, 0x98/4, chan->ramin->instance >> 12);
+	}
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	ret = nv50_fifo_channel_enable(dev, chan->id, 0);
+	if (ret) {
+		NV_ERROR(dev, "error enabling ch%d: %d\n", chan->id, ret);
+		nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+		return ret;
+	}
+
+	return 0;
+}
+
+void
+nv50_fifo_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	nv50_fifo_channel_disable(dev, chan->id, 0);
+
+	/* Dummy channel, also used on ch 127 */
+	if (chan->id == 0)
+		nv50_fifo_channel_disable(dev, 127, 0);
+
+	if ((nv_rd32(NV03_PFIFO_CACHE1_PUSH1) & 0xffff) == chan->id)
+		nv_wr32(NV03_PFIFO_CACHE1_PUSH1, 127);
+
+	nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+}
+
+int
+nv50_fifo_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *ramfc = chan->ramfc->gpuobj;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	/*XXX: incomplete, only touches the regs that NV does */
+	dev_priv->engine.instmem.prepare_access(dev, false);
+
+	nv_wr32(0x3244, INSTANCE_RD(ramfc, 0x08/4));
+	nv_wr32(0x3240, INSTANCE_RD(ramfc, 0x10/4));
+
+	nv_wr32(0x3224, INSTANCE_RD(ramfc, 0x3c/4));
+	nv_wr32(NV04_PFIFO_CACHE1_DMA_INSTANCE, INSTANCE_RD(ramfc, 0x48/4));
+	nv_wr32(0x3234, INSTANCE_RD(ramfc, 0x4c/4));
+	nv_wr32(0x3254, 1);
+	nv_wr32(NV03_PFIFO_RAMHT, INSTANCE_RD(ramfc, 0x80/4));
+
+	if (!IS_G80) {
+		nv_wr32(0x340c, INSTANCE_RD(ramfc, 0x88/4));
+		nv_wr32(0x3410, INSTANCE_RD(ramfc, 0x98/4));
+	}
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	nv_wr32(NV03_PFIFO_CACHE1_PUSH1, chan->id | (1<<16));
+	return 0;
+}
+
+int
+nv50_fifo_save_context(struct nouveau_channel *chan)
+{
+	NV_DEBUG(chan->dev, "ch%d\n", chan->id);
+	NV_ERROR(chan->dev, "stub!\n");
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_graph.c b/drivers/gpu/drm/nouveau/nv50_graph.c
new file mode 100644
index 0000000..1832c3f
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_graph.c
@@ -0,0 +1,286 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+#include "nv50_grctx.h"
+
+#define IS_G80 ((dev_priv->chipset & 0xf0) == 0x50)
+
+static void
+nv50_graph_init_reset(struct drm_device *dev)
+{
+	uint32_t pmc_e = NV_PMC_ENABLE_PGRAPH | (1 << 21);
+
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) & ~pmc_e);
+	nv_wr32(NV03_PMC_ENABLE, nv_rd32(NV03_PMC_ENABLE) |  pmc_e);
+}
+
+static void
+nv50_graph_init_intr(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV03_PGRAPH_INTR, 0xffffffff);
+	nv_wr32(0x400138, 0xffffffff);
+	nv_wr32(NV40_PGRAPH_INTR_EN, 0xffffffff);
+}
+
+static void
+nv50_graph_init_regs__nv(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(0x400804, 0xc0000000);
+	nv_wr32(0x406800, 0xc0000000);
+	nv_wr32(0x400c04, 0xc0000000);
+	nv_wr32(0x401804, 0xc0000000);
+	nv_wr32(0x405018, 0xc0000000);
+	nv_wr32(0x402000, 0xc0000000);
+
+	nv_wr32(0x400108, 0xffffffff);
+
+	nv_wr32(0x400824, 0x00004000);
+	nv_wr32(0x400500, 0x00000000);
+}
+
+static void
+nv50_graph_init_regs(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+
+	nv_wr32(NV04_PGRAPH_DEBUG_3, (1<<2) /* HW_CONTEXT_SWITCH_ENABLED */);
+}
+
+static int
+nv50_graph_init_ctxctl(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	uint32_t *voodoo = NULL;
+
+	NV_DEBUG(dev, "\n");
+
+	switch (dev_priv->chipset) {
+		/*(DEBLOBBED)*/
+	default:
+		NV_ERROR(dev, "no ctxprog for chipset NV%02x\n", dev_priv->chipset);
+		return -EINVAL;
+	}
+
+	nv_wr32(NV40_PGRAPH_CTXCTL_UCODE_INDEX, 0);
+	while (*voodoo != ~0) {
+		nv_wr32(NV40_PGRAPH_CTXCTL_UCODE_DATA, *voodoo);
+		voodoo++;
+	}
+
+	nv_wr32(0x400320, 4);
+	nv_wr32(NV40_PGRAPH_CTXCTL_CUR, 0);
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, 0);
+
+	return 0;
+}
+
+int
+nv50_graph_init(struct drm_device *dev)
+{
+	int ret;
+
+	NV_DEBUG(dev, "\n");
+
+	nv50_graph_init_reset(dev);
+	nv50_graph_init_regs__nv(dev);
+	nv50_graph_init_regs(dev);
+	nv50_graph_init_intr(dev);
+
+	ret = nv50_graph_init_ctxctl(dev);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+void
+nv50_graph_takedown(struct drm_device *dev)
+{
+	NV_DEBUG(dev, "\n");
+}
+
+void
+nv50_graph_fifo_access(struct drm_device *dev, bool enabled)
+{
+	const uint32_t mask = 0x00010001;
+
+	if (enabled)
+		nv_wr32(0x400500, nv_rd32(0x400500) | mask);
+	else
+		nv_wr32(0x400500, nv_rd32(0x400500) & ~mask);
+}
+
+int
+nv50_graph_create_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_gpuobj *ramin = chan->ramin->gpuobj;
+	struct nouveau_gpuobj *ctx;
+	uint32_t *ctxvals = NULL;
+	int grctx_size = 0x70000, hdr;
+	int ret, pos;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	ret = nouveau_gpuobj_new_ref(dev, chan, NULL, 0, grctx_size, 0x1000,
+				     NVOBJ_FLAG_ZERO_ALLOC |
+				     NVOBJ_FLAG_ZERO_FREE, &chan->ramin_grctx);
+	if (ret)
+		return ret;
+	ctx = chan->ramin_grctx->gpuobj;
+
+	hdr = IS_G80 ? 0x200 : 0x20;
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	INSTANCE_WR(ramin, (hdr + 0x00)/4, 0x00190002);
+	INSTANCE_WR(ramin, (hdr + 0x04)/4, chan->ramin_grctx->instance +
+					   grctx_size - 1);
+	INSTANCE_WR(ramin, (hdr + 0x08)/4, chan->ramin_grctx->instance);
+	INSTANCE_WR(ramin, (hdr + 0x0c)/4, 0);
+	INSTANCE_WR(ramin, (hdr + 0x10)/4, 0);
+	INSTANCE_WR(ramin, (hdr + 0x14)/4, 0x00010000);
+	dev_priv->engine.instmem.finish_access(dev);
+
+	switch (dev_priv->chipset) {
+		/*(DEBLOBBED)*/
+	default:
+		break;
+	}
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+
+	pos = 0;
+	while (*ctxvals) {
+		int cnt = *ctxvals++;
+
+		while (cnt--)
+			INSTANCE_WR(ctx, pos++, *ctxvals);
+		ctxvals++;
+	}
+
+	INSTANCE_WR(ctx, 0x00000/4, chan->ramin->instance >> 12);
+	if ((dev_priv->chipset & 0xf0) == 0xa0)
+		INSTANCE_WR(ctx, 0x00004/4, 0x00000002);
+	else
+		INSTANCE_WR(ctx, 0x0011c/4, 0x00000002);
+
+	dev_priv->engine.instmem.finish_access(dev);
+
+	return 0;
+}
+
+void
+nv50_graph_destroy_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	if (chan->ramin && chan->ramin->gpuobj) {
+		int i, hdr;
+
+		hdr = IS_G80 ? 0x200 : 0x20;
+		dev_priv->engine.instmem.prepare_access(dev, true);
+		for (i=hdr; i<hdr+24; i+=4)
+			INSTANCE_WR(chan->ramin->gpuobj, i/4, 0);
+		dev_priv->engine.instmem.finish_access(dev);
+
+		nouveau_gpuobj_ref_del(dev, &chan->ramin_grctx);
+	}
+}
+
+static int
+nv50_graph_transfer_context(struct drm_device *dev, uint32_t inst, int save)
+{
+	uint32_t old_cp, tv = 20000;
+	int i;
+
+	NV_DEBUG(dev, "inst=0x%08x, save=%d\n", inst, save);
+
+	old_cp = nv_rd32(NV20_PGRAPH_CHANNEL_CTX_POINTER);
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+	nv_wr32(0x400824, nv_rd32(0x400824) |
+		 (save ? NV40_PGRAPH_CTXCTL_0310_XFER_SAVE :
+			 NV40_PGRAPH_CTXCTL_0310_XFER_LOAD));
+	nv_wr32(NV40_PGRAPH_CTXCTL_0304, NV40_PGRAPH_CTXCTL_0304_XFER_CTX);
+
+	for (i = 0; i < tv; i++) {
+		if (nv_rd32(NV40_PGRAPH_CTXCTL_030C) == 0)
+			break;
+	}
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, old_cp);
+
+	if (i == tv) {
+		NV_ERROR(dev, "failed: inst=0x%08x save=%d\n", inst, save);
+		NV_ERROR(dev, "0x40030C = 0x%08x\n",
+			  nv_rd32(NV40_PGRAPH_CTXCTL_030C));
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+int
+nv50_graph_load_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst = chan->ramin->instance >> 12;
+	int ret; (void)ret;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+#if 0
+	if ((ret = nv50_graph_transfer_context(dev, inst, 0)))
+		return ret;
+#endif
+
+	nv_wr32(NV20_PGRAPH_CHANNEL_CTX_POINTER, inst);
+	nv_wr32(0x400320, 4);
+	nv_wr32(NV40_PGRAPH_CTXCTL_CUR, inst | (1<<31));
+
+	return 0;
+}
+
+int
+nv50_graph_save_context(struct nouveau_channel *chan)
+{
+	struct drm_device *dev = chan->dev;
+	uint32_t inst = chan->ramin->instance >> 12;
+
+	NV_DEBUG(dev, "ch%d\n", chan->id);
+
+	return nv50_graph_transfer_context(dev, inst, 1);
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_grctx.h b/drivers/gpu/drm/nouveau/nv50_grctx.h
new file mode 100644
index 0000000..a63796f
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_grctx.h
@@ -0,0 +1,6 @@
+#ifndef __NV50_GRCTX_H__
+#define __NV50_GRCTX_H__
+
+/*(DEBLOBBED)*/
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/nv50_instmem.c b/drivers/gpu/drm/nouveau/nv50_instmem.c
new file mode 100644
index 0000000..d69f0cc
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_instmem.c
@@ -0,0 +1,382 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ *
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+struct nv50_instmem_priv {
+	uint32_t save1700[5]; /* 0x1700->0x1710 */
+
+	struct nouveau_gpuobj_ref *pramin_pt;
+	struct nouveau_gpuobj_ref *pramin_bar;
+
+	bool last_access_wr;
+};
+
+#define NV50_INSTMEM_PAGE_SHIFT 12
+#define NV50_INSTMEM_PAGE_SIZE  (1 << NV50_INSTMEM_PAGE_SHIFT)
+#define NV50_INSTMEM_PT_SIZE(a)	(((a) >> 12) << 3)
+
+/*NOTE: - Assumes 0x1700 already covers the correct MiB of PRAMIN
+ */
+#define BAR0_WI32(g,o,v) do {                                     \
+	uint32_t offset;                                          \
+	if ((g)->im_backing) {                                    \
+		offset = (g)->im_backing->start;                  \
+	} else {                                                  \
+		offset  = chan->ramin->gpuobj->im_backing->start; \
+		offset += (g)->im_pramin->start;                  \
+	}                                                         \
+	offset += (o);                                            \
+	nv_wr32(NV_RAMIN + (offset & 0xfffff), (v));             \
+} while(0)
+
+int
+nv50_instmem_init(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_channel *chan;
+	uint32_t c_offset, c_size, c_ramfc, c_vmpd, c_base, pt_size;
+	struct nv50_instmem_priv *priv;
+	int ret, i;
+	uint32_t v, save_nv001700;
+
+	priv = drm_calloc(1, sizeof(*priv), DRM_MEM_DRIVER);
+	if (!priv)
+		return -ENOMEM;
+	dev_priv->engine.instmem.priv = priv;
+
+	/* Save state, will restore at takedown. */
+	for (i = 0x1700; i <= 0x1710; i+=4)
+		priv->save1700[(i-0x1700)/4] = nv_rd32(i);
+
+	/* Reserve the last MiB of VRAM, we should probably try to avoid
+	 * setting up the below tables over the top of the VBIOS image at
+	 * some point.
+	 */
+	dev_priv->ramin_rsvd_vram = 1 << 20;
+	c_offset = nouveau_mem_fb_amount(dev) - dev_priv->ramin_rsvd_vram;
+	c_size   = 128 << 10;
+	c_vmpd   = ((dev_priv->chipset & 0xf0) == 0x50) ? 0x1400 : 0x200;
+	c_ramfc  = ((dev_priv->chipset & 0xf0) == 0x50) ? 0x0 : 0x20;
+	c_base   = c_vmpd + 0x4000;
+	pt_size  = NV50_INSTMEM_PT_SIZE(dev_priv->ramin->size);
+
+	NV_DEBUG(dev, " Rsvd VRAM base: 0x%08x\n", c_offset);
+	NV_DEBUG(dev, "    VBIOS image: 0x%08x\n", (nv_rd32(0x619f04)&~0xff)<<8);
+	NV_DEBUG(dev, "  Aperture size: %d MiB\n",
+		 (uint32_t)dev_priv->ramin->size >> 20);
+	NV_DEBUG(dev, "        PT size: %d KiB\n", pt_size >> 10);
+
+	save_nv001700 = nv_rd32(NV50_PUNK_BAR0_PRAMIN);
+	nv_wr32(NV50_PUNK_BAR0_PRAMIN, (c_offset >> 16));
+
+	/* Create a fake channel, and use it as our "dummy" channels 0/127.
+	 * The main reason for creating a channel is so we can use the gpuobj
+	 * code.  However, it's probably worth noting that NVIDIA also setup
+	 * their channels 0/127 with the same values they configure here.
+	 * So, there may be some other reason for doing this.
+	 *
+	 * Have to create the entire channel manually, as the real channel
+	 * creation code assumes we have PRAMIN access, and we don't until
+	 * we're done here.
+	 */
+	chan = drm_calloc(1, sizeof(*chan), DRM_MEM_DRIVER);
+	if (!chan)
+		return -ENOMEM;
+	chan->id = 0;
+	chan->dev = dev;
+	chan->file_priv = (struct drm_file *)-2;
+	dev_priv->fifos[0] = dev_priv->fifos[127] = chan;
+
+	/* Channel's PRAMIN object + heap */
+	if ((ret = nouveau_gpuobj_new_fake(dev, 0, c_offset, 128<<10, 0,
+					   NULL, &chan->ramin)))
+		return ret;
+
+	if (nouveau_mem_init_heap(&chan->ramin_heap, c_base, c_size - c_base))
+		return -ENOMEM;
+
+	/* RAMFC + zero channel's PRAMIN up to start of VM pagedir */
+	if ((ret = nouveau_gpuobj_new_fake(dev, c_ramfc, c_offset + c_ramfc,
+					   0x4000, 0, NULL, &chan->ramfc)))
+		return ret;
+
+	for (i = 0; i < c_vmpd; i += 4)
+		BAR0_WI32(chan->ramin->gpuobj, i, 0);
+
+	/* VM page directory */
+	if ((ret = nouveau_gpuobj_new_fake(dev, c_vmpd, c_offset + c_vmpd,
+					   0x4000, 0, &chan->vm_pd, NULL)))
+		return ret;
+	for (i = 0; i < 0x4000; i += 8) {
+		BAR0_WI32(chan->vm_pd, i + 0x00, 0x00000000);
+		BAR0_WI32(chan->vm_pd, i + 0x04, 0x00000000);
+	}
+
+	/* PRAMIN page table, cheat and map into VM at 0x0000000000.
+	 * We map the entire fake channel into the start of the PRAMIN BAR
+	 */
+	if ((ret = nouveau_gpuobj_new_ref(dev, chan, NULL, 0, pt_size, 0x1000,
+					  0, &priv->pramin_pt)))
+		return ret;
+
+	for (i = 0, v = c_offset; i < pt_size; i+=8, v+=0x1000) {
+		if (v < (c_offset + c_size))
+			BAR0_WI32(priv->pramin_pt->gpuobj, i + 0, v | 1);
+		else
+			BAR0_WI32(priv->pramin_pt->gpuobj, i + 0, 0x00000009);
+		BAR0_WI32(priv->pramin_pt->gpuobj, i + 4, 0x00000000);
+	}
+
+	BAR0_WI32(chan->vm_pd, 0x00, priv->pramin_pt->instance | 0x63);
+	BAR0_WI32(chan->vm_pd, 0x04, 0x00000000);
+
+	/* DMA object for PRAMIN BAR */
+	if ((ret = nouveau_gpuobj_new_ref(dev, chan, chan, 0, 6*4, 16, 0,
+					  &priv->pramin_bar)))
+		return ret;
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x00, 0x7fc00000);
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x04, dev_priv->ramin->size - 1);
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x08, 0x00000000);
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x0c, 0x00000000);
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x10, 0x00000000);
+	BAR0_WI32(priv->pramin_bar->gpuobj, 0x14, 0x00000000);
+
+	/* Poke the relevant regs, and pray it works :) */
+	nv_wr32(NV50_PUNK_BAR_CFG_BASE, (chan->ramin->instance >> 12));
+	nv_wr32(NV50_PUNK_UNK1710, 0);
+	nv_wr32(NV50_PUNK_BAR_CFG_BASE, (chan->ramin->instance >> 12) |
+					 NV50_PUNK_BAR_CFG_BASE_VALID);
+	nv_wr32(NV50_PUNK_BAR1_CTXDMA, 0);
+	nv_wr32(NV50_PUNK_BAR3_CTXDMA, (priv->pramin_bar->instance >> 4) |
+					NV50_PUNK_BAR3_CTXDMA_VALID);
+
+	for (i = 0; i < 8; i++)
+		nv_wr32(0x1900 + (i*4), 0);
+
+	/* Assume that praying isn't enough, check that we can re-read the
+	 * entire fake channel back from the PRAMIN BAR */
+	dev_priv->engine.instmem.prepare_access(dev, false);
+	for (i = 0; i < c_size; i+=4) {
+		if (nv_rd32(NV_RAMIN + i) != nv_ri32(i)) {
+			NV_ERROR(dev, "Error reading back PRAMIN at 0x%08x\n", i);
+			return -EINVAL;
+		}
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	nv_wr32(NV50_PUNK_BAR0_PRAMIN, save_nv001700);
+
+	/* Global PRAMIN heap */
+	if (nouveau_mem_init_heap(&dev_priv->ramin_heap,
+				  c_size, dev_priv->ramin->size - c_size)) {
+		dev_priv->ramin_heap = NULL;
+		NV_ERROR(dev, "Failed to init RAMIN heap\n");
+	}
+
+	/*XXX: incorrect, but needed to make hash func "work" */
+	dev_priv->ramht_offset = 0x10000;
+	dev_priv->ramht_bits   = 9;
+	dev_priv->ramht_size   = (1 << dev_priv->ramht_bits);
+	return 0;
+}
+
+void
+nv50_instmem_takedown(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_instmem_priv *priv = dev_priv->engine.instmem.priv;
+	struct nouveau_channel *chan = dev_priv->fifos[0];
+	int i;
+
+	NV_DEBUG(dev, "\n");
+
+	if (!priv)
+		return;
+
+	/* Restore state from before init */
+	for (i = 0x1700; i <= 0x1710; i+=4)
+		nv_wr32(i, priv->save1700[(i-0x1700)/4]);
+
+	nouveau_gpuobj_ref_del(dev, &priv->pramin_bar);
+	nouveau_gpuobj_ref_del(dev, &priv->pramin_pt);
+
+	/* Destroy dummy channel */
+	if (chan) {
+		nouveau_gpuobj_del(dev, &chan->vm_pd);
+		nouveau_gpuobj_ref_del(dev, &chan->ramfc);
+		nouveau_gpuobj_ref_del(dev, &chan->ramin);
+		nouveau_mem_takedown(&chan->ramin_heap);
+
+		dev_priv->fifos[0] = dev_priv->fifos[127] = NULL;
+		drm_free(chan, sizeof(*chan), DRM_MEM_DRIVER);
+	}
+
+	dev_priv->engine.instmem.priv = NULL;
+	drm_free(priv, sizeof(*priv), DRM_MEM_DRIVER);
+}
+
+int
+nv50_instmem_populate(struct drm_device *dev, struct nouveau_gpuobj *gpuobj, uint32_t *sz)
+{
+	if (gpuobj->im_backing)
+		return -EINVAL;
+
+	*sz = (*sz + (NV50_INSTMEM_PAGE_SIZE-1)) & ~(NV50_INSTMEM_PAGE_SIZE-1);
+	if (*sz == 0)
+		return -EINVAL;
+
+	gpuobj->im_backing = nouveau_mem_alloc(dev, NV50_INSTMEM_PAGE_SIZE,
+					       *sz, NOUVEAU_MEM_FB |
+					       NOUVEAU_MEM_NOVM,
+					       (struct drm_file *)-2);
+	if (!gpuobj->im_backing) {
+		NV_ERROR(dev, "Couldn't allocate vram to back PRAMIN pages\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+void
+nv50_instmem_clear(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+
+	if (gpuobj && gpuobj->im_backing) {
+		if (gpuobj->im_bound)
+			dev_priv->engine.instmem.unbind(dev, gpuobj);
+		nouveau_mem_free(dev, gpuobj->im_backing);
+		gpuobj->im_backing = NULL;
+	}
+}
+
+int
+nv50_instmem_bind(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_instmem_priv *priv = dev_priv->engine.instmem.priv;
+	uint32_t pte, pte_end, vram;
+
+	if (!gpuobj->im_backing || !gpuobj->im_pramin || gpuobj->im_bound)
+		return -EINVAL;
+
+	NV_DEBUG(dev, "st=0x%0llx sz=0x%0llx\n",
+		 gpuobj->im_pramin->start, gpuobj->im_pramin->size);
+
+	pte     = (gpuobj->im_pramin->start >> 12) << 3;
+	pte_end = ((gpuobj->im_pramin->size >> 12) << 3) + pte;
+	vram    = gpuobj->im_backing->start;
+
+	NV_DEBUG(dev, "pramin=0x%llx, pte=%d, pte_end=%d\n",
+		 gpuobj->im_pramin->start, pte, pte_end);
+	NV_DEBUG(dev, "first vram page: 0x%llx\n",
+		 gpuobj->im_backing->start);
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	while (pte < pte_end) {
+		INSTANCE_WR(priv->pramin_pt->gpuobj, (pte + 0)/4, vram | 1);
+		INSTANCE_WR(priv->pramin_pt->gpuobj, (pte + 4)/4, 0x00000000);
+
+		pte += 8;
+		vram += NV50_INSTMEM_PAGE_SIZE;
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	nv_wr32(0x100c80, 0x00040001);
+	if (!nv_wait(0x100c80, 0x00000001, 0x00000000)) {
+		NV_ERROR(dev, "timeout: (0x100c80 & 1) == 0 (1)\n");
+		NV_ERROR(dev, "0x100c80 = 0x%08x\n", nv_rd32(0x100c80));
+		return -EBUSY;
+	}
+
+	nv_wr32(0x100c80, 0x00060001);
+	if (!nv_wait(0x100c80, 0x00000001, 0x00000000)) {
+		NV_ERROR(dev, "timeout: (0x100c80 & 1) == 0 (2)\n");
+		NV_ERROR(dev, "0x100c80 = 0x%08x\n", nv_rd32(0x100c80));
+		return -EBUSY;
+	}
+
+	gpuobj->im_bound = 1;
+	return 0;
+}
+
+int
+nv50_instmem_unbind(struct drm_device *dev, struct nouveau_gpuobj *gpuobj)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_instmem_priv *priv = dev_priv->engine.instmem.priv;
+	uint32_t pte, pte_end;
+
+	if (gpuobj->im_bound == 0)
+		return -EINVAL;
+
+	pte     = (gpuobj->im_pramin->start >> 12) << 3;
+	pte_end = ((gpuobj->im_pramin->size >> 12) << 3) + pte;
+
+	dev_priv->engine.instmem.prepare_access(dev, true);
+	while (pte < pte_end) {
+		INSTANCE_WR(priv->pramin_pt->gpuobj, (pte + 0)/4, 0x00000009);
+		INSTANCE_WR(priv->pramin_pt->gpuobj, (pte + 4)/4, 0x00000000);
+		pte += 8;
+	}
+	dev_priv->engine.instmem.finish_access(dev);
+
+	gpuobj->im_bound = 0;
+	return 0;
+}
+
+void
+nv50_instmem_prepare_access(struct drm_device *dev, bool write)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_instmem_priv *priv = dev_priv->engine.instmem.priv;
+
+	BUG_ON(dev_priv->ramin_map != NULL);
+	dev_priv->ramin_map = dev_priv->ramin;
+
+	priv->last_access_wr = write;
+}
+
+void
+nv50_instmem_finish_access(struct drm_device *dev)
+{
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nv50_instmem_priv *priv = dev_priv->engine.instmem.priv;
+
+	BUG_ON(dev_priv->ramin_map == NULL);
+	dev_priv->ramin_map = NULL;
+
+	if (priv->last_access_wr) {
+		nv_wr32(0x070000, 0x00000001);
+		if (!nv_wait(0x070000, 0x00000001, 0x00000000))
+			NV_ERROR(dev, "PRAMIN flush timeout\n");
+	}
+}
+
diff --git a/drivers/gpu/drm/nouveau/nv50_mc.c b/drivers/gpu/drm/nouveau/nv50_mc.c
new file mode 100644
index 0000000..6572f12
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_mc.c
@@ -0,0 +1,40 @@
+/*
+ * Copyright (C) 2007 Ben Skeggs.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm.h"
+#include "nouveau_drv.h"
+
+int
+nv50_mc_init(struct drm_device *dev)
+{
+	nv_wr32(NV03_PMC_ENABLE, 0xFFFFFFFF);
+	return 0;
+}
+
+void nv50_mc_takedown(struct drm_device *dev)
+{
+}
diff --git a/drivers/gpu/drm/nouveau/nv50_sor.c b/drivers/gpu/drm/nouveau/nv50_sor.c
new file mode 100644
index 0000000..f26cc7b
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nv50_sor.c
@@ -0,0 +1,292 @@
+/*
+ * Copyright (C) 2008 Maarten Maathuis.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining
+ * a copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial
+ * portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
+ * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+ * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+
+#include "drmP.h"
+#include "drm_crtc_helper.h"
+#include "nouveau_reg.h"
+#include "nouveau_drv.h"
+#include "nouveau_dma.h"
+#include "nouveau_encoder.h"
+#include "nouveau_connector.h"
+#include "nouveau_crtc.h"
+#include "nv50_display.h"
+#include "nv50_display_commands.h"
+
+extern int nouveau_duallink;
+extern int nouveau_uscript;
+
+static void
+nv50_sor_disconnect(struct nouveau_encoder *encoder)
+{
+	struct drm_device *dev = encoder->base.dev;
+	uint32_t offset = encoder->or * 0x40;
+
+	NV_DEBUG(dev, "Disconnecting SOR %d\n", encoder->or);
+
+	OUT_MODE(NV50_SOR0_MODE_CTRL + offset, NV50_SOR_MODE_CTRL_OFF);
+}
+
+static int
+nv50_sor_set_clock_mode(struct nouveau_encoder *encoder,
+			struct drm_display_mode *mode)
+{
+	struct drm_device *dev = encoder->base.dev;
+	uint32_t limit = encoder->dcb->type == OUTPUT_LVDS ? 112000 : 165000;
+	int ret;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	/* We don't yet know what to do, if anything at all. */
+	if (!nouveau_uscript && encoder->dcb->type == OUTPUT_LVDS)
+		return 0;
+
+	if (nouveau_uscript) {
+		NV_TRACE(dev, "executing display table for %d %d %d %d\n",
+			 encoder->dcb->type, encoder->dcb->location,
+			 encoder->dcb->or, mode->clock);
+		ret = nouveau_bios_run_display_table(dev, encoder->dcb, mode->clock);
+		if (ret)
+			NV_ERROR(dev, "error running display table, may hang\n");
+	}
+
+	/* 0x70000 was a late addition to nv, mentioned as fixing tmds
+	 * initialisation on certain gpu's. I presume it's some kind of
+	 * clock setting, but what precisely i do not know.
+	 */
+	nv_wr32(NV50_PDISPLAY_SOR_CLK_CLK_CTRL2(encoder->or),
+		0x70000 | ((mode->clock > limit) ? 0x101 : 0));
+
+	return 0;
+}
+
+static void nv50_sor_dpms(struct drm_encoder *drm_encoder, int mode)
+{
+	struct drm_device *dev = drm_encoder->dev;
+	struct drm_nouveau_private *dev_priv = dev->dev_private;
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	uint32_t val;
+	int or = encoder->or;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	if (dev_priv->in_modeset) {
+		nv50_sor_disconnect(encoder);
+		return;
+	}
+
+	/* wait for it to be done */
+	if (!nv_wait(NV50_PDISPLAY_SOR_REGS_DPMS_CTRL(or),
+		     NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_PENDING, 0)) {
+		NV_ERROR(dev, "timeout: SOR_DPMS_CTRL_PENDING(%d) == 0\n", or);
+		NV_ERROR(dev, "SOR_DPMS_CTRL(%d) = 0x%08x\n", or,
+			 nv_rd32(NV50_PDISPLAY_SOR_REGS_DPMS_CTRL(or)));
+	}
+
+	val = nv_rd32(NV50_PDISPLAY_SOR_REGS_DPMS_CTRL(or));
+
+	if (mode == DRM_MODE_DPMS_ON)
+		val |= NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_ON;
+	else
+		val &= ~NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_ON;
+
+	nv_wr32(NV50_PDISPLAY_SOR_REGS_DPMS_CTRL(or), val |
+		NV50_PDISPLAY_SOR_REGS_DPMS_CTRL_PENDING);
+	if (!nv_wait(NV50_PDISPLAY_SOR_REGS_DPMS_STATE(or),
+		     NV50_PDISPLAY_SOR_REGS_DPMS_STATE_WAIT, 0)) {
+		NV_ERROR(dev, "timeout: SOR_DPMS_STATE_WAIT(%d) == 0\n", or);
+		NV_ERROR(dev, "SOR_DPMS_STATE(%d) = 0x%08x\n", or,
+			 nv_rd32(NV50_PDISPLAY_SOR_REGS_DPMS_STATE(or)));
+	}
+}
+
+static void nv50_sor_save(struct drm_encoder *drm_encoder)
+{
+	NV_ERROR(drm_encoder->dev, "!!\n");
+}
+
+static void nv50_sor_restore(struct drm_encoder *drm_encoder)
+{
+	NV_ERROR(drm_encoder->dev, "!!\n");
+}
+
+static struct nouveau_connector *
+nouveau_encoder_connector_get(struct nouveau_encoder *encoder)
+{
+	struct drm_device *dev = encoder->base.dev;
+	struct drm_connector *drm_connector;
+
+	list_for_each_entry(drm_connector, &dev->mode_config.connector_list, head) {
+		if (drm_connector->encoder == &encoder->base)
+			return to_nouveau_connector(drm_connector);
+	}
+
+	return NULL;
+}
+
+static bool nv50_sor_mode_fixup(struct drm_encoder *drm_encoder,
+				struct drm_display_mode *mode,
+				struct drm_display_mode *adjusted_mode)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	struct nouveau_connector *connector;
+
+	connector = nouveau_encoder_connector_get(encoder);
+	if (!connector)
+		return false;
+
+	if ((connector->scaling_mode != DRM_MODE_SCALE_NON_GPU &&
+	     connector->scaling_mode != DRM_MODE_SCALE_NO_SCALE) &&
+	     connector->native_mode) {
+		int id = adjusted_mode->base.id;
+		*adjusted_mode = *connector->native_mode;
+		adjusted_mode->base.id = id;
+	}
+
+	return true;
+}
+
+static void nv50_sor_prepare(struct drm_encoder *drm_encoder)
+{
+}
+
+static void nv50_sor_commit(struct drm_encoder *drm_encoder)
+{
+}
+
+static void nv50_sor_mode_set(struct drm_encoder *drm_encoder,
+			      struct drm_display_mode *mode,
+			      struct drm_display_mode *adjusted_mode)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+	struct drm_device *dev = drm_encoder->dev;
+	struct nouveau_crtc *crtc = to_nouveau_crtc(drm_encoder->crtc);
+	uint32_t offset = encoder->or * 0x40;
+	uint32_t mode_ctl = NV50_SOR_MODE_CTRL_OFF;
+
+	NV_DEBUG(dev, "or %d\n", encoder->or);
+
+	if (encoder->base.encoder_type == DRM_MODE_ENCODER_LVDS) {
+		mode_ctl |= NV50_SOR_MODE_CTRL_LVDS;
+	} else {
+		mode_ctl |= NV50_SOR_MODE_CTRL_TMDS;
+		if (adjusted_mode->clock > 165000)
+			mode_ctl |= NV50_SOR_MODE_CTRL_TMDS_DUAL_LINK;
+	}
+
+	if (crtc->index == 1)
+		mode_ctl |= NV50_SOR_MODE_CTRL_CRTC1;
+	else
+		mode_ctl |= NV50_SOR_MODE_CTRL_CRTC0;
+
+	if (adjusted_mode->flags & DRM_MODE_FLAG_NHSYNC)
+		mode_ctl |= NV50_SOR_MODE_CTRL_NHSYNC;
+
+	if (adjusted_mode->flags & DRM_MODE_FLAG_NVSYNC)
+		mode_ctl |= NV50_SOR_MODE_CTRL_NVSYNC;
+
+	OUT_MODE(NV50_SOR0_MODE_CTRL + offset, mode_ctl);
+}
+
+static const struct drm_encoder_helper_funcs nv50_sor_helper_funcs = {
+	.dpms = nv50_sor_dpms,
+	.save = nv50_sor_save,
+	.restore = nv50_sor_restore,
+	.mode_fixup = nv50_sor_mode_fixup,
+	.prepare = nv50_sor_prepare,
+	.commit = nv50_sor_commit,
+	.mode_set = nv50_sor_mode_set,
+	.detect = NULL
+};
+
+static void nv50_sor_destroy(struct drm_encoder *drm_encoder)
+{
+	struct nouveau_encoder *encoder = to_nouveau_encoder(drm_encoder);
+
+	NV_DEBUG(drm_encoder->dev, "\n");
+
+	if (!drm_encoder)
+		return;
+
+	drm_encoder_cleanup(&encoder->base);
+
+	kfree(encoder);
+}
+
+static const struct drm_encoder_funcs nv50_sor_encoder_funcs = {
+	.destroy = nv50_sor_destroy,
+};
+
+int nv50_sor_create(struct drm_device *dev, struct dcb_entry *entry)
+{
+	struct nouveau_encoder *encoder = NULL;
+	int type;
+
+	NV_DEBUG(dev, "\n");
+
+	switch (entry->type) {
+	case OUTPUT_TMDS:
+		NV_INFO(dev, "Detected a TMDS output\n");
+		type = DRM_MODE_ENCODER_TMDS;
+		break;
+	case OUTPUT_LVDS:
+		NV_INFO(dev, "Detected a LVDS output\n");
+		type = DRM_MODE_ENCODER_LVDS;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	encoder = kzalloc(sizeof(*encoder), GFP_KERNEL);
+	if (!encoder)
+		return -ENOMEM;
+
+	encoder->dcb = entry;
+	encoder->or = ffs(entry->or) - 1;
+
+	encoder->dual_link = nouveau_duallink;
+
+	/* Set function pointers. */
+	encoder->set_clock_mode = nv50_sor_set_clock_mode;
+
+	drm_encoder_init(dev, &encoder->base, &nv50_sor_encoder_funcs, type);
+	drm_encoder_helper_add(&encoder->base, &nv50_sor_helper_funcs);
+
+	/* I've never seen possible crtc's restricted. */
+	encoder->base.possible_crtcs = 3;
+	encoder->base.possible_clones = 0;
+
+	/* Some default state, unknown what it precisely means. */
+	if (encoder->base.encoder_type == DRM_MODE_ENCODER_TMDS) {
+		int or = encoder->or;
+
+		nv_wr32(NV50_PDISPLAY_SOR_REGS_UNK_00C(or), 0x03010700);
+		nv_wr32(NV50_PDISPLAY_SOR_REGS_UNK_010(or), 0x0000152f);
+		nv_wr32(NV50_PDISPLAY_SOR_REGS_UNK_014(or), 0x00000000);
+		nv_wr32(NV50_PDISPLAY_SOR_REGS_UNK_018(or), 0x00245af8);
+	}
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/nouveau/nvreg.h b/drivers/gpu/drm/nouveau/nvreg.h
new file mode 100644
index 0000000..9afacbb
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/nvreg.h
@@ -0,0 +1,495 @@
+/* $XConsortium: nvreg.h /main/2 1996/10/28 05:13:41 kaleb $ */
+/*
+ * Copyright 1996-1997  David J. McKay
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * DAVID J. MCKAY BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF
+ * OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+/* $XFree86: xc/programs/Xserver/hw/xfree86/drivers/nv/nvreg.h,v 1.6 2002/01/25 21:56:06 tsi Exp $ */
+
+#ifndef __NVREG_H_
+#define __NVREG_H_
+
+#define NV_PMC_OFFSET               0x00000000
+#define NV_PMC_SIZE                 0x00001000
+
+#define NV_PBUS_OFFSET              0x00001000
+#define NV_PBUS_SIZE                0x00001000
+
+#define NV_PFIFO_OFFSET             0x00002000
+#define NV_PFIFO_SIZE               0x00002000
+
+#define NV_HDIAG_OFFSET             0x00005000
+#define NV_HDIAG_SIZE               0x00001000
+
+#define NV_PRAM_OFFSET              0x00006000
+#define NV_PRAM_SIZE                0x00001000
+
+#define NV_PVIDEO_OFFSET            0x00008000
+#define NV_PVIDEO_SIZE              0x00001000
+
+#define NV_PTIMER_OFFSET            0x00009000
+#define NV_PTIMER_SIZE              0x00001000
+
+#define NV_PPM_OFFSET               0x0000A000
+#define NV_PPM_SIZE                 0x00001000
+
+#define NV_PRMVGA_OFFSET            0x000A0000
+#define NV_PRMVGA_SIZE              0x00020000
+
+#define NV_PRMVIO0_OFFSET           0x000C0000
+#define NV_PRMVIO_SIZE              0x00002000
+#define NV_PRMVIO1_OFFSET           0x000C2000
+
+#define NV_PFB_OFFSET               0x00100000
+#define NV_PFB_SIZE                 0x00001000
+
+#define NV_PEXTDEV_OFFSET           0x00101000
+#define NV_PEXTDEV_SIZE             0x00001000
+
+#define NV_PME_OFFSET               0x00200000
+#define NV_PME_SIZE                 0x00001000
+
+#define NV_PROM_OFFSET              0x00300000
+#define NV_PROM_SIZE                0x00010000
+
+#define NV_PGRAPH_OFFSET            0x00400000
+#define NV_PGRAPH_SIZE              0x00010000
+
+#define NV_PCRTC0_OFFSET            0x00600000
+#define NV_PCRTC0_SIZE              0x00002000 /* empirical */
+
+#define NV_PRMCIO0_OFFSET           0x00601000
+#define NV_PRMCIO_SIZE              0x00002000
+#define NV_PRMCIO1_OFFSET           0x00603000
+
+#define NV50_DISPLAY_OFFSET           0x00610000
+#define NV50_DISPLAY_SIZE             0x0000FFFF
+
+#define NV_PRAMDAC0_OFFSET          0x00680000
+#define NV_PRAMDAC0_SIZE            0x00002000
+
+#define NV_PRMDIO0_OFFSET           0x00681000
+#define NV_PRMDIO_SIZE              0x00002000
+#define NV_PRMDIO1_OFFSET           0x00683000
+
+#define NV_PRAMIN_OFFSET            0x00700000
+#define NV_PRAMIN_SIZE              0x00100000
+
+#define NV_FIFO_OFFSET              0x00800000
+#define NV_FIFO_SIZE                0x00800000
+
+#define NV_PMC_BOOT_0			0x00000000
+#define NV_PMC_ENABLE			0x00000200
+
+#define NV_VIO_VSE2			0x000003c3
+#define NV_VIO_SRX			0x000003c4
+
+#define NV_CIO_CRX__COLOR		0x000003d4
+#define NV_CIO_CR__COLOR		0x000003d5
+
+#define NV_PBUS_DEBUG_1			0x00001084
+#define NV_PBUS_DEBUG_4			0x00001098
+#define NV_PBUS_DEBUG_DUALHEAD_CTL	0x000010f0
+#define NV_PBUS_POWERCTRL_1		0x00001584
+#define NV_PBUS_POWERCTRL_2		0x00001588
+#define NV_PBUS_POWERCTRL_4		0x00001590
+#define NV_PBUS_PCI_NV_19		0x0000184C
+#define NV_PBUS_PCI_NV_20		0x00001850
+#	define NV_PBUS_PCI_NV_20_ROM_SHADOW_DISABLED	(0 << 0)
+#	define NV_PBUS_PCI_NV_20_ROM_SHADOW_ENABLED	(1 << 0)
+
+#define NV_PFIFO_RAMHT			0x00002210
+
+#define NV_PRMVIO_MISC__WRITE		0x000c03c2
+#define NV_PRMVIO_SRX			0x000c03c4
+#define NV_PRMVIO_SR			0x000c03c5
+#	define NV_VIO_SR_RESET_INDEX		0x00
+#	define NV_VIO_SR_CLOCK_INDEX		0x01
+#	define NV_VIO_SR_PLANE_MASK_INDEX	0x02
+#	define NV_VIO_SR_CHAR_MAP_INDEX		0x03
+#	define NV_VIO_SR_MEM_MODE_INDEX		0x04
+#define NV_PRMVIO_MISC__READ		0x000c03cc
+#define NV_PRMVIO_GRX			0x000c03ce
+#define NV_PRMVIO_GX			0x000c03cf
+#	define NV_VIO_GX_SR_INDEX		0x00
+#	define NV_VIO_GX_SREN_INDEX		0x01
+#	define NV_VIO_GX_CCOMP_INDEX		0x02
+#	define NV_VIO_GX_ROP_INDEX		0x03
+#	define NV_VIO_GX_READ_MAP_INDEX		0x04
+#	define NV_VIO_GX_MODE_INDEX		0x05
+#	define NV_VIO_GX_MISC_INDEX		0x06
+#	define NV_VIO_GX_DONT_CARE_INDEX	0x07
+#	define NV_VIO_GX_BIT_MASK_INDEX		0x08
+
+#define NV_PFB_BOOT_0			0x00100000
+#define NV_PFB_CFG0			0x00100200
+#define NV_PFB_CFG1			0x00100204
+#define NV_PFB_CSTATUS			0x0010020C
+#define NV_PFB_REFCTRL			0x00100210
+#	define NV_PFB_REFCTRL_VALID_1			(1 << 31)
+#define NV_PFB_PAD			0x0010021C
+#	define NV_PFB_PAD_CKE_NORMAL			(1 << 0)
+#define NV_PFB_TILE_NV10		0x00100240
+#define NV_PFB_TILE_SIZE_NV10		0x00100244
+#define NV_PFB_REF			0x001002D0
+#	define NV_PFB_REF_CMD_REFRESH			(1 << 0)
+#define NV_PFB_PRE			0x001002D4
+#	define NV_PFB_PRE_CMD_PRECHARGE			(1 << 0)
+#define NV_PFB_CLOSE_PAGE2		0x0010033C
+#define NV_PFB_TILE_NV40		0x00100600
+#define NV_PFB_TILE_SIZE_NV40		0x00100604
+
+#define NV_PEXTDEV_BOOT_0		0x00101000
+#	define NV_PEXTDEV_BOOT_0_STRAP_FP_IFACE_12BIT	(8 << 12)
+#define NV_PEXTDEV_BOOT_3		0x0010100c
+
+#define NV_PCRTC_INTR_0					0x00600100
+#	define NV_PCRTC_INTR_0_VBLANK				(1 << 0)
+#define NV_PCRTC_INTR_EN_0				0x00600140
+#define NV_PCRTC_START					0x00600800
+#define NV_PCRTC_CONFIG					0x00600804
+#	define NV_PCRTC_CONFIG_START_ADDRESS_NON_VGA		(1 << 0)
+#	define NV_PCRTC_CONFIG_START_ADDRESS_HSYNC		(2 << 0)
+#define NV_PCRTC_CURSOR_CONFIG				0x00600810
+#	define NV_PCRTC_CURSOR_CONFIG_ENABLE_ENABLE		(1 << 0)
+#	define NV_PCRTC_CURSOR_CONFIG_DOUBLE_SCAN_ENABLE	(1 << 4)
+#	define NV_PCRTC_CURSOR_CONFIG_ADDRESS_SPACE_PNVM	(1 << 8)
+#	define NV_PCRTC_CURSOR_CONFIG_CUR_BPP_32		(1 << 12)
+#	define NV_PCRTC_CURSOR_CONFIG_CUR_PIXELS_64		(1 << 16)
+#	define NV_PCRTC_CURSOR_CONFIG_CUR_LINES_32		(2 << 24)
+#	define NV_PCRTC_CURSOR_CONFIG_CUR_LINES_64		(4 << 24)
+#	define NV_PCRTC_CURSOR_CONFIG_CUR_BLEND_ALPHA		(1 << 28)
+
+/* note: PCRTC_GPIO is not available on nv10, and in fact aliases 0x600810 */
+#define NV_PCRTC_GPIO					0x00600818
+#define NV_PCRTC_GPIO_EXT				0x0060081c
+#define NV_PCRTC_830					0x00600830
+#define NV_PCRTC_834					0x00600834
+#define NV_PCRTC_850					0x00600850
+#define NV_PCRTC_ENGINE_CTRL				0x00600860
+#	define NV_CRTC_FSEL_I2C					(1 << 4)
+#	define NV_CRTC_FSEL_OVERLAY				(1 << 12)
+
+#define NV_PRMCIO_ARX			0x006013c0
+#define NV_PRMCIO_AR__WRITE		0x006013c0
+#define NV_PRMCIO_AR__READ		0x006013c1
+#	define NV_CIO_AR_MODE_INDEX		0x10
+#	define NV_CIO_AR_OSCAN_INDEX		0x11
+#	define NV_CIO_AR_PLANE_INDEX		0x12
+#	define NV_CIO_AR_HPP_INDEX		0x13
+#	define NV_CIO_AR_CSEL_INDEX		0x14
+#define NV_PRMCIO_CRX__COLOR		0x006013d4
+#define NV_PRMCIO_CR__COLOR		0x006013d5
+	/* Standard VGA CRTC registers */
+#	define NV_CIO_CR_HDT_INDEX		0x00	/* horizontal display total */
+#	define NV_CIO_CR_HDE_INDEX		0x01	/* horizontal display end */
+#	define NV_CIO_CR_HBS_INDEX		0x02	/* horizontal blanking start */
+#	define NV_CIO_CR_HBE_INDEX		0x03	/* horizontal blanking end */
+#		define NV_CIO_CR_HBE_4_0		4:0
+#	define NV_CIO_CR_HRS_INDEX		0x04	/* horizontal retrace start */
+#	define NV_CIO_CR_HRE_INDEX		0x05	/* horizontal retrace end */
+#		define NV_CIO_CR_HRE_4_0		4:0
+#		define NV_CIO_CR_HRE_HBE_5		7:7
+#	define NV_CIO_CR_VDT_INDEX		0x06	/* vertical display total */
+#	define NV_CIO_CR_OVL_INDEX		0x07	/* overflow bits */
+#		define NV_CIO_CR_OVL_VDT_8		0:0
+#		define NV_CIO_CR_OVL_VDE_8		1:1
+#		define NV_CIO_CR_OVL_VRS_8		2:2
+#		define NV_CIO_CR_OVL_VBS_8		3:3
+#		define NV_CIO_CR_OVL_VDT_9		5:5
+#		define NV_CIO_CR_OVL_VDE_9		6:6
+#		define NV_CIO_CR_OVL_VRS_9		7:7
+#	define NV_CIO_CR_RSAL_INDEX		0x08	/* normally "preset row scan" */
+#	define NV_CIO_CR_CELL_HT_INDEX		0x09	/* cell height?! normally "max scan line" */
+#		define NV_CIO_CR_CELL_HT_VBS_9		5:5
+#		define NV_CIO_CR_CELL_HT_SCANDBL	7:7
+#	define NV_CIO_CR_CURS_ST_INDEX		0x0a	/* cursor start */
+#	define NV_CIO_CR_CURS_END_INDEX		0x0b	/* cursor end */
+#	define NV_CIO_CR_SA_HI_INDEX		0x0c	/* screen start address high */
+#	define NV_CIO_CR_SA_LO_INDEX		0x0d	/* screen start address low */
+#	define NV_CIO_CR_TCOFF_HI_INDEX		0x0e	/* cursor offset high */
+#	define NV_CIO_CR_TCOFF_LO_INDEX		0x0f	/* cursor offset low */
+#	define NV_CIO_CR_VRS_INDEX		0x10	/* vertical retrace start */
+#	define NV_CIO_CR_VRE_INDEX		0x11	/* vertical retrace end */
+#		define NV_CIO_CR_VRE_3_0		3:0
+#	define NV_CIO_CR_VDE_INDEX		0x12	/* vertical display end */
+#	define NV_CIO_CR_OFFSET_INDEX		0x13	/* sets screen pitch */
+#	define NV_CIO_CR_ULINE_INDEX		0x14	/* underline location */
+#	define NV_CIO_CR_VBS_INDEX		0x15	/* vertical blank start */
+#	define NV_CIO_CR_VBE_INDEX		0x16	/* vertical blank end */
+#	define NV_CIO_CR_MODE_INDEX		0x17	/* crtc mode control */
+#	define NV_CIO_CR_LCOMP_INDEX		0x18	/* line compare */
+	/* Extended VGA CRTC registers */
+#	define NV_CIO_CRE_RPC0_INDEX		0x19	/* repaint control 0 */
+#		define NV_CIO_CRE_RPC0_OFFSET_10_8	7:5
+#	define NV_CIO_CRE_RPC1_INDEX		0x1a	/* repaint control 1 */
+#		define NV_CIO_CRE_RPC1_LARGE		2:2
+#	define NV_CIO_CRE_FF_INDEX		0x1b	/* fifo control */
+#	define NV_CIO_CRE_ENH_INDEX		0x1c	/* enhanced? */
+#	define NV_CIO_SR_LOCK_INDEX		0x1f	/* crtc lock */
+#		define NV_CIO_SR_UNLOCK_RW_VALUE	0x57
+#		define NV_CIO_SR_LOCK_VALUE		0x99
+#	define NV_CIO_CRE_FFLWM__INDEX		0x20	/* fifo low water mark */
+#	define NV_CIO_CRE_21			0x21	/* vga shadow crtc lock */
+#	define NV_CIO_CRE_LSR_INDEX		0x25	/* ? */
+#		define NV_CIO_CRE_LSR_VDT_10		0:0
+#		define NV_CIO_CRE_LSR_VDE_10		1:1
+#		define NV_CIO_CRE_LSR_VRS_10		2:2
+#		define NV_CIO_CRE_LSR_VBS_10		3:3
+#		define NV_CIO_CRE_LSR_HBE_6		4:4
+#	define NV_CIO_CR_ARX_INDEX		0x26	/* attribute index -- ro copy of 0x60.3c0 */
+#	define NV_CIO_CRE_CHIP_ID_INDEX		0x27	/* chip revision */
+#	define NV_CIO_CRE_PIXEL_INDEX		0x28
+#	define NV_CIO_CRE_HEB__INDEX		0x2d	/* horizontal extra bits? */
+#		define NV_CIO_CRE_HEB_HDT_8		0:0
+#		define NV_CIO_CRE_HEB_HDE_8		1:1
+#		define NV_CIO_CRE_HEB_HBS_8		2:2
+#		define NV_CIO_CRE_HEB_HRS_8		3:3
+#		define NV_CIO_CRE_HEB_ILC_8		4:4
+#	define NV_CIO_CRE_2E			0x2e	/* some scratch or dummy reg to force writes to sink in */
+#	define NV_CIO_CRE_HCUR_ADDR2_INDEX	0x2f	/* cursor */
+#	define NV_CIO_CRE_HCUR_ADDR0_INDEX	0x30		/* pixmap */
+#		define NV_CIO_CRE_HCUR_ADDR0_ADR	6:0
+#		define NV_CIO_CRE_HCUR_ASI		7:7
+#	define NV_CIO_CRE_HCUR_ADDR1_INDEX	0x31			/* address */
+#		define NV_CIO_CRE_HCUR_ADDR1_ENABLE	0:0
+#		define NV_CIO_CRE_HCUR_ADDR1_CUR_DBL	1:1
+#		define NV_CIO_CRE_HCUR_ADDR1_ADR	7:2
+#	define NV_CIO_CRE_LCD__INDEX		0x33
+#		define NV_CIO_CRE_LCD_LCD_SELECT	0:0
+#	define NV_CIO_CRE_DDC0_STATUS__INDEX	0x36
+#	define NV_CIO_CRE_DDC0_WR__INDEX	0x37
+#	define NV_CIO_CRE_ILACE__INDEX		0x39	/* interlace */
+#	define NV_CIO_CRE_SCRATCH3__INDEX	0x3b
+#	define NV_CIO_CRE_SCRATCH4__INDEX	0x3c
+#	define NV_CIO_CRE_DDC_STATUS__INDEX	0x3e
+#	define NV_CIO_CRE_DDC_WR__INDEX		0x3f
+#	define NV_CIO_CRE_EBR_INDEX		0x41	/* extra bits ? (vertical) */
+#		define NV_CIO_CRE_EBR_VDT_11		0:0
+#		define NV_CIO_CRE_EBR_VDE_11		2:2
+#		define NV_CIO_CRE_EBR_VRS_11		4:4
+#		define NV_CIO_CRE_EBR_VBS_11		6:6
+#	define NV_CIO_CRE_44			0x44	/* head control */
+#	define NV_CIO_CRE_CSB			0x45	/* colour saturation boost */
+#	define NV_CIO_CRE_RCR			0x46
+#		define NV_CIO_CRE_RCR_ENDIAN_BIG	7:7
+#	define NV_CIO_CRE_47			0x47	/* extended fifo lwm, used on nv30+ */
+#	define NV_CIO_CRE_4B			0x4b	/* given patterns in 0x[2-3][a-c] regs, probably scratch 6 */
+#	define NV_CIO_CRE_TVOUT_LATENCY		0x52
+#	define NV_CIO_CRE_53			0x53	/* `fp_htiming' according to Haiku */
+#	define NV_CIO_CRE_54			0x54	/* `fp_vtiming' according to Haiku */
+#	define NV_CIO_CRE_57			0x57	/* index reg for cr58 */
+#	define NV_CIO_CRE_58			0x58	/* data reg for cr57 */
+#	define NV_CIO_CRE_59			0x59	/* related to on/off-chip-ness of digital outputs */
+#	define NV_CIO_CRE_5B			0x5B	/* newer colour saturation reg */
+#	define NV_CIO_CRE_85			0x85
+#	define NV_CIO_CRE_86			0x86
+#define NV_PRMCIO_INP0__COLOR		0x006013da
+
+#define NV_PRAMDAC_CU_START_POS				0x00680300
+#	define NV_PRAMDAC_CU_START_POS_X			15:0
+#	define NV_PRAMDAC_CU_START_POS_Y			31:16
+#define NV_RAMDAC_NV10_CURSYNC				0x00680404
+
+#define NV_PRAMDAC_NVPLL_COEFF				0x00680500
+#define NV_PRAMDAC_MPLL_COEFF				0x00680504
+#define NV_PRAMDAC_VPLL_COEFF				0x00680508
+#	define NV30_RAMDAC_ENABLE_VCO2				(8 << 4)
+
+#define NV_PRAMDAC_PLL_COEFF_SELECT			0x0068050c
+#	define NV_RAMDAC_PLL_SELECT_USE_VPLL2_TRUE		(4 << 0)
+#	define NV_PRAMDAC_PLL_COEFF_SELECT_SOURCE_PROG_MPLL	(1 << 8)
+#	define NV_PRAMDAC_PLL_COEFF_SELECT_SOURCE_PROG_VPLL	(2 << 8)
+#	define NV_PRAMDAC_PLL_COEFF_SELECT_SOURCE_PROG_NVPLL	(4 << 8)
+#	define NV_RAMDAC_PLL_SELECT_PLL_SOURCE_VPLL2		(8 << 8)
+#	define NV_PRAMDAC_PLL_COEFF_SELECT_VCLK_RATIO_DB2	(1 << 28)
+#	define NV_RAMDAC_PLL_SELECT_VCLK2_RATIO_DB2		(2 << 28)
+
+#define NV_PRAMDAC_PLL_SETUP_CONTROL			0x00680510
+#define NV_RAMDAC_VPLL2					0x00680520
+#define NV_PRAMDAC_SEL_CLK				0x00680524
+#define NV_RAMDAC_DITHER_NV11				0x00680528
+#define NV_PRAMDAC_DACCLK				0x0068052c
+#	define NV_PRAMDAC_DACCLK_SEL_DACCLK			(1 << 0)
+
+#define NV_RAMDAC_NVPLL_B				0x00680570
+#define NV_RAMDAC_MPLL_B				0x00680574
+#define NV_RAMDAC_VPLL_B				0x00680578
+#define NV_RAMDAC_VPLL2_B				0x0068057c
+#	define NV31_RAMDAC_ENABLE_VCO2				(8 << 28)
+#define NV_PRAMDAC_580					0x00680580
+#	define NV_RAMDAC_580_VPLL1_ACTIVE			(1 << 8)
+#	define NV_RAMDAC_580_VPLL2_ACTIVE			(1 << 28)
+
+#define NV_PRAMDAC_GENERAL_CONTROL			0x00680600
+#define NV_PRAMDAC_TEST_CONTROL				0x00680608
+#	define NV_PRAMDAC_TEST_CONTROL_TP_INS_EN_ASSERTED	(1 << 12)
+#	define NV_PRAMDAC_TEST_CONTROL_PWRDWN_DAC_OFF		(1 << 16)
+#	define NV_PRAMDAC_TEST_CONTROL_SENSEB_ALLHI		(1 << 28)
+#define NV_PRAMDAC_TESTPOINT_DATA			0x00680610
+#	define NV_PRAMDAC_TESTPOINT_DATA_NOTBLANK		(8 << 28)
+#define NV_PRAMDAC_630					0x00680630
+#define NV_PRAMDAC_634					0x00680634
+
+#define NV_PRAMDAC_FP_VDISPLAY_END			0x00680800
+#define NV_PRAMDAC_FP_VTOTAL				0x00680804
+#define NV_PRAMDAC_FP_VCRTC				0x00680808
+#define NV_PRAMDAC_FP_VSYNC_START			0x0068080c
+#define NV_PRAMDAC_FP_VSYNC_END				0x00680810
+#define NV_PRAMDAC_FP_VVALID_START			0x00680814
+#define NV_PRAMDAC_FP_VVALID_END			0x00680818
+#define NV_PRAMDAC_FP_HDISPLAY_END			0x00680820
+#define NV_PRAMDAC_FP_HTOTAL				0x00680824
+#define NV_PRAMDAC_FP_HCRTC				0x00680828
+#define NV_PRAMDAC_FP_HSYNC_START			0x0068082c
+#define NV_PRAMDAC_FP_HSYNC_END				0x00680830
+#define NV_PRAMDAC_FP_HVALID_START			0x00680834
+#define NV_PRAMDAC_FP_HVALID_END			0x00680838
+
+#define NV_RAMDAC_FP_DITHER				0x0068083c
+#define NV_PRAMDAC_FP_TG_CONTROL			0x00680848
+#	define NV_PRAMDAC_FP_TG_CONTROL_VSYNC_POS		(1 << 0)
+#	define NV_PRAMDAC_FP_TG_CONTROL_VSYNC_DISABLE		(2 << 0)
+#	define NV_PRAMDAC_FP_TG_CONTROL_HSYNC_POS		(1 << 4)
+#	define NV_PRAMDAC_FP_TG_CONTROL_HSYNC_DISABLE		(2 << 4)
+#	define NV_PRAMDAC_FP_TG_CONTROL_MODE_SCALE		(0 << 8)
+#	define NV_PRAMDAC_FP_TG_CONTROL_MODE_CENTER		(1 << 8)
+#	define NV_PRAMDAC_FP_TG_CONTROL_MODE_NATIVE		(2 << 8)
+#	define NV_PRAMDAC_FP_TG_CONTROL_READ_PROG		(1 << 20)
+#	define NV_PRAMDAC_FP_TG_CONTROL_WIDTH_12		(1 << 24)
+#	define NV_PRAMDAC_FP_TG_CONTROL_DISPEN_POS		(1 << 28)
+#	define NV_PRAMDAC_FP_TG_CONTROL_DISPEN_DISABLE		(2 << 28)
+#define NV_PRAMDAC_850					0x00680850
+#define NV_PRAMDAC_85C					0x0068085c
+#define NV_PRAMDAC_FP_DEBUG_0				0x00680880
+#	define NV_PRAMDAC_FP_DEBUG_0_XSCALE_ENABLE		(1 << 0)
+#	define NV_PRAMDAC_FP_DEBUG_0_YSCALE_ENABLE		(1 << 4)
+/* This doesn't seem to be essential for tmds, but still often set */
+#	define NV_RAMDAC_FP_DEBUG_0_TMDS_ENABLED		(8 << 4)
+#	define NV_PRAMDAC_FP_DEBUG_0_XINTERP_BILINEAR		(1 << 8)
+#	define NV_PRAMDAC_FP_DEBUG_0_YINTERP_BILINEAR		(1 << 12)
+#	define NV_PRAMDAC_FP_DEBUG_0_XWEIGHT_ROUND		(1 << 20)
+#	define NV_PRAMDAC_FP_DEBUG_0_YWEIGHT_ROUND		(1 << 24)
+#       define NV_PRAMDAC_FP_DEBUG_0_PWRDOWN_FPCLK              (1 << 28)
+#define NV_PRAMDAC_FP_DEBUG_1				0x00680884
+#	define NV_PRAMDAC_FP_DEBUG_1_XSCALE_VALUE		11:0
+#	define NV_PRAMDAC_FP_DEBUG_1_XSCALE_TESTMODE_ENABLE	(1 << 12)
+#	define NV_PRAMDAC_FP_DEBUG_1_YSCALE_VALUE		27:16
+#	define NV_PRAMDAC_FP_DEBUG_1_YSCALE_TESTMODE_ENABLE	(1 << 28)
+#define NV_PRAMDAC_FP_DEBUG_2				0x00680888
+#define NV_PRAMDAC_FP_DEBUG_3				0x0068088C
+
+/* see NV_PRAMDAC_INDIR_TMDS in rules.xml */
+#define NV_PRAMDAC_FP_TMDS_CONTROL			0x006808b0
+#	define NV_PRAMDAC_FP_TMDS_CONTROL_WRITE_DISABLE		(1 << 16)
+#define NV_PRAMDAC_FP_TMDS_DATA				0x006808b4
+
+/* Some kind of switch */
+#define NV_PRAMDAC_900					0x00680900
+#define NV_PRAMDAC_A20					0x00680A20
+#define NV_PRAMDAC_A24					0x00680A24
+#define NV_PRAMDAC_A34					0x00680A34
+
+/* names fabricated from NV_USER_DAC info */
+#define NV_PRMDIO_PIXEL_MASK		0x006813c6
+#	define NV_PRMDIO_PIXEL_MASK_MASK	0xff
+#define NV_PRMDIO_READ_MODE_ADDRESS	0x006813c7
+#define NV_PRMDIO_WRITE_MODE_ADDRESS	0x006813c8
+#define NV_PRMDIO_PALETTE_DATA		0x006813c9
+
+#define NV_PGRAPH_DEBUG_0		0x00400080
+#define NV_PGRAPH_DEBUG_1		0x00400084
+#define NV_PGRAPH_DEBUG_2_NV04		0x00400088
+#define NV_PGRAPH_DEBUG_2		0x00400620
+#define NV_PGRAPH_DEBUG_3		0x0040008c
+#define NV_PGRAPH_DEBUG_4		0x00400090
+#define NV_PGRAPH_INTR			0x00400100
+#define NV_PGRAPH_INTR_EN		0x00400140
+#define NV_PGRAPH_CTX_CONTROL		0x00400144
+#define NV_PGRAPH_CTX_CONTROL_NV04	0x00400170
+#define NV_PGRAPH_ABS_UCLIP_XMIN	0x0040053C
+#define NV_PGRAPH_ABS_UCLIP_YMIN	0x00400540
+#define NV_PGRAPH_ABS_UCLIP_XMAX	0x00400544
+#define NV_PGRAPH_ABS_UCLIP_YMAX	0x00400548
+#define NV_PGRAPH_BETA_AND		0x00400608
+#define NV_PGRAPH_LIMIT_VIOL_PIX	0x00400610
+#define NV_PGRAPH_BOFFSET0		0x00400640
+#define NV_PGRAPH_BOFFSET1		0x00400644
+#define NV_PGRAPH_BOFFSET2		0x00400648
+#define NV_PGRAPH_BLIMIT0		0x00400684
+#define NV_PGRAPH_BLIMIT1		0x00400688
+#define NV_PGRAPH_BLIMIT2		0x0040068c
+#define NV_PGRAPH_STATUS		0x00400700
+#define NV_PGRAPH_SURFACE		0x00400710
+#define NV_PGRAPH_STATE			0x00400714
+#define NV_PGRAPH_FIFO			0x00400720
+#define NV_PGRAPH_PATTERN_SHAPE		0x00400810
+#define NV_PGRAPH_TILE			0x00400b00
+
+#define NV_PVIDEO_INTR_EN		0x00008140
+#define NV_PVIDEO_BUFFER		0x00008700
+#define NV_PVIDEO_STOP			0x00008704
+#define NV_PVIDEO_UVPLANE_BASE(buff)	(0x00008800+(buff)*4)
+#define NV_PVIDEO_UVPLANE_LIMIT(buff)	(0x00008808+(buff)*4)
+#define NV_PVIDEO_UVPLANE_OFFSET_BUFF(buff)	(0x00008820+(buff)*4)
+#define NV_PVIDEO_BASE(buff)		(0x00008900+(buff)*4)
+#define NV_PVIDEO_LIMIT(buff)		(0x00008908+(buff)*4)
+#define NV_PVIDEO_LUMINANCE(buff)	(0x00008910+(buff)*4)
+#define NV_PVIDEO_CHROMINANCE(buff)	(0x00008918+(buff)*4)
+#define NV_PVIDEO_OFFSET_BUFF(buff)	(0x00008920+(buff)*4)
+#define NV_PVIDEO_SIZE_IN(buff)		(0x00008928+(buff)*4)
+#define NV_PVIDEO_POINT_IN(buff)	(0x00008930+(buff)*4)
+#define NV_PVIDEO_DS_DX(buff)		(0x00008938+(buff)*4)
+#define NV_PVIDEO_DT_DY(buff)		(0x00008940+(buff)*4)
+#define NV_PVIDEO_POINT_OUT(buff)	(0x00008948+(buff)*4)
+#define NV_PVIDEO_SIZE_OUT(buff)	(0x00008950+(buff)*4)
+#define NV_PVIDEO_FORMAT(buff)		(0x00008958+(buff)*4)
+#	define NV_PVIDEO_FORMAT_PLANAR			(1 << 0)
+#	define NV_PVIDEO_FORMAT_COLOR_LE_CR8YB8CB8YA8	(1 << 16)
+#	define NV_PVIDEO_FORMAT_DISPLAY_COLOR_KEY	(1 << 20)
+#	define NV_PVIDEO_FORMAT_MATRIX_ITURBT709	(1 << 24)
+#define NV_PVIDEO_COLOR_KEY		0x00008B00
+
+/* NV04 overlay defines from VIDIX & Haiku */
+#define NV_PVIDEO_INTR_EN_0		0x00680140
+#define NV_PVIDEO_STEP_SIZE		0x00680200
+#define NV_PVIDEO_CONTROL_Y		0x00680204
+#define NV_PVIDEO_CONTROL_X		0x00680208
+#define NV_PVIDEO_BUFF0_START_ADDRESS	0x0068020c
+#define NV_PVIDEO_BUFF0_PITCH_LENGTH	0x00680214
+#define NV_PVIDEO_BUFF0_OFFSET		0x0068021c
+#define NV_PVIDEO_BUFF1_START_ADDRESS	0x00680210
+#define NV_PVIDEO_BUFF1_PITCH_LENGTH	0x00680218
+#define NV_PVIDEO_BUFF1_OFFSET		0x00680220
+#define NV_PVIDEO_OE_STATE		0x00680224
+#define NV_PVIDEO_SU_STATE		0x00680228
+#define NV_PVIDEO_RM_STATE		0x0068022c
+#define NV_PVIDEO_WINDOW_START		0x00680230
+#define NV_PVIDEO_WINDOW_SIZE		0x00680234
+#define NV_PVIDEO_FIFO_THRES_SIZE	0x00680238
+#define NV_PVIDEO_FIFO_BURST_LENGTH	0x0068023c
+#define NV_PVIDEO_KEY			0x00680240
+#define NV_PVIDEO_OVERLAY		0x00680244
+#define NV_PVIDEO_RED_CSC_OFFSET	0x00680280
+#define NV_PVIDEO_GREEN_CSC_OFFSET	0x00680284
+#define NV_PVIDEO_BLUE_CSC_OFFSET	0x00680288
+#define NV_PVIDEO_CSC_ADJUST		0x0068028c
+
+#endif
diff --git a/include/drm/Kbuild b/include/drm/Kbuild
index b940fdf..cfa6af4 100644
--- a/include/drm/Kbuild
+++ b/include/drm/Kbuild
@@ -8,3 +8,4 @@ unifdef-y += radeon_drm.h
 unifdef-y += sis_drm.h
 unifdef-y += savage_drm.h
 unifdef-y += via_drm.h
+unifdef-y += nouveau_drm.h
diff --git a/include/drm/drmP.h b/include/drm/drmP.h
index 04fbd1e..f2a6bff 100644
--- a/include/drm/drmP.h
+++ b/include/drm/drmP.h
@@ -1267,6 +1267,8 @@ extern void drm_idlelock_release(struct drm_lock_data *lock_data);
 extern int drm_i_have_hw_lock(struct drm_device *dev, struct drm_file *file_priv);
 
 				/* Buffer management support (drm_bufs.h) */
+extern struct drm_map_list *drm_find_matching_map(struct drm_device *dev,
+						  drm_local_map_t *map);
 extern int drm_addbufs_agp(struct drm_device *dev, struct drm_buf_desc * request);
 extern int drm_addbufs_pci(struct drm_device *dev, struct drm_buf_desc * request);
 extern int drm_addmap(struct drm_device *dev, resource_size_t offset,
diff --git a/include/drm/nouveau_drm.h b/include/drm/nouveau_drm.h
new file mode 100644
index 0000000..4147f35
--- /dev/null
+++ b/include/drm/nouveau_drm.h
@@ -0,0 +1,299 @@
+/*
+ * Copyright 2005 Stephane Marchesin.
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __NOUVEAU_DRM_H__
+#define __NOUVEAU_DRM_H__
+
+#define NOUVEAU_DRM_HEADER_PATCHLEVEL 12
+
+struct drm_nouveau_channel_alloc {
+	uint32_t     fb_ctxdma_handle;
+	uint32_t     tt_ctxdma_handle;
+
+	int          channel;
+
+	/* Notifier memory */
+	drm_handle_t notifier;
+	int          notifier_size;
+
+	/* DRM-enforced subchannel assignments */
+	struct {
+		uint32_t handle;
+		uint32_t grclass;
+	} subchan[8];
+	uint32_t nr_subchan;
+
+/* !MM_ENABLED ONLY */
+	uint32_t     put_base;
+	/* FIFO control regs */
+	drm_handle_t ctrl;
+	int          ctrl_size;
+	/* DMA command buffer */
+	drm_handle_t cmdbuf;
+	int          cmdbuf_size;
+};
+
+struct drm_nouveau_channel_free {
+	int channel;
+};
+
+struct drm_nouveau_grobj_alloc {
+	int      channel;
+	uint32_t handle;
+	int      class;
+};
+
+#define NOUVEAU_MEM_ACCESS_RO	1
+#define NOUVEAU_MEM_ACCESS_WO	2
+#define NOUVEAU_MEM_ACCESS_RW	3
+struct drm_nouveau_notifierobj_alloc {
+	int      channel;
+	uint32_t handle;
+	int      count;
+
+	uint32_t offset;
+};
+
+struct drm_nouveau_gpuobj_free {
+	int      channel;
+	uint32_t handle;
+};
+
+/* This is needed to avoid a race condition.
+ * Otherwise you may be writing in the fetch area.
+ * Is this large enough, as it's only 32 bytes, and the maximum fetch size is 256 bytes?
+ */
+#define NOUVEAU_DMA_SKIPS 8
+
+#define NOUVEAU_MEM_FB			0x00000001
+#define NOUVEAU_MEM_AGP			0x00000002
+#define NOUVEAU_MEM_FB_ACCEPTABLE	0x00000004
+#define NOUVEAU_MEM_AGP_ACCEPTABLE	0x00000008
+#define NOUVEAU_MEM_PCI			0x00000010
+#define NOUVEAU_MEM_PCI_ACCEPTABLE	0x00000020
+#define NOUVEAU_MEM_PINNED		0x00000040
+#define NOUVEAU_MEM_USER_BACKED		0x00000080
+#define NOUVEAU_MEM_MAPPED		0x00000100
+#define NOUVEAU_MEM_TILE		0x00000200
+#define NOUVEAU_MEM_TILE_ZETA		0x00000400
+#define NOUVEAU_MEM_INSTANCE		0x01000000 /* internal */
+#define NOUVEAU_MEM_NOTIFIER            0x02000000 /* internal */
+#define NOUVEAU_MEM_NOVM		0x04000000 /* internal */
+#define NOUVEAU_MEM_USER		0x08000000 /* internal */
+#define NOUVEAU_MEM_INTERNAL (NOUVEAU_MEM_INSTANCE | \
+			      NOUVEAU_MEM_NOTIFIER | \
+			      NOUVEAU_MEM_NOVM | \
+			      NOUVEAU_MEM_USER)
+
+struct drm_nouveau_mem_alloc {
+	int flags;
+	int alignment;
+	uint64_t size;	// in bytes
+	uint64_t offset;
+	drm_handle_t map_handle;
+};
+
+struct drm_nouveau_mem_free {
+	uint64_t offset;
+	int flags;
+};
+
+struct drm_nouveau_mem_tile {
+	uint64_t offset;
+	uint64_t delta;
+	uint64_t size;
+	int flags;
+};
+
+/* FIXME : maybe unify {GET,SET}PARAMs */
+#define NOUVEAU_GETPARAM_PCI_VENDOR      3
+#define NOUVEAU_GETPARAM_PCI_DEVICE      4
+#define NOUVEAU_GETPARAM_BUS_TYPE        5
+#define NOUVEAU_GETPARAM_FB_PHYSICAL     6
+#define NOUVEAU_GETPARAM_AGP_PHYSICAL    7
+#define NOUVEAU_GETPARAM_FB_SIZE         8
+#define NOUVEAU_GETPARAM_AGP_SIZE        9
+#define NOUVEAU_GETPARAM_PCI_PHYSICAL    10
+#define NOUVEAU_GETPARAM_CHIPSET_ID      11
+#define NOUVEAU_GETPARAM_MM_ENABLED      12
+#define NOUVEAU_GETPARAM_VM_VRAM_BASE    13
+struct drm_nouveau_getparam {
+	uint64_t param;
+	uint64_t value;
+};
+
+#define NOUVEAU_SETPARAM_CMDBUF_LOCATION 1
+#define NOUVEAU_SETPARAM_CMDBUF_SIZE     2
+struct drm_nouveau_setparam {
+	uint64_t param;
+	uint64_t value;
+};
+
+#define NOUVEAU_GEM_DOMAIN_CPU       (1 << 0)
+#define NOUVEAU_GEM_DOMAIN_VRAM      (1 << 1)
+#define NOUVEAU_GEM_DOMAIN_GART      (1 << 2)
+#define NOUVEAU_GEM_DOMAIN_NOMAP     (1 << 3)
+#define NOUVEAU_GEM_DOMAIN_TILE      (1 << 30)
+#define NOUVEAU_GEM_DOMAIN_TILE_ZETA (1 << 31)
+
+struct drm_nouveau_gem_new {
+	uint64_t size;
+	uint32_t channel_hint;
+	uint32_t align;
+	uint32_t handle;
+	uint32_t domain;
+	uint32_t offset;
+};
+
+struct drm_nouveau_gem_pushbuf_bo {
+	uint64_t user_priv;
+	uint32_t handle;
+	uint32_t read_domains;
+	uint32_t write_domains;
+	uint32_t valid_domains;
+	uint32_t presumed_ok;
+	uint32_t presumed_domain;
+	uint64_t presumed_offset;
+};
+
+#define NOUVEAU_GEM_RELOC_LOW  (1 << 0)
+#define NOUVEAU_GEM_RELOC_HIGH (1 << 1)
+#define NOUVEAU_GEM_RELOC_OR   (1 << 2)
+struct drm_nouveau_gem_pushbuf_reloc {
+	uint32_t bo_index;
+	uint32_t reloc_index;
+	uint32_t flags;
+	uint32_t data;
+	uint32_t vor;
+	uint32_t tor;
+};
+
+#define NOUVEAU_GEM_MAX_BUFFERS 1024
+#define NOUVEAU_GEM_MAX_RELOCS 1024
+
+struct drm_nouveau_gem_pushbuf {
+	uint32_t channel;
+	uint32_t nr_dwords;
+	uint32_t nr_buffers;
+	uint32_t nr_relocs;
+	uint64_t dwords;
+	uint64_t buffers;
+	uint64_t relocs;
+};
+
+struct drm_nouveau_gem_pushbuf_call {
+	uint32_t channel;
+	uint32_t handle;
+	uint32_t offset;
+	uint32_t nr_buffers;
+	uint32_t nr_relocs;
+	uint32_t pad0;
+	uint64_t buffers;
+	uint64_t relocs;
+};
+
+struct drm_nouveau_gem_pin {
+	uint32_t handle;
+	uint32_t domain;
+	uint64_t offset;
+};
+
+struct drm_nouveau_gem_unpin {
+	uint32_t handle;
+};
+
+struct drm_nouveau_gem_mmap {
+	uint32_t handle;
+	uint32_t pad;
+	uint64_t vaddr;
+};
+
+struct drm_nouveau_gem_cpu_prep {
+	uint32_t handle;
+};
+
+struct drm_nouveau_gem_cpu_fini {
+	uint32_t handle;
+};
+
+struct drm_nouveau_gem_tile {
+	uint32_t handle;
+	uint32_t delta;
+	uint32_t size;
+	uint32_t flags;
+};
+
+enum nouveau_card_type {
+	NV_UNKNOWN =0,
+	NV_04      =4,
+	NV_05      =5,
+	NV_10      =10,
+	NV_11      =11,
+	NV_17      =17,
+	NV_20      =20,
+	NV_30      =30,
+	NV_40      =40,
+	NV_44      =44,
+	NV_50      =50,
+	NV_LAST    =0xffff,
+};
+
+enum nouveau_bus_type {
+	NV_AGP     =0,
+	NV_PCI     =1,
+	NV_PCIE    =2,
+};
+
+#define NOUVEAU_MAX_SAREA_CLIPRECTS 16
+
+struct drm_nouveau_sarea {
+	/* the cliprects */
+	struct drm_clip_rect boxes[NOUVEAU_MAX_SAREA_CLIPRECTS];
+	unsigned int nbox;
+};
+
+#define DRM_NOUVEAU_CARD_INIT          0x00
+#define DRM_NOUVEAU_GETPARAM           0x01
+#define DRM_NOUVEAU_SETPARAM           0x02
+#define DRM_NOUVEAU_CHANNEL_ALLOC      0x03
+#define DRM_NOUVEAU_CHANNEL_FREE       0x04
+#define DRM_NOUVEAU_GROBJ_ALLOC        0x05
+#define DRM_NOUVEAU_NOTIFIEROBJ_ALLOC  0x06
+#define DRM_NOUVEAU_GPUOBJ_FREE        0x07
+#define DRM_NOUVEAU_MEM_ALLOC          0x08
+#define DRM_NOUVEAU_MEM_FREE           0x09
+#define DRM_NOUVEAU_MEM_TILE           0x0a
+#define DRM_NOUVEAU_SUSPEND            0x0b
+#define DRM_NOUVEAU_RESUME             0x0c
+#define DRM_NOUVEAU_GEM_NEW            0x40
+#define DRM_NOUVEAU_GEM_PUSHBUF        0x41
+#define DRM_NOUVEAU_GEM_PUSHBUF_CALL   0x42
+#define DRM_NOUVEAU_GEM_PIN            0x43
+#define DRM_NOUVEAU_GEM_UNPIN          0x44
+#define DRM_NOUVEAU_GEM_MMAP           0x45
+#define DRM_NOUVEAU_GEM_CPU_PREP       0x46
+#define DRM_NOUVEAU_GEM_CPU_FINI       0x47
+#define DRM_NOUVEAU_GEM_TILE           0x48
+
+#endif /* __NOUVEAU_DRM_H__ */
